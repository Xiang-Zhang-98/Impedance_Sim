2023-08-05 00:21:36.250170 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 0 finished
---------------------------------------  --------------
epoch                                       0
replay_buffer/size                       2000
trainer/QF Loss                             0.0106392
trainer/Policy Loss                         2.13939e-05
trainer/Raw Policy Loss                     2.13939e-05
trainer/Preactivation Policy Loss           0
trainer/Q Predictions Mean                 -0.000189623
trainer/Q Predictions Std                   0.000231493
trainer/Q Predictions Max                   0.000382626
trainer/Q Predictions Min                  -0.00111505
trainer/Q Targets Mean                      0.0238559
trainer/Q Targets Std                       0.100315
trainer/Q Targets Max                       1.32851
trainer/Q Targets Min                      -0.000305842
trainer/Bellman Errors Mean                 0.0106392
trainer/Bellman Errors Std                  0.0876356
trainer/Bellman Errors Max                  1.76586
trainer/Bellman Errors Min                  1.90042e-14
trainer/Policy Action Mean                  1.80012e-06
trainer/Policy Action Std                   3.16137e-05
trainer/Policy Action Max                   0.00060864
trainer/Policy Action Min                  -0.000461609
expl/num steps total                     2000
expl/num paths total                       50
expl/path length Mean                      40
expl/path length Std                        0
expl/path length Max                       40
expl/path length Min                       40
expl/Rewards Mean                           0.0235745
expl/Rewards Std                            0.102171
expl/Rewards Max                            1.36111
expl/Rewards Min                            0
expl/Returns Mean                           0.942979
expl/Returns Std                            2.81817
expl/Returns Max                           18.7297
expl/Returns Min                            0
expl/Actions Mean                          -0.0175578
expl/Actions Std                            0.507458
expl/Actions Max                            1
expl/Actions Min                           -1
expl/Num Paths                             50
expl/Average Returns                        0.942979
expl/env_infos/final/reward_dist Mean       0.0272223
expl/env_infos/final/reward_dist Std        0.190556
expl/env_infos/final/reward_dist Max        1.36111
expl/env_infos/final/reward_dist Min        0
expl/env_infos/initial/reward_dist Mean     0.000284116
expl/env_infos/initial/reward_dist Std      0.00105991
expl/env_infos/initial/reward_dist Max      0.00552457
expl/env_infos/initial/reward_dist Min      0
expl/env_infos/reward_dist Mean             0.0235745
expl/env_infos/reward_dist Std              0.102171
expl/env_infos/reward_dist Max              1.36111
expl/env_infos/reward_dist Min              0
eval/num steps total                      400
eval/num paths total                       10
eval/path length Mean                      40
eval/path length Std                        0
eval/path length Max                       40
eval/path length Min                       40
eval/Rewards Mean                           0.0104047
eval/Rewards Std                            0.0310723
eval/Rewards Max                            0.191575
eval/Rewards Min                            0
eval/Returns Mean                           0.416189
eval/Returns Std                            0.478634
eval/Returns Max                            1.57124
eval/Returns Min                            0.00161683
eval/Actions Mean                           2.77183e-06
eval/Actions Std                            2.72438e-05
eval/Actions Max                            0.000103615
eval/Actions Min                           -7.15226e-05
eval/Num Paths                             10
eval/Average Returns                        0.416189
eval/env_infos/final/reward_dist Mean       0
eval/env_infos/final/reward_dist Std        0
eval/env_infos/final/reward_dist Max        0
eval/env_infos/final/reward_dist Min        0
eval/env_infos/initial/reward_dist Mean     0
eval/env_infos/initial/reward_dist Std      0
eval/env_infos/initial/reward_dist Max      0
eval/env_infos/initial/reward_dist Min      0
eval/env_infos/reward_dist Mean             0.0104047
eval/env_infos/reward_dist Std              0.0310723
eval/env_infos/reward_dist Max              0.191575
eval/env_infos/reward_dist Min              0
time/data storing (s)                       0.00589711
time/evaluation sampling (s)                3.45859
time/exploration sampling (s)              17.2773
time/logging (s)                            0.00790663
time/saving (s)                             0.00134073
time/training (s)                           4.23752
time/epoch (s)                             24.9886
time/total (s)                             28.2041
Epoch                                       0
---------------------------------------  --------------
2023-08-05 00:22:01.506729 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 1 finished
---------------------------------------  --------------
epoch                                       1
replay_buffer/size                       4000
trainer/QF Loss                             0.314936
trainer/Policy Loss                        -0.361966
trainer/Raw Policy Loss                    -0.361966
trainer/Preactivation Policy Loss           0
trainer/Q Predictions Mean                  0.276223
trainer/Q Predictions Std                   0.0773637
trainer/Q Predictions Max                   1.56009
trainer/Q Predictions Min                   0.119239
trainer/Q Targets Mean                      0.520647
trainer/Q Targets Std                       0.520985
trainer/Q Targets Max                       1.8241
trainer/Q Targets Min                       0.242374
trainer/Bellman Errors Mean                 0.314936
trainer/Bellman Errors Std                  0.725962
trainer/Bellman Errors Max                  2.53333
trainer/Bellman Errors Min                  1.13612e-09
trainer/Policy Action Mean                  0.333262
trainer/Policy Action Std                   0.942526
trainer/Policy Action Max                   1
trainer/Policy Action Min                  -1
expl/num steps total                     4000
expl/num paths total                      100
expl/path length Mean                      40
expl/path length Std                        0
expl/path length Max                       40
expl/path length Min                       40
expl/Rewards Mean                           0.543058
expl/Rewards Std                            0.657831
expl/Rewards Max                            1.57078
expl/Rewards Min                            0
expl/Returns Mean                          21.7223
expl/Returns Std                           19.389
expl/Returns Max                           44.8289
expl/Returns Min                            0
expl/Actions Mean                           0.263773
expl/Actions Std                            0.806331
expl/Actions Max                            1
expl/Actions Min                           -1
expl/Num Paths                             50
expl/Average Returns                       21.7223
expl/env_infos/final/reward_dist Mean       0.795331
expl/env_infos/final/reward_dist Std        0.774347
expl/env_infos/final/reward_dist Max        1.57078
expl/env_infos/final/reward_dist Min        0
expl/env_infos/initial/reward_dist Mean     0.00259012
expl/env_infos/initial/reward_dist Std      0.00548881
expl/env_infos/initial/reward_dist Max      0.0187417
expl/env_infos/initial/reward_dist Min      0
expl/env_infos/reward_dist Mean             0.543058
expl/env_infos/reward_dist Std              0.657831
expl/env_infos/reward_dist Max              1.57078
expl/env_infos/reward_dist Min              0
eval/num steps total                      800
eval/num paths total                       20
eval/path length Mean                      40
eval/path length Std                        0
eval/path length Max                       40
eval/path length Min                       40
eval/Rewards Mean                           0.668097
eval/Rewards Std                            0.710118
eval/Rewards Max                            1.56921
eval/Rewards Min                            0
eval/Returns Mean                          26.7239
eval/Returns Std                           21.8125
eval/Returns Max                           45.1681
eval/Returns Min                            0.00229262
eval/Actions Mean                           0.333319
eval/Actions Std                            0.942738
eval/Actions Max                            1
eval/Actions Min                           -1
eval/Num Paths                             10
eval/Average Returns                       26.7239
eval/env_infos/final/reward_dist Mean       0.939982
eval/env_infos/final/reward_dist Std        0.767497
eval/env_infos/final/reward_dist Max        1.56921
eval/env_infos/final/reward_dist Min        0
eval/env_infos/initial/reward_dist Mean     0.00312861
eval/env_infos/initial/reward_dist Std      0.00773507
eval/env_infos/initial/reward_dist Max      0.0258113
eval/env_infos/initial/reward_dist Min      0
eval/env_infos/reward_dist Mean             0.668097
eval/env_infos/reward_dist Std              0.710118
eval/env_infos/reward_dist Max              1.56921
eval/env_infos/reward_dist Min              0
time/data storing (s)                       0.0060763
time/evaluation sampling (s)                4.50789
time/exploration sampling (s)              17.3288
time/logging (s)                            0.00527769
time/saving (s)                             0.00100531
time/training (s)                           3.40155
time/epoch (s)                             25.2506
time/total (s)                             53.4575
Epoch                                       1
---------------------------------------  --------------
2023-08-05 00:22:25.534226 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 2 finished
---------------------------------------  --------------
epoch                                       2
replay_buffer/size                       6000
trainer/QF Loss                             2.00269
trainer/Policy Loss                        -5.03777
trainer/Raw Policy Loss                    -5.03777
trainer/Preactivation Policy Loss           0
trainer/Q Predictions Mean                  3.5377
trainer/Q Predictions Std                   1.20972
trainer/Q Predictions Max                   9.48577
trainer/Q Predictions Min                   1.02995
trainer/Q Targets Mean                      4.37972
trainer/Q Targets Std                       0.595646
trainer/Q Targets Max                       8.11233
trainer/Q Targets Min                       3.44825
trainer/Bellman Errors Mean                 2.00269
trainer/Bellman Errors Std                  2.48073
trainer/Bellman Errors Max                 28.448
trainer/Bellman Errors Min                  7.49142e-08
trainer/Policy Action Mean                  0.333333
trainer/Policy Action Std                   0.942809
trainer/Policy Action Max                   1
trainer/Policy Action Min                  -1
expl/num steps total                     6000
expl/num paths total                      150
expl/path length Mean                      40
expl/path length Std                        0
expl/path length Max                       40
expl/path length Min                       40
expl/Rewards Mean                           0.332507
expl/Rewards Std                            0.586338
expl/Rewards Max                            1.57063
expl/Rewards Min                            0
expl/Returns Mean                          13.3003
expl/Returns Std                           18.9743
expl/Returns Max                           45.5425
expl/Returns Min                            0
expl/Actions Mean                           0.259468
expl/Actions Std                            0.800593
expl/Actions Max                            1
expl/Actions Min                           -1
expl/Num Paths                             50
expl/Average Returns                       13.3003
expl/env_infos/final/reward_dist Mean       0.501423
expl/env_infos/final/reward_dist Std        0.730949
expl/env_infos/final/reward_dist Max        1.57063
expl/env_infos/final/reward_dist Min        0
expl/env_infos/initial/reward_dist Mean     0.00209017
expl/env_infos/initial/reward_dist Std      0.006456
expl/env_infos/initial/reward_dist Max      0.0279545
expl/env_infos/initial/reward_dist Min      0
expl/env_infos/reward_dist Mean             0.332507
expl/env_infos/reward_dist Std              0.586338
expl/env_infos/reward_dist Max              1.57063
expl/env_infos/reward_dist Min              0
eval/num steps total                     1200
eval/num paths total                       30
eval/path length Mean                      40
eval/path length Std                        0
eval/path length Max                       40
eval/path length Min                       40
eval/Rewards Mean                           0.672487
eval/Rewards Std                            0.710838
eval/Rewards Max                            1.57066
eval/Rewards Min                            0
eval/Returns Mean                          26.8995
eval/Returns Std                           21.9645
eval/Returns Max                           45.773
eval/Returns Min                            0
eval/Actions Mean                           0.333333
eval/Actions Std                            0.942809
eval/Actions Max                            1
eval/Actions Min                           -1
eval/Num Paths                             10
eval/Average Returns                       26.8995
eval/env_infos/final/reward_dist Mean       0.93964
eval/env_infos/final/reward_dist Std        0.76723
eval/env_infos/final/reward_dist Max        1.57066
eval/env_infos/final/reward_dist Min        0
eval/env_infos/initial/reward_dist Mean     0.0027532
eval/env_infos/initial/reward_dist Std      0.00432131
eval/env_infos/initial/reward_dist Max      0.01264
eval/env_infos/initial/reward_dist Min      0
eval/env_infos/reward_dist Mean             0.672487
eval/env_infos/reward_dist Std              0.710838
eval/env_infos/reward_dist Max              1.57066
eval/env_infos/reward_dist Min              0
time/data storing (s)                       0.00603537
time/evaluation sampling (s)                3.48541
time/exploration sampling (s)              16.9316
time/logging (s)                            0.00532452
time/saving (s)                             0.00100093
time/training (s)                           3.59591
time/epoch (s)                             24.0252
time/total (s)                             77.4847
Epoch                                       2
---------------------------------------  --------------
2023-08-05 00:22:49.841967 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 3 finished
---------------------------------------  --------------
epoch                                       3
replay_buffer/size                       8000
trainer/QF Loss                            21.2022
trainer/Policy Loss                       -16.8545
trainer/Raw Policy Loss                   -16.8545
trainer/Preactivation Policy Loss           0
trainer/Q Predictions Mean                 12.2036
trainer/Q Predictions Std                   4.01705
trainer/Q Predictions Max                  19.5335
trainer/Q Predictions Min                   2.64329
trainer/Q Targets Mean                     14.7799
trainer/Q Targets Std                       0.755845
trainer/Q Targets Max                      18.5713
trainer/Q Targets Min                      11.273
trainer/Bellman Errors Mean                21.2022
trainer/Bellman Errors Std                 33.9425
trainer/Bellman Errors Max                138.011
trainer/Bellman Errors Min                  4.72792e-08
trainer/Policy Action Mean                  0.333333
trainer/Policy Action Std                   0.942809
trainer/Policy Action Max                   1
trainer/Policy Action Min                  -1
expl/num steps total                     8000
expl/num paths total                      200
expl/path length Mean                      40
expl/path length Std                        0
expl/path length Max                       40
expl/path length Min                       40
expl/Rewards Mean                           0.420115
expl/Rewards Std                            0.620468
expl/Rewards Max                            1.57079
expl/Rewards Min                            0
expl/Returns Mean                          16.8046
expl/Returns Std                           19.6058
expl/Returns Max                           44.0772
expl/Returns Min                            0
expl/Actions Mean                           0.250654
expl/Actions Std                            0.811544
expl/Actions Max                            1
expl/Actions Min                           -1
expl/Num Paths                             50
expl/Average Returns                       16.8046
expl/env_infos/final/reward_dist Mean       0.604083
expl/env_infos/final/reward_dist Std        0.751584
expl/env_infos/final/reward_dist Max        1.57079
expl/env_infos/final/reward_dist Min        0
expl/env_infos/initial/reward_dist Mean     0.000716011
expl/env_infos/initial/reward_dist Std      0.00238192
expl/env_infos/initial/reward_dist Max      0.0136073
expl/env_infos/initial/reward_dist Min      0
expl/env_infos/reward_dist Mean             0.420115
expl/env_infos/reward_dist Std              0.620468
expl/env_infos/reward_dist Max              1.57079
expl/env_infos/reward_dist Min              0
eval/num steps total                     1600
eval/num paths total                       40
eval/path length Mean                      40
eval/path length Std                        0
eval/path length Max                       40
eval/path length Min                       40
eval/Rewards Mean                           0.321224
eval/Rewards Std                            0.592102
eval/Rewards Max                            1.57067
eval/Rewards Min                            0
eval/Returns Mean                          12.8489
eval/Returns Std                           19.6294
eval/Returns Max                           44.278
eval/Returns Min                            0
eval/Actions Mean                           0.333333
eval/Actions Std                            0.942809
eval/Actions Max                            1
eval/Actions Min                           -1
eval/Num Paths                             10
eval/Average Returns                       12.8489
eval/env_infos/final/reward_dist Mean       0.470931
eval/env_infos/final/reward_dist Std        0.71936
eval/env_infos/final/reward_dist Max        1.57067
eval/env_infos/final/reward_dist Min        0
eval/env_infos/initial/reward_dist Mean     0
eval/env_infos/initial/reward_dist Std      0
eval/env_infos/initial/reward_dist Max      0
eval/env_infos/initial/reward_dist Min      0
eval/env_infos/reward_dist Mean             0.321224
eval/env_infos/reward_dist Std              0.592102
eval/env_infos/reward_dist Max              1.57067
eval/env_infos/reward_dist Min              0
time/data storing (s)                       0.00595742
time/evaluation sampling (s)                3.56558
time/exploration sampling (s)              17.008
time/logging (s)                            0.00532947
time/saving (s)                             0.00100851
time/training (s)                           3.71962
time/epoch (s)                             24.3055
time/total (s)                            101.792
Epoch                                       3
---------------------------------------  --------------
2023-08-05 00:23:14.352217 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 4 finished
---------------------------------------  ---------------
epoch                                        4
replay_buffer/size                       10000
trainer/QF Loss                            129.583
trainer/Policy Loss                        -42.0787
trainer/Raw Policy Loss                    -42.0787
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  31.1865
trainer/Q Predictions Std                    9.962
trainer/Q Predictions Max                   47.2609
trainer/Q Predictions Min                    4.24921
trainer/Q Targets Mean                      37.2525
trainer/Q Targets Std                        1.3355
trainer/Q Targets Max                       45.8714
trainer/Q Targets Min                       27.9453
trainer/Bellman Errors Mean                129.583
trainer/Bellman Errors Std                 241.756
trainer/Bellman Errors Max                1104.94
trainer/Bellman Errors Min                   6.05592e-05
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     10000
expl/num paths total                       250
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.374868
expl/Rewards Std                             0.600753
expl/Rewards Max                             1.57076
expl/Rewards Min                             0
expl/Returns Mean                           14.9947
expl/Returns Std                            18.9909
expl/Returns Max                            44.2141
expl/Returns Min                             0
expl/Actions Mean                            0.260085
expl/Actions Std                             0.809912
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        14.9947
expl/env_infos/final/reward_dist Mean        0.529159
expl/env_infos/final/reward_dist Std         0.737857
expl/env_infos/final/reward_dist Max         1.57076
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000904858
expl/env_infos/initial/reward_dist Std       0.00316463
expl/env_infos/initial/reward_dist Max       0.0211391
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.374868
expl/env_infos/reward_dist Std               0.600753
expl/env_infos/reward_dist Max               1.57076
expl/env_infos/reward_dist Min               0
eval/num steps total                      2000
eval/num paths total                        50
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.892663
eval/Rewards Std                             0.688936
eval/Rewards Max                             1.56945
eval/Rewards Min                             0
eval/Returns Mean                           35.7065
eval/Returns Std                            17.8574
eval/Returns Max                            45.5066
eval/Returns Min                             0.00415822
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        35.7065
eval/env_infos/final/reward_dist Mean        1.25392
eval/env_infos/final/reward_dist Std         0.626961
eval/env_infos/final/reward_dist Max         1.56945
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.00169247
eval/env_infos/initial/reward_dist Std       0.00338398
eval/env_infos/initial/reward_dist Max       0.0106051
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.892663
eval/env_infos/reward_dist Std               0.688936
eval/env_infos/reward_dist Max               1.56945
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00599236
time/evaluation sampling (s)                 3.61357
time/exploration sampling (s)               17.1676
time/logging (s)                             0.00547105
time/saving (s)                              0.000995145
time/training (s)                            3.71448
time/epoch (s)                              24.5081
time/total (s)                             126.302
Epoch                                        4
---------------------------------------  ---------------
2023-08-05 00:23:39.043938 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 5 finished
---------------------------------------  ---------------
epoch                                        5
replay_buffer/size                       12000
trainer/QF Loss                            564.997
trainer/Policy Loss                        -84.287
trainer/Raw Policy Loss                    -84.287
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  62.3388
trainer/Q Predictions Std                   20.1809
trainer/Q Predictions Max                  108.753
trainer/Q Predictions Min                    6.24397
trainer/Q Targets Mean                      75.9032
trainer/Q Targets Std                        2.72153
trainer/Q Targets Max                       98.9417
trainer/Q Targets Min                       55.8762
trainer/Bellman Errors Mean                564.997
trainer/Bellman Errors Std                1097.66
trainer/Bellman Errors Max                4672.11
trainer/Bellman Errors Min                   5.75113e-05
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     12000
expl/num paths total                       300
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.375473
expl/Rewards Std                             0.601455
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           15.0189
expl/Returns Std                            19.0727
expl/Returns Max                            44.6742
expl/Returns Min                             0
expl/Actions Mean                            0.255006
expl/Actions Std                             0.805496
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        15.0189
expl/env_infos/final/reward_dist Mean        0.605955
expl/env_infos/final/reward_dist Std         0.752804
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.0019977
expl/env_infos/initial/reward_dist Std       0.00539214
expl/env_infos/initial/reward_dist Max       0.0227492
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.375473
expl/env_infos/reward_dist Std               0.601455
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                      2400
eval/num paths total                        60
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.889337
eval/Rewards Std                             0.690356
eval/Rewards Max                             1.57046
eval/Rewards Min                             0
eval/Returns Mean                           35.5735
eval/Returns Std                            17.7922
eval/Returns Max                            45.4423
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        35.5735
eval/env_infos/final/reward_dist Mean        1.25452
eval/env_infos/final/reward_dist Std         0.627266
eval/env_infos/final/reward_dist Max         1.57046
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.00219335
eval/env_infos/initial/reward_dist Std       0.00584577
eval/env_infos/initial/reward_dist Max       0.0196067
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.889337
eval/env_infos/reward_dist Std               0.690356
eval/env_infos/reward_dist Max               1.57046
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00597545
time/evaluation sampling (s)                 3.95651
time/exploration sampling (s)               17.0963
time/logging (s)                             0.00536688
time/saving (s)                              0.000977921
time/training (s)                            3.62351
time/epoch (s)                              24.6886
time/total (s)                             150.993
Epoch                                        5
---------------------------------------  ---------------
2023-08-05 00:24:03.660867 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 6 finished
---------------------------------------  ---------------
epoch                                        6
replay_buffer/size                       14000
trainer/QF Loss                           1577.4
trainer/Policy Loss                       -142.698
trainer/Raw Policy Loss                   -142.698
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 106.896
trainer/Q Predictions Std                   33.3387
trainer/Q Predictions Max                  168.175
trainer/Q Predictions Min                    8.93156
trainer/Q Targets Mean                     130.02
trainer/Q Targets Std                        5.2333
trainer/Q Targets Max                      172.278
trainer/Q Targets Min                       89.9201
trainer/Bellman Errors Mean               1577.4
trainer/Bellman Errors Std                3209.25
trainer/Bellman Errors Max               14566.4
trainer/Bellman Errors Min                   0.000906347
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     14000
expl/num paths total                       350
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.397768
expl/Rewards Std                             0.610036
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           15.9107
expl/Returns Std                            18.9495
expl/Returns Max                            44.3455
expl/Returns Min                             0
expl/Actions Mean                            0.248054
expl/Actions Std                             0.790902
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        15.9107
expl/env_infos/final/reward_dist Mean        0.623689
expl/env_infos/final/reward_dist Std         0.764056
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000757677
expl/env_infos/initial/reward_dist Std       0.00337413
expl/env_infos/initial/reward_dist Max       0.0194041
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.397768
expl/env_infos/reward_dist Std               0.610036
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                      2800
eval/num paths total                        70
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.439811
eval/Rewards Std                             0.6577
eval/Rewards Max                             1.57049
eval/Rewards Min                             0
eval/Returns Mean                           17.5924
eval/Returns Std                            21.5051
eval/Returns Max                            44.4833
eval/Returns Min                             0.00175161
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        17.5924
eval/env_infos/final/reward_dist Mean        0.628329
eval/env_infos/final/reward_dist Std         0.768587
eval/env_infos/final/reward_dist Max         1.57049
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.439811
eval/env_infos/reward_dist Std               0.6577
eval/env_infos/reward_dist Max               1.57049
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00829895
time/evaluation sampling (s)                 3.80923
time/exploration sampling (s)               17.0323
time/logging (s)                             0.00536829
time/saving (s)                              0.000965547
time/training (s)                            3.75829
time/epoch (s)                              24.6145
time/total (s)                             175.61
Epoch                                        6
---------------------------------------  ---------------
2023-08-05 00:24:27.920603 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 7 finished
---------------------------------------  ---------------
epoch                                        7
replay_buffer/size                       16000
trainer/QF Loss                           3570.5
trainer/Policy Loss                       -217.043
trainer/Raw Policy Loss                   -217.043
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 163.733
trainer/Q Predictions Std                   49.4418
trainer/Q Predictions Max                  266.679
trainer/Q Predictions Min                   10.7981
trainer/Q Targets Mean                     199.348
trainer/Q Targets Std                        8.41324
trainer/Q Targets Max                      262.909
trainer/Q Targets Min                      132.298
trainer/Bellman Errors Mean               3570.5
trainer/Bellman Errors Std                7432.74
trainer/Bellman Errors Max               40467.2
trainer/Bellman Errors Min                   7.83242e-05
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     16000
expl/num paths total                       400
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.627459
expl/Rewards Std                             0.679009
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           25.0983
expl/Returns Std                            19.6242
expl/Returns Max                            44.2048
expl/Returns Min                             0
expl/Actions Mean                            0.260793
expl/Actions Std                             0.804356
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        25.0983
expl/env_infos/final/reward_dist Mean        0.95984
expl/env_infos/final/reward_dist Std         0.753608
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000837366
expl/env_infos/initial/reward_dist Std       0.00228907
expl/env_infos/initial/reward_dist Max       0.01104
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.627459
expl/env_infos/reward_dist Std               0.679009
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                      3200
eval/num paths total                        80
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.408258
eval/Rewards Std                             0.63183
eval/Rewards Max                             1.56849
eval/Rewards Min                             0
eval/Returns Mean                           16.3303
eval/Returns Std                            20.3392
eval/Returns Max                            44.282
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        16.3303
eval/env_infos/final/reward_dist Mean        0.619904
eval/env_infos/final/reward_dist Std         0.759469
eval/env_infos/final/reward_dist Max         1.56849
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.000288361
eval/env_infos/initial/reward_dist Std       0.000865084
eval/env_infos/initial/reward_dist Max       0.00288361
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.408258
eval/env_infos/reward_dist Std               0.63183
eval/env_infos/reward_dist Max               1.56849
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00615724
time/evaluation sampling (s)                 3.34682
time/exploration sampling (s)               17.0778
time/logging (s)                             0.00531657
time/saving (s)                              0.000998573
time/training (s)                            3.82
time/epoch (s)                              24.2571
time/total (s)                             199.869
Epoch                                        7
---------------------------------------  ---------------
2023-08-05 00:24:53.028180 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 8 finished
---------------------------------------  ---------------
epoch                                        8
replay_buffer/size                       18000
trainer/QF Loss                           6882.6
trainer/Policy Loss                       -305.966
trainer/Raw Policy Loss                   -305.966
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 232.616
trainer/Q Predictions Std                   68.2154
trainer/Q Predictions Max                  379.004
trainer/Q Predictions Min                   13.5777
trainer/Q Targets Mean                     282.44
trainer/Q Targets Std                       12.2817
trainer/Q Targets Max                      396.452
trainer/Q Targets Min                      175.005
trainer/Bellman Errors Mean               6882.6
trainer/Bellman Errors Std               14822.5
trainer/Bellman Errors Max               72067.9
trainer/Bellman Errors Min                   3.72529e-05
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     18000
expl/num paths total                       450
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.475471
expl/Rewards Std                             0.642557
expl/Rewards Max                             1.57078
expl/Rewards Min                             0
expl/Returns Mean                           19.0188
expl/Returns Std                            19.6534
expl/Returns Max                            44.1873
expl/Returns Min                             0
expl/Actions Mean                            0.270203
expl/Actions Std                             0.807938
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        19.0188
expl/env_infos/final/reward_dist Mean        0.762691
expl/env_infos/final/reward_dist Std         0.770699
expl/env_infos/final/reward_dist Max         1.57078
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000717904
expl/env_infos/initial/reward_dist Std       0.0022653
expl/env_infos/initial/reward_dist Max       0.0100513
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.475471
expl/env_infos/reward_dist Std               0.642557
expl/env_infos/reward_dist Max               1.57078
expl/env_infos/reward_dist Min               0
eval/num steps total                      3600
eval/num paths total                        90
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.223885
eval/Rewards Std                             0.516704
eval/Rewards Max                             1.57067
eval/Rewards Min                             0
eval/Returns Mean                            8.9554
eval/Returns Std                            17.7218
eval/Returns Max                            44.5154
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         8.9554
eval/env_infos/final/reward_dist Mean        0.318879
eval/env_infos/final/reward_dist Std         0.624433
eval/env_infos/final/reward_dist Max         1.57067
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.223885
eval/env_infos/reward_dist Std               0.516704
eval/env_infos/reward_dist Max               1.57067
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00596764
time/evaluation sampling (s)                 3.39679
time/exploration sampling (s)               17.6779
time/logging (s)                             0.00534752
time/saving (s)                              0.00097224
time/training (s)                            4.01833
time/epoch (s)                              25.1053
time/total (s)                             224.976
Epoch                                        8
---------------------------------------  ---------------
2023-08-05 00:25:18.001829 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 9 finished
---------------------------------------  ----------------
epoch                                         9
replay_buffer/size                        20000
trainer/QF Loss                           12018.8
trainer/Policy Loss                        -410.31
trainer/Raw Policy Loss                    -410.31
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  315.169
trainer/Q Predictions Std                    91.1099
trainer/Q Predictions Max                   505.388
trainer/Q Predictions Min                    16.5534
trainer/Q Targets Mean                      380.257
trainer/Q Targets Std                        15.9899
trainer/Q Targets Max                       473.904
trainer/Q Targets Min                       255.768
trainer/Bellman Errors Mean               12018.8
trainer/Bellman Errors Std                26865.6
trainer/Bellman Errors Max               128503
trainer/Bellman Errors Min                    0.000307919
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      20000
expl/num paths total                        500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.384195
expl/Rewards Std                              0.593922
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            15.3678
expl/Returns Std                             18.2595
expl/Returns Max                             45.5202
expl/Returns Min                              0
expl/Actions Mean                             0.259807
expl/Actions Std                              0.812278
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.3678
expl/env_infos/final/reward_dist Mean         0.604513
expl/env_infos/final/reward_dist Std          0.737426
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000799937
expl/env_infos/initial/reward_dist Std        0.00390673
expl/env_infos/initial/reward_dist Max        0.0262802
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.384195
expl/env_infos/reward_dist Std                0.593922
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                       4000
eval/num paths total                        100
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.447144
eval/Rewards Std                              0.661673
eval/Rewards Max                              1.57076
eval/Rewards Min                              0
eval/Returns Mean                            17.8858
eval/Returns Std                             21.9047
eval/Returns Max                             46.3823
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.8858
eval/env_infos/final/reward_dist Mean         0.627654
eval/env_infos/final/reward_dist Std          0.76871
eval/env_infos/final/reward_dist Max          1.57076
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00266502
eval/env_infos/initial/reward_dist Std        0.0069129
eval/env_infos/initial/reward_dist Max        0.0231686
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.447144
eval/env_infos/reward_dist Std                0.661673
eval/env_infos/reward_dist Max                1.57076
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00601051
time/evaluation sampling (s)                  3.48709
time/exploration sampling (s)                17.9999
time/logging (s)                              0.00532599
time/saving (s)                               0.00101742
time/training (s)                             3.47197
time/epoch (s)                               24.9713
time/total (s)                              249.95
Epoch                                         9
---------------------------------------  ----------------
2023-08-05 00:25:43.494317 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 10 finished
---------------------------------------  ----------------
epoch                                        10
replay_buffer/size                        22000
trainer/QF Loss                           18160.8
trainer/Policy Loss                        -530.663
trainer/Raw Policy Loss                    -530.663
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  411.463
trainer/Q Predictions Std                   110.042
trainer/Q Predictions Max                   731.282
trainer/Q Predictions Min                    19.4908
trainer/Q Targets Mean                      493.417
trainer/Q Targets Std                        23.762
trainer/Q Targets Max                       679.154
trainer/Q Targets Min                       285.195
trainer/Bellman Errors Mean               18160.8
trainer/Bellman Errors Std                41393.7
trainer/Bellman Errors Max               222562
trainer/Bellman Errors Min                    2.05729e-06
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      22000
expl/num paths total                        550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.449703
expl/Rewards Std                              0.634133
expl/Rewards Max                              1.57072
expl/Rewards Min                              0
expl/Returns Mean                            17.9881
expl/Returns Std                             19.6156
expl/Returns Max                             44.0046
expl/Returns Min                              0
expl/Actions Mean                             0.257434
expl/Actions Std                              0.810883
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.9881
expl/env_infos/final/reward_dist Mean         0.663094
expl/env_infos/final/reward_dist Std          0.761663
expl/env_infos/final/reward_dist Max          1.57072
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00209558
expl/env_infos/initial/reward_dist Std        0.00590195
expl/env_infos/initial/reward_dist Max        0.0217167
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.449703
expl/env_infos/reward_dist Std                0.634133
expl/env_infos/reward_dist Max                1.57072
expl/env_infos/reward_dist Min                0
eval/num steps total                       4400
eval/num paths total                        110
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.406896
eval/Rewards Std                              0.630669
eval/Rewards Max                              1.57029
eval/Rewards Min                              0
eval/Returns Mean                            16.2759
eval/Returns Std                             20.2132
eval/Returns Max                             44.1829
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.2759
eval/env_infos/final/reward_dist Mean         0.620421
eval/env_infos/final/reward_dist Std          0.759627
eval/env_infos/final/reward_dist Max          1.57011
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.406896
eval/env_infos/reward_dist Std                0.630669
eval/env_infos/reward_dist Max                1.57029
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585975
time/evaluation sampling (s)                  3.4965
time/exploration sampling (s)                18.0076
time/logging (s)                              0.00747506
time/saving (s)                               0.00110622
time/training (s)                             3.9737
time/epoch (s)                               25.4922
time/total (s)                              275.444
Epoch                                        10
---------------------------------------  ----------------
2023-08-05 00:26:09.062933 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 11 finished
---------------------------------------  ----------------
epoch                                        11
replay_buffer/size                        24000
trainer/QF Loss                           28498.6
trainer/Policy Loss                        -670.154
trainer/Raw Policy Loss                    -670.154
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  521.896
trainer/Q Predictions Std                   138.273
trainer/Q Predictions Max                   921.233
trainer/Q Predictions Min                    19.1275
trainer/Q Targets Mean                      623.997
trainer/Q Targets Std                        32.9352
trainer/Q Targets Max                       844.281
trainer/Q Targets Min                       334.758
trainer/Bellman Errors Mean               28498.6
trainer/Bellman Errors Std                64935.8
trainer/Bellman Errors Max               425642
trainer/Bellman Errors Min                    0.0110465
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      24000
expl/num paths total                        600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.464506
expl/Rewards Std                              0.643622
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            18.5802
expl/Returns Std                             20.058
expl/Returns Max                             43.497
expl/Returns Min                              0
expl/Actions Mean                             0.270624
expl/Actions Std                              0.798048
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.5802
expl/env_infos/final/reward_dist Mean         0.711492
expl/env_infos/final/reward_dist Std          0.767879
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00149454
expl/env_infos/initial/reward_dist Std        0.00466285
expl/env_infos/initial/reward_dist Max        0.0237394
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.464506
expl/env_infos/reward_dist Std                0.643622
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                       4800
eval/num paths total                        120
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.217671
eval/Rewards Std                              0.470615
eval/Rewards Max                              1.56899
eval/Rewards Min                              0
eval/Returns Mean                             8.70684
eval/Returns Std                             15.156
eval/Returns Max                             44.7856
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          8.70684
eval/env_infos/final/reward_dist Mean         0.422541
eval/env_infos/final/reward_dist Std          0.652656
eval/env_infos/final/reward_dist Max          1.56899
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000980699
eval/env_infos/initial/reward_dist Std        0.0029421
eval/env_infos/initial/reward_dist Max        0.00980699
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.217671
eval/env_infos/reward_dist Std                0.470615
eval/env_infos/reward_dist Max                1.56899
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00607335
time/evaluation sampling (s)                  3.52925
time/exploration sampling (s)                17.9867
time/logging (s)                              0.00540303
time/saving (s)                               0.000972842
time/training (s)                             4.03473
time/epoch (s)                               25.5632
time/total (s)                              301.01
Epoch                                        11
---------------------------------------  ----------------
2023-08-05 00:26:35.017873 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 12 finished
---------------------------------------  ----------------
epoch                                        12
replay_buffer/size                        26000
trainer/QF Loss                           39405.8
trainer/Policy Loss                        -826.216
trainer/Raw Policy Loss                    -826.216
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  648.945
trainer/Q Predictions Std                   161.198
trainer/Q Predictions Max                  1010.59
trainer/Q Predictions Min                    26.0994
trainer/Q Targets Mean                      771.301
trainer/Q Targets Std                        42.3092
trainer/Q Targets Max                      1045.31
trainer/Q Targets Min                       407.103
trainer/Bellman Errors Mean               39405.8
trainer/Bellman Errors Std                93263.8
trainer/Bellman Errors Max               544076
trainer/Bellman Errors Min                    0.000499025
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      26000
expl/num paths total                        650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.527637
expl/Rewards Std                              0.653355
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            21.1055
expl/Returns Std                             19.7169
expl/Returns Max                             44.068
expl/Returns Min                              0
expl/Actions Mean                             0.249628
expl/Actions Std                              0.800398
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.1055
expl/env_infos/final/reward_dist Mean         0.745664
expl/env_infos/final/reward_dist Std          0.772398
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00209758
expl/env_infos/initial/reward_dist Std        0.0058504
expl/env_infos/initial/reward_dist Max        0.0288029
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.527637
expl/env_infos/reward_dist Std                0.653355
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                       5200
eval/num paths total                        130
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.784635
eval/Rewards Std                              0.708893
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            31.3854
eval/Returns Std                             20.5414
eval/Returns Max                             45.4187
eval/Returns Min                              0.00660916
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.3854
eval/env_infos/final/reward_dist Mean         1.09821
eval/env_infos/final/reward_dist Std          0.718951
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00364476
eval/env_infos/initial/reward_dist Std        0.00749025
eval/env_infos/initial/reward_dist Max        0.0220753
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.784635
eval/env_infos/reward_dist Std                0.708893
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00599625
time/evaluation sampling (s)                  3.42509
time/exploration sampling (s)                18.4887
time/logging (s)                              0.00531133
time/saving (s)                               0.000986954
time/training (s)                             4.02647
time/epoch (s)                               25.9525
time/total (s)                              326.964
Epoch                                        12
---------------------------------------  ----------------
2023-08-05 00:26:59.871861 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 13 finished
---------------------------------------  ----------------
epoch                                        13
replay_buffer/size                        28000
trainer/QF Loss                           58955.2
trainer/Policy Loss                       -1002.53
trainer/Raw Policy Loss                   -1002.53
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  789.117
trainer/Q Predictions Std                   197.305
trainer/Q Predictions Max                  1275.65
trainer/Q Predictions Min                    25.8339
trainer/Q Targets Mean                      938.142
trainer/Q Targets Std                        49.0675
trainer/Q Targets Max                      1373.72
trainer/Q Targets Min                       485.786
trainer/Bellman Errors Mean               58955.2
trainer/Bellman Errors Std               138635
trainer/Bellman Errors Max               823113
trainer/Bellman Errors Min                    0.000663415
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      28000
expl/num paths total                        700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.496738
expl/Rewards Std                              0.653669
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            19.8695
expl/Returns Std                             20.1154
expl/Returns Max                             44.909
expl/Returns Min                              0
expl/Actions Mean                             0.270499
expl/Actions Std                              0.809677
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.8695
expl/env_infos/final/reward_dist Mean         0.744856
expl/env_infos/final/reward_dist Std          0.77613
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000703853
expl/env_infos/initial/reward_dist Std        0.00247729
expl/env_infos/initial/reward_dist Max        0.0147315
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.496738
expl/env_infos/reward_dist Std                0.653669
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                       5600
eval/num paths total                        140
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.437035
eval/Rewards Std                              0.640881
eval/Rewards Max                              1.57076
eval/Rewards Min                              0
eval/Returns Mean                            17.4814
eval/Returns Std                             21.0401
eval/Returns Max                             46.3755
eval/Returns Min                              0.00214432
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.4814
eval/env_infos/final/reward_dist Mean         0.645499
eval/env_infos/final/reward_dist Std          0.743091
eval/env_infos/final/reward_dist Max          1.57076
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00243066
eval/env_infos/initial/reward_dist Std        0.00296021
eval/env_infos/initial/reward_dist Max        0.0081953
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.437035
eval/env_infos/reward_dist Std                0.640881
eval/env_infos/reward_dist Max                1.57076
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00599421
time/evaluation sampling (s)                  3.44753
time/exploration sampling (s)                17.8174
time/logging (s)                              0.00537089
time/saving (s)                               0.00100882
time/training (s)                             3.57443
time/epoch (s)                               24.8517
time/total (s)                              351.818
Epoch                                        13
---------------------------------------  ----------------
2023-08-05 00:27:25.522924 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 14 finished
---------------------------------------  ----------------
epoch                                        14
replay_buffer/size                        30000
trainer/QF Loss                           83451.4
trainer/Policy Loss                       -1197.71
trainer/Raw Policy Loss                   -1197.71
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  943.68
trainer/Q Predictions Std                   233.796
trainer/Q Predictions Max                  1600.12
trainer/Q Predictions Min                    24.254
trainer/Q Targets Mean                     1122.42
trainer/Q Targets Std                        55.2209
trainer/Q Targets Max                      1585.86
trainer/Q Targets Min                       586.8
trainer/Bellman Errors Mean               83451.4
trainer/Bellman Errors Std               199467
trainer/Bellman Errors Max                    1.4141e+06
trainer/Bellman Errors Min                    0.025183
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      30000
expl/num paths total                        750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.511085
expl/Rewards Std                              0.65799
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            20.4434
expl/Returns Std                             19.9332
expl/Returns Max                             45.6531
expl/Returns Min                              0
expl/Actions Mean                             0.25899
expl/Actions Std                              0.80754
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.4434
expl/env_infos/final/reward_dist Mean         0.778377
expl/env_infos/final/reward_dist Std          0.77888
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00158103
expl/env_infos/initial/reward_dist Std        0.00607783
expl/env_infos/initial/reward_dist Max        0.035496
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.511085
expl/env_infos/reward_dist Std                0.65799
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                       6000
eval/num paths total                        150
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.261913
eval/Rewards Std                              0.52807
eval/Rewards Max                              1.57053
eval/Rewards Min                              0
eval/Returns Mean                            10.4765
eval/Returns Std                             17.6398
eval/Returns Max                             45.0474
eval/Returns Min                              0.000727889
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         10.4765
eval/env_infos/final/reward_dist Mean         0.467714
eval/env_infos/final/reward_dist Std          0.713665
eval/env_infos/final/reward_dist Max          1.57053
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.261913
eval/env_infos/reward_dist Std                0.52807
eval/env_infos/reward_dist Max                1.57053
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00602857
time/evaluation sampling (s)                  3.34506
time/exploration sampling (s)                18.36
time/logging (s)                              0.00743515
time/saving (s)                               0.00111051
time/training (s)                             3.93104
time/epoch (s)                               25.6507
time/total (s)                              377.471
Epoch                                        14
---------------------------------------  ----------------
2023-08-05 00:27:50.758511 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 15 finished
---------------------------------------  ----------------
epoch                                        15
replay_buffer/size                        32000
trainer/QF Loss                          113405
trainer/Policy Loss                       -1418.42
trainer/Raw Policy Loss                   -1418.42
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 1118.61
trainer/Q Predictions Std                   272.419
trainer/Q Predictions Max                  1971.91
trainer/Q Predictions Min                    33.7282
trainer/Q Targets Mean                     1327.78
trainer/Q Targets Std                        68.5826
trainer/Q Targets Max                      1791.12
trainer/Q Targets Min                       700.108
trainer/Bellman Errors Mean              113405
trainer/Bellman Errors Std               272842
trainer/Bellman Errors Max                    1.77005e+06
trainer/Bellman Errors Min                    0.00230147
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      32000
expl/num paths total                        800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.455992
expl/Rewards Std                              0.642525
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            18.2397
expl/Returns Std                             19.8371
expl/Returns Max                             43.8742
expl/Returns Min                              0
expl/Actions Mean                             0.261843
expl/Actions Std                              0.810146
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.2397
expl/env_infos/final/reward_dist Mean         0.690359
expl/env_infos/final/reward_dist Std          0.776146
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00110268
expl/env_infos/initial/reward_dist Std        0.00356365
expl/env_infos/initial/reward_dist Max        0.0180979
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.455992
expl/env_infos/reward_dist Std                0.642525
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                       6400
eval/num paths total                        160
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.705707
eval/Rewards Std                              0.690277
eval/Rewards Max                              1.56833
eval/Rewards Min                              0
eval/Returns Mean                            28.2283
eval/Returns Std                             19.2235
eval/Returns Max                             44.746
eval/Returns Min                              0.00402999
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.2283
eval/env_infos/final/reward_dist Mean         1.07973
eval/env_infos/final/reward_dist Std          0.707612
eval/env_infos/final/reward_dist Max          1.56833
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.705707
eval/env_infos/reward_dist Std                0.690277
eval/env_infos/reward_dist Max                1.56833
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595369
time/evaluation sampling (s)                  3.49536
time/exploration sampling (s)                17.7765
time/logging (s)                              0.00442262
time/saving (s)                               0.00985302
time/training (s)                             3.93704
time/epoch (s)                               25.2291
time/total (s)                              402.703
Epoch                                        15
---------------------------------------  ----------------
2023-08-05 00:28:15.525117 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 16 finished
---------------------------------------  ----------------
epoch                                        16
replay_buffer/size                        34000
trainer/QF Loss                          143535
trainer/Policy Loss                       -1657.33
trainer/Raw Policy Loss                   -1657.33
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 1314.9
trainer/Q Predictions Std                   303.886
trainer/Q Predictions Max                  2323.84
trainer/Q Predictions Min                    36.4165
trainer/Q Targets Mean                     1553.22
trainer/Q Targets Std                        77.3507
trainer/Q Targets Max                      1964.55
trainer/Q Targets Min                       820.509
trainer/Bellman Errors Mean              143535
trainer/Bellman Errors Std               342957
trainer/Bellman Errors Max                    2.27775e+06
trainer/Bellman Errors Min                    0.00922932
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      34000
expl/num paths total                        850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.503309
expl/Rewards Std                              0.659797
expl/Rewards Max                              1.57069
expl/Rewards Min                              0
expl/Returns Mean                            20.1324
expl/Returns Std                             20.1924
expl/Returns Max                             44.236
expl/Returns Min                              0
expl/Actions Mean                             0.249985
expl/Actions Std                              0.799875
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.1324
expl/env_infos/final/reward_dist Mean         0.782971
expl/env_infos/final/reward_dist Std          0.783023
expl/env_infos/final/reward_dist Max          1.57069
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00197756
expl/env_infos/initial/reward_dist Std        0.00475262
expl/env_infos/initial/reward_dist Max        0.0194747
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.503309
expl/env_infos/reward_dist Std                0.659797
expl/env_infos/reward_dist Max                1.57069
expl/env_infos/reward_dist Min                0
eval/num steps total                       6800
eval/num paths total                        170
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.445778
eval/Rewards Std                              0.66131
eval/Rewards Max                              1.57062
eval/Rewards Min                              0
eval/Returns Mean                            17.8311
eval/Returns Std                             21.8168
eval/Returns Max                             44.803
eval/Returns Min                              0.000752522
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.8311
eval/env_infos/final/reward_dist Mean         0.628314
eval/env_infos/final/reward_dist Std          0.768896
eval/env_infos/final/reward_dist Max          1.57062
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.445778
eval/env_infos/reward_dist Std                0.66131
eval/env_infos/reward_dist Max                1.57062
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589976
time/evaluation sampling (s)                  3.3452
time/exploration sampling (s)                17.2918
time/logging (s)                              0.00532693
time/saving (s)                               0.00100057
time/training (s)                             4.11631
time/epoch (s)                               24.7655
time/total (s)                              427.47
Epoch                                        16
---------------------------------------  ----------------
2023-08-05 00:28:40.292338 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 17 finished
---------------------------------------  ----------------
epoch                                        17
replay_buffer/size                        36000
trainer/QF Loss                          219916
trainer/Policy Loss                       -1918.97
trainer/Raw Policy Loss                   -1918.97
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 1502.12
trainer/Q Predictions Std                   372.799
trainer/Q Predictions Max                  2669.26
trainer/Q Predictions Min                    40.1295
trainer/Q Targets Mean                     1800.51
trainer/Q Targets Std                        89.1902
trainer/Q Targets Max                      2504.38
trainer/Q Targets Min                      1037.61
trainer/Bellman Errors Mean              219916
trainer/Bellman Errors Std               516672
trainer/Bellman Errors Max                    3.07335e+06
trainer/Bellman Errors Min                    0.0037104
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      36000
expl/num paths total                        900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.441119
expl/Rewards Std                              0.635381
expl/Rewards Max                              1.57055
expl/Rewards Min                              0
expl/Returns Mean                            17.6448
expl/Returns Std                             20.0848
expl/Returns Max                             44.5325
expl/Returns Min                              0
expl/Actions Mean                             0.264912
expl/Actions Std                              0.810584
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.6448
expl/env_infos/final/reward_dist Mean         0.636343
expl/env_infos/final/reward_dist Std          0.759493
expl/env_infos/final/reward_dist Max          1.57055
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00113268
expl/env_infos/initial/reward_dist Std        0.00320482
expl/env_infos/initial/reward_dist Max        0.0142138
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.441119
expl/env_infos/reward_dist Std                0.635381
expl/env_infos/reward_dist Max                1.57055
expl/env_infos/reward_dist Min                0
eval/num steps total                       7200
eval/num paths total                        180
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.894649
eval/Rewards Std                              0.690044
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            35.786
eval/Returns Std                             17.8949
eval/Returns Max                             45.4556
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.786
eval/env_infos/final/reward_dist Mean         1.25601
eval/env_infos/final/reward_dist Std          0.628003
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00174051
eval/env_infos/initial/reward_dist Std        0.00499374
eval/env_infos/initial/reward_dist Max        0.0167088
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.894649
eval/env_infos/reward_dist Std                0.690044
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0060298
time/evaluation sampling (s)                  3.34576
time/exploration sampling (s)                17.6122
time/logging (s)                              0.00535017
time/saving (s)                               0.000984172
time/training (s)                             3.79461
time/epoch (s)                               24.7649
time/total (s)                              452.237
Epoch                                        17
---------------------------------------  ----------------
2023-08-05 00:29:05.655684 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 18 finished
---------------------------------------  ----------------
epoch                                        18
replay_buffer/size                        38000
trainer/QF Loss                          257316
trainer/Policy Loss                       -2204.45
trainer/Raw Policy Loss                   -2204.45
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 1752.74
trainer/Q Predictions Std                   406.718
trainer/Q Predictions Max                  3053.22
trainer/Q Predictions Min                    45.3949
trainer/Q Targets Mean                     2070.96
trainer/Q Targets Std                       102.931
trainer/Q Targets Max                      2975.68
trainer/Q Targets Min                      1153.14
trainer/Bellman Errors Mean              257316
trainer/Bellman Errors Std               627209
trainer/Bellman Errors Max                    3.95474e+06
trainer/Bellman Errors Min                    0.000669718
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      38000
expl/num paths total                        950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.351841
expl/Rewards Std                              0.588349
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            14.0736
expl/Returns Std                             18.7687
expl/Returns Max                             45.6935
expl/Returns Min                              0
expl/Actions Mean                             0.263542
expl/Actions Std                              0.807932
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.0736
expl/env_infos/final/reward_dist Mean         0.537698
expl/env_infos/final/reward_dist Std          0.734806
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000500455
expl/env_infos/initial/reward_dist Std        0.00222908
expl/env_infos/initial/reward_dist Max        0.014201
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.351841
expl/env_infos/reward_dist Std                0.588349
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                       7600
eval/num paths total                        190
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.271127
eval/Rewards Std                              0.53917
eval/Rewards Max                              1.56612
eval/Rewards Min                              0
eval/Returns Mean                            10.8451
eval/Returns Std                             17.757
eval/Returns Max                             44.7674
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         10.8451
eval/env_infos/final/reward_dist Mean         0.462675
eval/env_infos/final/reward_dist Std          0.706424
eval/env_infos/final/reward_dist Max          1.56612
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000265907
eval/env_infos/initial/reward_dist Std        0.00063969
eval/env_infos/initial/reward_dist Max        0.00212445
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.271127
eval/env_infos/reward_dist Std                0.53917
eval/env_infos/reward_dist Max                1.56612
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593183
time/evaluation sampling (s)                  3.44011
time/exploration sampling (s)                17.63
time/logging (s)                              0.00800478
time/saving (s)                               0.00127889
time/training (s)                             4.2783
time/epoch (s)                               25.3636
time/total (s)                              477.603
Epoch                                        18
---------------------------------------  ----------------
2023-08-05 00:29:30.652896 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 19 finished
---------------------------------------  ----------------
epoch                                        19
replay_buffer/size                        40000
trainer/QF Loss                          322359
trainer/Policy Loss                       -2511.82
trainer/Raw Policy Loss                   -2511.82
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 2001.25
trainer/Q Predictions Std                   448.47
trainer/Q Predictions Max                  3490.45
trainer/Q Predictions Min                    47.4024
trainer/Q Targets Mean                     2362.22
trainer/Q Targets Std                       121.545
trainer/Q Targets Max                      3329.93
trainer/Q Targets Min                      1287.54
trainer/Bellman Errors Mean              322359
trainer/Bellman Errors Std               760145
trainer/Bellman Errors Max                    5.26245e+06
trainer/Bellman Errors Min                    0.000292063
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      40000
expl/num paths total                       1000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.591314
expl/Rewards Std                              0.669527
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            23.6526
expl/Returns Std                             19.547
expl/Returns Max                             44.1617
expl/Returns Min                              0
expl/Actions Mean                             0.262292
expl/Actions Std                              0.807049
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         23.6526
expl/env_infos/final/reward_dist Mean         0.920088
expl/env_infos/final/reward_dist Std          0.755472
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00180009
expl/env_infos/initial/reward_dist Std        0.00504396
expl/env_infos/initial/reward_dist Max        0.0311253
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.591314
expl/env_infos/reward_dist Std                0.669527
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                       8000
eval/num paths total                        200
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.169823
eval/Rewards Std                              0.438027
eval/Rewards Max                              1.56912
eval/Rewards Min                              0
eval/Returns Mean                             6.79292
eval/Returns Std                             14.3168
eval/Returns Max                             44.3904
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          6.79292
eval/env_infos/final/reward_dist Mean         0.306169
eval/env_infos/final/reward_dist Std          0.611367
eval/env_infos/final/reward_dist Max          1.56912
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.169823
eval/env_infos/reward_dist Std                0.438027
eval/env_infos/reward_dist Max                1.56912
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00601457
time/evaluation sampling (s)                  3.50324
time/exploration sampling (s)                17.4544
time/logging (s)                              0.00534435
time/saving (s)                               0.00101002
time/training (s)                             4.02099
time/epoch (s)                               24.991
time/total (s)                              502.596
Epoch                                        19
---------------------------------------  ----------------
2023-08-05 00:29:56.285195 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 20 finished
---------------------------------------  ----------------
epoch                                        20
replay_buffer/size                        42000
trainer/QF Loss                          424619
trainer/Policy Loss                       -2847.86
trainer/Raw Policy Loss                   -2847.86
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 2263.52
trainer/Q Predictions Std                   518.019
trainer/Q Predictions Max                  4000.3
trainer/Q Predictions Min                    55.3699
trainer/Q Targets Mean                     2676.95
trainer/Q Targets Std                       140.506
trainer/Q Targets Max                      3551.62
trainer/Q Targets Min                      1456.42
trainer/Bellman Errors Mean              424619
trainer/Bellman Errors Std                    1.02537e+06
trainer/Bellman Errors Max                    6.69595e+06
trainer/Bellman Errors Min                    0.0118563
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      42000
expl/num paths total                       1050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.392509
expl/Rewards Std                              0.61619
expl/Rewards Max                              1.57066
expl/Rewards Min                              0
expl/Returns Mean                            15.7004
expl/Returns Std                             19.5068
expl/Returns Max                             44.5855
expl/Returns Min                              0
expl/Actions Mean                             0.262542
expl/Actions Std                              0.797478
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.7004
expl/env_infos/final/reward_dist Mean         0.607901
expl/env_infos/final/reward_dist Std          0.756655
expl/env_infos/final/reward_dist Max          1.57066
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0011846
expl/env_infos/initial/reward_dist Std        0.00389003
expl/env_infos/initial/reward_dist Max        0.0181334
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.392509
expl/env_infos/reward_dist Std                0.61619
expl/env_infos/reward_dist Max                1.57066
expl/env_infos/reward_dist Min                0
eval/num steps total                       8400
eval/num paths total                        210
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.557076
eval/Rewards Std                              0.694884
eval/Rewards Max                              1.57039
eval/Rewards Min                              0
eval/Returns Mean                            22.283
eval/Returns Std                             22.1809
eval/Returns Max                             45.15
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.283
eval/env_infos/final/reward_dist Mean         0.790186
eval/env_infos/final/reward_dist Std          0.779343
eval/env_infos/final/reward_dist Max          1.57039
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000385097
eval/env_infos/initial/reward_dist Std        0.00077979
eval/env_infos/initial/reward_dist Max        0.00219819
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.557076
eval/env_infos/reward_dist Std                0.694884
eval/env_infos/reward_dist Max                1.57039
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00606155
time/evaluation sampling (s)                  3.38653
time/exploration sampling (s)                18.067
time/logging (s)                              0.00540154
time/saving (s)                               0.00102476
time/training (s)                             4.16388
time/epoch (s)                               25.6299
time/total (s)                              528.228
Epoch                                        20
---------------------------------------  ----------------
2023-08-05 00:30:22.533073 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 21 finished
---------------------------------------  ----------------
epoch                                        21
replay_buffer/size                        44000
trainer/QF Loss                          484212
trainer/Policy Loss                       -3211.57
trainer/Raw Policy Loss                   -3211.57
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 2575.79
trainer/Q Predictions Std                   549.176
trainer/Q Predictions Max                  4231.03
trainer/Q Predictions Min                    56.072
trainer/Q Targets Mean                     3024.38
trainer/Q Targets Std                       160.534
trainer/Q Targets Max                      4342.39
trainer/Q Targets Min                      1672.81
trainer/Bellman Errors Mean              484212
trainer/Bellman Errors Std                    1.15724e+06
trainer/Bellman Errors Max                    8.58138e+06
trainer/Bellman Errors Min                    4.673e-05
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      44000
expl/num paths total                       1100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.467455
expl/Rewards Std                              0.645737
expl/Rewards Max                              1.57061
expl/Rewards Min                              0
expl/Returns Mean                            18.6982
expl/Returns Std                             20.0197
expl/Returns Max                             43.6183
expl/Returns Min                              0
expl/Actions Mean                             0.282176
expl/Actions Std                              0.801859
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.6982
expl/env_infos/final/reward_dist Mean         0.716432
expl/env_infos/final/reward_dist Std          0.776911
expl/env_infos/final/reward_dist Max          1.57061
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000585047
expl/env_infos/initial/reward_dist Std        0.00307088
expl/env_infos/initial/reward_dist Max        0.0212444
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.467455
expl/env_infos/reward_dist Std                0.645737
expl/env_infos/reward_dist Max                1.57061
expl/env_infos/reward_dist Min                0
eval/num steps total                       8800
eval/num paths total                        220
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.445814
eval/Rewards Std                              0.660205
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            17.8325
eval/Returns Std                             21.8282
eval/Returns Max                             45.483
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.8325
eval/env_infos/final/reward_dist Mean         0.627607
eval/env_infos/final/reward_dist Std          0.768462
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00407359
eval/env_infos/initial/reward_dist Std        0.00815868
eval/env_infos/initial/reward_dist Max        0.021336
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.445814
eval/env_infos/reward_dist Std                0.660205
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00601068
time/evaluation sampling (s)                  3.43334
time/exploration sampling (s)                17.9337
time/logging (s)                              0.00791679
time/saving (s)                               0.00127248
time/training (s)                             4.8658
time/epoch (s)                               26.2481
time/total (s)                              554.478
Epoch                                        21
---------------------------------------  ----------------
2023-08-05 00:30:47.636120 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 22 finished
---------------------------------------  ----------------
epoch                                        22
replay_buffer/size                        46000
trainer/QF Loss                          620847
trainer/Policy Loss                       -3598.99
trainer/Raw Policy Loss                   -3598.99
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 2877.33
trainer/Q Predictions Std                   617.019
trainer/Q Predictions Max                  4481.32
trainer/Q Predictions Min                    59.2113
trainer/Q Targets Mean                     3387.82
trainer/Q Targets Std                       172.341
trainer/Q Targets Max                      4589.2
trainer/Q Targets Min                      1922.97
trainer/Bellman Errors Mean              620847
trainer/Bellman Errors Std                    1.48576e+06
trainer/Bellman Errors Max                    1.08746e+07
trainer/Bellman Errors Min                    0.0395909
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      46000
expl/num paths total                       1150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.436172
expl/Rewards Std                              0.639255
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            17.4469
expl/Returns Std                             20.2986
expl/Returns Max                             45.5455
expl/Returns Min                              0
expl/Actions Mean                             0.259348
expl/Actions Std                              0.802835
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.4469
expl/env_infos/final/reward_dist Mean         0.645888
expl/env_infos/final/reward_dist Std          0.763368
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000901352
expl/env_infos/initial/reward_dist Std        0.00348324
expl/env_infos/initial/reward_dist Max        0.0179782
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.436172
expl/env_infos/reward_dist Std                0.639255
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                       9200
eval/num paths total                        230
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.658333
eval/Rewards Std                              0.704552
eval/Rewards Max                              1.57063
eval/Rewards Min                              0
eval/Returns Mean                            26.3333
eval/Returns Std                             21.5184
eval/Returns Max                             45.0438
eval/Returns Min                              0.00026983
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.3333
eval/env_infos/final/reward_dist Mean         0.93389
eval/env_infos/final/reward_dist Std          0.762792
eval/env_infos/final/reward_dist Max          1.57063
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000489058
eval/env_infos/initial/reward_dist Std        0.00146717
eval/env_infos/initial/reward_dist Max        0.00489058
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.658333
eval/env_infos/reward_dist Std                0.704552
eval/env_infos/reward_dist Max                1.57063
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00608928
time/evaluation sampling (s)                  3.71995
time/exploration sampling (s)                17.2662
time/logging (s)                              0.005356
time/saving (s)                               0.000979084
time/training (s)                             4.09835
time/epoch (s)                               25.0969
time/total (s)                              579.578
Epoch                                        22
---------------------------------------  ----------------
2023-08-05 00:31:13.318095 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 23 finished
---------------------------------------  ----------------
epoch                                        23
replay_buffer/size                        48000
trainer/QF Loss                          812228
trainer/Policy Loss                       -4003.28
trainer/Raw Policy Loss                   -4003.28
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 3186.46
trainer/Q Predictions Std                   696.693
trainer/Q Predictions Max                  4963.14
trainer/Q Predictions Min                    63.3915
trainer/Q Targets Mean                     3770.28
trainer/Q Targets Std                       193.183
trainer/Q Targets Max                      5443.9
trainer/Q Targets Min                      2138.57
trainer/Bellman Errors Mean              812228
trainer/Bellman Errors Std                    1.91659e+06
trainer/Bellman Errors Max                    1.35843e+07
trainer/Bellman Errors Min                    0.00625706
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      48000
expl/num paths total                       1200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.399707
expl/Rewards Std                              0.615467
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            15.9883
expl/Returns Std                             19.3998
expl/Returns Max                             44.5897
expl/Returns Min                              0
expl/Actions Mean                             0.265323
expl/Actions Std                              0.806196
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.9883
expl/env_infos/final/reward_dist Mean         0.606675
expl/env_infos/final/reward_dist Std          0.753201
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00108257
expl/env_infos/initial/reward_dist Std        0.00301628
expl/env_infos/initial/reward_dist Max        0.013183
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.399707
expl/env_infos/reward_dist Std                0.615467
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                       9600
eval/num paths total                        240
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.69088
eval/Rewards Std                              0.698469
eval/Rewards Max                              1.57064
eval/Rewards Min                              0
eval/Returns Mean                            27.6352
eval/Returns Std                             21.1644
eval/Returns Max                             45.0882
eval/Returns Min                              0.00805428
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         27.6352
eval/env_infos/final/reward_dist Mean         1.00234
eval/env_infos/final/reward_dist Std          0.713651
eval/env_infos/final/reward_dist Max          1.57064
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000436129
eval/env_infos/initial/reward_dist Std        0.000731256
eval/env_infos/initial/reward_dist Max        0.00221773
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.69088
eval/env_infos/reward_dist Std                0.698469
eval/env_infos/reward_dist Max                1.57064
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595267
time/evaluation sampling (s)                  4.18433
time/exploration sampling (s)                17.4922
time/logging (s)                              0.00537554
time/saving (s)                               0.00104629
time/training (s)                             3.99069
time/epoch (s)                               25.6796
time/total (s)                              605.26
Epoch                                        23
---------------------------------------  ----------------
2023-08-05 00:31:39.393652 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 24 finished
---------------------------------------  ----------------
epoch                                        24
replay_buffer/size                        50000
trainer/QF Loss                          988954
trainer/Policy Loss                       -4457.45
trainer/Raw Policy Loss                   -4457.45
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 3557.28
trainer/Q Predictions Std                   780.531
trainer/Q Predictions Max                  6323.15
trainer/Q Predictions Min                    68.0109
trainer/Q Targets Mean                     4203.05
trainer/Q Targets Std                       215.529
trainer/Q Targets Max                      5637.41
trainer/Q Targets Min                      2398.29
trainer/Bellman Errors Mean              988954
trainer/Bellman Errors Std                    2.37788e+06
trainer/Bellman Errors Max                    1.83006e+07
trainer/Bellman Errors Min                    0.00672913
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      50000
expl/num paths total                       1250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.41283
expl/Rewards Std                              0.632264
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            16.5132
expl/Returns Std                             20.1129
expl/Returns Max                             44.4087
expl/Returns Min                              0
expl/Actions Mean                             0.263454
expl/Actions Std                              0.804318
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.5132
expl/env_infos/final/reward_dist Mean         0.62836
expl/env_infos/final/reward_dist Std          0.768559
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00104325
expl/env_infos/initial/reward_dist Std        0.00376274
expl/env_infos/initial/reward_dist Max        0.0219299
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.41283
expl/env_infos/reward_dist Std                0.632264
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      10000
eval/num paths total                        250
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.554142
eval/Rewards Std                              0.694605
eval/Rewards Max                              1.57036
eval/Rewards Min                              0
eval/Returns Mean                            22.1657
eval/Returns Std                             22.1499
eval/Returns Max                             44.6279
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.1657
eval/env_infos/final/reward_dist Mean         0.783728
eval/env_infos/final/reward_dist Std          0.783671
eval/env_infos/final/reward_dist Max          1.57036
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.554142
eval/env_infos/reward_dist Std                0.694605
eval/env_infos/reward_dist Max                1.57036
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00603101
time/evaluation sampling (s)                  4.42026
time/exploration sampling (s)                17.4919
time/logging (s)                              0.00539236
time/saving (s)                               0.00100093
time/training (s)                             4.14828
time/epoch (s)                               26.0729
time/total (s)                              631.335
Epoch                                        24
---------------------------------------  ----------------
2023-08-05 00:32:04.329705 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 25 finished
---------------------------------------  ---------------
epoch                                       25
replay_buffer/size                       52000
trainer/QF Loss                              1.04447e+06
trainer/Policy Loss                      -4922.61
trainer/Raw Policy Loss                  -4922.61
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                3975.46
trainer/Q Predictions Std                  789.325
trainer/Q Predictions Max                 6901.09
trainer/Q Predictions Min                   71.0704
trainer/Q Targets Mean                    4642.66
trainer/Q Targets Std                      238.683
trainer/Q Targets Max                     6599.92
trainer/Q Targets Min                     2621.96
trainer/Bellman Errors Mean                  1.04447e+06
trainer/Bellman Errors Std                   2.51059e+06
trainer/Bellman Errors Max                   2.06758e+07
trainer/Bellman Errors Min                   0.000774622
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     52000
expl/num paths total                      1300
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.582069
expl/Rewards Std                             0.677193
expl/Rewards Max                             1.57078
expl/Rewards Min                             0
expl/Returns Mean                           23.2828
expl/Returns Std                            19.9927
expl/Returns Max                            44.3631
expl/Returns Min                             0
expl/Actions Mean                            0.264134
expl/Actions Std                             0.800443
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        23.2828
expl/env_infos/final/reward_dist Mean        0.845732
expl/env_infos/final/reward_dist Std         0.780654
expl/env_infos/final/reward_dist Max         1.57078
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000869772
expl/env_infos/initial/reward_dist Std       0.00290299
expl/env_infos/initial/reward_dist Max       0.0146198
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.582069
expl/env_infos/reward_dist Std               0.677193
expl/env_infos/reward_dist Max               1.57078
expl/env_infos/reward_dist Min               0
eval/num steps total                     10400
eval/num paths total                       260
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.779318
eval/Rewards Std                             0.709904
eval/Rewards Max                             1.57062
eval/Rewards Min                             0
eval/Returns Mean                           31.1727
eval/Returns Std                            20.3976
eval/Returns Max                            45.1087
eval/Returns Min                             0.00392584
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        31.1727
eval/env_infos/final/reward_dist Mean        1.09857
eval/env_infos/final/reward_dist Std         0.719181
eval/env_infos/final/reward_dist Max         1.57062
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.00193501
eval/env_infos/initial/reward_dist Std       0.00580504
eval/env_infos/initial/reward_dist Max       0.0193501
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.779318
eval/env_infos/reward_dist Std               0.709904
eval/env_infos/reward_dist Max               1.57062
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00694701
time/evaluation sampling (s)                 3.53551
time/exploration sampling (s)               17.1088
time/logging (s)                             0.0054004
time/saving (s)                              0.000991229
time/training (s)                            4.27552
time/epoch (s)                              24.9332
time/total (s)                             656.27
Epoch                                       25
---------------------------------------  ---------------
2023-08-05 00:32:29.420693 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 26 finished
---------------------------------------  ---------------
epoch                                       26
replay_buffer/size                       54000
trainer/QF Loss                              1.38326e+06
trainer/Policy Loss                      -5428.28
trainer/Raw Policy Loss                  -5428.28
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                4356.83
trainer/Q Predictions Std                  910.768
trainer/Q Predictions Max                 7527.98
trainer/Q Predictions Min                   74.7563
trainer/Q Targets Mean                    5117.28
trainer/Q Targets Std                      281.469
trainer/Q Targets Max                     7724.35
trainer/Q Targets Min                     2950.1
trainer/Bellman Errors Mean                  1.38326e+06
trainer/Bellman Errors Std                   3.4076e+06
trainer/Bellman Errors Max                   2.73524e+07
trainer/Bellman Errors Min                   1.16825e-05
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     54000
expl/num paths total                      1350
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.385477
expl/Rewards Std                             0.610228
expl/Rewards Max                             1.57078
expl/Rewards Min                             0
expl/Returns Mean                           15.4191
expl/Returns Std                            19.3326
expl/Returns Max                            45.1923
expl/Returns Min                             0
expl/Actions Mean                            0.263589
expl/Actions Std                             0.806392
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        15.4191
expl/env_infos/final/reward_dist Mean        0.560474
expl/env_infos/final/reward_dist Std         0.74767
expl/env_infos/final/reward_dist Max         1.57078
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000907456
expl/env_infos/initial/reward_dist Std       0.00307023
expl/env_infos/initial/reward_dist Max       0.0142427
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.385477
expl/env_infos/reward_dist Std               0.610228
expl/env_infos/reward_dist Max               1.57078
expl/env_infos/reward_dist Min               0
eval/num steps total                     10800
eval/num paths total                       270
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.558146
eval/Rewards Std                             0.694558
eval/Rewards Max                             1.57077
eval/Rewards Min                             0
eval/Returns Mean                           22.3258
eval/Returns Std                            22.3165
eval/Returns Max                            45.3554
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        22.3258
eval/env_infos/final/reward_dist Mean        0.782973
eval/env_infos/final/reward_dist Std         0.782985
eval/env_infos/final/reward_dist Max         1.57077
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.00316339
eval/env_infos/initial/reward_dist Std       0.0083991
eval/env_infos/initial/reward_dist Max       0.0281694
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.558146
eval/env_infos/reward_dist Std               0.694558
eval/env_infos/reward_dist Max               1.57077
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00913155
time/evaluation sampling (s)                 3.44149
time/exploration sampling (s)               17.5003
time/logging (s)                             0.00530847
time/saving (s)                              0.00100415
time/training (s)                            4.13122
time/epoch (s)                              25.0884
time/total (s)                             681.361
Epoch                                       26
---------------------------------------  ---------------
2023-08-05 00:32:55.609206 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 27 finished
---------------------------------------  ---------------
epoch                                       27
replay_buffer/size                       56000
trainer/QF Loss                              1.55082e+06
trainer/Policy Loss                      -5964.02
trainer/Raw Policy Loss                  -5964.02
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                4809.71
trainer/Q Predictions Std                  972.071
trainer/Q Predictions Max                 8289.88
trainer/Q Predictions Min                   76.8855
trainer/Q Targets Mean                    5625.7
trainer/Q Targets Std                      295.509
trainer/Q Targets Max                     8407.17
trainer/Q Targets Min                     3204.94
trainer/Bellman Errors Mean                  1.55082e+06
trainer/Bellman Errors Std                   3.72511e+06
trainer/Bellman Errors Max                   3.0146e+07
trainer/Bellman Errors Min                   0.00906587
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     56000
expl/num paths total                      1400
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.417792
expl/Rewards Std                             0.614576
expl/Rewards Max                             1.57068
expl/Rewards Min                             0
expl/Returns Mean                           16.7117
expl/Returns Std                            19.1212
expl/Returns Max                            44.6766
expl/Returns Min                             0
expl/Actions Mean                            0.250456
expl/Actions Std                             0.809316
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        16.7117
expl/env_infos/final/reward_dist Mean        0.660513
expl/env_infos/final/reward_dist Std         0.759703
expl/env_infos/final/reward_dist Max         1.57068
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.00142058
expl/env_infos/initial/reward_dist Std       0.00401486
expl/env_infos/initial/reward_dist Max       0.0194981
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.417792
expl/env_infos/reward_dist Std               0.614576
expl/env_infos/reward_dist Max               1.57068
expl/env_infos/reward_dist Min               0
eval/num steps total                     11200
eval/num paths total                       280
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.553543
eval/Rewards Std                             0.694493
eval/Rewards Max                             1.57072
eval/Rewards Min                             0
eval/Returns Mean                           22.1417
eval/Returns Std                            22.1336
eval/Returns Max                            45.0125
eval/Returns Min                             0.00819032
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        22.1417
eval/env_infos/final/reward_dist Mean        0.784287
eval/env_infos/final/reward_dist Std         0.784288
eval/env_infos/final/reward_dist Max         1.57072
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.000133332
eval/env_infos/initial/reward_dist Std       0.000399997
eval/env_infos/initial/reward_dist Max       0.00133332
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.553543
eval/env_infos/reward_dist Std               0.694493
eval/env_infos/reward_dist Max               1.57072
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00601131
time/evaluation sampling (s)                 3.35629
time/exploration sampling (s)               18.0096
time/logging (s)                             0.00535996
time/saving (s)                              0.000976913
time/training (s)                            4.80776
time/epoch (s)                              26.186
time/total (s)                             707.549
Epoch                                       27
---------------------------------------  ---------------
2023-08-05 00:33:21.899267 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 28 finished
---------------------------------------  ---------------
epoch                                       28
replay_buffer/size                       58000
trainer/QF Loss                              1.90837e+06
trainer/Policy Loss                      -6523.87
trainer/Raw Policy Loss                  -6523.87
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                5251.94
trainer/Q Predictions Std                 1072.39
trainer/Q Predictions Max                 8908.39
trainer/Q Predictions Min                   80.5484
trainer/Q Targets Mean                    6161.65
trainer/Q Targets Std                      319.617
trainer/Q Targets Max                     8898.73
trainer/Q Targets Min                     3607.38
trainer/Bellman Errors Mean                  1.90837e+06
trainer/Bellman Errors Std                   4.65191e+06
trainer/Bellman Errors Max                   3.65643e+07
trainer/Bellman Errors Min                   0.054703
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     58000
expl/num paths total                      1450
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.410685
expl/Rewards Std                             0.617751
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           16.4274
expl/Returns Std                            19.4314
expl/Returns Max                            44.3736
expl/Returns Min                             0
expl/Actions Mean                            0.271477
expl/Actions Std                             0.803711
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        16.4274
expl/env_infos/final/reward_dist Mean        0.62291
expl/env_infos/final/reward_dist Std         0.762948
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000749271
expl/env_infos/initial/reward_dist Std       0.00269687
expl/env_infos/initial/reward_dist Max       0.0131831
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.410685
expl/env_infos/reward_dist Std               0.617751
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     11600
eval/num paths total                       290
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.562067
eval/Rewards Std                             0.696148
eval/Rewards Max                             1.57068
eval/Rewards Min                             0
eval/Returns Mean                           22.4827
eval/Returns Std                            22.4652
eval/Returns Max                            45.3063
eval/Returns Min                             0.00598244
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        22.4827
eval/env_infos/final/reward_dist Mean        0.784125
eval/env_infos/final/reward_dist Std         0.784128
eval/env_infos/final/reward_dist Max         1.57068
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.00202114
eval/env_infos/initial/reward_dist Std       0.00545056
eval/env_infos/initial/reward_dist Max       0.0182815
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.562067
eval/env_infos/reward_dist Std               0.696148
eval/env_infos/reward_dist Max               1.57068
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00601343
time/evaluation sampling (s)                 3.32663
time/exploration sampling (s)               18.0261
time/logging (s)                             0.00535457
time/saving (s)                              0.000990385
time/training (s)                            4.92253
time/epoch (s)                              26.2876
time/total (s)                             733.838
Epoch                                       28
---------------------------------------  ---------------
2023-08-05 00:33:47.374700 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 29 finished
---------------------------------------  ---------------
epoch                                       29
replay_buffer/size                       60000
trainer/QF Loss                              2.30432e+06
trainer/Policy Loss                      -7123.72
trainer/Raw Policy Loss                  -7123.72
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                5717.25
trainer/Q Predictions Std                 1169.97
trainer/Q Predictions Max                 9347.99
trainer/Q Predictions Min                   87.1792
trainer/Q Targets Mean                    6722.61
trainer/Q Targets Std                      358.225
trainer/Q Targets Max                     9641.26
trainer/Q Targets Min                     3801.73
trainer/Bellman Errors Mean                  2.30432e+06
trainer/Bellman Errors Std                   5.65192e+06
trainer/Bellman Errors Max                   4.31782e+07
trainer/Bellman Errors Min                   0.0827124
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     60000
expl/num paths total                      1500
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.352774
expl/Rewards Std                             0.577584
expl/Rewards Max                             1.57051
expl/Rewards Min                             0
expl/Returns Mean                           14.111
expl/Returns Std                            18.1374
expl/Returns Max                            44.0113
expl/Returns Min                             0
expl/Actions Mean                            0.259863
expl/Actions Std                             0.802469
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        14.111
expl/env_infos/final/reward_dist Mean        0.4849
expl/env_infos/final/reward_dist Std         0.714722
expl/env_infos/final/reward_dist Max         1.57051
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.00105041
expl/env_infos/initial/reward_dist Std       0.00390439
expl/env_infos/initial/reward_dist Max       0.0207688
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.352774
expl/env_infos/reward_dist Std               0.577584
expl/env_infos/reward_dist Max               1.57051
expl/env_infos/reward_dist Min               0
eval/num steps total                     12000
eval/num paths total                       300
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.540193
eval/Rewards Std                             0.676777
eval/Rewards Max                             1.5703
eval/Rewards Min                             0
eval/Returns Mean                           21.6077
eval/Returns Std                            21.3621
eval/Returns Max                            46.207
eval/Returns Min                             0.00767175
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        21.6077
eval/env_infos/final/reward_dist Mean        0.79635
eval/env_infos/final/reward_dist Std         0.758382
eval/env_infos/final/reward_dist Max         1.5703
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.00239058
eval/env_infos/initial/reward_dist Std       0.00473138
eval/env_infos/initial/reward_dist Max       0.0149985
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.540193
eval/env_infos/reward_dist Std               0.676777
eval/env_infos/reward_dist Max               1.5703
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00594589
time/evaluation sampling (s)                 3.46929
time/exploration sampling (s)               17.9491
time/logging (s)                             0.00537069
time/saving (s)                              0.00100122
time/training (s)                            4.04236
time/epoch (s)                              25.4731
time/total (s)                             759.313
Epoch                                       29
---------------------------------------  ---------------
2023-08-05 00:34:13.055795 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 30 finished
---------------------------------------  ---------------
epoch                                       30
replay_buffer/size                       62000
trainer/QF Loss                              2.75163e+06
trainer/Policy Loss                      -7743
trainer/Raw Policy Loss                  -7743
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                6215.6
trainer/Q Predictions Std                 1276.63
trainer/Q Predictions Max                10249.6
trainer/Q Predictions Min                   69.9279
trainer/Q Targets Mean                    7311.98
trainer/Q Targets Std                      368.526
trainer/Q Targets Max                    10506.4
trainer/Q Targets Min                     4107.56
trainer/Bellman Errors Mean                  2.75163e+06
trainer/Bellman Errors Std                   6.66664e+06
trainer/Bellman Errors Max                   6.22452e+07
trainer/Bellman Errors Min                   0.202236
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     62000
expl/num paths total                      1550
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.432807
expl/Rewards Std                             0.633062
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           17.3123
expl/Returns Std                            20.0208
expl/Returns Max                            45.5569
expl/Returns Min                             0
expl/Actions Mean                            0.26354
expl/Actions Std                             0.815159
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        17.3123
expl/env_infos/final/reward_dist Mean        0.623332
expl/env_infos/final/reward_dist Std         0.763735
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.00203974
expl/env_infos/initial/reward_dist Std       0.00504499
expl/env_infos/initial/reward_dist Max       0.0217758
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.432807
expl/env_infos/reward_dist Std               0.633062
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     12400
eval/num paths total                       310
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.88349
eval/Rewards Std                             0.692873
eval/Rewards Max                             1.57038
eval/Rewards Min                             0
eval/Returns Mean                           35.3396
eval/Returns Std                            17.6675
eval/Returns Max                            44.7131
eval/Returns Min                             0.00840702
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        35.3396
eval/env_infos/final/reward_dist Mean        1.25526
eval/env_infos/final/reward_dist Std         0.627633
eval/env_infos/final/reward_dist Max         1.57038
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.88349
eval/env_infos/reward_dist Std               0.692873
eval/env_infos/reward_dist Max               1.57038
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00605266
time/evaluation sampling (s)                 3.44815
time/exploration sampling (s)               17.9135
time/logging (s)                             0.00532898
time/saving (s)                              0.0010153
time/training (s)                            4.30465
time/epoch (s)                              25.6787
time/total (s)                             784.994
Epoch                                       30
---------------------------------------  ---------------
2023-08-05 00:34:38.155697 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 31 finished
---------------------------------------  ---------------
epoch                                       31
replay_buffer/size                       64000
trainer/QF Loss                              3.03529e+06
trainer/Policy Loss                      -8427.15
trainer/Raw Policy Loss                  -8427.15
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                6792.21
trainer/Q Predictions Std                 1330.38
trainer/Q Predictions Max                10361.5
trainer/Q Predictions Min                  103.004
trainer/Q Targets Mean                    7955.82
trainer/Q Targets Std                      444.222
trainer/Q Targets Max                    11085
trainer/Q Targets Min                     4471.97
trainer/Bellman Errors Mean                  3.03529e+06
trainer/Bellman Errors Std                   7.13646e+06
trainer/Bellman Errors Max                   6.02548e+07
trainer/Bellman Errors Min                   7.72476e-05
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     64000
expl/num paths total                      1600
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.407144
expl/Rewards Std                             0.61996
expl/Rewards Max                             1.57074
expl/Rewards Min                             0
expl/Returns Mean                           16.2858
expl/Returns Std                            19.3681
expl/Returns Max                            43.8006
expl/Returns Min                             0
expl/Actions Mean                            0.260382
expl/Actions Std                             0.803876
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        16.2858
expl/env_infos/final/reward_dist Mean        0.600311
expl/env_infos/final/reward_dist Std         0.758823
expl/env_infos/final/reward_dist Max         1.57074
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000140816
expl/env_infos/initial/reward_dist Std       0.000613463
expl/env_infos/initial/reward_dist Max       0.00378768
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.407144
expl/env_infos/reward_dist Std               0.61996
expl/env_infos/reward_dist Max               1.57074
expl/env_infos/reward_dist Min               0
eval/num steps total                     12800
eval/num paths total                       320
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.113117
eval/Rewards Std                             0.384129
eval/Rewards Max                             1.56911
eval/Rewards Min                             0
eval/Returns Mean                            4.5247
eval/Returns Std                            13.5392
eval/Returns Max                            45.1423
eval/Returns Min                             0.000180795
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         4.5247
eval/env_infos/final/reward_dist Mean        0.156918
eval/env_infos/final/reward_dist Std         0.47073
eval/env_infos/final/reward_dist Max         1.56911
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.00279007
eval/env_infos/initial/reward_dist Std       0.00831013
eval/env_infos/initial/reward_dist Max       0.0277199
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.113117
eval/env_infos/reward_dist Std               0.384129
eval/env_infos/reward_dist Max               1.56911
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00599961
time/evaluation sampling (s)                 3.39348
time/exploration sampling (s)               17.4824
time/logging (s)                             0.00542031
time/saving (s)                              0.00105041
time/training (s)                            4.20927
time/epoch (s)                              25.0976
time/total (s)                             810.093
Epoch                                       31
---------------------------------------  ---------------
2023-08-05 00:35:03.135267 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 32 finished
---------------------------------------  ---------------
epoch                                       32
replay_buffer/size                       66000
trainer/QF Loss                              3.70183e+06
trainer/Policy Loss                      -9116.52
trainer/Raw Policy Loss                  -9116.52
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                7340.4
trainer/Q Predictions Std                 1485.03
trainer/Q Predictions Max                11917.7
trainer/Q Predictions Min                   78.4745
trainer/Q Targets Mean                    8615.7
trainer/Q Targets Std                      450.479
trainer/Q Targets Max                    12231.8
trainer/Q Targets Min                     4816.61
trainer/Bellman Errors Mean                  3.70183e+06
trainer/Bellman Errors Std                   8.76007e+06
trainer/Bellman Errors Max                   8.62071e+07
trainer/Bellman Errors Min                   0.0385294
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     66000
expl/num paths total                      1650
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.494393
expl/Rewards Std                             0.650527
expl/Rewards Max                             1.57075
expl/Rewards Min                             0
expl/Returns Mean                           19.7757
expl/Returns Std                            19.9557
expl/Returns Max                            45.068
expl/Returns Min                             0
expl/Actions Mean                            0.261104
expl/Actions Std                             0.80001
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        19.7757
expl/env_infos/final/reward_dist Mean        0.771459
expl/env_infos/final/reward_dist Std         0.77325
expl/env_infos/final/reward_dist Max         1.57075
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.00193626
expl/env_infos/initial/reward_dist Std       0.00467765
expl/env_infos/initial/reward_dist Max       0.015954
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.494393
expl/env_infos/reward_dist Std               0.650527
expl/env_infos/reward_dist Max               1.57075
expl/env_infos/reward_dist Min               0
eval/num steps total                     13200
eval/num paths total                       330
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.444203
eval/Rewards Std                             0.66048
eval/Rewards Max                             1.56987
eval/Rewards Min                             0
eval/Returns Mean                           17.7681
eval/Returns Std                            21.7576
eval/Returns Max                            45.3944
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        17.7681
eval/env_infos/final/reward_dist Mean        0.627552
eval/env_infos/final/reward_dist Std         0.768591
eval/env_infos/final/reward_dist Max         1.56987
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.00118827
eval/env_infos/initial/reward_dist Std       0.0035648
eval/env_infos/initial/reward_dist Max       0.0118827
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.444203
eval/env_infos/reward_dist Std               0.66048
eval/env_infos/reward_dist Max               1.56987
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00607408
time/evaluation sampling (s)                 3.28865
time/exploration sampling (s)               17.4649
time/logging (s)                             0.00535805
time/saving (s)                              0.000983101
time/training (s)                            4.21121
time/epoch (s)                              24.9771
time/total (s)                             835.072
Epoch                                       32
---------------------------------------  ---------------
2023-08-05 00:35:28.382771 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 33 finished
---------------------------------------  ---------------
epoch                                       33
replay_buffer/size                       68000
trainer/QF Loss                              4.25243e+06
trainer/Policy Loss                      -9849.78
trainer/Raw Policy Loss                  -9849.78
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                7934.9
trainer/Q Predictions Std                 1592.08
trainer/Q Predictions Max                13841.6
trainer/Q Predictions Min                  110.341
trainer/Q Targets Mean                    9318.53
trainer/Q Targets Std                      495.538
trainer/Q Targets Max                    13659.6
trainer/Q Targets Min                     5292.21
trainer/Bellman Errors Mean                  4.25243e+06
trainer/Bellman Errors Std                   1.00502e+07
trainer/Bellman Errors Max                   8.28997e+07
trainer/Bellman Errors Min                   0.0563135
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942809
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     68000
expl/num paths total                      1700
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.36589
expl/Rewards Std                             0.605247
expl/Rewards Max                             1.57078
expl/Rewards Min                             0
expl/Returns Mean                           14.6356
expl/Returns Std                            19.5917
expl/Returns Max                            44.7538
expl/Returns Min                             0
expl/Actions Mean                            0.266793
expl/Actions Std                             0.803807
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        14.6356
expl/env_infos/final/reward_dist Mean        0.548796
expl/env_infos/final/reward_dist Std         0.732666
expl/env_infos/final/reward_dist Max         1.57078
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000866111
expl/env_infos/initial/reward_dist Std       0.00321052
expl/env_infos/initial/reward_dist Max       0.0192506
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.36589
expl/env_infos/reward_dist Std               0.605247
expl/env_infos/reward_dist Max               1.57078
expl/env_infos/reward_dist Min               0
eval/num steps total                     13600
eval/num paths total                       340
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.22715
eval/Rewards Std                             0.521838
eval/Rewards Max                             1.56988
eval/Rewards Min                             0
eval/Returns Mean                            9.08599
eval/Returns Std                            18.148
eval/Returns Max                            45.7731
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942809
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         9.08599
eval/env_infos/final/reward_dist Mean        0.313962
eval/env_infos/final/reward_dist Std         0.627924
eval/env_infos/final/reward_dist Max         1.56988
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.00245926
eval/env_infos/initial/reward_dist Std       0.00737778
eval/env_infos/initial/reward_dist Max       0.0245926
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.22715
eval/env_infos/reward_dist Std               0.521838
eval/env_infos/reward_dist Max               1.56988
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00592958
time/evaluation sampling (s)                 3.36836
time/exploration sampling (s)               17.6148
time/logging (s)                             0.00437868
time/saving (s)                              0.00998263
time/training (s)                            4.24053
time/epoch (s)                              25.244
time/total (s)                             860.318
Epoch                                       33
---------------------------------------  ---------------
2023-08-05 00:35:54.056930 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 34 finished
---------------------------------------  ----------------
epoch                                        34
replay_buffer/size                        70000
trainer/QF Loss                               4.69959e+06
trainer/Policy Loss                      -10613.6
trainer/Raw Policy Loss                  -10613.6
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 8584.2
trainer/Q Predictions Std                  1641.87
trainer/Q Predictions Max                 13120.1
trainer/Q Predictions Min                   110.798
trainer/Q Targets Mean                    10034.6
trainer/Q Targets Std                       527.063
trainer/Q Targets Max                     14443.1
trainer/Q Targets Min                      6322.78
trainer/Bellman Errors Mean                   4.69959e+06
trainer/Bellman Errors Std                    1.07847e+07
trainer/Bellman Errors Max                    9.63633e+07
trainer/Bellman Errors Min                    0.0416574
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      70000
expl/num paths total                       1750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.288573
expl/Rewards Std                              0.548411
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            11.5429
expl/Returns Std                             17.6187
expl/Returns Max                             43.861
expl/Returns Min                              0
expl/Actions Mean                             0.26026
expl/Actions Std                              0.811188
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         11.5429
expl/env_infos/final/reward_dist Mean         0.412975
expl/env_infos/final/reward_dist Std          0.686257
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00130202
expl/env_infos/initial/reward_dist Std        0.00434173
expl/env_infos/initial/reward_dist Max        0.0247158
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.288573
expl/env_infos/reward_dist Std                0.548411
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      14000
eval/num paths total                        350
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.420066
eval/Rewards Std                              0.63999
eval/Rewards Max                              1.57068
eval/Rewards Min                              0
eval/Returns Mean                            16.8027
eval/Returns Std                             20.7247
eval/Returns Max                             45.1529
eval/Returns Min                              0.00392824
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.8027
eval/env_infos/final/reward_dist Mean         0.620083
eval/env_infos/final/reward_dist Std          0.759768
eval/env_infos/final/reward_dist Max          1.57068
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000128846
eval/env_infos/initial/reward_dist Std        0.000386539
eval/env_infos/initial/reward_dist Max        0.00128846
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.420066
eval/env_infos/reward_dist Std                0.63999
eval/env_infos/reward_dist Max                1.57068
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00597271
time/evaluation sampling (s)                  3.44027
time/exploration sampling (s)                17.8841
time/logging (s)                              0.00539784
time/saving (s)                               0.00102338
time/training (s)                             4.33634
time/epoch (s)                               25.6731
time/total (s)                              885.993
Epoch                                        34
---------------------------------------  ----------------
2023-08-05 00:36:19.880650 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 35 finished
---------------------------------------  ----------------
epoch                                        35
replay_buffer/size                        72000
trainer/QF Loss                               5.51044e+06
trainer/Policy Loss                      -11422.1
trainer/Raw Policy Loss                  -11422.1
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 9252.21
trainer/Q Predictions Std                  1811.55
trainer/Q Predictions Max                 15528.5
trainer/Q Predictions Min                   116.516
trainer/Q Targets Mean                    10799.9
trainer/Q Targets Std                       545.158
trainer/Q Targets Max                     14393.1
trainer/Q Targets Min                      6253.38
trainer/Bellman Errors Mean                   5.51044e+06
trainer/Bellman Errors Std                    1.35782e+07
trainer/Bellman Errors Max                    1.12565e+08
trainer/Bellman Errors Min                    0.0457392
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      72000
expl/num paths total                       1800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.460899
expl/Rewards Std                              0.645226
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            18.436
expl/Returns Std                             20.2116
expl/Returns Max                             44.0906
expl/Returns Min                              0
expl/Actions Mean                             0.266832
expl/Actions Std                              0.813894
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.436
expl/env_infos/final/reward_dist Mean         0.684968
expl/env_infos/final/reward_dist Std          0.773057
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0020446
expl/env_infos/initial/reward_dist Std        0.00488949
expl/env_infos/initial/reward_dist Max        0.0220778
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.460899
expl/env_infos/reward_dist Std                0.645226
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      14400
eval/num paths total                        360
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.395625
eval/Rewards Std                              0.622098
eval/Rewards Max                              1.57067
eval/Rewards Min                              0
eval/Returns Mean                            15.825
eval/Returns Std                             19.6528
eval/Returns Max                             43.975
eval/Returns Min                              0.000114555
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         15.825
eval/env_infos/final/reward_dist Mean         0.617691
eval/env_infos/final/reward_dist Std          0.756996
eval/env_infos/final/reward_dist Max          1.56971
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.395625
eval/env_infos/reward_dist Std                0.622098
eval/env_infos/reward_dist Max                1.57067
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0059845
time/evaluation sampling (s)                  3.52865
time/exploration sampling (s)                17.9819
time/logging (s)                              0.0053678
time/saving (s)                               0.00103154
time/training (s)                             4.29836
time/epoch (s)                               25.8213
time/total (s)                              911.816
Epoch                                        35
---------------------------------------  ----------------
2023-08-05 00:36:45.521208 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 36 finished
---------------------------------------  ----------------
epoch                                        36
replay_buffer/size                        74000
trainer/QF Loss                               6.49129e+06
trainer/Policy Loss                      -12267.2
trainer/Raw Policy Loss                  -12267.2
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 9908.07
trainer/Q Predictions Std                  1969.03
trainer/Q Predictions Max                 15955.7
trainer/Q Predictions Min                   121.82
trainer/Q Targets Mean                    11589.1
trainer/Q Targets Std                       622.985
trainer/Q Targets Max                     16203.8
trainer/Q Targets Min                      6446.45
trainer/Bellman Errors Mean                   6.49129e+06
trainer/Bellman Errors Std                    1.58422e+07
trainer/Bellman Errors Max                    1.30633e+08
trainer/Bellman Errors Min                    0.042057
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      74000
expl/num paths total                       1850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.550545
expl/Rewards Std                              0.66549
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            22.0218
expl/Returns Std                             19.9285
expl/Returns Max                             45.2122
expl/Returns Min                              0
expl/Actions Mean                             0.244213
expl/Actions Std                              0.803078
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.0218
expl/env_infos/final/reward_dist Mean         0.842118
expl/env_infos/final/reward_dist Std          0.776916
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00197299
expl/env_infos/initial/reward_dist Std        0.00560007
expl/env_infos/initial/reward_dist Max        0.0255957
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.550545
expl/env_infos/reward_dist Std                0.66549
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      14800
eval/num paths total                        370
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.613595
eval/Rewards Std                              0.690348
eval/Rewards Max                              1.57066
eval/Rewards Min                              0
eval/Returns Mean                            24.5438
eval/Returns Std                             20.9718
eval/Returns Max                             45.2072
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.5438
eval/env_infos/final/reward_dist Mean         0.934186
eval/env_infos/final/reward_dist Std          0.762956
eval/env_infos/final/reward_dist Max          1.57066
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00100177
eval/env_infos/initial/reward_dist Std        0.00153758
eval/env_infos/initial/reward_dist Max        0.00359635
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.613595
eval/env_infos/reward_dist Std                0.690348
eval/env_infos/reward_dist Max                1.57066
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00601951
time/evaluation sampling (s)                  3.44152
time/exploration sampling (s)                18.0293
time/logging (s)                              0.00537865
time/saving (s)                               0.00100675
time/training (s)                             4.15498
time/epoch (s)                               25.6382
time/total (s)                              937.456
Epoch                                        36
---------------------------------------  ----------------
2023-08-05 00:37:10.523383 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 37 finished
---------------------------------------  ----------------
epoch                                        37
replay_buffer/size                        76000
trainer/QF Loss                               6.98624e+06
trainer/Policy Loss                      -13149.7
trainer/Raw Policy Loss                  -13149.7
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                10671.9
trainer/Q Predictions Std                  2029.74
trainer/Q Predictions Max                 16475.4
trainer/Q Predictions Min                   143.913
trainer/Q Targets Mean                    12435.1
trainer/Q Targets Std                       624.988
trainer/Q Targets Max                     17693.7
trainer/Q Targets Min                      7014.56
trainer/Bellman Errors Mean                   6.98624e+06
trainer/Bellman Errors Std                    1.64237e+07
trainer/Bellman Errors Max                    1.49393e+08
trainer/Bellman Errors Min                    0.805436
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      76000
expl/num paths total                       1900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.435853
expl/Rewards Std                              0.635719
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            17.4341
expl/Returns Std                             19.9237
expl/Returns Max                             44.2024
expl/Returns Min                              0
expl/Actions Mean                             0.270455
expl/Actions Std                              0.804463
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.4341
expl/env_infos/final/reward_dist Mean         0.657505
expl/env_infos/final/reward_dist Std          0.77222
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00101568
expl/env_infos/initial/reward_dist Std        0.00299584
expl/env_infos/initial/reward_dist Max        0.016515
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.435853
expl/env_infos/reward_dist Std                0.635719
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      15200
eval/num paths total                        380
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.704081
eval/Rewards Std                              0.689663
eval/Rewards Max                              1.57049
eval/Rewards Min                              0
eval/Returns Mean                            28.1632
eval/Returns Std                             19.4339
eval/Returns Max                             44.9622
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.1632
eval/env_infos/final/reward_dist Mean         1.08121
eval/env_infos/final/reward_dist Std          0.708549
eval/env_infos/final/reward_dist Max          1.57049
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00168469
eval/env_infos/initial/reward_dist Std        0.00357471
eval/env_infos/initial/reward_dist Max        0.0110935
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.704081
eval/env_infos/reward_dist Std                0.689663
eval/env_infos/reward_dist Max                1.57049
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594373
time/evaluation sampling (s)                  3.50251
time/exploration sampling (s)                17.4735
time/logging (s)                              0.00532618
time/saving (s)                               0.000979797
time/training (s)                             4.01151
time/epoch (s)                               24.9997
time/total (s)                              962.458
Epoch                                        37
---------------------------------------  ----------------
2023-08-05 00:37:36.064957 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 38 finished
---------------------------------------  ----------------
epoch                                        38
replay_buffer/size                        78000
trainer/QF Loss                               8.65267e+06
trainer/Policy Loss                      -14051.5
trainer/Raw Policy Loss                  -14051.5
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                11351.3
trainer/Q Predictions Std                  2268.94
trainer/Q Predictions Max                 17553.4
trainer/Q Predictions Min                   134.765
trainer/Q Targets Mean                    13300.2
trainer/Q Targets Std                       670.681
trainer/Q Targets Max                     18278.1
trainer/Q Targets Min                      7490.14
trainer/Bellman Errors Mean                   8.65267e+06
trainer/Bellman Errors Std                    2.12284e+07
trainer/Bellman Errors Max                    1.69984e+08
trainer/Bellman Errors Min                    0.055851
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      78000
expl/num paths total                       1950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.455631
expl/Rewards Std                              0.635552
expl/Rewards Max                              1.57071
expl/Rewards Min                              0
expl/Returns Mean                            18.2252
expl/Returns Std                             19.6712
expl/Returns Max                             44.5468
expl/Returns Min                              0
expl/Actions Mean                             0.253815
expl/Actions Std                              0.803646
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.2252
expl/env_infos/final/reward_dist Mean         0.683075
expl/env_infos/final/reward_dist Std          0.771165
expl/env_infos/final/reward_dist Max          1.57071
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00122843
expl/env_infos/initial/reward_dist Std        0.00357418
expl/env_infos/initial/reward_dist Max        0.0165982
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.455631
expl/env_infos/reward_dist Std                0.635552
expl/env_infos/reward_dist Max                1.57071
expl/env_infos/reward_dist Min                0
eval/num steps total                      15600
eval/num paths total                        390
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.527119
eval/Rewards Std                              0.677399
eval/Rewards Max                              1.56957
eval/Rewards Min                              0
eval/Returns Mean                            21.0848
eval/Returns Std                             21.3681
eval/Returns Max                             45.0541
eval/Returns Min                              0.000629967
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         21.0848
eval/env_infos/final/reward_dist Mean         0.776406
eval/env_infos/final/reward_dist Std          0.776688
eval/env_infos/final/reward_dist Max          1.56957
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00116832
eval/env_infos/initial/reward_dist Std        0.00283408
eval/env_infos/initial/reward_dist Max        0.00942777
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.527119
eval/env_infos/reward_dist Std                0.677399
eval/env_infos/reward_dist Max                1.56957
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594447
time/evaluation sampling (s)                  3.37931
time/exploration sampling (s)                18.0698
time/logging (s)                              0.0053462
time/saving (s)                               0.00100989
time/training (s)                             4.07755
time/epoch (s)                               25.539
time/total (s)                              987.999
Epoch                                        38
---------------------------------------  ----------------
2023-08-05 00:38:00.965075 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 39 finished
---------------------------------------  ----------------
epoch                                        39
replay_buffer/size                        80000
trainer/QF Loss                               8.90986e+06
trainer/Policy Loss                      -15061.9
trainer/Raw Policy Loss                  -15061.9
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                12242.6
trainer/Q Predictions Std                  2303.97
trainer/Q Predictions Max                 20886.9
trainer/Q Predictions Min                   134.813
trainer/Q Targets Mean                    14227.4
trainer/Q Targets Std                       801.852
trainer/Q Targets Max                     21292.9
trainer/Q Targets Min                      8173.57
trainer/Bellman Errors Mean                   8.90986e+06
trainer/Bellman Errors Std                    2.18643e+07
trainer/Bellman Errors Max                    1.96236e+08
trainer/Bellman Errors Min                    0.0478516
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      80000
expl/num paths total                       2000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.485486
expl/Rewards Std                              0.65014
expl/Rewards Max                              1.57071
expl/Rewards Min                              0
expl/Returns Mean                            19.4195
expl/Returns Std                             19.8948
expl/Returns Max                             45.1127
expl/Returns Min                              0
expl/Actions Mean                             0.282194
expl/Actions Std                              0.79367
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.4195
expl/env_infos/final/reward_dist Mean         0.743242
expl/env_infos/final/reward_dist Std          0.77429
expl/env_infos/final/reward_dist Max          1.57071
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00098353
expl/env_infos/initial/reward_dist Std        0.00399
expl/env_infos/initial/reward_dist Max        0.0221061
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.485486
expl/env_infos/reward_dist Std                0.65014
expl/env_infos/reward_dist Max                1.57071
expl/env_infos/reward_dist Min                0
eval/num steps total                      16000
eval/num paths total                        400
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.557578
eval/Rewards Std                              0.695483
eval/Rewards Max                              1.56993
eval/Rewards Min                              0
eval/Returns Mean                            22.3031
eval/Returns Std                             22.3013
eval/Returns Max                             45.2773
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.3031
eval/env_infos/final/reward_dist Mean         0.784319
eval/env_infos/final/reward_dist Std          0.784319
eval/env_infos/final/reward_dist Max          1.56993
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000786892
eval/env_infos/initial/reward_dist Std        0.00210541
eval/env_infos/initial/reward_dist Max        0.00706172
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.557578
eval/env_infos/reward_dist Std                0.695483
eval/env_infos/reward_dist Max                1.56993
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594278
time/evaluation sampling (s)                  3.32944
time/exploration sampling (s)                17.4203
time/logging (s)                              0.00539271
time/saving (s)                               0.00102119
time/training (s)                             4.13555
time/epoch (s)                               24.8977
time/total (s)                             1012.9
Epoch                                        39
---------------------------------------  ----------------
2023-08-05 00:38:26.368619 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 40 finished
---------------------------------------  ----------------
epoch                                        40
replay_buffer/size                        82000
trainer/QF Loss                               1.05878e+07
trainer/Policy Loss                      -16058.8
trainer/Raw Policy Loss                  -16058.8
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                13012.8
trainer/Q Predictions Std                  2494.04
trainer/Q Predictions Max                 20983
trainer/Q Predictions Min                   117.407
trainer/Q Targets Mean                    15197.6
trainer/Q Targets Std                       807.336
trainer/Q Targets Max                     20608.3
trainer/Q Targets Min                      8735.48
trainer/Bellman Errors Mean                   1.05878e+07
trainer/Bellman Errors Std                    2.52376e+07
trainer/Bellman Errors Max                    2.6844e+08
trainer/Bellman Errors Min                    0.647522
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      82000
expl/num paths total                       2050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.396385
expl/Rewards Std                              0.614307
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            15.8554
expl/Returns Std                             19.5022
expl/Returns Max                             46.2148
expl/Returns Min                              0
expl/Actions Mean                             0.262723
expl/Actions Std                              0.808124
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.8554
expl/env_infos/final/reward_dist Mean         0.6221
expl/env_infos/final/reward_dist Std          0.762135
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00172872
expl/env_infos/initial/reward_dist Std        0.00448579
expl/env_infos/initial/reward_dist Max        0.0185312
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.396385
expl/env_infos/reward_dist Std                0.614307
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      16400
eval/num paths total                        410
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.638244
eval/Rewards Std                              0.697532
eval/Rewards Max                              1.57065
eval/Rewards Min                              0
eval/Returns Mean                            25.5298
eval/Returns Std                             21.3188
eval/Returns Max                             46.1774
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.5298
eval/env_infos/final/reward_dist Mean         0.9321
eval/env_infos/final/reward_dist Std          0.761588
eval/env_infos/final/reward_dist Max          1.57065
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00429531
eval/env_infos/initial/reward_dist Std        0.00743986
eval/env_infos/initial/reward_dist Max        0.0221532
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.638244
eval/env_infos/reward_dist Std                0.697532
eval/env_infos/reward_dist Max                1.57065
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596402
time/evaluation sampling (s)                  3.49138
time/exploration sampling (s)                17.7722
time/logging (s)                              0.00527699
time/saving (s)                               0.00096935
time/training (s)                             4.12532
time/epoch (s)                               25.4011
time/total (s)                             1038.3
Epoch                                        40
---------------------------------------  ----------------
2023-08-05 00:38:52.183905 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 41 finished
---------------------------------------  ----------------
epoch                                        41
replay_buffer/size                        84000
trainer/QF Loss                               1.17121e+07
trainer/Policy Loss                      -17066.5
trainer/Raw Policy Loss                  -17066.5
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                13800.8
trainer/Q Predictions Std                  2576.91
trainer/Q Predictions Max                 21867.9
trainer/Q Predictions Min                   161.605
trainer/Q Targets Mean                    16140.6
trainer/Q Targets Std                       861.405
trainer/Q Targets Max                     22591.7
trainer/Q Targets Min                      8878.58
trainer/Bellman Errors Mean                   1.17121e+07
trainer/Bellman Errors Std                    2.67675e+07
trainer/Bellman Errors Max                    2.4713e+08
trainer/Bellman Errors Min                    0.92904
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      84000
expl/num paths total                       2100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.513081
expl/Rewards Std                              0.656905
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            20.5232
expl/Returns Std                             19.7181
expl/Returns Max                             44.5671
expl/Returns Min                              0
expl/Actions Mean                             0.255962
expl/Actions Std                              0.802877
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.5232
expl/env_infos/final/reward_dist Mean         0.758551
expl/env_infos/final/reward_dist Std          0.779233
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000549487
expl/env_infos/initial/reward_dist Std        0.0022589
expl/env_infos/initial/reward_dist Max        0.0113957
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.513081
expl/env_infos/reward_dist Std                0.656905
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      16800
eval/num paths total                        420
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.660261
eval/Rewards Std                              0.708385
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            26.4104
eval/Returns Std                             21.6072
eval/Returns Max                             45.5376
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.4104
eval/env_infos/final/reward_dist Mean         0.941909
eval/env_infos/final/reward_dist Std          0.769066
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0033749
eval/env_infos/initial/reward_dist Std        0.00683563
eval/env_infos/initial/reward_dist Max        0.0192891
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.660261
eval/env_infos/reward_dist Std                0.708385
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0060241
time/evaluation sampling (s)                  3.47353
time/exploration sampling (s)                18.1654
time/logging (s)                              0.00538243
time/saving (s)                               0.000990486
time/training (s)                             4.16172
time/epoch (s)                               25.813
time/total (s)                             1064.12
Epoch                                        41
---------------------------------------  ----------------
2023-08-05 00:39:17.612787 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 42 finished
---------------------------------------  ----------------
epoch                                        42
replay_buffer/size                        86000
trainer/QF Loss                               1.32943e+07
trainer/Policy Loss                      -18174.3
trainer/Raw Policy Loss                  -18174.3
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                14749.9
trainer/Q Predictions Std                  2800.08
trainer/Q Predictions Max                 25355.4
trainer/Q Predictions Min                   170.784
trainer/Q Targets Mean                    17192.5
trainer/Q Targets Std                       913.476
trainer/Q Targets Max                     24641.4
trainer/Q Targets Min                      9556.79
trainer/Bellman Errors Mean                   1.32943e+07
trainer/Bellman Errors Std                    3.1451e+07
trainer/Bellman Errors Max                    2.90059e+08
trainer/Bellman Errors Min                    0.013279
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      86000
expl/num paths total                       2150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.362982
expl/Rewards Std                              0.588212
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            14.5193
expl/Returns Std                             18.3588
expl/Returns Max                             43.7147
expl/Returns Min                              0
expl/Actions Mean                             0.271679
expl/Actions Std                              0.798061
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.5193
expl/env_infos/final/reward_dist Mean         0.556914
expl/env_infos/final/reward_dist Std          0.742211
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00084751
expl/env_infos/initial/reward_dist Std        0.00296063
expl/env_infos/initial/reward_dist Max        0.0140073
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.362982
expl/env_infos/reward_dist Std                0.588212
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      17200
eval/num paths total                        430
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.676991
eval/Rewards Std                              0.711636
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            27.0796
eval/Returns Std                             22.1175
eval/Returns Max                             46.7222
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         27.0796
eval/env_infos/final/reward_dist Mean         0.94072
eval/env_infos/final/reward_dist Std          0.768098
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00748049
eval/env_infos/initial/reward_dist Std        0.00987118
eval/env_infos/initial/reward_dist Max        0.0277786
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.676991
eval/env_infos/reward_dist Std                0.711636
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596387
time/evaluation sampling (s)                  3.37786
time/exploration sampling (s)                17.7766
time/logging (s)                              0.00536606
time/saving (s)                               0.00097877
time/training (s)                             4.25963
time/epoch (s)                               25.4264
time/total (s)                             1089.54
Epoch                                        42
---------------------------------------  ----------------
2023-08-05 00:39:42.837223 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 43 finished
---------------------------------------  ----------------
epoch                                        43
replay_buffer/size                        88000
trainer/QF Loss                               1.45074e+07
trainer/Policy Loss                      -19290.1
trainer/Raw Policy Loss                  -19290.1
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                15679.1
trainer/Q Predictions Std                  2875.58
trainer/Q Predictions Max                 27552
trainer/Q Predictions Min                   154.107
trainer/Q Targets Mean                    18244.4
trainer/Q Targets Std                       984.549
trainer/Q Targets Max                     26315.5
trainer/Q Targets Min                     10032.3
trainer/Bellman Errors Mean                   1.45074e+07
trainer/Bellman Errors Std                    3.37388e+07
trainer/Bellman Errors Max                    3.24133e+08
trainer/Bellman Errors Min                    0.100113
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      88000
expl/num paths total                       2200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.501522
expl/Rewards Std                              0.649771
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            20.0609
expl/Returns Std                             19.7198
expl/Returns Max                             45.6002
expl/Returns Min                              0
expl/Actions Mean                             0.271854
expl/Actions Std                              0.798484
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.0609
expl/env_infos/final/reward_dist Mean         0.746336
expl/env_infos/final/reward_dist Std          0.777374
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000969956
expl/env_infos/initial/reward_dist Std        0.00366961
expl/env_infos/initial/reward_dist Max        0.0227579
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.501522
expl/env_infos/reward_dist Std                0.649771
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      17600
eval/num paths total                        440
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.994536
eval/Rewards Std                              0.647194
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            39.7814
eval/Returns Std                             13.3291
eval/Returns Max                             45.1716
eval/Returns Min                              0.0156872
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         39.7814
eval/env_infos/final/reward_dist Mean         1.40305
eval/env_infos/final/reward_dist Std          0.468446
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00290769
eval/env_infos/initial/reward_dist Std        0.00565141
eval/env_infos/initial/reward_dist Max        0.0178043
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.994536
eval/env_infos/reward_dist Std                0.647194
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00691793
time/evaluation sampling (s)                  3.42413
time/exploration sampling (s)                17.5579
time/logging (s)                              0.00543813
time/saving (s)                               0.0010176
time/training (s)                             4.22666
time/epoch (s)                               25.222
time/total (s)                             1114.77
Epoch                                        43
---------------------------------------  ----------------
2023-08-05 00:40:08.248215 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 44 finished
---------------------------------------  ----------------
epoch                                        44
replay_buffer/size                        90000
trainer/QF Loss                               1.5873e+07
trainer/Policy Loss                      -20459.2
trainer/Raw Policy Loss                  -20459.2
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                16651.6
trainer/Q Predictions Std                  2969.11
trainer/Q Predictions Max                 24915.7
trainer/Q Predictions Min                   166.357
trainer/Q Targets Mean                    19368.9
trainer/Q Targets Std                       994.636
trainer/Q Targets Max                     27553.4
trainer/Q Targets Min                     10589.3
trainer/Bellman Errors Mean                   1.5873e+07
trainer/Bellman Errors Std                    3.75377e+07
trainer/Bellman Errors Max                    3.59011e+08
trainer/Bellman Errors Min                    0.454044
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      90000
expl/num paths total                       2250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.545642
expl/Rewards Std                              0.669
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            21.8257
expl/Returns Std                             20.3002
expl/Returns Max                             44.9253
expl/Returns Min                              0
expl/Actions Mean                             0.264004
expl/Actions Std                              0.8012
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.8257
expl/env_infos/final/reward_dist Mean         0.787732
expl/env_infos/final/reward_dist Std          0.775228
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000923289
expl/env_infos/initial/reward_dist Std        0.00346492
expl/env_infos/initial/reward_dist Max        0.0219545
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.545642
expl/env_infos/reward_dist Std                0.669
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      18000
eval/num paths total                        450
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.00229
eval/Rewards Std                              0.651097
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            40.0917
eval/Returns Std                             13.366
eval/Returns Max                             45.5498
eval/Returns Min                              0.0369765
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         40.0917
eval/env_infos/final/reward_dist Mean         1.41195
eval/env_infos/final/reward_dist Std          0.470651
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00420558
eval/env_infos/initial/reward_dist Std        0.00844383
eval/env_infos/initial/reward_dist Max        0.022687
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.00229
eval/env_infos/reward_dist Std                0.651097
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00599157
time/evaluation sampling (s)                  3.48175
time/exploration sampling (s)                17.593
time/logging (s)                              0.00532194
time/saving (s)                               0.000977244
time/training (s)                             4.32127
time/epoch (s)                               25.4083
time/total (s)                             1140.18
Epoch                                        44
---------------------------------------  ----------------
2023-08-05 00:40:34.387104 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 45 finished
---------------------------------------  ----------------
epoch                                        45
replay_buffer/size                        92000
trainer/QF Loss                               1.9368e+07
trainer/Policy Loss                      -21711.2
trainer/Raw Policy Loss                  -21711.2
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                17598.8
trainer/Q Predictions Std                  3383.22
trainer/Q Predictions Max                 27193.1
trainer/Q Predictions Min                   143.601
trainer/Q Targets Mean                    20572.8
trainer/Q Targets Std                      1114.99
trainer/Q Targets Max                     29472.9
trainer/Q Targets Min                     11400.2
trainer/Bellman Errors Mean                   1.9368e+07
trainer/Bellman Errors Std                    4.68143e+07
trainer/Bellman Errors Max                    4.9208e+08
trainer/Bellman Errors Min                    0.0214577
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      92000
expl/num paths total                       2300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.368888
expl/Rewards Std                              0.599162
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            14.7555
expl/Returns Std                             18.8981
expl/Returns Max                             44.5308
expl/Returns Min                              0
expl/Actions Mean                             0.25112
expl/Actions Std                              0.804862
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.7555
expl/env_infos/final/reward_dist Mean         0.561873
expl/env_infos/final/reward_dist Std          0.74916
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00085782
expl/env_infos/initial/reward_dist Std        0.00249479
expl/env_infos/initial/reward_dist Max        0.0108304
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.368888
expl/env_infos/reward_dist Std                0.599162
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      18400
eval/num paths total                        460
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.777907
eval/Rewards Std                              0.710727
eval/Rewards Max                              1.57055
eval/Rewards Min                              0
eval/Returns Mean                            31.1163
eval/Returns Std                             20.3643
eval/Returns Max                             45.4607
eval/Returns Min                              0.00693839
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.1163
eval/env_infos/final/reward_dist Mean         1.0984
eval/env_infos/final/reward_dist Std          0.719073
eval/env_infos/final/reward_dist Max          1.57055
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00132717
eval/env_infos/initial/reward_dist Std        0.0039815
eval/env_infos/initial/reward_dist Max        0.0132717
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.777907
eval/env_infos/reward_dist Std                0.710727
eval/env_infos/reward_dist Max                1.57055
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589798
time/evaluation sampling (s)                  3.4808
time/exploration sampling (s)                18.3763
time/logging (s)                              0.00536874
time/saving (s)                               0.00100249
time/training (s)                             4.26718
time/epoch (s)                               26.1365
time/total (s)                             1166.32
Epoch                                        45
---------------------------------------  ----------------
2023-08-05 00:40:59.527892 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 46 finished
---------------------------------------  ----------------
epoch                                        46
replay_buffer/size                        94000
trainer/QF Loss                               2.07995e+07
trainer/Policy Loss                      -22948.4
trainer/Raw Policy Loss                  -22948.4
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                18623.7
trainer/Q Predictions Std                  3414.22
trainer/Q Predictions Max                 29825.4
trainer/Q Predictions Min                   185.166
trainer/Q Targets Mean                    21741.9
trainer/Q Targets Std                      1189.17
trainer/Q Targets Max                     31253.4
trainer/Q Targets Min                     11953.6
trainer/Bellman Errors Mean                   2.07995e+07
trainer/Bellman Errors Std                    4.78172e+07
trainer/Bellman Errors Max                    4.49899e+08
trainer/Bellman Errors Min                    0.0858307
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      94000
expl/num paths total                       2350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.673312
expl/Rewards Std                              0.68908
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            26.9325
expl/Returns Std                             19.3621
expl/Returns Max                             44.6334
expl/Returns Min                              0
expl/Actions Mean                             0.253136
expl/Actions Std                              0.79852
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.9325
expl/env_infos/final/reward_dist Mean         1.00511
expl/env_infos/final/reward_dist Std          0.751568
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000648959
expl/env_infos/initial/reward_dist Std        0.00207258
expl/env_infos/initial/reward_dist Max        0.0115281
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.673312
expl/env_infos/reward_dist Std                0.68908
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      18800
eval/num paths total                        470
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.779681
eval/Rewards Std                              0.710198
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            31.1873
eval/Returns Std                             20.4054
eval/Returns Max                             45.0506
eval/Returns Min                              0.0111833
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.1873
eval/env_infos/final/reward_dist Mean         1.09763
eval/env_infos/final/reward_dist Std          0.718571
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000172102
eval/env_infos/initial/reward_dist Std        0.000516307
eval/env_infos/initial/reward_dist Max        0.00172102
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.779681
eval/env_infos/reward_dist Std                0.710198
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590259
time/evaluation sampling (s)                  3.38047
time/exploration sampling (s)                17.4504
time/logging (s)                              0.00537642
time/saving (s)                               0.0010055
time/training (s)                             4.29514
time/epoch (s)                               25.1383
time/total (s)                             1191.46
Epoch                                        46
---------------------------------------  ----------------
2023-08-05 00:41:24.971935 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 47 finished
---------------------------------------  ----------------
epoch                                        47
replay_buffer/size                        96000
trainer/QF Loss                               2.2576e+07
trainer/Policy Loss                      -24244
trainer/Raw Policy Loss                  -24244
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                19747.1
trainer/Q Predictions Std                  3552.64
trainer/Q Predictions Max                 30841.6
trainer/Q Predictions Min                   210.909
trainer/Q Targets Mean                    22960.6
trainer/Q Targets Std                      1313.33
trainer/Q Targets Max                     32236.8
trainer/Q Targets Min                     11614.5
trainer/Bellman Errors Mean                   2.2576e+07
trainer/Bellman Errors Std                    5.16595e+07
trainer/Bellman Errors Max                    5.03812e+08
trainer/Bellman Errors Min                    0.02565
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      96000
expl/num paths total                       2400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.559475
expl/Rewards Std                              0.675649
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            22.379
expl/Returns Std                             20.3694
expl/Returns Max                             45.6621
expl/Returns Min                              0
expl/Actions Mean                             0.26595
expl/Actions Std                              0.795895
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.379
expl/env_infos/final/reward_dist Mean         0.84354
expl/env_infos/final/reward_dist Std          0.778671
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00305486
expl/env_infos/initial/reward_dist Std        0.00805157
expl/env_infos/initial/reward_dist Max        0.0377721
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.559475
expl/env_infos/reward_dist Std                0.675649
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      19200
eval/num paths total                        480
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.662507
eval/Rewards Std                              0.710792
eval/Rewards Max                              1.57054
eval/Rewards Min                              0
eval/Returns Mean                            26.5003
eval/Returns Std                             21.6285
eval/Returns Max                             44.8762
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.5003
eval/env_infos/final/reward_dist Mean         0.941328
eval/env_infos/final/reward_dist Std          0.768368
eval/env_infos/final/reward_dist Max          1.57054
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.662507
eval/env_infos/reward_dist Std                0.710792
eval/env_infos/reward_dist Max                1.57054
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00664646
time/evaluation sampling (s)                  3.49872
time/exploration sampling (s)                17.5922
time/logging (s)                              0.00534071
time/saving (s)                               0.00100931
time/training (s)                             4.3377
time/epoch (s)                               25.4416
time/total (s)                             1216.9
Epoch                                        47
---------------------------------------  ----------------
2023-08-05 00:41:50.338677 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 48 finished
---------------------------------------  ----------------
epoch                                        48
replay_buffer/size                        98000
trainer/QF Loss                               2.52053e+07
trainer/Policy Loss                      -25578.1
trainer/Raw Policy Loss                  -25578.1
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                20822.5
trainer/Q Predictions Std                  3758.14
trainer/Q Predictions Max                 35933.1
trainer/Q Predictions Min                   194.922
trainer/Q Targets Mean                    24227.3
trainer/Q Targets Std                      1236.44
trainer/Q Targets Max                     35382.1
trainer/Q Targets Min                     13445.6
trainer/Bellman Errors Mean                   2.52053e+07
trainer/Bellman Errors Std                    5.90722e+07
trainer/Bellman Errors Max                    5.78752e+08
trainer/Bellman Errors Min                    0.604263
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      98000
expl/num paths total                       2450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.558319
expl/Rewards Std                              0.665007
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            22.3328
expl/Returns Std                             19.356
expl/Returns Max                             44.27
expl/Returns Min                              0
expl/Actions Mean                             0.263074
expl/Actions Std                              0.806439
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.3328
expl/env_infos/final/reward_dist Mean         0.84783
expl/env_infos/final/reward_dist Std          0.770561
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00065443
expl/env_infos/initial/reward_dist Std        0.00249402
expl/env_infos/initial/reward_dist Max        0.0136623
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.558319
expl/env_infos/reward_dist Std                0.665007
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      19600
eval/num paths total                        490
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.535798
eval/Rewards Std                              0.681929
eval/Rewards Max                              1.56981
eval/Rewards Min                              0
eval/Returns Mean                            21.4319
eval/Returns Std                             21.545
eval/Returns Max                             45.0987
eval/Returns Min                              0.0022091
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         21.4319
eval/env_infos/final/reward_dist Mean         0.777089
eval/env_infos/final/reward_dist Std          0.77736
eval/env_infos/final/reward_dist Max          1.56981
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00124282
eval/env_infos/initial/reward_dist Std        0.00372847
eval/env_infos/initial/reward_dist Max        0.0124282
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.535798
eval/env_infos/reward_dist Std                0.681929
eval/env_infos/reward_dist Max                1.56981
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587919
time/evaluation sampling (s)                  3.55225
time/exploration sampling (s)                17.7244
time/logging (s)                              0.00530014
time/saving (s)                               0.000964439
time/training (s)                             4.07541
time/epoch (s)                               25.3642
time/total (s)                             1242.27
Epoch                                        48
---------------------------------------  ----------------
2023-08-05 00:42:15.625921 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 49 finished
---------------------------------------  ----------------
epoch                                        49
replay_buffer/size                       100000
trainer/QF Loss                               2.89854e+07
trainer/Policy Loss                      -26999.2
trainer/Raw Policy Loss                  -26999.2
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                21899.9
trainer/Q Predictions Std                  4038.82
trainer/Q Predictions Max                 32994.6
trainer/Q Predictions Min                   217.116
trainer/Q Targets Mean                    25547.7
trainer/Q Targets Std                      1476
trainer/Q Targets Max                     37306.7
trainer/Q Targets Min                     13911.8
trainer/Bellman Errors Mean                   2.89854e+07
trainer/Bellman Errors Std                    6.60266e+07
trainer/Bellman Errors Max                    6.31193e+08
trainer/Bellman Errors Min                   22.3404
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     100000
expl/num paths total                       2500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.319698
expl/Rewards Std                              0.579611
expl/Rewards Max                              1.57063
expl/Rewards Min                              0
expl/Returns Mean                            12.7879
expl/Returns Std                             18.9801
expl/Returns Max                             44.8544
expl/Returns Min                              0
expl/Actions Mean                             0.262637
expl/Actions Std                              0.802102
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.7879
expl/env_infos/final/reward_dist Mean         0.474666
expl/env_infos/final/reward_dist Std          0.717189
expl/env_infos/final/reward_dist Max          1.57063
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00164827
expl/env_infos/initial/reward_dist Std        0.00357978
expl/env_infos/initial/reward_dist Max        0.011051
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.319698
expl/env_infos/reward_dist Std                0.579611
expl/env_infos/reward_dist Max                1.57063
expl/env_infos/reward_dist Min                0
eval/num steps total                      20000
eval/num paths total                        500
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.769826
eval/Rewards Std                              0.703876
eval/Rewards Max                              1.57046
eval/Rewards Min                              0
eval/Returns Mean                            30.793
eval/Returns Std                             20.1455
eval/Returns Max                             44.865
eval/Returns Min                              0.00742658
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.793
eval/env_infos/final/reward_dist Mean         1.09127
eval/env_infos/final/reward_dist Std          0.713864
eval/env_infos/final/reward_dist Max          1.57046
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000509091
eval/env_infos/initial/reward_dist Std        0.00152727
eval/env_infos/initial/reward_dist Max        0.00509091
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.769826
eval/env_infos/reward_dist Std                0.703876
eval/env_infos/reward_dist Max                1.57046
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00607815
time/evaluation sampling (s)                  3.54626
time/exploration sampling (s)                17.5132
time/logging (s)                              0.00533542
time/saving (s)                               0.000978594
time/training (s)                             4.21293
time/epoch (s)                               25.2848
time/total (s)                             1267.55
Epoch                                        49
---------------------------------------  ----------------
2023-08-05 00:42:40.850899 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 50 finished
---------------------------------------  ----------------
epoch                                        50
replay_buffer/size                       102000
trainer/QF Loss                               3.26806e+07
trainer/Policy Loss                      -28478.7
trainer/Raw Policy Loss                  -28478.7
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                23074
trainer/Q Predictions Std                  4282.87
trainer/Q Predictions Max                 40370.7
trainer/Q Predictions Min                   192.392
trainer/Q Targets Mean                    26953.7
trainer/Q Targets Std                      1490.09
trainer/Q Targets Max                     38452.3
trainer/Q Targets Min                     14778.9
trainer/Bellman Errors Mean                   3.26806e+07
trainer/Bellman Errors Std                    7.65721e+07
trainer/Bellman Errors Max                    7.15669e+08
trainer/Bellman Errors Min                    4.33485
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     102000
expl/num paths total                       2550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.523298
expl/Rewards Std                              0.66939
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            20.9319
expl/Returns Std                             20.6679
expl/Returns Max                             44.6107
expl/Returns Min                              0
expl/Actions Mean                             0.267763
expl/Actions Std                              0.798415
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.9319
expl/env_infos/final/reward_dist Mean         0.783594
expl/env_infos/final/reward_dist Std          0.781978
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00236869
expl/env_infos/initial/reward_dist Std        0.00650995
expl/env_infos/initial/reward_dist Max        0.028473
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.523298
expl/env_infos/reward_dist Std                0.66939
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      20400
eval/num paths total                        510
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.561796
eval/Rewards Std                              0.69691
eval/Rewards Max                              1.5696
eval/Rewards Min                              0
eval/Returns Mean                            22.4719
eval/Returns Std                             22.4583
eval/Returns Max                             46.3521
eval/Returns Min                              0.00058066
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.4719
eval/env_infos/final/reward_dist Mean         0.784724
eval/env_infos/final/reward_dist Std          0.784064
eval/env_infos/final/reward_dist Max          1.5696
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00458162
eval/env_infos/initial/reward_dist Std        0.0105317
eval/env_infos/initial/reward_dist Max        0.0345168
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.561796
eval/env_infos/reward_dist Std                0.69691
eval/env_infos/reward_dist Max                1.5696
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00687314
time/evaluation sampling (s)                  3.43117
time/exploration sampling (s)                17.3855
time/logging (s)                              0.00537271
time/saving (s)                               0.000990394
time/training (s)                             4.39261
time/epoch (s)                               25.2225
time/total (s)                             1292.78
Epoch                                        50
---------------------------------------  ----------------
2023-08-05 00:43:06.159544 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 51 finished
---------------------------------------  ----------------
epoch                                        51
replay_buffer/size                       104000
trainer/QF Loss                               3.60158e+07
trainer/Policy Loss                      -29935.7
trainer/Raw Policy Loss                  -29935.7
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                24264.5
trainer/Q Predictions Std                  4506.87
trainer/Q Predictions Max                 39739
trainer/Q Predictions Min                   208.315
trainer/Q Targets Mean                    28343.8
trainer/Q Targets Std                      1525.72
trainer/Q Targets Max                     41435.9
trainer/Q Targets Min                     15373.4
trainer/Bellman Errors Mean                   3.60158e+07
trainer/Bellman Errors Std                    8.42157e+07
trainer/Bellman Errors Max                    7.71588e+08
trainer/Bellman Errors Min                    0.451416
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     104000
expl/num paths total                       2600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.355541
expl/Rewards Std                              0.584958
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            14.2216
expl/Returns Std                             18.3164
expl/Returns Max                             44.9118
expl/Returns Min                              0
expl/Actions Mean                             0.2719
expl/Actions Std                              0.799021
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.2216
expl/env_infos/final/reward_dist Mean         0.533294
expl/env_infos/final/reward_dist Std          0.73696
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00231004
expl/env_infos/initial/reward_dist Std        0.00492102
expl/env_infos/initial/reward_dist Max        0.0203525
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.355541
expl/env_infos/reward_dist Std                0.584958
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      20800
eval/num paths total                        520
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.663158
eval/Rewards Std                              0.711443
eval/Rewards Max                              1.57066
eval/Rewards Min                              0
eval/Returns Mean                            26.5263
eval/Returns Std                             21.6359
eval/Returns Max                             44.8506
eval/Returns Min                              0.000153946
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.5263
eval/env_infos/final/reward_dist Mean         0.94144
eval/env_infos/final/reward_dist Std          0.768683
eval/env_infos/final/reward_dist Max          1.57066
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.663158
eval/env_infos/reward_dist Std                0.711443
eval/env_infos/reward_dist Max                1.57066
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00688256
time/evaluation sampling (s)                  3.36386
time/exploration sampling (s)                17.6586
time/logging (s)                              0.00537215
time/saving (s)                               0.00100094
time/training (s)                             4.27044
time/epoch (s)                               25.3061
time/total (s)                             1318.09
Epoch                                        51
---------------------------------------  ----------------
2023-08-05 00:43:30.736463 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 52 finished
---------------------------------------  ----------------
epoch                                        52
replay_buffer/size                       106000
trainer/QF Loss                               3.96846e+07
trainer/Policy Loss                      -31524.1
trainer/Raw Policy Loss                  -31524.1
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                25520.9
trainer/Q Predictions Std                  4720.42
trainer/Q Predictions Max                 40415
trainer/Q Predictions Min                   231.713
trainer/Q Targets Mean                    29849.8
trainer/Q Targets Std                      1651.42
trainer/Q Targets Max                     40295.6
trainer/Q Targets Min                     16209.2
trainer/Bellman Errors Mean                   3.96846e+07
trainer/Bellman Errors Std                    9.0438e+07
trainer/Bellman Errors Max                    8.69618e+08
trainer/Bellman Errors Min                    1.82145
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     106000
expl/num paths total                       2650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.342572
expl/Rewards Std                              0.585236
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            13.7029
expl/Returns Std                             18.5503
expl/Returns Max                             44.2556
expl/Returns Min                              0
expl/Actions Mean                             0.263096
expl/Actions Std                              0.799296
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.7029
expl/env_infos/final/reward_dist Mean         0.52816
expl/env_infos/final/reward_dist Std          0.735973
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000156222
expl/env_infos/initial/reward_dist Std        0.000787957
expl/env_infos/initial/reward_dist Max        0.00485596
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.342572
expl/env_infos/reward_dist Std                0.585236
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      21200
eval/num paths total                        530
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.787939
eval/Rewards Std                              0.708861
eval/Rewards Max                              1.5707
eval/Rewards Min                              0
eval/Returns Mean                            31.5175
eval/Returns Std                             20.6301
eval/Returns Max                             45.4505
eval/Returns Min                              0.00522327
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.5175
eval/env_infos/final/reward_dist Mean         1.09863
eval/env_infos/final/reward_dist Std          0.719223
eval/env_infos/final/reward_dist Max          1.5707
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00437343
eval/env_infos/initial/reward_dist Std        0.00709321
eval/env_infos/initial/reward_dist Max        0.0209547
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.787939
eval/env_infos/reward_dist Std                0.708861
eval/env_infos/reward_dist Max                1.5707
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00616246
time/evaluation sampling (s)                  3.37344
time/exploration sampling (s)                17.1019
time/logging (s)                              0.00533996
time/saving (s)                               0.00102219
time/training (s)                             4.08654
time/epoch (s)                               24.5744
time/total (s)                             1342.66
Epoch                                        52
---------------------------------------  ----------------
2023-08-05 00:43:55.675325 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 53 finished
---------------------------------------  ----------------
epoch                                        53
replay_buffer/size                       108000
trainer/QF Loss                               4.10234e+07
trainer/Policy Loss                      -33074.9
trainer/Raw Policy Loss                  -33074.9
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                26824.9
trainer/Q Predictions Std                  4670.7
trainer/Q Predictions Max                 42095.1
trainer/Q Predictions Min                   234.126
trainer/Q Targets Mean                    31330.7
trainer/Q Targets Std                      1661.57
trainer/Q Targets Max                     42370.3
trainer/Q Targets Min                     17677.5
trainer/Bellman Errors Mean                   4.10234e+07
trainer/Bellman Errors Std                    9.16513e+07
trainer/Bellman Errors Max                    9.54891e+08
trainer/Bellman Errors Min                    1.57718
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     108000
expl/num paths total                       2700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.453775
expl/Rewards Std                              0.636264
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            18.151
expl/Returns Std                             19.7481
expl/Returns Max                             43.9805
expl/Returns Min                              0
expl/Actions Mean                             0.251654
expl/Actions Std                              0.80489
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.151
expl/env_infos/final/reward_dist Mean         0.661979
expl/env_infos/final/reward_dist Std          0.765173
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000973557
expl/env_infos/initial/reward_dist Std        0.00384641
expl/env_infos/initial/reward_dist Max        0.0246919
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.453775
expl/env_infos/reward_dist Std                0.636264
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      21600
eval/num paths total                        540
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.340302
eval/Rewards Std                              0.608166
eval/Rewards Max                              1.57048
eval/Rewards Min                              0
eval/Returns Mean                            13.6121
eval/Returns Std                             20.7681
eval/Returns Max                             45.7181
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         13.6121
eval/env_infos/final/reward_dist Mean         0.470997
eval/env_infos/final/reward_dist Std          0.71946
eval/env_infos/final/reward_dist Max          1.57048
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00114832
eval/env_infos/initial/reward_dist Std        0.00282198
eval/env_infos/initial/reward_dist Max        0.00940835
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.340302
eval/env_infos/reward_dist Std                0.608166
eval/env_infos/reward_dist Max                1.57048
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00604812
time/evaluation sampling (s)                  3.52457
time/exploration sampling (s)                17.1033
time/logging (s)                              0.00743696
time/saving (s)                               0.00108503
time/training (s)                             4.29602
time/epoch (s)                               24.9385
time/total (s)                             1367.6
Epoch                                        53
---------------------------------------  ----------------
2023-08-05 00:44:20.804721 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 54 finished
---------------------------------------  ----------------
epoch                                        54
replay_buffer/size                       110000
trainer/QF Loss                               4.73209e+07
trainer/Policy Loss                      -34777.9
trainer/Raw Policy Loss                  -34777.9
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                28172.3
trainer/Q Predictions Std                  5068.91
trainer/Q Predictions Max                 46175.2
trainer/Q Predictions Min                   233.516
trainer/Q Targets Mean                    32946.3
trainer/Q Targets Std                      1829.23
trainer/Q Targets Max                     49879.5
trainer/Q Targets Min                     17950.2
trainer/Bellman Errors Mean                   4.73209e+07
trainer/Bellman Errors Std                    1.04311e+08
trainer/Bellman Errors Max                    1.04542e+09
trainer/Bellman Errors Min                    1.13722
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     110000
expl/num paths total                       2750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.575091
expl/Rewards Std                              0.67466
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            23.0036
expl/Returns Std                             19.8358
expl/Returns Max                             43.6555
expl/Returns Min                              0
expl/Actions Mean                             0.26122
expl/Actions Std                              0.800663
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         23.0036
expl/env_infos/final/reward_dist Mean         0.87246
expl/env_infos/final/reward_dist Std          0.773768
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0007701
expl/env_infos/initial/reward_dist Std        0.00322794
expl/env_infos/initial/reward_dist Max        0.019736
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.575091
expl/env_infos/reward_dist Std                0.67466
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      22000
eval/num paths total                        550
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.338441
eval/Rewards Std                              0.593972
eval/Rewards Max                              1.56937
eval/Rewards Min                              0
eval/Returns Mean                            13.5376
eval/Returns Std                             19.7539
eval/Returns Max                             43.9131
eval/Returns Min                              0.000680897
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         13.5376
eval/env_infos/final/reward_dist Mean         0.503331
eval/env_infos/final/reward_dist Std          0.700953
eval/env_infos/final/reward_dist Max          1.56937
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000385567
eval/env_infos/initial/reward_dist Std        0.0011567
eval/env_infos/initial/reward_dist Max        0.00385567
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.338441
eval/env_infos/reward_dist Std                0.593972
eval/env_infos/reward_dist Max                1.56937
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00691588
time/evaluation sampling (s)                  3.53784
time/exploration sampling (s)                17.2608
time/logging (s)                              0.00763511
time/saving (s)                               0.00119971
time/training (s)                             4.31144
time/epoch (s)                               25.1258
time/total (s)                             1392.73
Epoch                                        54
---------------------------------------  ----------------
2023-08-05 00:44:45.750395 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 55 finished
---------------------------------------  ----------------
epoch                                        55
replay_buffer/size                       112000
trainer/QF Loss                               5.11809e+07
trainer/Policy Loss                      -36418.5
trainer/Raw Policy Loss                  -36418.5
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                29537.7
trainer/Q Predictions Std                  5243.97
trainer/Q Predictions Max                 46607.3
trainer/Q Predictions Min                   234.904
trainer/Q Targets Mean                    34522.2
trainer/Q Targets Std                      1997.06
trainer/Q Targets Max                     52372.3
trainer/Q Targets Min                     18487
trainer/Bellman Errors Mean                   5.11809e+07
trainer/Bellman Errors Std                    1.12266e+08
trainer/Bellman Errors Max                    1.15429e+09
trainer/Bellman Errors Min                    0.745255
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     112000
expl/num paths total                       2800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.573949
expl/Rewards Std                              0.674567
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            22.958
expl/Returns Std                             20.2078
expl/Returns Max                             44.8373
expl/Returns Min                              0
expl/Actions Mean                             0.25919
expl/Actions Std                              0.811538
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.958
expl/env_infos/final/reward_dist Mean         0.842662
expl/env_infos/final/reward_dist Std          0.778488
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00186266
expl/env_infos/initial/reward_dist Std        0.00495996
expl/env_infos/initial/reward_dist Max        0.0191021
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.573949
expl/env_infos/reward_dist Std                0.674567
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      22400
eval/num paths total                        560
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.536022
eval/Rewards Std                              0.685262
eval/Rewards Max                              1.57058
eval/Rewards Min                              0
eval/Returns Mean                            21.4409
eval/Returns Std                             21.4959
eval/Returns Max                             45.3883
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         21.4409
eval/env_infos/final/reward_dist Mean         0.784754
eval/env_infos/final/reward_dist Std          0.784754
eval/env_infos/final/reward_dist Max          1.57058
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00167958
eval/env_infos/initial/reward_dist Std        0.00503875
eval/env_infos/initial/reward_dist Max        0.0167958
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.536022
eval/env_infos/reward_dist Std                0.685262
eval/env_infos/reward_dist Max                1.57058
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00817875
time/evaluation sampling (s)                  3.46538
time/exploration sampling (s)                17.1314
time/logging (s)                              0.00538037
time/saving (s)                               0.000967514
time/training (s)                             4.32829
time/epoch (s)                               24.9396
time/total (s)                             1417.67
Epoch                                        55
---------------------------------------  ----------------
2023-08-05 00:45:11.671944 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 56 finished
---------------------------------------  ----------------
epoch                                        56
replay_buffer/size                       114000
trainer/QF Loss                               6.25012e+07
trainer/Policy Loss                      -38161.3
trainer/Raw Policy Loss                  -38161.3
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                30821.3
trainer/Q Predictions Std                  5877.12
trainer/Q Predictions Max                 54909.8
trainer/Q Predictions Min                   226.342
trainer/Q Targets Mean                    36154.2
trainer/Q Targets Std                      2057.46
trainer/Q Targets Max                     55377.8
trainer/Q Targets Min                     19854.5
trainer/Bellman Errors Mean                   6.25012e+07
trainer/Bellman Errors Std                    1.43521e+08
trainer/Bellman Errors Max                    1.27255e+09
trainer/Bellman Errors Min                    0.0858307
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     114000
expl/num paths total                       2850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.525749
expl/Rewards Std                              0.669211
expl/Rewards Max                              1.57074
expl/Rewards Min                              0
expl/Returns Mean                            21.03
expl/Returns Std                             20.498
expl/Returns Max                             44.0518
expl/Returns Min                              0
expl/Actions Mean                             0.255849
expl/Actions Std                              0.804744
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.03
expl/env_infos/final/reward_dist Mean         0.791588
expl/env_infos/final/reward_dist Std          0.778771
expl/env_infos/final/reward_dist Max          1.57074
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00191889
expl/env_infos/initial/reward_dist Std        0.00541954
expl/env_infos/initial/reward_dist Max        0.0234476
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.525749
expl/env_infos/reward_dist Std                0.669211
expl/env_infos/reward_dist Max                1.57074
expl/env_infos/reward_dist Min                0
eval/num steps total                      22800
eval/num paths total                        570
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.554525
eval/Rewards Std                              0.694132
eval/Rewards Max                              1.57044
eval/Rewards Min                              0
eval/Returns Mean                            22.181
eval/Returns Std                             22.1858
eval/Returns Max                             45.3139
eval/Returns Min                              3.48795e-05
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.181
eval/env_infos/final/reward_dist Mean         0.784595
eval/env_infos/final/reward_dist Std          0.784596
eval/env_infos/final/reward_dist Max          1.57027
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00133409
eval/env_infos/initial/reward_dist Std        0.00371198
eval/env_infos/initial/reward_dist Max        0.0124409
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.554525
eval/env_infos/reward_dist Std                0.694132
eval/env_infos/reward_dist Max                1.57044
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00822357
time/evaluation sampling (s)                  3.41907
time/exploration sampling (s)                17.4192
time/logging (s)                              0.00435262
time/saving (s)                               0.00999808
time/training (s)                             5.05718
time/epoch (s)                               25.918
time/total (s)                             1443.59
Epoch                                        56
---------------------------------------  ----------------
2023-08-05 00:45:36.699951 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 57 finished
---------------------------------------  ----------------
epoch                                        57
replay_buffer/size                       116000
trainer/QF Loss                               6.33359e+07
trainer/Policy Loss                      -40062.2
trainer/Raw Policy Loss                  -40062.2
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                32489.5
trainer/Q Predictions Std                  5952.14
trainer/Q Predictions Max                 53278.6
trainer/Q Predictions Min                   258.439
trainer/Q Targets Mean                    37940.5
trainer/Q Targets Std                      2129.67
trainer/Q Targets Max                     52378.2
trainer/Q Targets Min                     20446.2
trainer/Bellman Errors Mean                   6.33359e+07
trainer/Bellman Errors Std                    1.50224e+08
trainer/Bellman Errors Max                    1.41937e+09
trainer/Bellman Errors Min                    1.38246
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     116000
expl/num paths total                       2900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.457342
expl/Rewards Std                              0.639619
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            18.2937
expl/Returns Std                             20.0901
expl/Returns Max                             46.0257
expl/Returns Min                              0
expl/Actions Mean                             0.2636
expl/Actions Std                              0.805184
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.2937
expl/env_infos/final/reward_dist Mean         0.700563
expl/env_infos/final/reward_dist Std          0.758001
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00232807
expl/env_infos/initial/reward_dist Std        0.00595973
expl/env_infos/initial/reward_dist Max        0.024823
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.457342
expl/env_infos/reward_dist Std                0.639619
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      23200
eval/num paths total                        580
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.449696
eval/Rewards Std                              0.661718
eval/Rewards Max                              1.57053
eval/Rewards Min                              0
eval/Returns Mean                            17.9879
eval/Returns Std                             22.0142
eval/Returns Max                             45.0627
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.9879
eval/env_infos/final/reward_dist Mean         0.627567
eval/env_infos/final/reward_dist Std          0.76861
eval/env_infos/final/reward_dist Max          1.57053
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00153986
eval/env_infos/initial/reward_dist Std        0.00222805
eval/env_infos/initial/reward_dist Max        0.0057231
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.449696
eval/env_infos/reward_dist Std                0.661718
eval/env_infos/reward_dist Max                1.57053
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00828605
time/evaluation sampling (s)                  3.369
time/exploration sampling (s)                17.3438
time/logging (s)                              0.00529192
time/saving (s)                               0.000977098
time/training (s)                             4.29941
time/epoch (s)                               25.0267
time/total (s)                             1468.62
Epoch                                        57
---------------------------------------  ----------------
2023-08-05 00:46:02.287261 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 58 finished
---------------------------------------  ----------------
epoch                                        58
replay_buffer/size                       118000
trainer/QF Loss                               6.30833e+07
trainer/Policy Loss                      -41834.6
trainer/Raw Policy Loss                  -41834.6
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                34119.7
trainer/Q Predictions Std                  5802.06
trainer/Q Predictions Max                 59029.2
trainer/Q Predictions Min                   273.778
trainer/Q Targets Mean                    39660.7
trainer/Q Targets Std                      2117.3
trainer/Q Targets Max                     56178.5
trainer/Q Targets Min                     22411.7
trainer/Bellman Errors Mean                   6.30833e+07
trainer/Bellman Errors Std                    1.39777e+08
trainer/Bellman Errors Max                    1.53922e+09
trainer/Bellman Errors Min                    0.00343323
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     118000
expl/num paths total                       2950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.429013
expl/Rewards Std                              0.62296
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            17.1605
expl/Returns Std                             19.0571
expl/Returns Max                             44.179
expl/Returns Min                              0
expl/Actions Mean                             0.263123
expl/Actions Std                              0.797726
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.1605
expl/env_infos/final/reward_dist Mean         0.660409
expl/env_infos/final/reward_dist Std          0.766689
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000927026
expl/env_infos/initial/reward_dist Std        0.00341433
expl/env_infos/initial/reward_dist Max        0.0176602
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.429013
expl/env_infos/reward_dist Std                0.62296
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      23600
eval/num paths total                        590
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.664432
eval/Rewards Std                              0.709988
eval/Rewards Max                              1.57059
eval/Rewards Min                              0
eval/Returns Mean                            26.5773
eval/Returns Std                             21.7125
eval/Returns Max                             45.3324
eval/Returns Min                              0.000719702
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.5773
eval/env_infos/final/reward_dist Mean         0.940775
eval/env_infos/final/reward_dist Std          0.768141
eval/env_infos/final/reward_dist Max          1.57059
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00220506
eval/env_infos/initial/reward_dist Std        0.0050672
eval/env_infos/initial/reward_dist Max        0.0166053
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.664432
eval/env_infos/reward_dist Std                0.709988
eval/env_infos/reward_dist Max                1.57059
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00823296
time/evaluation sampling (s)                  3.43257
time/exploration sampling (s)                17.7409
time/logging (s)                              0.00537921
time/saving (s)                               0.000972586
time/training (s)                             4.39684
time/epoch (s)                               25.5848
time/total (s)                             1494.21
Epoch                                        58
---------------------------------------  ----------------
2023-08-05 00:46:27.884173 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 59 finished
---------------------------------------  ----------------
epoch                                        59
replay_buffer/size                       120000
trainer/QF Loss                               7.15558e+07
trainer/Policy Loss                      -43762.4
trainer/Raw Policy Loss                  -43762.4
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                35549.1
trainer/Q Predictions Std                  6254.86
trainer/Q Predictions Max                 56423.8
trainer/Q Predictions Min                   291.277
trainer/Q Targets Mean                    41470.9
trainer/Q Targets Std                      2192.32
trainer/Q Targets Max                     55655.7
trainer/Q Targets Min                     22506.8
trainer/Bellman Errors Mean                   7.15558e+07
trainer/Bellman Errors Std                    1.601e+08
trainer/Bellman Errors Max                    1.66674e+09
trainer/Bellman Errors Min                    0.140625
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     120000
expl/num paths total                       3000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.42565
expl/Rewards Std                              0.624097
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            17.026
expl/Returns Std                             19.367
expl/Returns Max                             43.9803
expl/Returns Min                              0
expl/Actions Mean                             0.255905
expl/Actions Std                              0.804252
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.026
expl/env_infos/final/reward_dist Mean         0.641699
expl/env_infos/final/reward_dist Std          0.76319
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00112163
expl/env_infos/initial/reward_dist Std        0.00398441
expl/env_infos/initial/reward_dist Max        0.023914
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.42565
expl/env_infos/reward_dist Std                0.624097
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      24000
eval/num paths total                        600
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.360097
eval/Rewards Std                              0.588714
eval/Rewards Max                              1.56848
eval/Rewards Min                              0
eval/Returns Mean                            14.4039
eval/Returns Std                             18.7262
eval/Returns Max                             45.4242
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         14.4039
eval/env_infos/final/reward_dist Mean         0.6094
eval/env_infos/final/reward_dist Std          0.746592
eval/env_infos/final/reward_dist Max          1.56848
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00247009
eval/env_infos/initial/reward_dist Std        0.00726573
eval/env_infos/initial/reward_dist Max        0.0242638
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.360097
eval/env_infos/reward_dist Std                0.588714
eval/env_infos/reward_dist Max                1.56848
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00683599
time/evaluation sampling (s)                  3.48733
time/exploration sampling (s)                17.7266
time/logging (s)                              0.00531888
time/saving (s)                               0.000977356
time/training (s)                             4.36723
time/epoch (s)                               25.5943
time/total (s)                             1519.81
Epoch                                        59
---------------------------------------  ----------------
2023-08-05 00:46:53.776588 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 60 finished
---------------------------------------  ----------------
epoch                                        60
replay_buffer/size                       122000
trainer/QF Loss                               7.59674e+07
trainer/Policy Loss                      -45788.5
trainer/Raw Policy Loss                  -45788.5
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                37295.2
trainer/Q Predictions Std                  6454.26
trainer/Q Predictions Max                 61037.7
trainer/Q Predictions Min                   276.333
trainer/Q Targets Mean                    43358.9
trainer/Q Targets Std                      2321.93
trainer/Q Targets Max                     62904.5
trainer/Q Targets Min                     23641.5
trainer/Bellman Errors Mean                   7.59674e+07
trainer/Bellman Errors Std                    1.70495e+08
trainer/Bellman Errors Max                    1.80727e+09
trainer/Bellman Errors Min                   71.8521
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     122000
expl/num paths total                       3050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.46429
expl/Rewards Std                              0.639037
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            18.5716
expl/Returns Std                             19.6815
expl/Returns Max                             44.9997
expl/Returns Min                              0
expl/Actions Mean                             0.237159
expl/Actions Std                              0.801641
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.5716
expl/env_infos/final/reward_dist Mean         0.681805
expl/env_infos/final/reward_dist Std          0.770971
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000687437
expl/env_infos/initial/reward_dist Std        0.00258684
expl/env_infos/initial/reward_dist Max        0.0153641
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.46429
expl/env_infos/reward_dist Std                0.639037
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      24400
eval/num paths total                        610
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.990979
eval/Rewards Std                              0.655291
eval/Rewards Max                              1.57043
eval/Rewards Min                              0
eval/Returns Mean                            39.6392
eval/Returns Std                             13.2283
eval/Returns Max                             45.4171
eval/Returns Min                              0.0370827
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         39.6392
eval/env_infos/final/reward_dist Mean         1.412
eval/env_infos/final/reward_dist Std          0.470669
eval/env_infos/final/reward_dist Max          1.57043
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00199508
eval/env_infos/initial/reward_dist Std        0.00598523
eval/env_infos/initial/reward_dist Max        0.0199508
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.990979
eval/env_infos/reward_dist Std                0.655291
eval/env_infos/reward_dist Max                1.57043
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00616921
time/evaluation sampling (s)                  3.49076
time/exploration sampling (s)                18.0543
time/logging (s)                              0.00531918
time/saving (s)                               0.00100702
time/training (s)                             4.33232
time/epoch (s)                               25.8899
time/total (s)                             1545.7
Epoch                                        60
---------------------------------------  ----------------
2023-08-05 00:47:19.015821 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 61 finished
---------------------------------------  ----------------
epoch                                        61
replay_buffer/size                       124000
trainer/QF Loss                               8.37458e+07
trainer/Policy Loss                      -47759.5
trainer/Raw Policy Loss                  -47759.5
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                38832.7
trainer/Q Predictions Std                  6653.22
trainer/Q Predictions Max                 62338.5
trainer/Q Predictions Min                   361.917
trainer/Q Targets Mean                    45267.3
trainer/Q Targets Std                      2334.38
trainer/Q Targets Max                     66002.7
trainer/Q Targets Min                     24762.2
trainer/Bellman Errors Mean                   8.37458e+07
trainer/Bellman Errors Std                    1.76439e+08
trainer/Bellman Errors Max                    1.97083e+09
trainer/Bellman Errors Min                   13.4827
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     124000
expl/num paths total                       3100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.415192
expl/Rewards Std                              0.627732
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            16.6077
expl/Returns Std                             19.9593
expl/Returns Max                             43.9905
expl/Returns Min                              0
expl/Actions Mean                             0.251313
expl/Actions Std                              0.807124
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.6077
expl/env_infos/final/reward_dist Mean         0.619796
expl/env_infos/final/reward_dist Std          0.759762
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00106211
expl/env_infos/initial/reward_dist Std        0.00382977
expl/env_infos/initial/reward_dist Max        0.0224092
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.415192
expl/env_infos/reward_dist Std                0.627732
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      24800
eval/num paths total                        620
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.753619
eval/Rewards Std                              0.701072
eval/Rewards Max                              1.57061
eval/Rewards Min                              0
eval/Returns Mean                            30.1448
eval/Returns Std                             19.9036
eval/Returns Max                             46.3753
eval/Returns Min                              0.00569722
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.1448
eval/env_infos/final/reward_dist Mean         1.0903
eval/env_infos/final/reward_dist Std          0.714175
eval/env_infos/final/reward_dist Max          1.57061
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000531944
eval/env_infos/initial/reward_dist Std        0.00159583
eval/env_infos/initial/reward_dist Max        0.00531944
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.753619
eval/env_infos/reward_dist Std                0.701072
eval/env_infos/reward_dist Max                1.57061
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00607089
time/evaluation sampling (s)                  3.42382
time/exploration sampling (s)                17.44
time/logging (s)                              0.00534384
time/saving (s)                               0.000999917
time/training (s)                             4.36046
time/epoch (s)                               25.2367
time/total (s)                             1570.94
Epoch                                        61
---------------------------------------  ----------------
2023-08-05 00:47:43.979273 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 62 finished
---------------------------------------  ----------------
epoch                                        62
replay_buffer/size                       126000
trainer/QF Loss                               9.56311e+07
trainer/Policy Loss                      -49943.2
trainer/Raw Policy Loss                  -49943.2
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                40668.2
trainer/Q Predictions Std                  7421.11
trainer/Q Predictions Max                 66227.3
trainer/Q Predictions Min                   183.688
trainer/Q Targets Mean                    47294.8
trainer/Q Targets Std                      2723.11
trainer/Q Targets Max                     67273.8
trainer/Q Targets Min                     25991.2
trainer/Bellman Errors Mean                   9.56311e+07
trainer/Bellman Errors Std                    2.26417e+08
trainer/Bellman Errors Max                    2.62229e+09
trainer/Bellman Errors Min                    4.59901
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     126000
expl/num paths total                       3150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.482258
expl/Rewards Std                              0.652071
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            19.2903
expl/Returns Std                             20.3671
expl/Returns Max                             44.2583
expl/Returns Min                              0
expl/Actions Mean                             0.252308
expl/Actions Std                              0.81077
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.2903
expl/env_infos/final/reward_dist Mean         0.717518
expl/env_infos/final/reward_dist Std          0.766566
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00229064
expl/env_infos/initial/reward_dist Std        0.00546737
expl/env_infos/initial/reward_dist Max        0.0244025
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.482258
expl/env_infos/reward_dist Std                0.652071
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      25200
eval/num paths total                        630
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.556603
eval/Rewards Std                              0.694482
eval/Rewards Max                              1.57023
eval/Rewards Min                              0
eval/Returns Mean                            22.2641
eval/Returns Std                             22.2479
eval/Returns Max                             45.0733
eval/Returns Min                              0.00689846
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.2641
eval/env_infos/final/reward_dist Mean         0.783749
eval/env_infos/final/reward_dist Std          0.78375
eval/env_infos/final/reward_dist Max          1.57023
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00195407
eval/env_infos/initial/reward_dist Std        0.00586221
eval/env_infos/initial/reward_dist Max        0.0195407
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.556603
eval/env_infos/reward_dist Std                0.694482
eval/env_infos/reward_dist Max                1.57023
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00665146
time/evaluation sampling (s)                  3.34385
time/exploration sampling (s)                17.243
time/logging (s)                              0.00538711
time/saving (s)                               0.000969788
time/training (s)                             4.36105
time/epoch (s)                               24.9609
time/total (s)                             1595.9
Epoch                                        62
---------------------------------------  ----------------
2023-08-05 00:48:09.339864 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 63 finished
---------------------------------------  ----------------
epoch                                        63
replay_buffer/size                       128000
trainer/QF Loss                               1.02069e+08
trainer/Policy Loss                      -51987.2
trainer/Raw Policy Loss                  -51987.2
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                42242.2
trainer/Q Predictions Std                  7426.1
trainer/Q Predictions Max                 71704.8
trainer/Q Predictions Min                   316.233
trainer/Q Targets Mean                    49311.2
trainer/Q Targets Std                      2694.85
trainer/Q Targets Max                     74003
trainer/Q Targets Min                     26868
trainer/Bellman Errors Mean                   1.02069e+08
trainer/Bellman Errors Std                    2.20419e+08
trainer/Bellman Errors Max                    2.35255e+09
trainer/Bellman Errors Min                    0.015625
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     128000
expl/num paths total                       3200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.426393
expl/Rewards Std                              0.625977
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            17.0557
expl/Returns Std                             19.4547
expl/Returns Max                             44.5087
expl/Returns Min                              0
expl/Actions Mean                             0.26551
expl/Actions Std                              0.801386
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.0557
expl/env_infos/final/reward_dist Mean         0.621359
expl/env_infos/final/reward_dist Std          0.76121
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00123092
expl/env_infos/initial/reward_dist Std        0.0043177
expl/env_infos/initial/reward_dist Max        0.0239256
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.426393
expl/env_infos/reward_dist Std                0.625977
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      25600
eval/num paths total                        640
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.45029
eval/Rewards Std                              0.643882
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            18.0116
eval/Returns Std                             20.7747
eval/Returns Max                             45.1941
eval/Returns Min                              0.00518608
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         18.0116
eval/env_infos/final/reward_dist Mean         0.689781
eval/env_infos/final/reward_dist Std          0.740669
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00150723
eval/env_infos/initial/reward_dist Std        0.00379882
eval/env_infos/initial/reward_dist Max        0.0127053
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.45029
eval/env_infos/reward_dist Std                0.643882
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0082029
time/evaluation sampling (s)                  3.49302
time/exploration sampling (s)                17.5447
time/logging (s)                              0.00535728
time/saving (s)                               0.00101573
time/training (s)                             4.30575
time/epoch (s)                               25.3581
time/total (s)                             1621.26
Epoch                                        63
---------------------------------------  ----------------
2023-08-05 00:48:34.257848 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 64 finished
---------------------------------------  ----------------
epoch                                        64
replay_buffer/size                       130000
trainer/QF Loss                               1.14843e+08
trainer/Policy Loss                      -54124.4
trainer/Raw Policy Loss                  -54124.4
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                43963.5
trainer/Q Predictions Std                  7896.77
trainer/Q Predictions Max                 72572.9
trainer/Q Predictions Min                   296.404
trainer/Q Targets Mean                    51334.5
trainer/Q Targets Std                      2892.23
trainer/Q Targets Max                     77594.5
trainer/Q Targets Min                     26145.1
trainer/Bellman Errors Mean                   1.14843e+08
trainer/Bellman Errors Std                    2.58206e+08
trainer/Bellman Errors Max                    2.58144e+09
trainer/Bellman Errors Min                    0.878906
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     130000
expl/num paths total                       3250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.445778
expl/Rewards Std                              0.62993
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            17.8311
expl/Returns Std                             19.5779
expl/Returns Max                             44.3121
expl/Returns Min                              0
expl/Actions Mean                             0.230142
expl/Actions Std                              0.797837
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.8311
expl/env_infos/final/reward_dist Mean         0.697388
expl/env_infos/final/reward_dist Std          0.754928
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00200355
expl/env_infos/initial/reward_dist Std        0.0058199
expl/env_infos/initial/reward_dist Max        0.0311363
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.445778
expl/env_infos/reward_dist Std                0.62993
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      26000
eval/num paths total                        650
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.325641
eval/Rewards Std                              0.595018
eval/Rewards Max                              1.57036
eval/Rewards Min                              0
eval/Returns Mean                            13.0256
eval/Returns Std                             19.9254
eval/Returns Max                             45.8619
eval/Returns Min                              0.00797223
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         13.0256
eval/env_infos/final/reward_dist Mean         0.470485
eval/env_infos/final/reward_dist Std          0.718678
eval/env_infos/final/reward_dist Max          1.57036
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00333674
eval/env_infos/initial/reward_dist Std        0.00667405
eval/env_infos/initial/reward_dist Max        0.0168804
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.325641
eval/env_infos/reward_dist Std                0.595018
eval/env_infos/reward_dist Max                1.57036
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00819123
time/evaluation sampling (s)                  3.3448
time/exploration sampling (s)                17.3151
time/logging (s)                              0.00741473
time/saving (s)                               0.00109051
time/training (s)                             4.24092
time/epoch (s)                               24.9175
time/total (s)                             1646.18
Epoch                                        64
---------------------------------------  ----------------
2023-08-05 00:48:59.174257 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 65 finished
---------------------------------------  ----------------
epoch                                        65
replay_buffer/size                       132000
trainer/QF Loss                               1.18917e+08
trainer/Policy Loss                      -56372.8
trainer/Raw Policy Loss                  -56372.8
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                45897.7
trainer/Q Predictions Std                  8037.74
trainer/Q Predictions Max                 72924.5
trainer/Q Predictions Min                   293.975
trainer/Q Targets Mean                    53466.7
trainer/Q Targets Std                      2923.86
trainer/Q Targets Max                     73370.5
trainer/Q Targets Min                     29071
trainer/Bellman Errors Mean                   1.18917e+08
trainer/Bellman Errors Std                    2.65102e+08
trainer/Bellman Errors Max                    2.77618e+09
trainer/Bellman Errors Min                    1.52588e-05
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     132000
expl/num paths total                       3300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.405694
expl/Rewards Std                              0.611268
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            16.2278
expl/Returns Std                             18.8901
expl/Returns Max                             43.3873
expl/Returns Min                              0
expl/Actions Mean                             0.256428
expl/Actions Std                              0.802136
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.2278
expl/env_infos/final/reward_dist Mean         0.651757
expl/env_infos/final/reward_dist Std          0.764476
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00125031
expl/env_infos/initial/reward_dist Std        0.0035445
expl/env_infos/initial/reward_dist Max        0.0161414
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.405694
expl/env_infos/reward_dist Std                0.611268
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      26400
eval/num paths total                        660
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.446337
eval/Rewards Std                              0.660811
eval/Rewards Max                              1.57021
eval/Rewards Min                              0
eval/Returns Mean                            17.8535
eval/Returns Std                             21.8503
eval/Returns Max                             45.3579
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.8535
eval/env_infos/final/reward_dist Mean         0.629163
eval/env_infos/final/reward_dist Std          0.7677
eval/env_infos/final/reward_dist Max          1.57021
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0009016
eval/env_infos/initial/reward_dist Std        0.0027048
eval/env_infos/initial/reward_dist Max        0.009016
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.446337
eval/env_infos/reward_dist Std                0.660811
eval/env_infos/reward_dist Max                1.57021
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00820805
time/evaluation sampling (s)                  3.36212
time/exploration sampling (s)                17.2876
time/logging (s)                              0.00396362
time/saving (s)                               0.000759332
time/training (s)                             4.2465
time/epoch (s)                               24.9092
time/total (s)                             1671.09
Epoch                                        65
---------------------------------------  ----------------
2023-08-05 00:49:24.121316 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 66 finished
---------------------------------------  ----------------
epoch                                        66
replay_buffer/size                       134000
trainer/QF Loss                               1.30547e+08
trainer/Policy Loss                      -58769.7
trainer/Raw Policy Loss                  -58769.7
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                47808.7
trainer/Q Predictions Std                  8496.4
trainer/Q Predictions Max                 84654.5
trainer/Q Predictions Min                   349.956
trainer/Q Targets Mean                    55685.8
trainer/Q Targets Std                      3005.3
trainer/Q Targets Max                     80345.6
trainer/Q Targets Min                     30295
trainer/Bellman Errors Mean                   1.30547e+08
trainer/Bellman Errors Std                    2.85045e+08
trainer/Bellman Errors Max                    3.0545e+09
trainer/Bellman Errors Min                    1.61171
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     134000
expl/num paths total                       3350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.527103
expl/Rewards Std                              0.655185
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            21.0841
expl/Returns Std                             19.4646
expl/Returns Max                             44.7839
expl/Returns Min                              0
expl/Actions Mean                             0.25266
expl/Actions Std                              0.805474
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.0841
expl/env_infos/final/reward_dist Mean         0.778101
expl/env_infos/final/reward_dist Std          0.77885
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000721198
expl/env_infos/initial/reward_dist Std        0.00248014
expl/env_infos/initial/reward_dist Max        0.016028
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.527103
expl/env_infos/reward_dist Std                0.655185
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      26800
eval/num paths total                        670
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.64594
eval/Rewards Std                              0.70088
eval/Rewards Max                              1.57066
eval/Rewards Min                              0
eval/Returns Mean                            25.8376
eval/Returns Std                             21.2158
eval/Returns Max                             45.3549
eval/Returns Min                              0.00210003
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.8376
eval/env_infos/final/reward_dist Mean         0.933309
eval/env_infos/final/reward_dist Std          0.762368
eval/env_infos/final/reward_dist Max          1.57066
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.64594
eval/env_infos/reward_dist Std                0.70088
eval/env_infos/reward_dist Max                1.57066
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593456
time/evaluation sampling (s)                  3.47295
time/exploration sampling (s)                17.2689
time/logging (s)                              0.00545462
time/saving (s)                               0.000998785
time/training (s)                             4.19214
time/epoch (s)                               24.9464
time/total (s)                             1696.04
Epoch                                        66
---------------------------------------  ----------------
2023-08-05 00:49:48.987422 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 67 finished
---------------------------------------  ----------------
epoch                                        67
replay_buffer/size                       136000
trainer/QF Loss                               1.3678e+08
trainer/Policy Loss                      -61184.3
trainer/Raw Policy Loss                  -61184.3
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                49645.5
trainer/Q Predictions Std                  8422.75
trainer/Q Predictions Max                 77901.2
trainer/Q Predictions Min                   331.72
trainer/Q Targets Mean                    58017.9
trainer/Q Targets Std                      3103.31
trainer/Q Targets Max                     78493.6
trainer/Q Targets Min                     31641.6
trainer/Bellman Errors Mean                   1.3678e+08
trainer/Bellman Errors Std                    2.79911e+08
trainer/Bellman Errors Max                    3.32958e+09
trainer/Bellman Errors Min                    0.0835571
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     136000
expl/num paths total                       3400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.475337
expl/Rewards Std                              0.636318
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            19.0135
expl/Returns Std                             19.4038
expl/Returns Max                             45.0028
expl/Returns Min                              0
expl/Actions Mean                             0.264575
expl/Actions Std                              0.800728
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.0135
expl/env_infos/final/reward_dist Mean         0.741764
expl/env_infos/final/reward_dist Std          0.760466
expl/env_infos/final/reward_dist Max          1.5707
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00158824
expl/env_infos/initial/reward_dist Std        0.00551344
expl/env_infos/initial/reward_dist Max        0.0308961
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.475337
expl/env_infos/reward_dist Std                0.636318
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      27200
eval/num paths total                        680
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.894416
eval/Rewards Std                              0.689691
eval/Rewards Max                              1.5703
eval/Rewards Min                              0
eval/Returns Mean                            35.7766
eval/Returns Std                             17.883
eval/Returns Max                             45.2166
eval/Returns Min                              0.00232429
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.7766
eval/env_infos/final/reward_dist Mean         1.25526
eval/env_infos/final/reward_dist Std          0.627629
eval/env_infos/final/reward_dist Max          1.5703
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00221477
eval/env_infos/initial/reward_dist Std        0.0038111
eval/env_infos/initial/reward_dist Max        0.0112677
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.894416
eval/env_infos/reward_dist Std                0.689691
eval/env_infos/reward_dist Max                1.5703
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00592555
time/evaluation sampling (s)                  3.53606
time/exploration sampling (s)                17.2538
time/logging (s)                              0.00550648
time/saving (s)                               0.000999884
time/training (s)                             4.06083
time/epoch (s)                               24.8631
time/total (s)                             1720.9
Epoch                                        67
---------------------------------------  ----------------
2023-08-05 00:50:14.120764 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 68 finished
---------------------------------------  ----------------
epoch                                        68
replay_buffer/size                       138000
trainer/QF Loss                               1.57876e+08
trainer/Policy Loss                      -63567.7
trainer/Raw Policy Loss                  -63567.7
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                51414.4
trainer/Q Predictions Std                  9206.7
trainer/Q Predictions Max                 81314.8
trainer/Q Predictions Min                   319.947
trainer/Q Targets Mean                    60259.9
trainer/Q Targets Std                      3142.61
trainer/Q Targets Max                     89824.4
trainer/Q Targets Min                     32646.3
trainer/Bellman Errors Mean                   1.57876e+08
trainer/Bellman Errors Std                    3.43691e+08
trainer/Bellman Errors Max                    3.44031e+09
trainer/Bellman Errors Min                    6.23048
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     138000
expl/num paths total                       3450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.531115
expl/Rewards Std                              0.65549
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            21.2446
expl/Returns Std                             19.5373
expl/Returns Max                             45.9215
expl/Returns Min                              0
expl/Actions Mean                             0.261925
expl/Actions Std                              0.801036
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.2446
expl/env_infos/final/reward_dist Mean         0.836319
expl/env_infos/final/reward_dist Std          0.773689
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00139062
expl/env_infos/initial/reward_dist Std        0.00288842
expl/env_infos/initial/reward_dist Max        0.0113677
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.531115
expl/env_infos/reward_dist Std                0.65549
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      27600
eval/num paths total                        690
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.442964
eval/Rewards Std                              0.659409
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            17.7186
eval/Returns Std                             21.6901
eval/Returns Max                             44.6838
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.7186
eval/env_infos/final/reward_dist Mean         0.627621
eval/env_infos/final/reward_dist Std          0.768677
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.442964
eval/env_infos/reward_dist Std                0.659409
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588593
time/evaluation sampling (s)                  3.45171
time/exploration sampling (s)                17.4745
time/logging (s)                              0.00539914
time/saving (s)                               0.0010081
time/training (s)                             4.19191
time/epoch (s)                               25.1304
time/total (s)                             1746.04
Epoch                                        68
---------------------------------------  ----------------
2023-08-05 00:50:38.753270 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 69 finished
---------------------------------------  ----------------
epoch                                        69
replay_buffer/size                       140000
trainer/QF Loss                               1.6268e+08
trainer/Policy Loss                      -66018.8
trainer/Raw Policy Loss                  -66018.8
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                53742.6
trainer/Q Predictions Std                  9347.59
trainer/Q Predictions Max                 82309.4
trainer/Q Predictions Min                   288.387
trainer/Q Targets Mean                    62664.4
trainer/Q Targets Std                      3261.12
trainer/Q Targets Max                     90183.6
trainer/Q Targets Min                     35188.4
trainer/Bellman Errors Mean                   1.6268e+08
trainer/Bellman Errors Std                    3.62854e+08
trainer/Bellman Errors Max                    3.83743e+09
trainer/Bellman Errors Min                    0.376114
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     140000
expl/num paths total                       3500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.410401
expl/Rewards Std                              0.615895
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            16.416
expl/Returns Std                             19.1386
expl/Returns Max                             44.8338
expl/Returns Min                              0
expl/Actions Mean                             0.26816
expl/Actions Std                              0.801381
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.416
expl/env_infos/final/reward_dist Mean         0.563057
expl/env_infos/final/reward_dist Std          0.750845
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00108149
expl/env_infos/initial/reward_dist Std        0.00323397
expl/env_infos/initial/reward_dist Max        0.0179119
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.410401
expl/env_infos/reward_dist Std                0.615895
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      28000
eval/num paths total                        700
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.896085
eval/Rewards Std                              0.68817
eval/Rewards Max                              1.57029
eval/Rewards Min                              0
eval/Returns Mean                            35.8434
eval/Returns Std                             17.927
eval/Returns Max                             45.889
eval/Returns Min                              0.00187525
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.8434
eval/env_infos/final/reward_dist Mean         1.25389
eval/env_infos/final/reward_dist Std          0.626947
eval/env_infos/final/reward_dist Max          1.57029
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00369867
eval/env_infos/initial/reward_dist Std        0.00692932
eval/env_infos/initial/reward_dist Max        0.0226855
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.896085
eval/env_infos/reward_dist Std                0.68817
eval/env_infos/reward_dist Max                1.57029
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00597245
time/evaluation sampling (s)                  3.4739
time/exploration sampling (s)                17.0305
time/logging (s)                              0.00542822
time/saving (s)                               0.000986846
time/training (s)                             4.11263
time/epoch (s)                               24.6294
time/total (s)                             1770.67
Epoch                                        69
---------------------------------------  ----------------
2023-08-05 00:51:03.571215 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 70 finished
---------------------------------------  ----------------
epoch                                        70
replay_buffer/size                       142000
trainer/QF Loss                               1.83001e+08
trainer/Policy Loss                      -68560.3
trainer/Raw Policy Loss                  -68560.3
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                55417.4
trainer/Q Predictions Std                  9800.78
trainer/Q Predictions Max                 87192.3
trainer/Q Predictions Min                   352.479
trainer/Q Targets Mean                    65018.9
trainer/Q Targets Std                      3357.89
trainer/Q Targets Max                     91503.8
trainer/Q Targets Min                     35424
trainer/Bellman Errors Mean                   1.83001e+08
trainer/Bellman Errors Std                    3.92671e+08
trainer/Bellman Errors Max                    4.14514e+09
trainer/Bellman Errors Min                    5.42017
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     142000
expl/num paths total                       3550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.438715
expl/Rewards Std                              0.622507
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            17.5486
expl/Returns Std                             18.9646
expl/Returns Max                             46.2495
expl/Returns Min                              0
expl/Actions Mean                             0.245516
expl/Actions Std                              0.804338
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.5486
expl/env_infos/final/reward_dist Mean         0.670964
expl/env_infos/final/reward_dist Std          0.767028
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00241781
expl/env_infos/initial/reward_dist Std        0.00595458
expl/env_infos/initial/reward_dist Max        0.0246539
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.438715
expl/env_infos/reward_dist Std                0.622507
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      28400
eval/num paths total                        710
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.43518
eval/Rewards Std                              0.648285
eval/Rewards Max                              1.56999
eval/Rewards Min                              0
eval/Returns Mean                            17.4072
eval/Returns Std                             21.2535
eval/Returns Max                             45.2581
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.4072
eval/env_infos/final/reward_dist Mean         0.618393
eval/env_infos/final/reward_dist Std          0.757771
eval/env_infos/final/reward_dist Max          1.56999
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000652013
eval/env_infos/initial/reward_dist Std        0.00155085
eval/env_infos/initial/reward_dist Max        0.00513712
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.43518
eval/env_infos/reward_dist Std                0.648285
eval/env_infos/reward_dist Max                1.56999
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00592708
time/evaluation sampling (s)                  3.46557
time/exploration sampling (s)                17.0595
time/logging (s)                              0.00550332
time/saving (s)                               0.000958321
time/training (s)                             4.27713
time/epoch (s)                               24.8146
time/total (s)                             1795.49
Epoch                                        70
---------------------------------------  ----------------
2023-08-05 00:51:28.919686 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 71 finished
---------------------------------------  ----------------
epoch                                        71
replay_buffer/size                       144000
trainer/QF Loss                               1.80078e+08
trainer/Policy Loss                      -71263.5
trainer/Raw Policy Loss                  -71263.5
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                58082.3
trainer/Q Predictions Std                  9698.29
trainer/Q Predictions Max                105281
trainer/Q Predictions Min                   383.494
trainer/Q Targets Mean                    67607.7
trainer/Q Targets Std                      3630.62
trainer/Q Targets Max                    102449
trainer/Q Targets Min                     36768.3
trainer/Bellman Errors Mean                   1.80078e+08
trainer/Bellman Errors Std                    3.70332e+08
trainer/Bellman Errors Max                    4.42179e+09
trainer/Bellman Errors Min                   36.2818
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     144000
expl/num paths total                       3600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.570376
expl/Rewards Std                              0.662838
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            22.8151
expl/Returns Std                             19.3594
expl/Returns Max                             44.4411
expl/Returns Min                              0
expl/Actions Mean                             0.254
expl/Actions Std                              0.804338
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.8151
expl/env_infos/final/reward_dist Mean         0.836218
expl/env_infos/final/reward_dist Std          0.774221
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00150117
expl/env_infos/initial/reward_dist Std        0.00406343
expl/env_infos/initial/reward_dist Max        0.0168173
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.570376
expl/env_infos/reward_dist Std                0.662838
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      28800
eval/num paths total                        720
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.500453
eval/Rewards Std                              0.664997
eval/Rewards Max                              1.57015
eval/Rewards Min                              0
eval/Returns Mean                            20.0181
eval/Returns Std                             20.9725
eval/Returns Max                             44.9837
eval/Returns Min                              0.00100575
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.0181
eval/env_infos/final/reward_dist Mean         0.775737
eval/env_infos/final/reward_dist Std          0.776059
eval/env_infos/final/reward_dist Max          1.57015
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000121507
eval/env_infos/initial/reward_dist Std        0.000364521
eval/env_infos/initial/reward_dist Max        0.00121507
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.500453
eval/env_infos/reward_dist Std                0.664997
eval/env_infos/reward_dist Max                1.57015
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595963
time/evaluation sampling (s)                  3.71967
time/exploration sampling (s)                17.1791
time/logging (s)                              0.0053652
time/saving (s)                               0.00101089
time/training (s)                             4.43426
time/epoch (s)                               25.3454
time/total (s)                             1820.83
Epoch                                        71
---------------------------------------  ----------------
2023-08-05 00:51:54.127291 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 72 finished
---------------------------------------  ----------------
epoch                                        72
replay_buffer/size                       146000
trainer/QF Loss                               1.96994e+08
trainer/Policy Loss                      -73819.8
trainer/Raw Policy Loss                  -73819.8
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                60197.2
trainer/Q Predictions Std                 10214.5
trainer/Q Predictions Max                101074
trainer/Q Predictions Min                   334.818
trainer/Q Targets Mean                    70037.3
trainer/Q Targets Std                      3658.61
trainer/Q Targets Max                    102333
trainer/Q Targets Min                     37713.8
trainer/Bellman Errors Mean                   1.96994e+08
trainer/Bellman Errors Std                    4.28639e+08
trainer/Bellman Errors Max                    4.81343e+09
trainer/Bellman Errors Min                    0.57428
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     146000
expl/num paths total                       3650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.404102
expl/Rewards Std                              0.615794
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            16.1641
expl/Returns Std                             19.2157
expl/Returns Max                             44.5432
expl/Returns Min                              0
expl/Actions Mean                             0.267068
expl/Actions Std                              0.795839
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.1641
expl/env_infos/final/reward_dist Mean         0.592524
expl/env_infos/final/reward_dist Std          0.756384
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000890685
expl/env_infos/initial/reward_dist Std        0.0033266
expl/env_infos/initial/reward_dist Max        0.0174093
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.404102
expl/env_infos/reward_dist Std                0.615794
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      29200
eval/num paths total                        730
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.197058
eval/Rewards Std                              0.477349
eval/Rewards Max                              1.569
eval/Rewards Min                              0
eval/Returns Mean                             7.88231
eval/Returns Std                             15.875
eval/Returns Max                             44.2438
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          7.88231
eval/env_infos/final/reward_dist Mean         0.305984
eval/env_infos/final/reward_dist Std          0.611662
eval/env_infos/final/reward_dist Max          1.569
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.197058
eval/env_infos/reward_dist Std                0.477349
eval/env_infos/reward_dist Max                1.569
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594574
time/evaluation sampling (s)                  4.23392
time/exploration sampling (s)                16.8917
time/logging (s)                              0.0053431
time/saving (s)                               0.000969642
time/training (s)                             4.06684
time/epoch (s)                               25.2047
time/total (s)                             1846.04
Epoch                                        72
---------------------------------------  ----------------
2023-08-05 00:52:19.168428 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 73 finished
---------------------------------------  ----------------
epoch                                        73
replay_buffer/size                       148000
trainer/QF Loss                               2.11524e+08
trainer/Policy Loss                      -76644.1
trainer/Raw Policy Loss                  -76644.1
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                62323.6
trainer/Q Predictions Std                 10416.9
trainer/Q Predictions Max                100314
trainer/Q Predictions Min                   388.469
trainer/Q Targets Mean                    72744.8
trainer/Q Targets Std                      3903.25
trainer/Q Targets Max                    100339
trainer/Q Targets Min                     39657
trainer/Bellman Errors Mean                   2.11524e+08
trainer/Bellman Errors Std                    4.22102e+08
trainer/Bellman Errors Max                    5.09451e+09
trainer/Bellman Errors Min                    0.672913
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     148000
expl/num paths total                       3700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.578504
expl/Rewards Std                              0.680259
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            23.1402
expl/Returns Std                             20.3839
expl/Returns Max                             45.1455
expl/Returns Min                              0
expl/Actions Mean                             0.26676
expl/Actions Std                              0.804158
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         23.1402
expl/env_infos/final/reward_dist Mean         0.865938
expl/env_infos/final/reward_dist Std          0.772689
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00141319
expl/env_infos/initial/reward_dist Std        0.00401996
expl/env_infos/initial/reward_dist Max        0.0189877
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.578504
expl/env_infos/reward_dist Std                0.680259
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      29600
eval/num paths total                        740
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.896209
eval/Rewards Std                              0.689737
eval/Rewards Max                              1.5707
eval/Rewards Min                              0
eval/Returns Mean                            35.8484
eval/Returns Std                             17.9343
eval/Returns Max                             46.3286
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.8484
eval/env_infos/final/reward_dist Mean         1.25479
eval/env_infos/final/reward_dist Std          0.627394
eval/env_infos/final/reward_dist Max          1.5707
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00326532
eval/env_infos/initial/reward_dist Std        0.00610367
eval/env_infos/initial/reward_dist Max        0.0202113
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.896209
eval/env_infos/reward_dist Std                0.689737
eval/env_infos/reward_dist Max                1.5707
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594493
time/evaluation sampling (s)                  3.53787
time/exploration sampling (s)                16.9204
time/logging (s)                              0.00536471
time/saving (s)                               0.00105358
time/training (s)                             4.56793
time/epoch (s)                               25.0385
time/total (s)                             1871.08
Epoch                                        73
---------------------------------------  ----------------
2023-08-05 00:52:44.467528 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 74 finished
---------------------------------------  ----------------
epoch                                        74
replay_buffer/size                       150000
trainer/QF Loss                               2.26559e+08
trainer/Policy Loss                      -79597.6
trainer/Raw Policy Loss                  -79597.6
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                64864.7
trainer/Q Predictions Std                 11009.3
trainer/Q Predictions Max                103420
trainer/Q Predictions Min                   418.298
trainer/Q Targets Mean                    75416.1
trainer/Q Targets Std                      4299.46
trainer/Q Targets Max                    102318
trainer/Q Targets Min                     40902.8
trainer/Bellman Errors Mean                   2.26559e+08
trainer/Bellman Errors Std                    4.66472e+08
trainer/Bellman Errors Max                    5.44276e+09
trainer/Bellman Errors Min                   51.9976
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     150000
expl/num paths total                       3750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.463588
expl/Rewards Std                              0.640629
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            18.5435
expl/Returns Std                             19.5934
expl/Returns Max                             44.9633
expl/Returns Min                              0
expl/Actions Mean                             0.261945
expl/Actions Std                              0.808112
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.5435
expl/env_infos/final/reward_dist Mean         0.688657
expl/env_infos/final/reward_dist Std          0.776992
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000406135
expl/env_infos/initial/reward_dist Std        0.00182566
expl/env_infos/initial/reward_dist Max        0.0103644
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.463588
expl/env_infos/reward_dist Std                0.640629
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      30000
eval/num paths total                        750
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.555674
eval/Rewards Std                              0.695732
eval/Rewards Max                              1.57001
eval/Rewards Min                              0
eval/Returns Mean                            22.227
eval/Returns Std                             22.2142
eval/Returns Max                             45.5789
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.227
eval/env_infos/final/reward_dist Mean         0.784509
eval/env_infos/final/reward_dist Std          0.784147
eval/env_infos/final/reward_dist Max          1.57001
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00134493
eval/env_infos/initial/reward_dist Std        0.0040348
eval/env_infos/initial/reward_dist Max        0.0134493
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.555674
eval/env_infos/reward_dist Std                0.695732
eval/env_infos/reward_dist Max                1.57001
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591518
time/evaluation sampling (s)                  4.05889
time/exploration sampling (s)                16.9155
time/logging (s)                              0.00535637
time/saving (s)                               0.00100038
time/training (s)                             4.30994
time/epoch (s)                               25.2966
time/total (s)                             1896.38
Epoch                                        74
---------------------------------------  ----------------
2023-08-05 00:53:10.717949 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 75 finished
---------------------------------------  ----------------
epoch                                        75
replay_buffer/size                       152000
trainer/QF Loss                               2.39901e+08
trainer/Policy Loss                      -82483.3
trainer/Raw Policy Loss                  -82483.3
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                67243.6
trainer/Q Predictions Std                 11160.6
trainer/Q Predictions Max                105324
trainer/Q Predictions Min                   431.417
trainer/Q Targets Mean                    78222.1
trainer/Q Targets Std                      4286.54
trainer/Q Targets Max                    114575
trainer/Q Targets Min                     41522.8
trainer/Bellman Errors Mean                   2.39901e+08
trainer/Bellman Errors Std                    4.98399e+08
trainer/Bellman Errors Max                    5.95147e+09
trainer/Bellman Errors Min                    2.9541
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     152000
expl/num paths total                       3800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.454033
expl/Rewards Std                              0.64557
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            18.1613
expl/Returns Std                             20.4554
expl/Returns Max                             44.806
expl/Returns Min                              0
expl/Actions Mean                             0.264327
expl/Actions Std                              0.794965
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.1613
expl/env_infos/final/reward_dist Mean         0.657634
expl/env_infos/final/reward_dist Std          0.772807
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0025177
expl/env_infos/initial/reward_dist Std        0.00615757
expl/env_infos/initial/reward_dist Max        0.0308577
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.454033
expl/env_infos/reward_dist Std                0.64557
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      30400
eval/num paths total                        760
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.544955
eval/Rewards Std                              0.684005
eval/Rewards Max                              1.5701
eval/Rewards Min                              0
eval/Returns Mean                            21.7982
eval/Returns Std                             21.8052
eval/Returns Max                             45.3074
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         21.7982
eval/env_infos/final/reward_dist Mean         0.775803
eval/env_infos/final/reward_dist Std          0.775292
eval/env_infos/final/reward_dist Max          1.5701
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00493024
eval/env_infos/initial/reward_dist Std        0.00786678
eval/env_infos/initial/reward_dist Max        0.0220915
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.544955
eval/env_infos/reward_dist Std                0.684005
eval/env_infos/reward_dist Max                1.5701
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596508
time/evaluation sampling (s)                  4.00091
time/exploration sampling (s)                17.1714
time/logging (s)                              0.00792512
time/saving (s)                               0.00123997
time/training (s)                             5.06299
time/epoch (s)                               26.2505
time/total (s)                             1922.63
Epoch                                        75
---------------------------------------  ----------------
2023-08-05 00:53:36.137276 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 76 finished
---------------------------------------  ----------------
epoch                                        76
replay_buffer/size                       154000
trainer/QF Loss                               2.78648e+08
trainer/Policy Loss                      -85329.2
trainer/Raw Policy Loss                  -85329.2
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                69315.1
trainer/Q Predictions Std                 12280.5
trainer/Q Predictions Max                117330
trainer/Q Predictions Min                   475.375
trainer/Q Targets Mean                    80977.2
trainer/Q Targets Std                      4308.97
trainer/Q Targets Max                    115594
trainer/Q Targets Min                     45331.1
trainer/Bellman Errors Mean                   2.78648e+08
trainer/Bellman Errors Std                    6.15055e+08
trainer/Bellman Errors Max                    6.34045e+09
trainer/Bellman Errors Min                    0.242249
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     154000
expl/num paths total                       3850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.492437
expl/Rewards Std                              0.636933
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            19.6975
expl/Returns Std                             18.8422
expl/Returns Max                             45.1666
expl/Returns Min                              0
expl/Actions Mean                             0.249084
expl/Actions Std                              0.803887
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.6975
expl/env_infos/final/reward_dist Mean         0.745946
expl/env_infos/final/reward_dist Std          0.777005
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0019317
expl/env_infos/initial/reward_dist Std        0.00576633
expl/env_infos/initial/reward_dist Max        0.0287209
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.492437
expl/env_infos/reward_dist Std                0.636933
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      30800
eval/num paths total                        770
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.440075
eval/Rewards Std                              0.657912
eval/Rewards Max                              1.5705
eval/Rewards Min                              0
eval/Returns Mean                            17.603
eval/Returns Std                             21.5384
eval/Returns Max                             44.3299
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.603
eval/env_infos/final/reward_dist Mean         0.627641
eval/env_infos/final/reward_dist Std          0.7687
eval/env_infos/final/reward_dist Max          1.5705
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.440075
eval/env_infos/reward_dist Std                0.657912
eval/env_infos/reward_dist Max                1.5705
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00598072
time/evaluation sampling (s)                  3.59703
time/exploration sampling (s)                17.6479
time/logging (s)                              0.00754054
time/saving (s)                               0.0011026
time/training (s)                             4.15533
time/epoch (s)                               25.4149
time/total (s)                             1948.05
Epoch                                        76
---------------------------------------  ----------------
2023-08-05 00:54:01.756191 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 77 finished
---------------------------------------  ----------------
epoch                                        77
replay_buffer/size                       156000
trainer/QF Loss                               2.99326e+08
trainer/Policy Loss                      -88348.7
trainer/Raw Policy Loss                  -88348.7
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                72016.8
trainer/Q Predictions Std                 12936.4
trainer/Q Predictions Max                115161
trainer/Q Predictions Min                   346.694
trainer/Q Targets Mean                    83827.6
trainer/Q Targets Std                      4740.85
trainer/Q Targets Max                    128360
trainer/Q Targets Min                     45566.2
trainer/Bellman Errors Mean                   2.99326e+08
trainer/Bellman Errors Std                    6.81969e+08
trainer/Bellman Errors Max                    6.88171e+09
trainer/Bellman Errors Min                    6.56641
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     156000
expl/num paths total                       3900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.448296
expl/Rewards Std                              0.633525
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            17.9318
expl/Returns Std                             19.4624
expl/Returns Max                             43.7924
expl/Returns Min                              0
expl/Actions Mean                             0.263335
expl/Actions Std                              0.81108
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.9318
expl/env_infos/final/reward_dist Mean         0.656716
expl/env_infos/final/reward_dist Std          0.769806
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000964199
expl/env_infos/initial/reward_dist Std        0.003134
expl/env_infos/initial/reward_dist Max        0.017137
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.448296
expl/env_infos/reward_dist Std                0.633525
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      31200
eval/num paths total                        780
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.56797
eval/Rewards Std                              0.687556
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            22.7188
eval/Returns Std                             21.7382
eval/Returns Max                             45.01
eval/Returns Min                              2.22344e-05
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.7188
eval/env_infos/final/reward_dist Mean         0.83166
eval/env_infos/final/reward_dist Std          0.748533
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.56797
eval/env_infos/reward_dist Std                0.687556
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596821
time/evaluation sampling (s)                  3.60012
time/exploration sampling (s)                17.5951
time/logging (s)                              0.00535833
time/saving (s)                               0.00100808
time/training (s)                             4.40509
time/epoch (s)                               25.6127
time/total (s)                             1973.66
Epoch                                        77
---------------------------------------  ----------------
2023-08-05 00:54:28.138418 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 78 finished
---------------------------------------  ----------------
epoch                                        78
replay_buffer/size                       158000
trainer/QF Loss                               3.24306e+08
trainer/Policy Loss                      -91609.8
trainer/Raw Policy Loss                  -91609.8
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                74280.4
trainer/Q Predictions Std                 13266.8
trainer/Q Predictions Max                121576
trainer/Q Predictions Min                   394.004
trainer/Q Targets Mean                    86876
trainer/Q Targets Std                      4801.37
trainer/Q Targets Max                    125609
trainer/Q Targets Min                     47832.3
trainer/Bellman Errors Mean                   3.24306e+08
trainer/Bellman Errors Std                    7.1476e+08
trainer/Bellman Errors Max                    7.13239e+09
trainer/Bellman Errors Min                    4.71704
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     158000
expl/num paths total                       3950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.471565
expl/Rewards Std                              0.652892
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            18.8626
expl/Returns Std                             20.1259
expl/Returns Max                             45.1962
expl/Returns Min                              0
expl/Actions Mean                             0.251886
expl/Actions Std                              0.811576
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.8626
expl/env_infos/final/reward_dist Mean         0.721769
expl/env_infos/final/reward_dist Std          0.782015
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000730978
expl/env_infos/initial/reward_dist Std        0.00289242
expl/env_infos/initial/reward_dist Max        0.0182316
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.471565
expl/env_infos/reward_dist Std                0.652892
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      31600
eval/num paths total                        790
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.606579
eval/Rewards Std                              0.689736
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            24.2632
eval/Returns Std                             20.8556
eval/Returns Max                             44.9996
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.2632
eval/env_infos/final/reward_dist Mean         0.933362
eval/env_infos/final/reward_dist Std          0.762433
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000637703
eval/env_infos/initial/reward_dist Std        0.00176596
eval/env_infos/initial/reward_dist Max        0.00591977
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.606579
eval/env_infos/reward_dist Std                0.689736
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00599103
time/evaluation sampling (s)                  3.7857
time/exploration sampling (s)                18.4191
time/logging (s)                              0.00752666
time/saving (s)                               0.00110304
time/training (s)                             4.16236
time/epoch (s)                               26.3818
time/total (s)                             2000.05
Epoch                                        78
---------------------------------------  ----------------
2023-08-05 00:54:53.961210 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 79 finished
---------------------------------------  ----------------
epoch                                        79
replay_buffer/size                       160000
trainer/QF Loss                               3.19719e+08
trainer/Policy Loss                      -94454.5
trainer/Raw Policy Loss                  -94454.5
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                77132.1
trainer/Q Predictions Std                 12858.3
trainer/Q Predictions Max                126286
trainer/Q Predictions Min                   508.194
trainer/Q Targets Mean                    89651.3
trainer/Q Targets Std                      5093.76
trainer/Q Targets Max                    137386
trainer/Q Targets Min                     45251.7
trainer/Bellman Errors Mean                   3.19719e+08
trainer/Bellman Errors Std                    6.72118e+08
trainer/Bellman Errors Max                    7.83719e+09
trainer/Bellman Errors Min                    5.60358
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     160000
expl/num paths total                       4000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.508744
expl/Rewards Std                              0.653747
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            20.3498
expl/Returns Std                             19.6468
expl/Returns Max                             44.6723
expl/Returns Min                              0
expl/Actions Mean                             0.255139
expl/Actions Std                              0.807446
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.3498
expl/env_infos/final/reward_dist Mean         0.749971
expl/env_infos/final/reward_dist Std          0.780706
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00167626
expl/env_infos/initial/reward_dist Std        0.00438906
expl/env_infos/initial/reward_dist Max        0.0205542
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.508744
expl/env_infos/reward_dist Std                0.653747
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      32000
eval/num paths total                        800
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.783946
eval/Rewards Std                              0.709099
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            31.3578
eval/Returns Std                             20.5329
eval/Returns Max                             45.5199
eval/Returns Min                              0.000713812
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.3578
eval/env_infos/final/reward_dist Mean         1.09851
eval/env_infos/final/reward_dist Std          0.719147
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0037447
eval/env_infos/initial/reward_dist Std        0.00547716
eval/env_infos/initial/reward_dist Max        0.014475
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.783946
eval/env_infos/reward_dist Std                0.709099
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.006008
time/evaluation sampling (s)                  3.57867
time/exploration sampling (s)                18.0086
time/logging (s)                              0.00537291
time/saving (s)                               0.000980372
time/training (s)                             4.217
time/epoch (s)                               25.8167
time/total (s)                             2025.87
Epoch                                        79
---------------------------------------  ----------------
2023-08-05 00:55:19.271460 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 80 finished
---------------------------------------  ----------------
epoch                                        80
replay_buffer/size                       162000
trainer/QF Loss                               3.65421e+08
trainer/Policy Loss                      -97949.6
trainer/Raw Policy Loss                  -97949.6
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                79485.3
trainer/Q Predictions Std                 14086.6
trainer/Q Predictions Max                128367
trainer/Q Predictions Min                   395.074
trainer/Q Targets Mean                    92856.3
trainer/Q Targets Std                      5037.53
trainer/Q Targets Max                    157348
trainer/Q Targets Min                     50218.2
trainer/Bellman Errors Mean                   3.65421e+08
trainer/Bellman Errors Std                    8.23815e+08
trainer/Bellman Errors Max                    8.42398e+09
trainer/Bellman Errors Min                  153.915
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     162000
expl/num paths total                       4050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.531795
expl/Rewards Std                              0.671985
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            21.2718
expl/Returns Std                             20.541
expl/Returns Max                             45.703
expl/Returns Min                              0
expl/Actions Mean                             0.274641
expl/Actions Std                              0.809279
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.2718
expl/env_infos/final/reward_dist Mean         0.782154
expl/env_infos/final/reward_dist Std          0.782257
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00176938
expl/env_infos/initial/reward_dist Std        0.00522317
expl/env_infos/initial/reward_dist Max        0.024092
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.531795
expl/env_infos/reward_dist Std                0.671985
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      32400
eval/num paths total                        810
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.624085
eval/Rewards Std                              0.692591
eval/Rewards Max                              1.57056
eval/Rewards Min                              0
eval/Returns Mean                            24.9634
eval/Returns Std                             21.1013
eval/Returns Max                             45.3834
eval/Returns Min                              0.0037595
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.9634
eval/env_infos/final/reward_dist Mean         0.933853
eval/env_infos/final/reward_dist Std          0.762763
eval/env_infos/final/reward_dist Max          1.57056
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00329121
eval/env_infos/initial/reward_dist Std        0.00662131
eval/env_infos/initial/reward_dist Max        0.0180586
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.624085
eval/env_infos/reward_dist Std                0.692591
eval/env_infos/reward_dist Max                1.57056
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595948
time/evaluation sampling (s)                  3.49828
time/exploration sampling (s)                17.4282
time/logging (s)                              0.00532912
time/saving (s)                               0.00102797
time/training (s)                             4.3688
time/epoch (s)                               25.3076
time/total (s)                             2051.18
Epoch                                        80
---------------------------------------  ----------------
2023-08-05 00:55:45.251286 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 81 finished
---------------------------------------  -----------------
epoch                                         81
replay_buffer/size                        164000
trainer/QF Loss                                3.72226e+08
trainer/Policy Loss                      -101081
trainer/Raw Policy Loss                  -101081
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                 82488
trainer/Q Predictions Std                  14181.9
trainer/Q Predictions Max                 135068
trainer/Q Predictions Min                    358.102
trainer/Q Targets Mean                     96026.8
trainer/Q Targets Std                       5096.63
trainer/Q Targets Max                     146428
trainer/Q Targets Min                      53047.8
trainer/Bellman Errors Mean                    3.72226e+08
trainer/Bellman Errors Std                     8.27461e+08
trainer/Bellman Errors Max                     9.02576e+09
trainer/Bellman Errors Min                    23.1602
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      164000
expl/num paths total                        4100
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.438462
expl/Rewards Std                               0.636357
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             17.5385
expl/Returns Std                              19.9543
expl/Returns Max                              43.7889
expl/Returns Min                               0
expl/Actions Mean                              0.254749
expl/Actions Std                               0.811801
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.5385
expl/env_infos/final/reward_dist Mean          0.671693
expl/env_infos/final/reward_dist Std           0.76704
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00095858
expl/env_infos/initial/reward_dist Std         0.00309081
expl/env_infos/initial/reward_dist Max         0.0143364
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.438462
expl/env_infos/reward_dist Std                 0.636357
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       32800
eval/num paths total                         820
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.271886
eval/Rewards Std                               0.540295
eval/Rewards Max                               1.57018
eval/Rewards Min                               0
eval/Returns Mean                             10.8754
eval/Returns Std                              17.7646
eval/Returns Max                              44.5
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          10.8754
eval/env_infos/final/reward_dist Mean          0.463199
eval/env_infos/final/reward_dist Std           0.706999
eval/env_infos/final/reward_dist Max           1.57018
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        8.58684e-05
eval/env_infos/initial/reward_dist Std         0.000257605
eval/env_infos/initial/reward_dist Max         0.000858684
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.271886
eval/env_infos/reward_dist Std                 0.540295
eval/env_infos/reward_dist Max                 1.57018
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00605212
time/evaluation sampling (s)                   3.51756
time/exploration sampling (s)                 18.1417
time/logging (s)                               0.00536056
time/saving (s)                                0.00100803
time/training (s)                              4.3055
time/epoch (s)                                25.9772
time/total (s)                              2077.16
Epoch                                         81
---------------------------------------  -----------------
2023-08-05 00:56:11.013410 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 82 finished
---------------------------------------  -----------------
epoch                                         82
replay_buffer/size                        166000
trainer/QF Loss                                4.02476e+08
trainer/Policy Loss                      -104602
trainer/Raw Policy Loss                  -104602
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                 85237
trainer/Q Predictions Std                  14679.4
trainer/Q Predictions Max                 150089
trainer/Q Predictions Min                    389.428
trainer/Q Targets Mean                     99245.6
trainer/Q Targets Std                       5650.09
trainer/Q Targets Max                     176800
trainer/Q Targets Min                      55089.8
trainer/Bellman Errors Mean                    4.02476e+08
trainer/Bellman Errors Std                     8.70858e+08
trainer/Bellman Errors Max                     9.69782e+09
trainer/Bellman Errors Min                     3.9068
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      166000
expl/num paths total                        4150
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.495796
expl/Rewards Std                               0.660224
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             19.8318
expl/Returns Std                              20.4031
expl/Returns Max                              44.4771
expl/Returns Min                               0
expl/Actions Mean                              0.251054
expl/Actions Std                               0.803446
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.8318
expl/env_infos/final/reward_dist Mean          0.721623
expl/env_infos/final/reward_dist Std           0.781857
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00134312
expl/env_infos/initial/reward_dist Std         0.00450159
expl/env_infos/initial/reward_dist Max         0.0200163
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.495796
expl/env_infos/reward_dist Std                 0.660224
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       33200
eval/num paths total                         830
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.556793
eval/Rewards Std                               0.695234
eval/Rewards Max                               1.57072
eval/Rewards Min                               0
eval/Returns Mean                             22.2717
eval/Returns Std                              22.2263
eval/Returns Max                              45.0756
eval/Returns Min                               0.00230411
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.2717
eval/env_infos/final/reward_dist Mean          0.785348
eval/env_infos/final/reward_dist Std           0.784391
eval/env_infos/final/reward_dist Max           1.57072
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000498442
eval/env_infos/initial/reward_dist Std         0.00149533
eval/env_infos/initial/reward_dist Max         0.00498442
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.556793
eval/env_infos/reward_dist Std                 0.695234
eval/env_infos/reward_dist Max                 1.57072
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00589486
time/evaluation sampling (s)                   3.61681
time/exploration sampling (s)                 17.8294
time/logging (s)                               0.00741599
time/saving (s)                                0.00109267
time/training (s)                              4.30093
time/epoch (s)                                25.7616
time/total (s)                              2102.92
Epoch                                         82
---------------------------------------  -----------------
2023-08-05 00:56:36.755200 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 83 finished
---------------------------------------  -----------------
epoch                                         83
replay_buffer/size                        168000
trainer/QF Loss                                4.25575e+08
trainer/Policy Loss                      -108002
trainer/Raw Policy Loss                  -108002
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                 87990.7
trainer/Q Predictions Std                  15006.7
trainer/Q Predictions Max                 140304
trainer/Q Predictions Min                    402.955
trainer/Q Targets Mean                    102520
trainer/Q Targets Std                       5651.32
trainer/Q Targets Max                     155427
trainer/Q Targets Min                      56138
trainer/Bellman Errors Mean                    4.25575e+08
trainer/Bellman Errors Std                     9.17056e+08
trainer/Bellman Errors Max                     1.03909e+10
trainer/Bellman Errors Min                   125.86
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      168000
expl/num paths total                        4200
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.424214
expl/Rewards Std                               0.614991
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             16.9686
expl/Returns Std                              18.9379
expl/Returns Max                              43.635
expl/Returns Min                               0
expl/Actions Mean                              0.255416
expl/Actions Std                               0.803819
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.9686
expl/env_infos/final/reward_dist Mean          0.665487
expl/env_infos/final/reward_dist Std           0.761721
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000703811
expl/env_infos/initial/reward_dist Std         0.00329965
expl/env_infos/initial/reward_dist Max         0.0229885
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.424214
expl/env_infos/reward_dist Std                 0.614991
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       33600
eval/num paths total                         840
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.635654
eval/Rewards Std                               0.69838
eval/Rewards Max                               1.57066
eval/Rewards Min                               0
eval/Returns Mean                             25.4262
eval/Returns Std                              21.0164
eval/Returns Max                              44.5151
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          25.4262
eval/env_infos/final/reward_dist Mean          0.934815
eval/env_infos/final/reward_dist Std           0.763063
eval/env_infos/final/reward_dist Max           1.57066
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.635654
eval/env_infos/reward_dist Std                 0.69838
eval/env_infos/reward_dist Max                 1.57066
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00594441
time/evaluation sampling (s)                   3.38857
time/exploration sampling (s)                 18.0257
time/logging (s)                               0.0074094
time/saving (s)                                0.00109055
time/training (s)                              4.30912
time/epoch (s)                                25.7379
time/total (s)                              2128.66
Epoch                                         83
---------------------------------------  -----------------
2023-08-05 00:57:01.895575 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 84 finished
---------------------------------------  -----------------
epoch                                         84
replay_buffer/size                        170000
trainer/QF Loss                                4.48882e+08
trainer/Policy Loss                      -111634
trainer/Raw Policy Loss                  -111634
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                 90837.4
trainer/Q Predictions Std                  15399.3
trainer/Q Predictions Max                 150996
trainer/Q Predictions Min                    429.677
trainer/Q Targets Mean                    105804
trainer/Q Targets Std                       5620.82
trainer/Q Targets Max                     155383
trainer/Q Targets Min                      57707.1
trainer/Bellman Errors Mean                    4.48882e+08
trainer/Bellman Errors Std                     9.41572e+08
trainer/Bellman Errors Max                     1.07661e+10
trainer/Bellman Errors Min                   213.891
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      170000
expl/num paths total                        4250
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.495683
expl/Rewards Std                               0.65432
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             19.8273
expl/Returns Std                              19.7506
expl/Returns Max                              43.9028
expl/Returns Min                               0
expl/Actions Mean                              0.261795
expl/Actions Std                               0.811811
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.8273
expl/env_infos/final/reward_dist Mean          0.779511
expl/env_infos/final/reward_dist Std           0.779391
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000586353
expl/env_infos/initial/reward_dist Std         0.00217311
expl/env_infos/initial/reward_dist Max         0.0112218
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.495683
expl/env_infos/reward_dist Std                 0.65432
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       34000
eval/num paths total                         850
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.671533
eval/Rewards Std                               0.706711
eval/Rewards Max                               1.57009
eval/Rewards Min                               0
eval/Returns Mean                             26.8613
eval/Returns Std                              21.5684
eval/Returns Max                              45.1776
eval/Returns Min                               0.00234926
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.8613
eval/env_infos/final/reward_dist Mean          0.95839
eval/env_infos/final/reward_dist Std           0.747234
eval/env_infos/final/reward_dist Max           1.57009
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00286268
eval/env_infos/initial/reward_dist Std         0.00588412
eval/env_infos/initial/reward_dist Max         0.0173491
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.671533
eval/env_infos/reward_dist Std                 0.706711
eval/env_infos/reward_dist Max                 1.57009
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00593913
time/evaluation sampling (s)                   3.43283
time/exploration sampling (s)                 17.3545
time/logging (s)                               0.00533542
time/saving (s)                                0.000961914
time/training (s)                              4.33482
time/epoch (s)                                25.1344
time/total (s)                              2153.8
Epoch                                         84
---------------------------------------  -----------------
2023-08-05 00:57:27.022418 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 85 finished
---------------------------------------  -----------------
epoch                                         85
replay_buffer/size                        172000
trainer/QF Loss                                4.87561e+08
trainer/Policy Loss                      -115025
trainer/Raw Policy Loss                  -115025
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                 93599.3
trainer/Q Predictions Std                  16013.1
trainer/Q Predictions Max                 165208
trainer/Q Predictions Min                    425.358
trainer/Q Targets Mean                    109221
trainer/Q Targets Std                       6090.87
trainer/Q Targets Max                     154496
trainer/Q Targets Min                      58467.5
trainer/Bellman Errors Mean                    4.87561e+08
trainer/Bellman Errors Std                     1.03274e+09
trainer/Bellman Errors Max                     1.15835e+10
trainer/Bellman Errors Min                    12.8589
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      172000
expl/num paths total                        4300
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.62097
expl/Rewards Std                               0.681381
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             24.8388
expl/Returns Std                              19.6696
expl/Returns Max                              44.1617
expl/Returns Min                               0
expl/Actions Mean                              0.257933
expl/Actions Std                               0.797658
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          24.8388
expl/env_infos/final/reward_dist Mean          0.966315
expl/env_infos/final/reward_dist Std           0.757047
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00154066
expl/env_infos/initial/reward_dist Std         0.00416862
expl/env_infos/initial/reward_dist Max         0.0168035
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.62097
expl/env_infos/reward_dist Std                 0.681381
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       34400
eval/num paths total                         860
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.743414
eval/Rewards Std                               0.699828
eval/Rewards Max                               1.57065
eval/Rewards Min                               0
eval/Returns Mean                             29.7366
eval/Returns Std                              19.7748
eval/Returns Max                              45.1302
eval/Returns Min                               0.000410967
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          29.7366
eval/env_infos/final/reward_dist Mean          1.09027
eval/env_infos/final/reward_dist Std           0.714043
eval/env_infos/final/reward_dist Max           1.57065
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00255391
eval/env_infos/initial/reward_dist Std         0.00634349
eval/env_infos/initial/reward_dist Max         0.0214317
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.743414
eval/env_infos/reward_dist Std                 0.699828
eval/env_infos/reward_dist Max                 1.57065
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00601263
time/evaluation sampling (s)                   3.39284
time/exploration sampling (s)                 17.2521
time/logging (s)                               0.00530103
time/saving (s)                                0.000975201
time/training (s)                              4.46692
time/epoch (s)                                25.1242
time/total (s)                              2178.92
Epoch                                         85
---------------------------------------  -----------------
2023-08-05 00:57:51.978921 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 86 finished
---------------------------------------  -----------------
epoch                                         86
replay_buffer/size                        174000
trainer/QF Loss                                5.04873e+08
trainer/Policy Loss                      -118710
trainer/Raw Policy Loss                  -118710
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                 96713.1
trainer/Q Predictions Std                  15934.1
trainer/Q Predictions Max                 169395
trainer/Q Predictions Min                    412.79
trainer/Q Targets Mean                    112663
trainer/Q Targets Std                       6229.58
trainer/Q Targets Max                     165700
trainer/Q Targets Min                      61173.5
trainer/Bellman Errors Mean                    5.04873e+08
trainer/Bellman Errors Std                     1.00996e+09
trainer/Bellman Errors Max                     1.18905e+10
trainer/Bellman Errors Min                     1.35504
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      174000
expl/num paths total                        4350
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.515445
expl/Rewards Std                               0.660596
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             20.6178
expl/Returns Std                              20.2977
expl/Returns Max                              44.3537
expl/Returns Min                               0
expl/Actions Mean                              0.260067
expl/Actions Std                               0.803181
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          20.6178
expl/env_infos/final/reward_dist Mean          0.779814
expl/env_infos/final/reward_dist Std           0.771627
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000331275
expl/env_infos/initial/reward_dist Std         0.00107838
expl/env_infos/initial/reward_dist Max         0.00603681
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.515445
expl/env_infos/reward_dist Std                 0.660596
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       34800
eval/num paths total                         870
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.89343
eval/Rewards Std                               0.688614
eval/Rewards Max                               1.56942
eval/Rewards Min                               0
eval/Returns Mean                             35.7372
eval/Returns Std                              17.8688
eval/Returns Max                              45.4545
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          35.7372
eval/env_infos/final/reward_dist Mean          1.25395
eval/env_infos/final/reward_dist Std           0.626979
eval/env_infos/final/reward_dist Max           1.56942
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00324428
eval/env_infos/initial/reward_dist Std         0.00663887
eval/env_infos/initial/reward_dist Max         0.0193623
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.89343
eval/env_infos/reward_dist Std                 0.688614
eval/env_infos/reward_dist Max                 1.56942
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00595673
time/evaluation sampling (s)                   3.40584
time/exploration sampling (s)                 17.3955
time/logging (s)                               0.00541107
time/saving (s)                                0.000972903
time/training (s)                              4.14038
time/epoch (s)                                24.954
time/total (s)                              2203.88
Epoch                                         86
---------------------------------------  -----------------
2023-08-05 00:58:17.010431 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 87 finished
---------------------------------------  -----------------
epoch                                         87
replay_buffer/size                        176000
trainer/QF Loss                                4.8861e+08
trainer/Policy Loss                      -122538
trainer/Raw Policy Loss                  -122538
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                100528
trainer/Q Predictions Std                  15823.1
trainer/Q Predictions Max                 152546
trainer/Q Predictions Min                    130.446
trainer/Q Targets Mean                    116329
trainer/Q Targets Std                       6071.4
trainer/Q Targets Max                     165164
trainer/Q Targets Min                      63441.9
trainer/Bellman Errors Mean                    4.8861e+08
trainer/Bellman Errors Std                     9.9708e+08
trainer/Bellman Errors Max                     1.60072e+10
trainer/Bellman Errors Min                    20.4615
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      176000
expl/num paths total                        4400
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.584744
expl/Rewards Std                               0.674251
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             23.3898
expl/Returns Std                              19.9803
expl/Returns Max                              44.4352
expl/Returns Min                               0
expl/Actions Mean                              0.249696
expl/Actions Std                               0.799404
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          23.3898
expl/env_infos/final/reward_dist Mean          0.874016
expl/env_infos/final/reward_dist Std           0.775297
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00190434
expl/env_infos/initial/reward_dist Std         0.00550125
expl/env_infos/initial/reward_dist Max         0.0237393
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.584744
expl/env_infos/reward_dist Std                 0.674251
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       35200
eval/num paths total                         880
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.760401
eval/Rewards Std                               0.700914
eval/Rewards Max                               1.57015
eval/Rewards Min                               0
eval/Returns Mean                             30.4161
eval/Returns Std                              20.032
eval/Returns Max                              45.0283
eval/Returns Min                               0.00316648
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          30.4161
eval/env_infos/final/reward_dist Mean          1.08886
eval/env_infos/final/reward_dist Std           0.712974
eval/env_infos/final/reward_dist Max           1.57015
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00340284
eval/env_infos/initial/reward_dist Std         0.00592951
eval/env_infos/initial/reward_dist Max         0.0167437
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.760401
eval/env_infos/reward_dist Std                 0.700914
eval/env_infos/reward_dist Max                 1.57015
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00594243
time/evaluation sampling (s)                   3.40113
time/exploration sampling (s)                 17.1828
time/logging (s)                               0.00538252
time/saving (s)                                0.000982281
time/training (s)                              4.43258
time/epoch (s)                                25.0288
time/total (s)                              2228.91
Epoch                                         87
---------------------------------------  -----------------
2023-08-05 00:58:42.386956 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 88 finished
---------------------------------------  -----------------
epoch                                         88
replay_buffer/size                        178000
trainer/QF Loss                                5.69216e+08
trainer/Policy Loss                      -126420
trainer/Raw Policy Loss                  -126420
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                102890
trainer/Q Predictions Std                  17030.2
trainer/Q Predictions Max                 215510
trainer/Q Predictions Min                    468.118
trainer/Q Targets Mean                    119875
trainer/Q Targets Std                       6651.53
trainer/Q Targets Max                     213301
trainer/Q Targets Min                      68820.1
trainer/Bellman Errors Mean                    5.69216e+08
trainer/Bellman Errors Std                     1.12327e+09
trainer/Bellman Errors Max                     1.42445e+10
trainer/Bellman Errors Min                     0.12915
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      178000
expl/num paths total                        4450
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.283246
expl/Rewards Std                               0.551395
expl/Rewards Max                               1.57075
expl/Rewards Min                               0
expl/Returns Mean                             11.3298
expl/Returns Std                              18.0621
expl/Returns Max                              43.7408
expl/Returns Min                               0
expl/Actions Mean                              0.278821
expl/Actions Std                               0.805337
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          11.3298
expl/env_infos/final/reward_dist Mean          0.408908
expl/env_infos/final/reward_dist Std           0.687468
expl/env_infos/final/reward_dist Max           1.57075
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000167337
expl/env_infos/initial/reward_dist Std         0.000763849
expl/env_infos/initial/reward_dist Max         0.0049228
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.283246
expl/env_infos/reward_dist Std                 0.551395
expl/env_infos/reward_dist Max                 1.57075
expl/env_infos/reward_dist Min                 0
eval/num steps total                       35600
eval/num paths total                         890
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.887304
eval/Rewards Std                               0.691087
eval/Rewards Max                               1.57062
eval/Rewards Min                               0
eval/Returns Mean                             35.4922
eval/Returns Std                              17.7525
eval/Returns Max                              45.3621
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          35.4922
eval/env_infos/final/reward_dist Mean          1.25532
eval/env_infos/final/reward_dist Std           0.627659
eval/env_infos/final/reward_dist Max           1.57062
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00196829
eval/env_infos/initial/reward_dist Std         0.00590487
eval/env_infos/initial/reward_dist Max         0.0196829
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.887304
eval/env_infos/reward_dist Std                 0.691087
eval/env_infos/reward_dist Max                 1.57062
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00608597
time/evaluation sampling (s)                   3.41712
time/exploration sampling (s)                 17.6483
time/logging (s)                               0.00533349
time/saving (s)                                0.000958025
time/training (s)                              4.29607
time/epoch (s)                                25.3738
time/total (s)                              2254.29
Epoch                                         88
---------------------------------------  -----------------
2023-08-05 00:59:08.423832 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 89 finished
---------------------------------------  -----------------
epoch                                         89
replay_buffer/size                        180000
trainer/QF Loss                                6.11558e+08
trainer/Policy Loss                      -130277
trainer/Raw Policy Loss                  -130277
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                105919
trainer/Q Predictions Std                  17830.8
trainer/Q Predictions Max                 194181
trainer/Q Predictions Min                    589.164
trainer/Q Targets Mean                    123596
trainer/Q Targets Std                       6689.99
trainer/Q Targets Max                     176800
trainer/Q Targets Min                      67615.5
trainer/Bellman Errors Mean                    6.11558e+08
trainer/Bellman Errors Std                     1.20517e+09
trainer/Bellman Errors Max                     1.50562e+10
trainer/Bellman Errors Min                   279.778
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      180000
expl/num paths total                        4500
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.483176
expl/Rewards Std                               0.650533
expl/Rewards Max                               1.5708
expl/Rewards Min                               0
expl/Returns Mean                             19.327
expl/Returns Std                              20.1831
expl/Returns Max                              44.9423
expl/Returns Min                               0
expl/Actions Mean                              0.254428
expl/Actions Std                               0.799009
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.327
expl/env_infos/final/reward_dist Mean          0.71641
expl/env_infos/final/reward_dist Std           0.775434
expl/env_infos/final/reward_dist Max           1.5708
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00155788
expl/env_infos/initial/reward_dist Std         0.00511721
expl/env_infos/initial/reward_dist Max         0.0247895
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.483176
expl/env_infos/reward_dist Std                 0.650533
expl/env_infos/reward_dist Max                 1.5708
expl/env_infos/reward_dist Min                 0
eval/num steps total                       36000
eval/num paths total                         900
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.563862
eval/Rewards Std                               0.69693
eval/Rewards Max                               1.57037
eval/Rewards Min                               0
eval/Returns Mean                             22.5545
eval/Returns Std                              22.5467
eval/Returns Max                              46.1896
eval/Returns Min                               0.00163714
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.5545
eval/env_infos/final/reward_dist Mean          0.783809
eval/env_infos/final/reward_dist Std           0.783812
eval/env_infos/final/reward_dist Max           1.57037
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00164191
eval/env_infos/initial/reward_dist Std         0.00436274
eval/env_infos/initial/reward_dist Max         0.0146322
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.563862
eval/env_infos/reward_dist Std                 0.69693
eval/env_infos/reward_dist Max                 1.57037
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0060007
time/evaluation sampling (s)                   3.28579
time/exploration sampling (s)                 17.5863
time/logging (s)                               0.00792024
time/saving (s)                                0.00125317
time/training (s)                              5.14952
time/epoch (s)                                26.0368
time/total (s)                              2280.32
Epoch                                         89
---------------------------------------  -----------------
2023-08-05 00:59:34.711316 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 90 finished
---------------------------------------  -----------------
epoch                                         90
replay_buffer/size                        182000
trainer/QF Loss                                6.29934e+08
trainer/Policy Loss                      -134222
trainer/Raw Policy Loss                  -134222
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                109796
trainer/Q Predictions Std                  18363
trainer/Q Predictions Max                 222137
trainer/Q Predictions Min                    484.043
trainer/Q Targets Mean                    127302
trainer/Q Targets Std                       7389.62
trainer/Q Targets Max                     226437
trainer/Q Targets Min                      68955.8
trainer/Bellman Errors Mean                    6.29934e+08
trainer/Bellman Errors Std                     1.31147e+09
trainer/Bellman Errors Max                     1.57709e+10
trainer/Bellman Errors Min                   196
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      182000
expl/num paths total                        4550
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.380696
expl/Rewards Std                               0.608599
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             15.2278
expl/Returns Std                              19.5811
expl/Returns Max                              44.3043
expl/Returns Min                               0
expl/Actions Mean                              0.249375
expl/Actions Std                               0.818293
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          15.2278
expl/env_infos/final/reward_dist Mean          0.575193
expl/env_infos/final/reward_dist Std           0.741266
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000902
expl/env_infos/initial/reward_dist Std         0.0033445
expl/env_infos/initial/reward_dist Max         0.0165752
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.380696
expl/env_infos/reward_dist Std                 0.608599
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       36400
eval/num paths total                         910
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.337508
eval/Rewards Std                               0.575267
eval/Rewards Max                               1.57074
eval/Rewards Min                               0
eval/Returns Mean                             13.5003
eval/Returns Std                              18.8192
eval/Returns Max                              44.894
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          13.5003
eval/env_infos/final/reward_dist Mean          0.549116
eval/env_infos/final/reward_dist Std           0.697431
eval/env_infos/final/reward_dist Max           1.57074
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000568325
eval/env_infos/initial/reward_dist Std         0.00170498
eval/env_infos/initial/reward_dist Max         0.00568325
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.337508
eval/env_infos/reward_dist Std                 0.575267
eval/env_infos/reward_dist Max                 1.57074
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00591547
time/evaluation sampling (s)                   3.53107
time/exploration sampling (s)                 17.6846
time/logging (s)                               0.0078708
time/saving (s)                                0.00126368
time/training (s)                              5.05266
time/epoch (s)                                26.2834
time/total (s)                              2306.61
Epoch                                         90
---------------------------------------  -----------------
2023-08-05 01:00:01.092230 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 91 finished
---------------------------------------  -----------------
epoch                                         91
replay_buffer/size                        184000
trainer/QF Loss                                6.38709e+08
trainer/Policy Loss                      -138475
trainer/Raw Policy Loss                  -138475
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                113375
trainer/Q Predictions Std                  18116.9
trainer/Q Predictions Max                 175906
trainer/Q Predictions Min                    508.421
trainer/Q Targets Mean                    131406
trainer/Q Targets Std                       7474.11
trainer/Q Targets Max                     203523
trainer/Q Targets Min                      71615.7
trainer/Bellman Errors Mean                    6.38709e+08
trainer/Bellman Errors Std                     1.27806e+09
trainer/Bellman Errors Max                     1.65001e+10
trainer/Bellman Errors Min                    19.6221
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      184000
expl/num paths total                        4600
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.428811
expl/Rewards Std                               0.632085
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             17.1524
expl/Returns Std                              19.8555
expl/Returns Max                              44.0951
expl/Returns Min                               0
expl/Actions Mean                              0.25648
expl/Actions Std                               0.797221
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.1524
expl/env_infos/final/reward_dist Mean          0.637279
expl/env_infos/final/reward_dist Std           0.762024
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000952612
expl/env_infos/initial/reward_dist Std         0.00296943
expl/env_infos/initial/reward_dist Max         0.014771
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.428811
expl/env_infos/reward_dist Std                 0.632085
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       36800
eval/num paths total                         920
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.664652
eval/Rewards Std                               0.710296
eval/Rewards Max                               1.57042
eval/Rewards Min                               0
eval/Returns Mean                             26.5861
eval/Returns Std                              21.7322
eval/Returns Max                              46.1127
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.5861
eval/env_infos/final/reward_dist Mean          0.941612
eval/env_infos/final/reward_dist Std           0.768824
eval/env_infos/final/reward_dist Max           1.57042
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00283118
eval/env_infos/initial/reward_dist Std         0.00548905
eval/env_infos/initial/reward_dist Max         0.0169277
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.664652
eval/env_infos/reward_dist Std                 0.710296
eval/env_infos/reward_dist Max                 1.57042
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00600589
time/evaluation sampling (s)                   3.45153
time/exploration sampling (s)                 18.5624
time/logging (s)                               0.00536899
time/saving (s)                                0.00101072
time/training (s)                              4.34794
time/epoch (s)                                26.3743
time/total (s)                              2332.99
Epoch                                         91
---------------------------------------  -----------------
2023-08-05 01:00:27.091948 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 92 finished
---------------------------------------  -----------------
epoch                                         92
replay_buffer/size                        186000
trainer/QF Loss                                7.72604e+08
trainer/Policy Loss                      -142479
trainer/Raw Policy Loss                  -142479
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                115741
trainer/Q Predictions Std                  20095.2
trainer/Q Predictions Max                 203268
trainer/Q Predictions Min                    453.232
trainer/Q Targets Mean                    135222
trainer/Q Targets Std                       7408.36
trainer/Q Targets Max                     198805
trainer/Q Targets Min                      73823.1
trainer/Bellman Errors Mean                    7.72604e+08
trainer/Bellman Errors Std                     1.67259e+09
trainer/Bellman Errors Max                     1.81262e+10
trainer/Bellman Errors Min                    35.626
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      186000
expl/num paths total                        4650
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.413982
expl/Rewards Std                               0.615355
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             16.5593
expl/Returns Std                              18.8369
expl/Returns Max                              44.8357
expl/Returns Min                               0
expl/Actions Mean                              0.245845
expl/Actions Std                               0.810531
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.5593
expl/env_infos/final/reward_dist Mean          0.665869
expl/env_infos/final/reward_dist Std           0.76796
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00159065
expl/env_infos/initial/reward_dist Std         0.00405541
expl/env_infos/initial/reward_dist Max         0.0171952
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.413982
expl/env_infos/reward_dist Std                 0.615355
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       37200
eval/num paths total                         930
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.447267
eval/Rewards Std                               0.66032
eval/Rewards Max                               1.57068
eval/Rewards Min                               0
eval/Returns Mean                             17.8907
eval/Returns Std                              21.8984
eval/Returns Max                              45.1287
eval/Returns Min                               0.00160326
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          17.8907
eval/env_infos/final/reward_dist Mean          0.62702
eval/env_infos/final/reward_dist Std           0.767941
eval/env_infos/final/reward_dist Max           1.57068
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00432481
eval/env_infos/initial/reward_dist Std         0.00695701
eval/env_infos/initial/reward_dist Max         0.0173172
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.447267
eval/env_infos/reward_dist Std                 0.66032
eval/env_infos/reward_dist Max                 1.57068
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00599761
time/evaluation sampling (s)                   3.35742
time/exploration sampling (s)                 18.2293
time/logging (s)                               0.00744039
time/saving (s)                                0.00109277
time/training (s)                              4.39786
time/epoch (s)                                25.9991
time/total (s)                              2358.99
Epoch                                         92
---------------------------------------  -----------------
2023-08-05 01:00:51.578404 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 93 finished
---------------------------------------  -----------------
epoch                                         93
replay_buffer/size                        188000
trainer/QF Loss                                7.27215e+08
trainer/Policy Loss                      -146828
trainer/Raw Policy Loss                  -146828
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                120172
trainer/Q Predictions Std                  19521.3
trainer/Q Predictions Max                 205079
trainer/Q Predictions Min                    453.067
trainer/Q Targets Mean                    139401
trainer/Q Targets Std                       7288.59
trainer/Q Targets Max                     193980
trainer/Q Targets Min                      76938.4
trainer/Bellman Errors Mean                    7.27215e+08
trainer/Bellman Errors Std                     1.46106e+09
trainer/Bellman Errors Max                     1.85518e+10
trainer/Bellman Errors Min                    86.4319
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      188000
expl/num paths total                        4700
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.343168
expl/Rewards Std                               0.576217
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             13.7267
expl/Returns Std                              18.4385
expl/Returns Max                              43.7847
expl/Returns Min                               0
expl/Actions Mean                              0.2517
expl/Actions Std                               0.811307
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          13.7267
expl/env_infos/final/reward_dist Mean          0.506731
expl/env_infos/final/reward_dist Std           0.716275
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000916496
expl/env_infos/initial/reward_dist Std         0.00272949
expl/env_infos/initial/reward_dist Max         0.0139879
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.343168
expl/env_infos/reward_dist Std                 0.576217
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       37600
eval/num paths total                         940
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.562581
eval/Rewards Std                               0.696918
eval/Rewards Max                               1.57079
eval/Rewards Min                               0
eval/Returns Mean                             22.5032
eval/Returns Std                              22.502
eval/Returns Max                              45.829
eval/Returns Min                               0.00176097
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.5032
eval/env_infos/final/reward_dist Mean          0.784037
eval/env_infos/final/reward_dist Std           0.784039
eval/env_infos/final/reward_dist Max           1.57079
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00159999
eval/env_infos/initial/reward_dist Std         0.00452425
eval/env_infos/initial/reward_dist Max         0.0151515
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.562581
eval/env_infos/reward_dist Std                 0.696918
eval/env_infos/reward_dist Max                 1.57079
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00588526
time/evaluation sampling (s)                   3.37006
time/exploration sampling (s)                 16.9547
time/logging (s)                               0.0053345
time/saving (s)                                0.000996189
time/training (s)                              4.14337
time/epoch (s)                                24.4803
time/total (s)                              2383.47
Epoch                                         93
---------------------------------------  -----------------
2023-08-05 01:01:16.662276 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 94 finished
---------------------------------------  -----------------
epoch                                         94
replay_buffer/size                        190000
trainer/QF Loss                                8.04122e+08
trainer/Policy Loss                      -151001
trainer/Raw Policy Loss                  -151001
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                123027
trainer/Q Predictions Std                  20285.1
trainer/Q Predictions Max                 210943
trainer/Q Predictions Min                    449.518
trainer/Q Targets Mean                    143226
trainer/Q Targets Std                       7928.16
trainer/Q Targets Max                     219553
trainer/Q Targets Min                      78014.6
trainer/Bellman Errors Mean                    8.04122e+08
trainer/Bellman Errors Std                     1.65541e+09
trainer/Bellman Errors Max                     1.98052e+10
trainer/Bellman Errors Min                   164.16
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      190000
expl/num paths total                        4750
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.450552
expl/Rewards Std                               0.634654
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             18.0221
expl/Returns Std                              19.6214
expl/Returns Max                              44.4612
expl/Returns Min                               0
expl/Actions Mean                              0.245917
expl/Actions Std                               0.808931
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.0221
expl/env_infos/final/reward_dist Mean          0.658915
expl/env_infos/final/reward_dist Std           0.773819
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00199556
expl/env_infos/initial/reward_dist Std         0.00491264
expl/env_infos/initial/reward_dist Max         0.0227262
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.450552
expl/env_infos/reward_dist Std                 0.634654
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       38000
eval/num paths total                         950
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              1.11395
eval/Rewards Std                               0.589714
eval/Rewards Max                               1.57051
eval/Rewards Min                               0
eval/Returns Mean                             44.558
eval/Returns Std                               0.588831
eval/Returns Max                              45.3725
eval/Returns Min                              43.5804
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          44.558
eval/env_infos/final/reward_dist Mean          1.56895
eval/env_infos/final/reward_dist Std           0.00152032
eval/env_infos/final/reward_dist Max           1.57051
eval/env_infos/final/reward_dist Min           1.56622
eval/env_infos/initial/reward_dist Mean        0.00421747
eval/env_infos/initial/reward_dist Std         0.00647096
eval/env_infos/initial/reward_dist Max         0.0169037
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                1.11395
eval/env_infos/reward_dist Std                 0.589714
eval/env_infos/reward_dist Max                 1.57051
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00598412
time/evaluation sampling (s)                   3.40681
time/exploration sampling (s)                 17.839
time/logging (s)                               0.00741424
time/saving (s)                                0.00110241
time/training (s)                              3.82308
time/epoch (s)                                25.0833
time/total (s)                              2408.56
Epoch                                         94
---------------------------------------  -----------------
2023-08-05 01:01:42.302362 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 95 finished
---------------------------------------  -----------------
epoch                                         95
replay_buffer/size                        192000
trainer/QF Loss                                8.43107e+08
trainer/Policy Loss                      -155379
trainer/Raw Policy Loss                  -155379
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                126535
trainer/Q Predictions Std                  20370.4
trainer/Q Predictions Max                 211798
trainer/Q Predictions Min                    485.662
trainer/Q Targets Mean                    147495
trainer/Q Targets Std                       8499.53
trainer/Q Targets Max                     226526
trainer/Q Targets Min                      80169.9
trainer/Bellman Errors Mean                    8.43107e+08
trainer/Bellman Errors Std                     1.60975e+09
trainer/Bellman Errors Max                     2.124e+10
trainer/Bellman Errors Min                   266.098
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      192000
expl/num paths total                        4800
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.608314
expl/Rewards Std                               0.683267
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             24.3326
expl/Returns Std                              19.7058
expl/Returns Max                              45.6124
expl/Returns Min                               0
expl/Actions Mean                              0.259136
expl/Actions Std                               0.802698
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          24.3326
expl/env_infos/final/reward_dist Mean          0.909873
expl/env_infos/final/reward_dist Std           0.773879
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00127157
expl/env_infos/initial/reward_dist Std         0.00451735
expl/env_infos/initial/reward_dist Max         0.0239872
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.608314
expl/env_infos/reward_dist Std                 0.683267
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       38400
eval/num paths total                         960
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.679493
eval/Rewards Std                               0.712858
eval/Rewards Max                               1.56943
eval/Rewards Min                               0
eval/Returns Mean                             27.1797
eval/Returns Std                              22.1826
eval/Returns Max                              46.1324
eval/Returns Min                               0.00212453
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          27.1797
eval/env_infos/final/reward_dist Mean          0.941201
eval/env_infos/final/reward_dist Std           0.768488
eval/env_infos/final/reward_dist Max           1.56943
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00331864
eval/env_infos/initial/reward_dist Std         0.00551352
eval/env_infos/initial/reward_dist Max         0.016655
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.679493
eval/env_infos/reward_dist Std                 0.712858
eval/env_infos/reward_dist Max                 1.56943
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00598875
time/evaluation sampling (s)                   3.43586
time/exploration sampling (s)                 18.0228
time/logging (s)                               0.00535806
time/saving (s)                                0.00100964
time/training (s)                              4.16288
time/epoch (s)                                25.6339
time/total (s)                              2434.19
Epoch                                         95
---------------------------------------  -----------------
2023-08-05 01:02:07.921894 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 96 finished
---------------------------------------  -----------------
epoch                                         96
replay_buffer/size                        194000
trainer/QF Loss                                8.21448e+08
trainer/Policy Loss                      -159946
trainer/Raw Policy Loss                  -159946
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                131335
trainer/Q Predictions Std                  20629.5
trainer/Q Predictions Max                 241812
trainer/Q Predictions Min                    469.663
trainer/Q Targets Mean                    151648
trainer/Q Targets Std                       8096.33
trainer/Q Targets Max                     210420
trainer/Q Targets Min                      84358.2
trainer/Bellman Errors Mean                    8.21448e+08
trainer/Bellman Errors Std                     1.68689e+09
trainer/Bellman Errors Max                     2.22205e+10
trainer/Bellman Errors Min                   175.562
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      194000
expl/num paths total                        4850
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.489631
expl/Rewards Std                               0.653831
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             19.5852
expl/Returns Std                              20.063
expl/Returns Max                              45.4818
expl/Returns Min                               0
expl/Actions Mean                              0.25775
expl/Actions Std                               0.803225
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.5852
expl/env_infos/final/reward_dist Mean          0.718624
expl/env_infos/final/reward_dist Std           0.77841
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00205552
expl/env_infos/initial/reward_dist Std         0.00512506
expl/env_infos/initial/reward_dist Max         0.0222588
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.489631
expl/env_infos/reward_dist Std                 0.653831
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       38800
eval/num paths total                         970
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.333058
eval/Rewards Std                               0.584718
eval/Rewards Max                               1.57009
eval/Rewards Min                               0
eval/Returns Mean                             13.3223
eval/Returns Std                              19.2553
eval/Returns Max                              46.6523
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          13.3223
eval/env_infos/final/reward_dist Mean          0.527589
eval/env_infos/final/reward_dist Std           0.701879
eval/env_infos/final/reward_dist Max           1.57009
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00250001
eval/env_infos/initial/reward_dist Std         0.00750003
eval/env_infos/initial/reward_dist Max         0.0250001
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.333058
eval/env_infos/reward_dist Std                 0.584718
eval/env_infos/reward_dist Max                 1.57009
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00591704
time/evaluation sampling (s)                   3.42213
time/exploration sampling (s)                 18.0558
time/logging (s)                               0.00535774
time/saving (s)                                0.000980607
time/training (s)                              4.12674
time/epoch (s)                                25.6169
time/total (s)                              2459.81
Epoch                                         96
---------------------------------------  -----------------
2023-08-05 01:02:33.704473 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 97 finished
---------------------------------------  -----------------
epoch                                         97
replay_buffer/size                        196000
trainer/QF Loss                                1.00484e+09
trainer/Policy Loss                      -164309
trainer/Raw Policy Loss                  -164309
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                133674
trainer/Q Predictions Std                  22793.7
trainer/Q Predictions Max                 211143
trainer/Q Predictions Min                    487.968
trainer/Q Targets Mean                    156097
trainer/Q Targets Std                       9027.93
trainer/Q Targets Max                     238973
trainer/Q Targets Min                      86757.9
trainer/Bellman Errors Mean                    1.00484e+09
trainer/Bellman Errors Std                     2.08956e+09
trainer/Bellman Errors Max                     2.36834e+10
trainer/Bellman Errors Min                     9.76562
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      196000
expl/num paths total                        4900
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.274555
expl/Rewards Std                               0.537933
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             10.9822
expl/Returns Std                              17.5035
expl/Returns Max                              44.7063
expl/Returns Min                               0
expl/Actions Mean                              0.259537
expl/Actions Std                               0.80245
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          10.9822
expl/env_infos/final/reward_dist Mean          0.400816
expl/env_infos/final/reward_dist Std           0.676497
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000653131
expl/env_infos/initial/reward_dist Std         0.00254006
expl/env_infos/initial/reward_dist Max         0.0163331
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.274555
expl/env_infos/reward_dist Std                 0.537933
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       39200
eval/num paths total                         980
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.669943
eval/Rewards Std                               0.707068
eval/Rewards Max                               1.57053
eval/Rewards Min                               0
eval/Returns Mean                             26.7977
eval/Returns Std                              21.5184
eval/Returns Max                              45.4435
eval/Returns Min                               0.00810544
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.7977
eval/env_infos/final/reward_dist Mean          0.955636
eval/env_infos/final/reward_dist Std           0.752168
eval/env_infos/final/reward_dist Max           1.57053
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00362719
eval/env_infos/initial/reward_dist Std         0.00740686
eval/env_infos/initial/reward_dist Max         0.0214792
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.669943
eval/env_infos/reward_dist Std                 0.707068
eval/env_infos/reward_dist Max                 1.57053
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00596439
time/evaluation sampling (s)                   3.40362
time/exploration sampling (s)                 18.1103
time/logging (s)                               0.0053164
time/saving (s)                                0.000969927
time/training (s)                              4.25364
time/epoch (s)                                25.7798
time/total (s)                              2485.59
Epoch                                         97
---------------------------------------  -----------------
2023-08-05 01:02:58.815715 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 98 finished
---------------------------------------  -----------------
epoch                                         98
replay_buffer/size                        198000
trainer/QF Loss                                1.004e+09
trainer/Policy Loss                      -169230
trainer/Raw Policy Loss                  -169230
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                137782
trainer/Q Predictions Std                  22880.1
trainer/Q Predictions Max                 209185
trainer/Q Predictions Min                    535.012
trainer/Q Targets Mean                    160575
trainer/Q Targets Std                       8576.69
trainer/Q Targets Max                     248952
trainer/Q Targets Min                      88987.8
trainer/Bellman Errors Mean                    1.004e+09
trainer/Bellman Errors Std                     2.07375e+09
trainer/Bellman Errors Max                     2.47313e+10
trainer/Bellman Errors Min                   146.259
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      198000
expl/num paths total                        4950
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.346503
expl/Rewards Std                               0.580905
expl/Rewards Max                               1.57066
expl/Rewards Min                               0
expl/Returns Mean                             13.8601
expl/Returns Std                              18.6206
expl/Returns Max                              45.0009
expl/Returns Min                               0
expl/Actions Mean                              0.27365
expl/Actions Std                               0.798193
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          13.8601
expl/env_infos/final/reward_dist Mean          0.51654
expl/env_infos/final/reward_dist Std           0.722713
expl/env_infos/final/reward_dist Max           1.57066
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00141066
expl/env_infos/initial/reward_dist Std         0.00441705
expl/env_infos/initial/reward_dist Max         0.0230557
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.346503
expl/env_infos/reward_dist Std                 0.580905
expl/env_infos/reward_dist Max                 1.57066
expl/env_infos/reward_dist Min                 0
eval/num steps total                       39600
eval/num paths total                         990
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.552435
eval/Rewards Std                               0.693304
eval/Rewards Max                               1.57079
eval/Rewards Min                               0
eval/Returns Mean                             22.0974
eval/Returns Std                              22.0938
eval/Returns Max                              44.9617
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.0974
eval/env_infos/final/reward_dist Mean          0.784397
eval/env_infos/final/reward_dist Std           0.784382
eval/env_infos/final/reward_dist Max           1.57079
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        2.12364e-05
eval/env_infos/initial/reward_dist Std         6.37092e-05
eval/env_infos/initial/reward_dist Max         0.000212364
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.552435
eval/env_infos/reward_dist Std                 0.693304
eval/env_infos/reward_dist Max                 1.57079
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00594935
time/evaluation sampling (s)                   3.4254
time/exploration sampling (s)                 17.5632
time/logging (s)                               0.00542648
time/saving (s)                                0.000975875
time/training (s)                              4.10778
time/epoch (s)                                25.1087
time/total (s)                              2510.7
Epoch                                         98
---------------------------------------  -----------------
2023-08-05 01:03:23.766908 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 99 finished
---------------------------------------  -----------------
epoch                                         99
replay_buffer/size                        200000
trainer/QF Loss                                1.05897e+09
trainer/Policy Loss                      -173944
trainer/Raw Policy Loss                  -173944
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                141937
trainer/Q Predictions Std                  23375.1
trainer/Q Predictions Max                 225967
trainer/Q Predictions Min                    531.414
trainer/Q Targets Mean                    165199
trainer/Q Targets Std                       8898.16
trainer/Q Targets Max                     242354
trainer/Q Targets Min                      91106.2
trainer/Bellman Errors Mean                    1.05897e+09
trainer/Bellman Errors Std                     2.17474e+09
trainer/Bellman Errors Max                     2.64864e+10
trainer/Bellman Errors Min                    13.3682
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      200000
expl/num paths total                        5000
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.476025
expl/Rewards Std                               0.650847
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             19.041
expl/Returns Std                              20.3286
expl/Returns Max                              43.9315
expl/Returns Min                               0
expl/Actions Mean                              0.257953
expl/Actions Std                               0.802877
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.041
expl/env_infos/final/reward_dist Mean          0.723415
expl/env_infos/final/reward_dist Std           0.777965
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000725579
expl/env_infos/initial/reward_dist Std         0.0030456
expl/env_infos/initial/reward_dist Max         0.0182819
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.476025
expl/env_infos/reward_dist Std                 0.650847
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       40000
eval/num paths total                        1000
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.764296
eval/Rewards Std                               0.703617
eval/Rewards Max                               1.57042
eval/Rewards Min                               0
eval/Returns Mean                             30.5718
eval/Returns Std                              20.2164
eval/Returns Max                              46.3829
eval/Returns Min                               0.0021601
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          30.5718
eval/env_infos/final/reward_dist Mean          1.09783
eval/env_infos/final/reward_dist Std           0.718701
eval/env_infos/final/reward_dist Max           1.57042
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00286981
eval/env_infos/initial/reward_dist Std         0.00426928
eval/env_infos/initial/reward_dist Max         0.0107318
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.764296
eval/env_infos/reward_dist Std                 0.703617
eval/env_infos/reward_dist Max                 1.57042
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00594867
time/evaluation sampling (s)                   3.41192
time/exploration sampling (s)                 17.2831
time/logging (s)                               0.00536449
time/saving (s)                                0.00101494
time/training (s)                              4.24109
time/epoch (s)                                24.9484
time/total (s)                              2535.65
Epoch                                         99
---------------------------------------  -----------------
2023-08-05 01:03:49.066995 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 100 finished
---------------------------------------  -----------------
epoch                                        100
replay_buffer/size                        202000
trainer/QF Loss                                1.17766e+09
trainer/Policy Loss                      -178544
trainer/Raw Policy Loss                  -178544
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                144847
trainer/Q Predictions Std                  24343.3
trainer/Q Predictions Max                 216814
trainer/Q Predictions Min                    474.641
trainer/Q Targets Mean                    169536
trainer/Q Targets Std                       9533.68
trainer/Q Targets Max                     251341
trainer/Q Targets Min                      93695.7
trainer/Bellman Errors Mean                    1.17766e+09
trainer/Bellman Errors Std                     2.34745e+09
trainer/Bellman Errors Max                     2.78122e+10
trainer/Bellman Errors Min                    10.7666
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      202000
expl/num paths total                        5050
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.532605
expl/Rewards Std                               0.666687
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             21.3042
expl/Returns Std                              20.6697
expl/Returns Max                              44.8048
expl/Returns Min                               0
expl/Actions Mean                              0.285011
expl/Actions Std                               0.79019
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          21.3042
expl/env_infos/final/reward_dist Mean          0.807227
expl/env_infos/final/reward_dist Std           0.776214
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.0014931
expl/env_infos/initial/reward_dist Std         0.00457731
expl/env_infos/initial/reward_dist Max         0.0226351
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.532605
expl/env_infos/reward_dist Std                 0.666687
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       40400
eval/num paths total                        1010
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.662998
eval/Rewards Std                               0.711074
eval/Rewards Max                               1.57008
eval/Rewards Min                               0
eval/Returns Mean                             26.5199
eval/Returns Std                              21.6541
eval/Returns Max                              45.1264
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.5199
eval/env_infos/final/reward_dist Mean          0.941146
eval/env_infos/final/reward_dist Std           0.768443
eval/env_infos/final/reward_dist Max           1.57008
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00118208
eval/env_infos/initial/reward_dist Std         0.00260703
eval/env_infos/initial/reward_dist Max         0.00836739
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.662998
eval/env_infos/reward_dist Std                 0.711074
eval/env_infos/reward_dist Max                 1.57008
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00674588
time/evaluation sampling (s)                   3.35985
time/exploration sampling (s)                 17.5638
time/logging (s)                               0.00532805
time/saving (s)                                0.00100534
time/training (s)                              4.36075
time/epoch (s)                                25.2974
time/total (s)                              2560.95
Epoch                                        100
---------------------------------------  -----------------
2023-08-05 01:04:14.283142 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 101 finished
---------------------------------------  -----------------
epoch                                        101
replay_buffer/size                        204000
trainer/QF Loss                                1.22662e+09
trainer/Policy Loss                      -183220
trainer/Raw Policy Loss                  -183220
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                149202
trainer/Q Predictions Std                  25264.5
trainer/Q Predictions Max                 231533
trainer/Q Predictions Min                    538.11
trainer/Q Targets Mean                    174138
trainer/Q Targets Std                       9250.7
trainer/Q Targets Max                     242459
trainer/Q Targets Min                      95685.7
trainer/Bellman Errors Mean                    1.22662e+09
trainer/Bellman Errors Std                     2.4805e+09
trainer/Bellman Errors Max                     2.92972e+10
trainer/Bellman Errors Min                     0.25
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      204000
expl/num paths total                        5100
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.460544
expl/Rewards Std                               0.641096
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             18.4218
expl/Returns Std                              19.6035
expl/Returns Max                              44.3584
expl/Returns Min                               0
expl/Actions Mean                              0.257612
expl/Actions Std                               0.817668
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.4218
expl/env_infos/final/reward_dist Mean          0.68841
expl/env_infos/final/reward_dist Std           0.776674
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000318399
expl/env_infos/initial/reward_dist Std         0.00164858
expl/env_infos/initial/reward_dist Max         0.0116598
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.460544
expl/env_infos/reward_dist Std                 0.641096
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       40800
eval/num paths total                        1020
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.507049
eval/Rewards Std                               0.66902
eval/Rewards Max                               1.57078
eval/Rewards Min                               0
eval/Returns Mean                             20.2819
eval/Returns Std                              20.9009
eval/Returns Max                              46.4432
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          20.2819
eval/env_infos/final/reward_dist Mean          0.776403
eval/env_infos/final/reward_dist Std           0.776806
eval/env_infos/final/reward_dist Max           1.57078
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00100835
eval/env_infos/initial/reward_dist Std         0.00302504
eval/env_infos/initial/reward_dist Max         0.0100835
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.507049
eval/env_infos/reward_dist Std                 0.66902
eval/env_infos/reward_dist Max                 1.57078
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00618534
time/evaluation sampling (s)                   3.38687
time/exploration sampling (s)                 17.3667
time/logging (s)                               0.00534611
time/saving (s)                                0.000972602
time/training (s)                              4.44749
time/epoch (s)                                25.2135
time/total (s)                              2586.17
Epoch                                        101
---------------------------------------  -----------------
2023-08-05 01:04:39.037631 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 102 finished
---------------------------------------  -----------------
epoch                                        102
replay_buffer/size                        206000
trainer/QF Loss                                1.2076e+09
trainer/Policy Loss                      -188874
trainer/Raw Policy Loss                  -188874
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                154574
trainer/Q Predictions Std                  24817.1
trainer/Q Predictions Max                 268216
trainer/Q Predictions Min                    815.486
trainer/Q Targets Mean                    179212
trainer/Q Targets Std                      10672.1
trainer/Q Targets Max                     274431
trainer/Q Targets Min                      97071
trainer/Bellman Errors Mean                    1.2076e+09
trainer/Bellman Errors Std                     2.44286e+09
trainer/Bellman Errors Max                     3.12902e+10
trainer/Bellman Errors Min                   429.267
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      206000
expl/num paths total                        5150
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.388998
expl/Rewards Std                               0.611906
expl/Rewards Max                               1.57071
expl/Rewards Min                               0
expl/Returns Mean                             15.5599
expl/Returns Std                              19.1996
expl/Returns Max                              43.4419
expl/Returns Min                               0
expl/Actions Mean                              0.266413
expl/Actions Std                               0.793678
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          15.5599
expl/env_infos/final/reward_dist Mean          0.594886
expl/env_infos/final/reward_dist Std           0.759855
expl/env_infos/final/reward_dist Max           1.57071
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00105456
expl/env_infos/initial/reward_dist Std         0.00362395
expl/env_infos/initial/reward_dist Max         0.016672
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.388998
expl/env_infos/reward_dist Std                 0.611906
expl/env_infos/reward_dist Max                 1.57071
expl/env_infos/reward_dist Min                 0
eval/num steps total                       41200
eval/num paths total                        1030
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.341714
eval/Rewards Std                               0.608705
eval/Rewards Max                               1.57002
eval/Rewards Min                               0
eval/Returns Mean                             13.6686
eval/Returns Std                              20.8671
eval/Returns Max                              46.4351
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          13.6686
eval/env_infos/final/reward_dist Mean          0.470691
eval/env_infos/final/reward_dist Std           0.718993
eval/env_infos/final/reward_dist Max           1.57002
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00426692
eval/env_infos/initial/reward_dist Std         0.00857861
eval/env_infos/initial/reward_dist Max         0.026336
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.341714
eval/env_infos/reward_dist Std                 0.608705
eval/env_infos/reward_dist Max                 1.57002
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00662339
time/evaluation sampling (s)                   3.30517
time/exploration sampling (s)                 17.2212
time/logging (s)                               0.0053595
time/saving (s)                                0.000968697
time/training (s)                              4.21253
time/epoch (s)                                24.7519
time/total (s)                              2610.92
Epoch                                        102
---------------------------------------  -----------------
2023-08-05 01:05:04.240638 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 103 finished
---------------------------------------  -----------------
epoch                                        103
replay_buffer/size                        208000
trainer/QF Loss                                1.36483e+09
trainer/Policy Loss                      -193548
trainer/Raw Policy Loss                  -193548
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                157524
trainer/Q Predictions Std                  26310
trainer/Q Predictions Max                 245542
trainer/Q Predictions Min                    531.713
trainer/Q Targets Mean                    183807
trainer/Q Targets Std                      10312.5
trainer/Q Targets Max                     282818
trainer/Q Targets Min                     101907
trainer/Bellman Errors Mean                    1.36483e+09
trainer/Bellman Errors Std                     2.85093e+09
trainer/Bellman Errors Max                     3.30043e+10
trainer/Bellman Errors Min                     0.299072
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      208000
expl/num paths total                        5200
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.447194
expl/Rewards Std                               0.628271
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             17.8878
expl/Returns Std                              19.4634
expl/Returns Max                              45.2786
expl/Returns Min                               0
expl/Actions Mean                              0.250758
expl/Actions Std                               0.800079
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.8878
expl/env_infos/final/reward_dist Mean          0.669926
expl/env_infos/final/reward_dist Std           0.763665
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.0014444
expl/env_infos/initial/reward_dist Std         0.00427152
expl/env_infos/initial/reward_dist Max         0.0184454
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.447194
expl/env_infos/reward_dist Std                 0.628271
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       41600
eval/num paths total                        1040
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.428572
eval/Rewards Std                               0.646002
eval/Rewards Max                               1.56992
eval/Rewards Min                               0
eval/Returns Mean                             17.1429
eval/Returns Std                              21.0809
eval/Returns Max                              45.0956
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          17.1429
eval/env_infos/final/reward_dist Mean          0.619758
eval/env_infos/final/reward_dist Std           0.759328
eval/env_infos/final/reward_dist Max           1.56992
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        1.25126e-05
eval/env_infos/initial/reward_dist Std         3.75378e-05
eval/env_infos/initial/reward_dist Max         0.000125126
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.428572
eval/env_infos/reward_dist Std                 0.646002
eval/env_infos/reward_dist Max                 1.56992
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00825921
time/evaluation sampling (s)                   3.33675
time/exploration sampling (s)                 17.5125
time/logging (s)                               0.00533673
time/saving (s)                                0.000991071
time/training (s)                              4.33644
time/epoch (s)                                25.2002
time/total (s)                              2636.13
Epoch                                        103
---------------------------------------  -----------------
2023-08-05 01:05:29.538292 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 104 finished
---------------------------------------  -----------------
epoch                                        104
replay_buffer/size                        210000
trainer/QF Loss                                1.32118e+09
trainer/Policy Loss                      -198735
trainer/Raw Policy Loss                  -198735
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                162706
trainer/Q Predictions Std                  25806
trainer/Q Predictions Max                 272546
trainer/Q Predictions Min                    617.88
trainer/Q Targets Mean                    188455
trainer/Q Targets Std                      10876.8
trainer/Q Targets Max                     275489
trainer/Q Targets Min                     104652
trainer/Bellman Errors Mean                    1.32118e+09
trainer/Bellman Errors Std                     2.73092e+09
trainer/Bellman Errors Max                     3.45123e+10
trainer/Bellman Errors Min                     0.12915
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      210000
expl/num paths total                        5250
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.319754
expl/Rewards Std                               0.555844
expl/Rewards Max                               1.57055
expl/Rewards Min                               0
expl/Returns Mean                             12.7902
expl/Returns Std                              17.2813
expl/Returns Max                              43.7186
expl/Returns Min                               0
expl/Actions Mean                              0.23633
expl/Actions Std                               0.805189
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          12.7902
expl/env_infos/final/reward_dist Mean          0.454826
expl/env_infos/final/reward_dist Std           0.69711
expl/env_infos/final/reward_dist Max           1.57055
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00060218
expl/env_infos/initial/reward_dist Std         0.00236041
expl/env_infos/initial/reward_dist Max         0.0142546
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.319754
expl/env_infos/reward_dist Std                 0.555844
expl/env_infos/reward_dist Max                 1.57055
expl/env_infos/reward_dist Min                 0
eval/num steps total                       42000
eval/num paths total                        1050
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.272929
eval/Rewards Std                               0.540934
eval/Rewards Max                               1.56949
eval/Rewards Min                               0
eval/Returns Mean                             10.9171
eval/Returns Std                              17.8426
eval/Returns Max                              45.0487
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          10.9171
eval/env_infos/final/reward_dist Mean          0.459854
eval/env_infos/final/reward_dist Std           0.702964
eval/env_infos/final/reward_dist Max           1.56949
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.272929
eval/env_infos/reward_dist Std                 0.540934
eval/env_infos/reward_dist Max                 1.56949
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00934598
time/evaluation sampling (s)                   3.5547
time/exploration sampling (s)                 17.3784
time/logging (s)                               0.00536623
time/saving (s)                                0.00101234
time/training (s)                              4.34607
time/epoch (s)                                25.2949
time/total (s)                              2661.42
Epoch                                        104
---------------------------------------  -----------------
2023-08-05 01:05:54.519660 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 105 finished
---------------------------------------  -----------------
epoch                                        105
replay_buffer/size                        212000
trainer/QF Loss                                1.39881e+09
trainer/Policy Loss                      -204005
trainer/Raw Policy Loss                  -204005
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                166602
trainer/Q Predictions Std                  26422.3
trainer/Q Predictions Max                 268039
trainer/Q Predictions Min                    662.492
trainer/Q Targets Mean                    193886
trainer/Q Targets Std                      10613.3
trainer/Q Targets Max                     261663
trainer/Q Targets Min                     105024
trainer/Bellman Errors Mean                    1.39881e+09
trainer/Bellman Errors Std                     2.67123e+09
trainer/Bellman Errors Max                     3.64008e+10
trainer/Bellman Errors Min                    10.5625
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      212000
expl/num paths total                        5300
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.468791
expl/Rewards Std                               0.652756
expl/Rewards Max                               1.5708
expl/Rewards Min                               0
expl/Returns Mean                             18.7516
expl/Returns Std                              20.425
expl/Returns Max                              43.7235
expl/Returns Min                               0
expl/Actions Mean                              0.266073
expl/Actions Std                               0.807674
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.7516
expl/env_infos/final/reward_dist Mean          0.718546
expl/env_infos/final/reward_dist Std           0.778558
expl/env_infos/final/reward_dist Max           1.5708
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00130062
expl/env_infos/initial/reward_dist Std         0.00358703
expl/env_infos/initial/reward_dist Max         0.0173778
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.468791
expl/env_infos/reward_dist Std                 0.652756
expl/env_infos/reward_dist Max                 1.5708
expl/env_infos/reward_dist Min                 0
eval/num steps total                       42400
eval/num paths total                        1060
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              1.08809
eval/Rewards Std                               0.593909
eval/Rewards Max                               1.57079
eval/Rewards Min                               0
eval/Returns Mean                             43.5234
eval/Returns Std                               4.04688
eval/Returns Max                              45.4506
eval/Returns Min                              31.4658
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          43.5234
eval/env_infos/final/reward_dist Mean          1.55985
eval/env_infos/final/reward_dist Std           0.027494
eval/env_infos/final/reward_dist Max           1.57079
eval/env_infos/final/reward_dist Min           1.47747
eval/env_infos/initial/reward_dist Mean        0.00456048
eval/env_infos/initial/reward_dist Std         0.00650848
eval/env_infos/initial/reward_dist Max         0.0170233
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                1.08809
eval/env_infos/reward_dist Std                 0.593909
eval/env_infos/reward_dist Max                 1.57079
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00612712
time/evaluation sampling (s)                   3.48505
time/exploration sampling (s)                 17.1867
time/logging (s)                               0.0053658
time/saving (s)                                0.00102053
time/training (s)                              4.29439
time/epoch (s)                                24.9787
time/total (s)                              2686.4
Epoch                                        105
---------------------------------------  -----------------
2023-08-05 01:06:19.448645 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 106 finished
---------------------------------------  -----------------
epoch                                        106
replay_buffer/size                        214000
trainer/QF Loss                                1.54721e+09
trainer/Policy Loss                      -209598
trainer/Raw Policy Loss                  -209598
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                170874
trainer/Q Predictions Std                  28411.2
trainer/Q Predictions Max                 277245
trainer/Q Predictions Min                    571.375
trainer/Q Targets Mean                    198990
trainer/Q Targets Std                      11083.4
trainer/Q Targets Max                     288367
trainer/Q Targets Min                     106695
trainer/Bellman Errors Mean                    1.54721e+09
trainer/Bellman Errors Std                     3.04976e+09
trainer/Bellman Errors Max                     3.841e+10
trainer/Bellman Errors Min                   777.016
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      214000
expl/num paths total                        5350
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.567207
expl/Rewards Std                               0.676952
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             22.6883
expl/Returns Std                              20.3065
expl/Returns Max                              44.8559
expl/Returns Min                               0
expl/Actions Mean                              0.262199
expl/Actions Std                               0.818615
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          22.6883
expl/env_infos/final/reward_dist Mean          0.845589
expl/env_infos/final/reward_dist Std           0.78034
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00106301
expl/env_infos/initial/reward_dist Std         0.00415302
expl/env_infos/initial/reward_dist Max         0.0265918
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.567207
expl/env_infos/reward_dist Std                 0.676952
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       42800
eval/num paths total                        1070
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.254205
eval/Rewards Std                               0.510592
eval/Rewards Max                               1.57058
eval/Rewards Min                               0
eval/Returns Mean                             10.1682
eval/Returns Std                              17.1115
eval/Returns Max                              44.4623
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          10.1682
eval/env_infos/final/reward_dist Mean          0.428843
eval/env_infos/final/reward_dist Std           0.616916
eval/env_infos/final/reward_dist Max           1.57058
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.254205
eval/env_infos/reward_dist Std                 0.510592
eval/env_infos/reward_dist Max                 1.57058
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00601697
time/evaluation sampling (s)                   3.49661
time/exploration sampling (s)                 17.1874
time/logging (s)                               0.00539823
time/saving (s)                                0.0010166
time/training (s)                              4.2299
time/epoch (s)                                24.9264
time/total (s)                              2711.33
Epoch                                        106
---------------------------------------  -----------------
2023-08-05 01:06:44.468099 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 107 finished
---------------------------------------  -----------------
epoch                                        107
replay_buffer/size                        216000
trainer/QF Loss                                1.65527e+09
trainer/Policy Loss                      -214619
trainer/Raw Policy Loss                  -214619
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                174794
trainer/Q Predictions Std                  28938.5
trainer/Q Predictions Max                 275197
trainer/Q Predictions Min                    648.718
trainer/Q Targets Mean                    203869
trainer/Q Targets Std                      11638.8
trainer/Q Targets Max                     294349
trainer/Q Targets Min                     108058
trainer/Bellman Errors Mean                    1.65527e+09
trainer/Bellman Errors Std                     3.40477e+09
trainer/Bellman Errors Max                     4.07336e+10
trainer/Bellman Errors Min                    25.4709
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      216000
expl/num paths total                        5400
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.41401
expl/Rewards Std                               0.624945
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             16.5604
expl/Returns Std                              19.7817
expl/Returns Max                              44.8915
expl/Returns Min                               0
expl/Actions Mean                              0.260671
expl/Actions Std                               0.799285
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.5604
expl/env_infos/final/reward_dist Mean          0.622711
expl/env_infos/final/reward_dist Std           0.763396
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00191778
expl/env_infos/initial/reward_dist Std         0.00564669
expl/env_infos/initial/reward_dist Max         0.0235883
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.41401
expl/env_infos/reward_dist Std                 0.624945
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       43200
eval/num paths total                        1080
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.282171
eval/Rewards Std                               0.54876
eval/Rewards Max                               1.57029
eval/Rewards Min                               0
eval/Returns Mean                             11.2868
eval/Returns Std                              18.0115
eval/Returns Max                              44.8474
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          11.2868
eval/env_infos/final/reward_dist Mean          0.462982
eval/env_infos/final/reward_dist Std           0.706825
eval/env_infos/final/reward_dist Max           1.57029
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.282171
eval/env_infos/reward_dist Std                 0.54876
eval/env_infos/reward_dist Max                 1.57029
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00598977
time/evaluation sampling (s)                   3.51756
time/exploration sampling (s)                 17.2549
time/logging (s)                               0.00541504
time/saving (s)                                0.00100612
time/training (s)                              4.23174
time/epoch (s)                                25.0166
time/total (s)                              2736.35
Epoch                                        107
---------------------------------------  -----------------
2023-08-05 01:07:09.392133 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 108 finished
---------------------------------------  -----------------
epoch                                        108
replay_buffer/size                        218000
trainer/QF Loss                                1.65793e+09
trainer/Policy Loss                      -220132
trainer/Raw Policy Loss                  -220132
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                179720
trainer/Q Predictions Std                  29108.6
trainer/Q Predictions Max                 300798
trainer/Q Predictions Min                    553.09
trainer/Q Targets Mean                    209096
trainer/Q Targets Std                      11653.9
trainer/Q Targets Max                     303617
trainer/Q Targets Min                     113890
trainer/Bellman Errors Mean                    1.65793e+09
trainer/Bellman Errors Std                     3.23744e+09
trainer/Bellman Errors Max                     4.29726e+10
trainer/Bellman Errors Min                     0.282227
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      218000
expl/num paths total                        5450
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.482483
expl/Rewards Std                               0.657912
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             19.2993
expl/Returns Std                              20.4902
expl/Returns Max                              44.2747
expl/Returns Min                               0
expl/Actions Mean                              0.27106
expl/Actions Std                               0.802083
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.2993
expl/env_infos/final/reward_dist Mean          0.721742
expl/env_infos/final/reward_dist Std           0.781752
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00133972
expl/env_infos/initial/reward_dist Std         0.00449516
expl/env_infos/initial/reward_dist Max         0.0202911
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.482483
expl/env_infos/reward_dist Std                 0.657912
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       43600
eval/num paths total                        1090
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.648209
eval/Rewards Std                               0.705457
eval/Rewards Max                               1.57074
eval/Rewards Min                               0
eval/Returns Mean                             25.9283
eval/Returns Std                              21.2766
eval/Returns Max                              44.9095
eval/Returns Min                               0.00260768
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          25.9283
eval/env_infos/final/reward_dist Mean          0.941774
eval/env_infos/final/reward_dist Std           0.768956
eval/env_infos/final/reward_dist Max           1.57074
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.648209
eval/env_infos/reward_dist Std                 0.705457
eval/env_infos/reward_dist Max                 1.57074
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00588953
time/evaluation sampling (s)                   3.58686
time/exploration sampling (s)                 17.0959
time/logging (s)                               0.00545982
time/saving (s)                                0.0009866
time/training (s)                              4.2253
time/epoch (s)                                24.9204
time/total (s)                              2761.27
Epoch                                        108
---------------------------------------  -----------------
2023-08-05 01:07:35.037386 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 109 finished
---------------------------------------  -----------------
epoch                                        109
replay_buffer/size                        220000
trainer/QF Loss                                1.80464e+09
trainer/Policy Loss                      -226066
trainer/Raw Policy Loss                  -226066
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                184741
trainer/Q Predictions Std                  30448.2
trainer/Q Predictions Max                 309553
trainer/Q Predictions Min                    621.052
trainer/Q Targets Mean                    214678
trainer/Q Targets Std                      12522.5
trainer/Q Targets Max                     331229
trainer/Q Targets Min                     115789
trainer/Bellman Errors Mean                    1.80464e+09
trainer/Bellman Errors Std                     3.69306e+09
trainer/Bellman Errors Max                     4.36598e+10
trainer/Bellman Errors Min                   196.876
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      220000
expl/num paths total                        5500
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.590216
expl/Rewards Std                               0.684018
expl/Rewards Max                               1.5707
expl/Rewards Min                               0
expl/Returns Mean                             23.6087
expl/Returns Std                              20.5614
expl/Returns Max                              45.453
expl/Returns Min                               0
expl/Actions Mean                              0.26145
expl/Actions Std                               0.804028
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          23.6087
expl/env_infos/final/reward_dist Mean          0.876785
expl/env_infos/final/reward_dist Std           0.777189
expl/env_infos/final/reward_dist Max           1.57066
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00291169
expl/env_infos/initial/reward_dist Std         0.00705819
expl/env_infos/initial/reward_dist Max         0.0341062
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.590216
expl/env_infos/reward_dist Std                 0.684018
expl/env_infos/reward_dist Max                 1.5707
expl/env_infos/reward_dist Min                 0
eval/num steps total                       44000
eval/num paths total                        1100
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.89413
eval/Rewards Std                               0.689692
eval/Rewards Max                               1.57056
eval/Rewards Min                               0
eval/Returns Mean                             35.7652
eval/Returns Std                              17.8807
eval/Returns Max                              45.0966
eval/Returns Min                               0.000882062
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          35.7652
eval/env_infos/final/reward_dist Mean          1.25567
eval/env_infos/final/reward_dist Std           0.627838
eval/env_infos/final/reward_dist Max           1.57056
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.0018771
eval/env_infos/initial/reward_dist Std         0.003662
eval/env_infos/initial/reward_dist Max         0.0123876
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.89413
eval/env_infos/reward_dist Std                 0.689692
eval/env_infos/reward_dist Max                 1.57056
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00613631
time/evaluation sampling (s)                   4.13038
time/exploration sampling (s)                 17.3057
time/logging (s)                               0.00539509
time/saving (s)                                0.000986185
time/training (s)                              4.19353
time/epoch (s)                                25.6421
time/total (s)                              2786.92
Epoch                                        109
---------------------------------------  -----------------
2023-08-05 01:08:00.334165 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 110 finished
---------------------------------------  -----------------
epoch                                        110
replay_buffer/size                        222000
trainer/QF Loss                                1.78395e+09
trainer/Policy Loss                      -231882
trainer/Raw Policy Loss                  -231882
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                190136
trainer/Q Predictions Std                  30767.9
trainer/Q Predictions Max                 301786
trainer/Q Predictions Min                    541.794
trainer/Q Targets Mean                    220140
trainer/Q Targets Std                      12396.7
trainer/Q Targets Max                     307086
trainer/Q Targets Min                     118313
trainer/Bellman Errors Mean                    1.78395e+09
trainer/Bellman Errors Std                     3.64685e+09
trainer/Bellman Errors Max                     4.76167e+10
trainer/Bellman Errors Min                   161.767
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      222000
expl/num paths total                        5550
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.463524
expl/Rewards Std                               0.628528
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             18.5409
expl/Returns Std                              19.155
expl/Returns Max                              44.2002
expl/Returns Min                               0
expl/Actions Mean                              0.255249
expl/Actions Std                               0.805122
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.5409
expl/env_infos/final/reward_dist Mean          0.64882
expl/env_infos/final/reward_dist Std           0.763525
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00191112
expl/env_infos/initial/reward_dist Std         0.00520456
expl/env_infos/initial/reward_dist Max         0.021552
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.463524
expl/env_infos/reward_dist Std                 0.628528
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       44400
eval/num paths total                        1110
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.66663
eval/Rewards Std                               0.711229
eval/Rewards Max                               1.57067
eval/Rewards Min                               0
eval/Returns Mean                             26.6652
eval/Returns Std                              21.7764
eval/Returns Max                              45.2679
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.6652
eval/env_infos/final/reward_dist Mean          0.941482
eval/env_infos/final/reward_dist Std           0.768718
eval/env_infos/final/reward_dist Max           1.57067
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000951272
eval/env_infos/initial/reward_dist Std         0.00246796
eval/env_infos/initial/reward_dist Max         0.00827144
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.66663
eval/env_infos/reward_dist Std                 0.711229
eval/env_infos/reward_dist Max                 1.57067
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00618059
time/evaluation sampling (s)                   3.96563
time/exploration sampling (s)                 17.2096
time/logging (s)                               0.00538876
time/saving (s)                                0.00102733
time/training (s)                              4.10607
time/epoch (s)                                25.2939
time/total (s)                              2812.21
Epoch                                        110
---------------------------------------  -----------------
2023-08-05 01:08:25.267138 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 111 finished
---------------------------------------  -----------------
epoch                                        111
replay_buffer/size                        224000
trainer/QF Loss                                1.9739e+09
trainer/Policy Loss                      -237617
trainer/Raw Policy Loss                  -237617
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                194063
trainer/Q Predictions Std                  31920.3
trainer/Q Predictions Max                 393257
trainer/Q Predictions Min                    574.589
trainer/Q Targets Mean                    225468
trainer/Q Targets Std                      12677.3
trainer/Q Targets Max                     401098
trainer/Q Targets Min                     113421
trainer/Bellman Errors Mean                    1.9739e+09
trainer/Bellman Errors Std                     4.12644e+09
trainer/Bellman Errors Max                     5.04854e+10
trainer/Bellman Errors Min                    50.7656
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      224000
expl/num paths total                        5600
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.432953
expl/Rewards Std                               0.630789
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             17.3181
expl/Returns Std                              19.5934
expl/Returns Max                              44.829
expl/Returns Min                               0
expl/Actions Mean                              0.270835
expl/Actions Std                               0.812639
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.3181
expl/env_infos/final/reward_dist Mean          0.622949
expl/env_infos/final/reward_dist Std           0.762566
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00162744
expl/env_infos/initial/reward_dist Std         0.00503055
expl/env_infos/initial/reward_dist Max         0.0287495
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.432953
expl/env_infos/reward_dist Std                 0.630789
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       44800
eval/num paths total                        1120
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.718229
eval/Rewards Std                               0.696026
eval/Rewards Max                               1.57073
eval/Rewards Min                               0
eval/Returns Mean                             28.7292
eval/Returns Std                              20.1879
eval/Returns Max                              45.2916
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          28.7292
eval/env_infos/final/reward_dist Mean          1.09294
eval/env_infos/final/reward_dist Std           0.715106
eval/env_infos/final/reward_dist Max           1.57073
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00212454
eval/env_infos/initial/reward_dist Std         0.00572715
eval/env_infos/initial/reward_dist Max         0.0192092
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.718229
eval/env_infos/reward_dist Std                 0.696026
eval/env_infos/reward_dist Max                 1.57073
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00601196
time/evaluation sampling (s)                   3.58935
time/exploration sampling (s)                 17.1353
time/logging (s)                               0.00543904
time/saving (s)                                0.000972476
time/training (s)                              4.19301
time/epoch (s)                                24.9301
time/total (s)                              2837.14
Epoch                                        111
---------------------------------------  -----------------
2023-08-05 01:08:50.848604 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 112 finished
---------------------------------------  -----------------
epoch                                        112
replay_buffer/size                        226000
trainer/QF Loss                                2.07414e+09
trainer/Policy Loss                      -242882
trainer/Raw Policy Loss                  -242882
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                198013
trainer/Q Predictions Std                  32354
trainer/Q Predictions Max                 343784
trainer/Q Predictions Min                    724.896
trainer/Q Targets Mean                    230556
trainer/Q Targets Std                      12793.9
trainer/Q Targets Max                     347594
trainer/Q Targets Min                     127551
trainer/Bellman Errors Mean                    2.07414e+09
trainer/Bellman Errors Std                     4.10744e+09
trainer/Bellman Errors Max                     5.27798e+10
trainer/Bellman Errors Min                    31.1155
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      226000
expl/num paths total                        5650
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.579006
expl/Rewards Std                               0.680748
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             23.1602
expl/Returns Std                              20.3338
expl/Returns Max                              44.5702
expl/Returns Min                               0
expl/Actions Mean                              0.257317
expl/Actions Std                               0.805797
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          23.1602
expl/env_infos/final/reward_dist Mean          0.886782
expl/env_infos/final/reward_dist Std           0.766904
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.0013516
expl/env_infos/initial/reward_dist Std         0.00375386
expl/env_infos/initial/reward_dist Max         0.020122
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.579006
expl/env_infos/reward_dist Std                 0.680748
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       45200
eval/num paths total                        1130
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.681196
eval/Rewards Std                               0.700478
eval/Rewards Max                               1.57054
eval/Rewards Min                               0
eval/Returns Mean                             27.2478
eval/Returns Std                              20.9911
eval/Returns Max                              45.1266
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          27.2478
eval/env_infos/final/reward_dist Mean          1.00154
eval/env_infos/final/reward_dist Std           0.713938
eval/env_infos/final/reward_dist Max           1.57054
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.681196
eval/env_infos/reward_dist Std                 0.700478
eval/env_infos/reward_dist Max                 1.57054
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0059789
time/evaluation sampling (s)                   3.87512
time/exploration sampling (s)                 17.5078
time/logging (s)                               0.00543883
time/saving (s)                                0.00101097
time/training (s)                              4.18307
time/epoch (s)                                25.5784
time/total (s)                              2862.72
Epoch                                        112
---------------------------------------  -----------------
2023-08-05 01:09:16.390781 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 113 finished
---------------------------------------  -----------------
epoch                                        113
replay_buffer/size                        228000
trainer/QF Loss                                2.12548e+09
trainer/Policy Loss                      -249270
trainer/Raw Policy Loss                  -249270
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                204244
trainer/Q Predictions Std                  33738.1
trainer/Q Predictions Max                 322305
trainer/Q Predictions Min                    546.287
trainer/Q Targets Mean                    236591
trainer/Q Targets Std                      13662.2
trainer/Q Targets Max                     360184
trainer/Q Targets Min                     128438
trainer/Bellman Errors Mean                    2.12548e+09
trainer/Bellman Errors Std                     4.45558e+09
trainer/Bellman Errors Max                     5.53033e+10
trainer/Bellman Errors Min                   627.346
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      228000
expl/num paths total                        5700
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.452791
expl/Rewards Std                               0.642336
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             18.1116
expl/Returns Std                              20.1008
expl/Returns Max                              44.6676
expl/Returns Min                               0
expl/Actions Mean                              0.272411
expl/Actions Std                               0.808784
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.1116
expl/env_infos/final/reward_dist Mean          0.692486
expl/env_infos/final/reward_dist Std           0.769883
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00194981
expl/env_infos/initial/reward_dist Std         0.00523516
expl/env_infos/initial/reward_dist Max         0.0246088
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.452791
expl/env_infos/reward_dist Std                 0.642336
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       45600
eval/num paths total                        1140
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.446167
eval/Rewards Std                               0.660578
eval/Rewards Max                               1.5705
eval/Rewards Min                               0
eval/Returns Mean                             17.8467
eval/Returns Std                              21.8449
eval/Returns Max                              44.9754
eval/Returns Min                               0.00163827
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          17.8467
eval/env_infos/final/reward_dist Mean          0.626732
eval/env_infos/final/reward_dist Std           0.76759
eval/env_infos/final/reward_dist Max           1.5705
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        5.89921e-05
eval/env_infos/initial/reward_dist Std         0.000176976
eval/env_infos/initial/reward_dist Max         0.000589921
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.446167
eval/env_infos/reward_dist Std                 0.660578
eval/env_infos/reward_dist Max                 1.5705
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00606657
time/evaluation sampling (s)                   4.00856
time/exploration sampling (s)                 17.1891
time/logging (s)                               0.00549073
time/saving (s)                                0.00100954
time/training (s)                              4.32883
time/epoch (s)                                25.5391
time/total (s)                              2888.27
Epoch                                        113
---------------------------------------  -----------------
2023-08-05 01:09:41.345016 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 114 finished
---------------------------------------  -----------------
epoch                                        114
replay_buffer/size                        230000
trainer/QF Loss                                2.41967e+09
trainer/Policy Loss                      -255379
trainer/Raw Policy Loss                  -255379
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                207723
trainer/Q Predictions Std                  35567
trainer/Q Predictions Max                 368657
trainer/Q Predictions Min                    639.692
trainer/Q Targets Mean                    242347
trainer/Q Targets Std                      12787.1
trainer/Q Targets Max                     338063
trainer/Q Targets Min                     134768
trainer/Bellman Errors Mean                    2.41967e+09
trainer/Bellman Errors Std                     5.26974e+09
trainer/Bellman Errors Max                     5.72512e+10
trainer/Bellman Errors Min                   288.469
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      230000
expl/num paths total                        5750
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.507584
expl/Rewards Std                               0.659408
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             20.3034
expl/Returns Std                              20.3439
expl/Returns Max                              44.3972
expl/Returns Min                               0
expl/Actions Mean                              0.265371
expl/Actions Std                               0.795431
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          20.3034
expl/env_infos/final/reward_dist Mean          0.754534
expl/env_infos/final/reward_dist Std           0.776749
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000897214
expl/env_infos/initial/reward_dist Std         0.00317021
expl/env_infos/initial/reward_dist Max         0.0170325
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.507584
expl/env_infos/reward_dist Std                 0.659408
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       46000
eval/num paths total                        1150
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.622772
eval/Rewards Std                               0.690243
eval/Rewards Max                               1.56983
eval/Rewards Min                               0
eval/Returns Mean                             24.9109
eval/Returns Std                              20.6522
eval/Returns Max                              45.0218
eval/Returns Min                               0.00125232
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          24.9109
eval/env_infos/final/reward_dist Mean          0.924951
eval/env_infos/final/reward_dist Std           0.755572
eval/env_infos/final/reward_dist Max           1.56983
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000109354
eval/env_infos/initial/reward_dist Std         0.000328063
eval/env_infos/initial/reward_dist Max         0.00109354
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.622772
eval/env_infos/reward_dist Std                 0.690243
eval/env_infos/reward_dist Max                 1.56983
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00601392
time/evaluation sampling (s)                   3.7625
time/exploration sampling (s)                 17.2596
time/logging (s)                               0.0055136
time/saving (s)                                0.00103033
time/training (s)                              3.91622
time/epoch (s)                                24.9509
time/total (s)                              2913.22
Epoch                                        114
---------------------------------------  -----------------
2023-08-05 01:10:06.212742 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 115 finished
---------------------------------------  -----------------
epoch                                        115
replay_buffer/size                        232000
trainer/QF Loss                                2.48724e+09
trainer/Policy Loss                      -261774
trainer/Raw Policy Loss                  -261774
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                213286
trainer/Q Predictions Std                  36210.6
trainer/Q Predictions Max                 372256
trainer/Q Predictions Min                    640.771
trainer/Q Targets Mean                    248453
trainer/Q Targets Std                      14666.6
trainer/Q Targets Max                     373053
trainer/Q Targets Min                     137594
trainer/Bellman Errors Mean                    2.48724e+09
trainer/Bellman Errors Std                     5.32163e+09
trainer/Bellman Errors Max                     6.05349e+10
trainer/Bellman Errors Min                   223.596
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      232000
expl/num paths total                        5800
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.385024
expl/Rewards Std                               0.604424
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             15.401
expl/Returns Std                              18.7151
expl/Returns Max                              44.6156
expl/Returns Min                               0
expl/Actions Mean                              0.255938
expl/Actions Std                               0.814709
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          15.401
expl/env_infos/final/reward_dist Mean          0.613981
expl/env_infos/final/reward_dist Std           0.756024
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000996729
expl/env_infos/initial/reward_dist Std         0.00361427
expl/env_infos/initial/reward_dist Max         0.016967
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.385024
expl/env_infos/reward_dist Std                 0.604424
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       46400
eval/num paths total                        1160
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.790582
eval/Rewards Std                               0.701346
eval/Rewards Max                               1.57079
eval/Rewards Min                               0
eval/Returns Mean                             31.6233
eval/Returns Std                              20.0099
eval/Returns Max                              46.018
eval/Returns Min                               0.00066222
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          31.6233
eval/env_infos/final/reward_dist Mean          1.12774
eval/env_infos/final/reward_dist Std           0.678101
eval/env_infos/final/reward_dist Max           1.57079
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00647541
eval/env_infos/initial/reward_dist Std         0.00981222
eval/env_infos/initial/reward_dist Max         0.0272146
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.790582
eval/env_infos/reward_dist Std                 0.701346
eval/env_infos/reward_dist Max                 1.57079
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00590558
time/evaluation sampling (s)                   3.70476
time/exploration sampling (s)                 16.8195
time/logging (s)                               0.00548599
time/saving (s)                                0.00108856
time/training (s)                              4.3279
time/epoch (s)                                24.8646
time/total (s)                              2938.09
Epoch                                        115
---------------------------------------  -----------------
2023-08-05 01:10:32.289043 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 116 finished
---------------------------------------  -----------------
epoch                                        116
replay_buffer/size                        234000
trainer/QF Loss                                2.49815e+09
trainer/Policy Loss                      -267842
trainer/Raw Policy Loss                  -267842
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                218225
trainer/Q Predictions Std                  35737.5
trainer/Q Predictions Max                 443689
trainer/Q Predictions Min                    616.063
trainer/Q Targets Mean                    254112
trainer/Q Targets Std                      14233.3
trainer/Q Targets Max                     452578
trainer/Q Targets Min                     138277
trainer/Bellman Errors Mean                    2.49815e+09
trainer/Bellman Errors Std                     5.0978e+09
trainer/Bellman Errors Max                     6.24908e+10
trainer/Bellman Errors Min                   311.192
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      234000
expl/num paths total                        5850
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.310546
expl/Rewards Std                               0.565368
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             12.4219
expl/Returns Std                              18.1752
expl/Returns Max                              44.0537
expl/Returns Min                               0
expl/Actions Mean                              0.273589
expl/Actions Std                               0.80691
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          12.4219
expl/env_infos/final/reward_dist Mean          0.479596
expl/env_infos/final/reward_dist Std           0.710548
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000680834
expl/env_infos/initial/reward_dist Std         0.00249204
expl/env_infos/initial/reward_dist Max         0.0143151
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.310546
expl/env_infos/reward_dist Std                 0.565368
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       46800
eval/num paths total                        1170
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.642249
eval/Rewards Std                               0.699742
eval/Rewards Max                               1.56952
eval/Rewards Min                               0
eval/Returns Mean                             25.69
eval/Returns Std                              21.3151
eval/Returns Max                              46.1572
eval/Returns Min                               0.00060753
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          25.69
eval/env_infos/final/reward_dist Mean          0.940899
eval/env_infos/final/reward_dist Std           0.768241
eval/env_infos/final/reward_dist Max           1.56952
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00508239
eval/env_infos/initial/reward_dist Std         0.0105491
eval/env_infos/initial/reward_dist Max         0.0317209
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.642249
eval/env_infos/reward_dist Std                 0.699742
eval/env_infos/reward_dist Max                 1.56952
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0059163
time/evaluation sampling (s)                   4.60738
time/exploration sampling (s)                 17.1458
time/logging (s)                               0.00540696
time/saving (s)                                0.00100272
time/training (s)                              4.30754
time/epoch (s)                                26.0731
time/total (s)                              2964.16
Epoch                                        116
---------------------------------------  -----------------
2023-08-05 01:10:56.727232 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 117 finished
---------------------------------------  -----------------
epoch                                        117
replay_buffer/size                        236000
trainer/QF Loss                                2.47496e+09
trainer/Policy Loss                      -274075
trainer/Raw Policy Loss                  -274075
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                224627
trainer/Q Predictions Std                  35445.8
trainer/Q Predictions Max                 361876
trainer/Q Predictions Min                    636.314
trainer/Q Targets Mean                    260033
trainer/Q Targets Std                      14203.8
trainer/Q Targets Max                     352700
trainer/Q Targets Min                     141114
trainer/Bellman Errors Mean                    2.47496e+09
trainer/Bellman Errors Std                     5.03733e+09
trainer/Bellman Errors Max                     6.52174e+10
trainer/Bellman Errors Min                    46.1975
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      236000
expl/num paths total                        5900
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.475158
expl/Rewards Std                               0.639087
expl/Rewards Max                               1.5707
expl/Rewards Min                               0
expl/Returns Mean                             19.0063
expl/Returns Std                              19.2318
expl/Returns Max                              43.5617
expl/Returns Min                               0
expl/Actions Mean                              0.246459
expl/Actions Std                               0.804458
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.0063
expl/env_infos/final/reward_dist Mean          0.717801
expl/env_infos/final/reward_dist Std           0.776045
expl/env_infos/final/reward_dist Max           1.5707
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00111782
expl/env_infos/initial/reward_dist Std         0.00392573
expl/env_infos/initial/reward_dist Max         0.0206055
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.475158
expl/env_infos/reward_dist Std                 0.639087
expl/env_infos/reward_dist Max                 1.5707
expl/env_infos/reward_dist Min                 0
eval/num steps total                       47200
eval/num paths total                        1180
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.853993
eval/Rewards Std                               0.686637
eval/Rewards Max                               1.57072
eval/Rewards Min                               0
eval/Returns Mean                             34.1597
eval/Returns Std                              17.5164
eval/Returns Max                              44.8993
eval/Returns Min                               0.00293914
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          34.1597
eval/env_infos/final/reward_dist Mean          1.24433
eval/env_infos/final/reward_dist Std           0.622771
eval/env_infos/final/reward_dist Max           1.57072
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000542294
eval/env_infos/initial/reward_dist Std         0.00162688
eval/env_infos/initial/reward_dist Max         0.00542294
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.853993
eval/env_infos/reward_dist Std                 0.686637
eval/env_infos/reward_dist Max                 1.57072
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00593505
time/evaluation sampling (s)                   3.55019
time/exploration sampling (s)                 17.1204
time/logging (s)                               0.00543242
time/saving (s)                                0.0010628
time/training (s)                              3.75208
time/epoch (s)                                24.4351
time/total (s)                              2988.6
Epoch                                        117
---------------------------------------  -----------------
2023-08-05 01:11:22.728259 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 118 finished
---------------------------------------  -----------------
epoch                                        118
replay_buffer/size                        238000
trainer/QF Loss                                2.59978e+09
trainer/Policy Loss                      -280833
trainer/Raw Policy Loss                  -280833
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                229819
trainer/Q Predictions Std                  36253.6
trainer/Q Predictions Max                 368583
trainer/Q Predictions Min                    604.541
trainer/Q Targets Mean                    266579
trainer/Q Targets Std                      15075.8
trainer/Q Targets Max                     402832
trainer/Q Targets Min                     146779
trainer/Bellman Errors Mean                    2.59978e+09
trainer/Bellman Errors Std                     4.80021e+09
trainer/Bellman Errors Max                     6.91202e+10
trainer/Bellman Errors Min                   128.681
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      238000
expl/num paths total                        5950
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.29589
expl/Rewards Std                               0.556433
expl/Rewards Max                               1.57064
expl/Rewards Min                               0
expl/Returns Mean                             11.8356
expl/Returns Std                              17.9341
expl/Returns Max                              43.5733
expl/Returns Min                               0
expl/Actions Mean                              0.274901
expl/Actions Std                               0.807591
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          11.8356
expl/env_infos/final/reward_dist Mean          0.462977
expl/env_infos/final/reward_dist Std           0.707614
expl/env_infos/final/reward_dist Max           1.57064
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000201087
expl/env_infos/initial/reward_dist Std         0.00117643
expl/env_infos/initial/reward_dist Max         0.00830369
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.29589
expl/env_infos/reward_dist Std                 0.556433
expl/env_infos/reward_dist Max                 1.57064
expl/env_infos/reward_dist Min                 0
eval/num steps total                       47600
eval/num paths total                        1190
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.627717
eval/Rewards Std                               0.697142
eval/Rewards Max                               1.57072
eval/Rewards Min                               0
eval/Returns Mean                             25.1087
eval/Returns Std                              20.8805
eval/Returns Max                              44.235
eval/Returns Min                               0.000747514
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          25.1087
eval/env_infos/final/reward_dist Mean          0.934499
eval/env_infos/final/reward_dist Std           0.763301
eval/env_infos/final/reward_dist Max           1.57072
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.627717
eval/env_infos/reward_dist Std                 0.697142
eval/env_infos/reward_dist Max                 1.57072
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00590654
time/evaluation sampling (s)                   4.18034
time/exploration sampling (s)                 17.3902
time/logging (s)                               0.00547452
time/saving (s)                                0.00101353
time/training (s)                              4.4137
time/epoch (s)                                25.9966
time/total (s)                              3014.6
Epoch                                        118
---------------------------------------  -----------------
2023-08-05 01:11:48.320589 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 119 finished
---------------------------------------  -----------------
epoch                                        119
replay_buffer/size                        240000
trainer/QF Loss                                2.79753e+09
trainer/Policy Loss                      -287047
trainer/Raw Policy Loss                  -287047
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                234509
trainer/Q Predictions Std                  37335.6
trainer/Q Predictions Max                 393826
trainer/Q Predictions Min                    682.431
trainer/Q Targets Mean                    272679
trainer/Q Targets Std                      15522.3
trainer/Q Targets Max                     418332
trainer/Q Targets Min                     142371
trainer/Bellman Errors Mean                    2.79753e+09
trainer/Bellman Errors Std                     5.45813e+09
trainer/Bellman Errors Max                     7.11627e+10
trainer/Bellman Errors Min                    13.5977
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      240000
expl/num paths total                        6000
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.485331
expl/Rewards Std                               0.648287
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             19.4132
expl/Returns Std                              19.6502
expl/Returns Max                              44.2921
expl/Returns Min                               0
expl/Actions Mean                              0.265211
expl/Actions Std                               0.798048
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.4132
expl/env_infos/final/reward_dist Mean          0.730037
expl/env_infos/final/reward_dist Std           0.775432
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00079858
expl/env_infos/initial/reward_dist Std         0.00391991
expl/env_infos/initial/reward_dist Max         0.0275075
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.485331
expl/env_infos/reward_dist Std                 0.648287
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       48000
eval/num paths total                        1200
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.759712
eval/Rewards Std                               0.702646
eval/Rewards Max                               1.57043
eval/Rewards Min                               0
eval/Returns Mean                             30.3885
eval/Returns Std                              20.0953
eval/Returns Max                              46.6436
eval/Returns Min                               0.00264841
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          30.3885
eval/env_infos/final/reward_dist Mean          1.09021
eval/env_infos/final/reward_dist Std           0.713715
eval/env_infos/final/reward_dist Max           1.57043
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00230506
eval/env_infos/initial/reward_dist Std         0.00414246
eval/env_infos/initial/reward_dist Max         0.012987
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.759712
eval/env_infos/reward_dist Std                 0.702646
eval/env_infos/reward_dist Max                 1.57043
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00612764
time/evaluation sampling (s)                   3.76113
time/exploration sampling (s)                 17.3429
time/logging (s)                               0.00732612
time/saving (s)                                0.00129504
time/training (s)                              4.47172
time/epoch (s)                                25.5905
time/total (s)                              3040.19
Epoch                                        119
---------------------------------------  -----------------
2023-08-05 01:12:13.880847 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 120 finished
---------------------------------------  -----------------
epoch                                        120
replay_buffer/size                        242000
trainer/QF Loss                                2.82812e+09
trainer/Policy Loss                      -293641
trainer/Raw Policy Loss                  -293641
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                240555
trainer/Q Predictions Std                  37907.2
trainer/Q Predictions Max                 443641
trainer/Q Predictions Min                    597.863
trainer/Q Targets Mean                    278586
trainer/Q Targets Std                      14877.4
trainer/Q Targets Max                     365714
trainer/Q Targets Min                     154148
trainer/Bellman Errors Mean                    2.82812e+09
trainer/Bellman Errors Std                     5.5751e+09
trainer/Bellman Errors Max                     7.70522e+10
trainer/Bellman Errors Min                   197.754
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      242000
expl/num paths total                        6050
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.623118
expl/Rewards Std                               0.681396
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             24.9247
expl/Returns Std                              19.8155
expl/Returns Max                              43.8896
expl/Returns Min                               0
expl/Actions Mean                              0.261761
expl/Actions Std                               0.810763
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          24.9247
expl/env_infos/final/reward_dist Mean          0.90491
expl/env_infos/final/reward_dist Std           0.770687
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00241322
expl/env_infos/initial/reward_dist Std         0.005744
expl/env_infos/initial/reward_dist Max         0.0224619
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.623118
expl/env_infos/reward_dist Std                 0.681396
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       48400
eval/num paths total                        1210
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.550714
eval/Rewards Std                               0.663163
eval/Rewards Max                               1.57024
eval/Rewards Min                               0
eval/Returns Mean                             22.0285
eval/Returns Std                              19.8886
eval/Returns Max                              45.3365
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.0285
eval/env_infos/final/reward_dist Mean          0.927192
eval/env_infos/final/reward_dist Std           0.757487
eval/env_infos/final/reward_dist Max           1.57024
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00119044
eval/env_infos/initial/reward_dist Std         0.00357133
eval/env_infos/initial/reward_dist Max         0.0119044
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.550714
eval/env_infos/reward_dist Std                 0.663163
eval/env_infos/reward_dist Max                 1.57024
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00596698
time/evaluation sampling (s)                   4.00606
time/exploration sampling (s)                 17.3678
time/logging (s)                               0.00533956
time/saving (s)                                0.00101979
time/training (s)                              4.16753
time/epoch (s)                                25.5537
time/total (s)                              3065.75
Epoch                                        120
---------------------------------------  -----------------
2023-08-05 01:12:39.234453 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 121 finished
---------------------------------------  -----------------
epoch                                        121
replay_buffer/size                        244000
trainer/QF Loss                                2.97373e+09
trainer/Policy Loss                      -300635
trainer/Raw Policy Loss                  -300635
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                246172
trainer/Q Predictions Std                  39010.6
trainer/Q Predictions Max                 410000
trainer/Q Predictions Min                    676.025
trainer/Q Targets Mean                    285118
trainer/Q Targets Std                      16139.6
trainer/Q Targets Max                     380106
trainer/Q Targets Min                     157754
trainer/Bellman Errors Mean                    2.97373e+09
trainer/Bellman Errors Std                     5.67468e+09
trainer/Bellman Errors Max                     7.91524e+10
trainer/Bellman Errors Min                    63.501
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      244000
expl/num paths total                        6100
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.413159
expl/Rewards Std                               0.620914
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             16.5264
expl/Returns Std                              19.5308
expl/Returns Max                              45.9452
expl/Returns Min                               0
expl/Actions Mean                              0.254082
expl/Actions Std                               0.801689
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.5264
expl/env_infos/final/reward_dist Mean          0.628049
expl/env_infos/final/reward_dist Std           0.7597
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00234246
expl/env_infos/initial/reward_dist Std         0.00643267
expl/env_infos/initial/reward_dist Max         0.0330539
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.413159
expl/env_infos/reward_dist Std                 0.620914
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       48800
eval/num paths total                        1220
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.40151
eval/Rewards Std                               0.62733
eval/Rewards Max                               1.57004
eval/Rewards Min                               0
eval/Returns Mean                             16.0604
eval/Returns Std                              20.0462
eval/Returns Max                              44.2038
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          16.0604
eval/env_infos/final/reward_dist Mean          0.619871
eval/env_infos/final/reward_dist Std           0.759479
eval/env_infos/final/reward_dist Max           1.57004
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.40151
eval/env_infos/reward_dist Std                 0.62733
eval/env_infos/reward_dist Max                 1.57004
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00597048
time/evaluation sampling (s)                   3.66057
time/exploration sampling (s)                 17.3131
time/logging (s)                               0.00803685
time/saving (s)                                0.00126056
time/training (s)                              4.36468
time/epoch (s)                                25.3536
time/total (s)                              3091.1
Epoch                                        121
---------------------------------------  -----------------
2023-08-05 01:13:04.961662 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 122 finished
---------------------------------------  -----------------
epoch                                        122
replay_buffer/size                        246000
trainer/QF Loss                                3.15231e+09
trainer/Policy Loss                      -307705
trainer/Raw Policy Loss                  -307705
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                251519
trainer/Q Predictions Std                  39824.8
trainer/Q Predictions Max                 382467
trainer/Q Predictions Min                    707.666
trainer/Q Targets Mean                    292013
trainer/Q Targets Std                      16617.1
trainer/Q Targets Max                     427396
trainer/Q Targets Min                     153327
trainer/Bellman Errors Mean                    3.15231e+09
trainer/Bellman Errors Std                     5.93722e+09
trainer/Bellman Errors Max                     8.35008e+10
trainer/Bellman Errors Min                     9
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      246000
expl/num paths total                        6150
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.436066
expl/Rewards Std                               0.628969
expl/Rewards Max                               1.57074
expl/Rewards Min                               0
expl/Returns Mean                             17.4426
expl/Returns Std                              19.4146
expl/Returns Max                              44.2985
expl/Returns Min                               0
expl/Actions Mean                              0.258928
expl/Actions Std                               0.794983
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.4426
expl/env_infos/final/reward_dist Mean          0.682944
expl/env_infos/final/reward_dist Std           0.770549
expl/env_infos/final/reward_dist Max           1.57074
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00106947
expl/env_infos/initial/reward_dist Std         0.00330743
expl/env_infos/initial/reward_dist Max         0.019045
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.436066
expl/env_infos/reward_dist Std                 0.628969
expl/env_infos/reward_dist Max                 1.57074
expl/env_infos/reward_dist Min                 0
eval/num steps total                       49200
eval/num paths total                        1230
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.204044
eval/Rewards Std                               0.485595
eval/Rewards Max                               1.57063
eval/Rewards Min                               0
eval/Returns Mean                              8.16176
eval/Returns Std                              16.3016
eval/Returns Max                              45.6281
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                           8.16176
eval/env_infos/final/reward_dist Mean          0.305214
eval/env_infos/final/reward_dist Std           0.610753
eval/env_infos/final/reward_dist Max           1.57063
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000644221
eval/env_infos/initial/reward_dist Std         0.00193266
eval/env_infos/initial/reward_dist Max         0.00644221
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.204044
eval/env_infos/reward_dist Std                 0.485595
eval/env_infos/reward_dist Max                 1.57063
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00602809
time/evaluation sampling (s)                   3.91551
time/exploration sampling (s)                 17.3977
time/logging (s)                               0.00532021
time/saving (s)                                0.000981765
time/training (s)                              4.3946
time/epoch (s)                                25.7202
time/total (s)                              3116.83
Epoch                                        122
---------------------------------------  -----------------
2023-08-05 01:13:30.564688 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 123 finished
---------------------------------------  -----------------
epoch                                        123
replay_buffer/size                        248000
trainer/QF Loss                                3.35786e+09
trainer/Policy Loss                      -314706
trainer/Raw Policy Loss                  -314706
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                256991
trainer/Q Predictions Std                  41836.6
trainer/Q Predictions Max                 395488
trainer/Q Predictions Min                    765.218
trainer/Q Targets Mean                    298754
trainer/Q Targets Std                      16590.9
trainer/Q Targets Max                     450096
trainer/Q Targets Min                     158977
trainer/Bellman Errors Mean                    3.35786e+09
trainer/Bellman Errors Std                     6.57922e+09
trainer/Bellman Errors Max                     8.51891e+10
trainer/Bellman Errors Min                     1.80566
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      248000
expl/num paths total                        6200
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.573316
expl/Rewards Std                               0.672668
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             22.9326
expl/Returns Std                              19.9241
expl/Returns Max                              44.4636
expl/Returns Min                               0
expl/Actions Mean                              0.25946
expl/Actions Std                               0.798722
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          22.9326
expl/env_infos/final/reward_dist Mean          0.888262
expl/env_infos/final/reward_dist Std           0.764088
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00142121
expl/env_infos/initial/reward_dist Std         0.00463433
expl/env_infos/initial/reward_dist Max         0.0237958
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.573316
expl/env_infos/reward_dist Std                 0.672668
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       49600
eval/num paths total                        1240
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.780239
eval/Rewards Std                               0.709091
eval/Rewards Max                               1.57069
eval/Rewards Min                               0
eval/Returns Mean                             31.2096
eval/Returns Std                              20.421
eval/Returns Max                              45.1547
eval/Returns Min                               0.0193369
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          31.2096
eval/env_infos/final/reward_dist Mean          1.09816
eval/env_infos/final/reward_dist Std           0.718914
eval/env_infos/final/reward_dist Max           1.57069
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.002422
eval/env_infos/initial/reward_dist Std         0.00399211
eval/env_infos/initial/reward_dist Max         0.0128337
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.780239
eval/env_infos/reward_dist Std                 0.709091
eval/env_infos/reward_dist Max                 1.57069
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00598138
time/evaluation sampling (s)                   3.44647
time/exploration sampling (s)                 17.7328
time/logging (s)                               0.00547778
time/saving (s)                                0.00100953
time/training (s)                              4.40867
time/epoch (s)                                25.6005
time/total (s)                              3142.43
Epoch                                        123
---------------------------------------  -----------------
2023-08-05 01:13:56.101950 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 124 finished
---------------------------------------  -----------------
epoch                                        124
replay_buffer/size                        250000
trainer/QF Loss                                3.64796e+09
trainer/Policy Loss                      -321677
trainer/Raw Policy Loss                  -321677
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                262620
trainer/Q Predictions Std                  43191.2
trainer/Q Predictions Max                 402310
trainer/Q Predictions Min                    629.187
trainer/Q Targets Mean                    305546
trainer/Q Targets Std                      16842.2
trainer/Q Targets Max                     448356
trainer/Q Targets Min                     166841
trainer/Bellman Errors Mean                    3.64796e+09
trainer/Bellman Errors Std                     7.72271e+09
trainer/Bellman Errors Max                     9.27371e+10
trainer/Bellman Errors Min                     4.51562
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      250000
expl/num paths total                        6250
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.324944
expl/Rewards Std                               0.575658
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             12.9978
expl/Returns Std                              18.6608
expl/Returns Max                              44.0908
expl/Returns Min                               0
expl/Actions Mean                              0.264642
expl/Actions Std                               0.804273
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          12.9978
expl/env_infos/final/reward_dist Mean          0.496902
expl/env_infos/final/reward_dist Std           0.723637
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00110931
expl/env_infos/initial/reward_dist Std         0.00485809
expl/env_infos/initial/reward_dist Max         0.0328766
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.324944
expl/env_infos/reward_dist Std                 0.575658
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       50000
eval/num paths total                        1250
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.896961
eval/Rewards Std                               0.68792
eval/Rewards Max                               1.57072
eval/Rewards Min                               0
eval/Returns Mean                             35.8784
eval/Returns Std                              17.9407
eval/Returns Max                              45.3801
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          35.8784
eval/env_infos/final/reward_dist Mean          1.25532
eval/env_infos/final/reward_dist Std           0.62766
eval/env_infos/final/reward_dist Max           1.57072
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00379468
eval/env_infos/initial/reward_dist Std         0.00528364
eval/env_infos/initial/reward_dist Max         0.0150451
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.896961
eval/env_infos/reward_dist Std                 0.68792
eval/env_infos/reward_dist Max                 1.57072
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00587087
time/evaluation sampling (s)                   3.75162
time/exploration sampling (s)                 17.5445
time/logging (s)                               0.00530981
time/saving (s)                                0.000996677
time/training (s)                              4.22609
time/epoch (s)                                25.5344
time/total (s)                              3167.97
Epoch                                        124
---------------------------------------  -----------------
2023-08-05 01:14:21.658621 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 125 finished
---------------------------------------  -----------------
epoch                                        125
replay_buffer/size                        252000
trainer/QF Loss                                3.57489e+09
trainer/Policy Loss                      -328299
trainer/Raw Policy Loss                  -328299
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                268404
trainer/Q Predictions Std                  41416.3
trainer/Q Predictions Max                 464586
trainer/Q Predictions Min                    635.873
trainer/Q Targets Mean                    311555
trainer/Q Targets Std                      17274.7
trainer/Q Targets Max                     467029
trainer/Q Targets Min                     169798
trainer/Bellman Errors Mean                    3.57489e+09
trainer/Bellman Errors Std                     6.18118e+09
trainer/Bellman Errors Max                     9.58095e+10
trainer/Bellman Errors Min                  3115.04
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      252000
expl/num paths total                        6300
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.385984
expl/Rewards Std                               0.614409
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             15.4394
expl/Returns Std                              19.7199
expl/Returns Max                              44.3783
expl/Returns Min                               0
expl/Actions Mean                              0.255179
expl/Actions Std                               0.788108
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          15.4394
expl/env_infos/final/reward_dist Mean          0.5652
expl/env_infos/final/reward_dist Std           0.752929
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000900878
expl/env_infos/initial/reward_dist Std         0.00344326
expl/env_infos/initial/reward_dist Max         0.0202981
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.385984
expl/env_infos/reward_dist Std                 0.614409
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       50400
eval/num paths total                        1260
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.888904
eval/Rewards Std                               0.691013
eval/Rewards Max                               1.57078
eval/Rewards Min                               0
eval/Returns Mean                             35.5562
eval/Returns Std                              17.7736
eval/Returns Max                              45.0357
eval/Returns Min                               0.0121565
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          35.5562
eval/env_infos/final/reward_dist Mean          1.25486
eval/env_infos/final/reward_dist Std           0.62743
eval/env_infos/final/reward_dist Max           1.57078
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00140333
eval/env_infos/initial/reward_dist Std         0.00420998
eval/env_infos/initial/reward_dist Max         0.0140333
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.888904
eval/env_infos/reward_dist Std                 0.691013
eval/env_infos/reward_dist Max                 1.57078
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00597512
time/evaluation sampling (s)                   3.71451
time/exploration sampling (s)                 17.5604
time/logging (s)                               0.00537645
time/saving (s)                                0.000984017
time/training (s)                              4.26668
time/epoch (s)                                25.5539
time/total (s)                              3193.52
Epoch                                        125
---------------------------------------  -----------------
2023-08-05 01:14:47.144046 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 126 finished
---------------------------------------  -----------------
epoch                                        126
replay_buffer/size                        254000
trainer/QF Loss                                3.82432e+09
trainer/Policy Loss                      -335739
trainer/Raw Policy Loss                  -335739
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                274748
trainer/Q Predictions Std                  44474.6
trainer/Q Predictions Max                 436573
trainer/Q Predictions Min                    688.393
trainer/Q Targets Mean                    318777
trainer/Q Targets Std                      18122.8
trainer/Q Targets Max                     464770
trainer/Q Targets Min                     172084
trainer/Bellman Errors Mean                    3.82432e+09
trainer/Bellman Errors Std                     7.62374e+09
trainer/Bellman Errors Max                     9.66416e+10
trainer/Bellman Errors Min                   866.566
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      254000
expl/num paths total                        6350
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.410775
expl/Rewards Std                               0.618081
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             16.431
expl/Returns Std                              19.3184
expl/Returns Max                              43.9349
expl/Returns Min                               0
expl/Actions Mean                              0.248558
expl/Actions Std                               0.800007
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.431
expl/env_infos/final/reward_dist Mean          0.595308
expl/env_infos/final/reward_dist Std           0.760358
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00142628
expl/env_infos/initial/reward_dist Std         0.00424341
expl/env_infos/initial/reward_dist Max         0.0242217
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.410775
expl/env_infos/reward_dist Std                 0.618081
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       50800
eval/num paths total                        1270
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.898036
eval/Rewards Std                               0.687627
eval/Rewards Max                               1.57074
eval/Rewards Min                               0
eval/Returns Mean                             35.9214
eval/Returns Std                              17.9536
eval/Returns Max                              45.4905
eval/Returns Min                               0.00548656
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          35.9214
eval/env_infos/final/reward_dist Mean          1.25553
eval/env_infos/final/reward_dist Std           0.627766
eval/env_infos/final/reward_dist Max           1.57074
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00724817
eval/env_infos/initial/reward_dist Std         0.00936014
eval/env_infos/initial/reward_dist Max         0.0222195
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.898036
eval/env_infos/reward_dist Std                 0.687627
eval/env_infos/reward_dist Max                 1.57074
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0058997
time/evaluation sampling (s)                   3.60556
time/exploration sampling (s)                 17.5265
time/logging (s)                               0.00746978
time/saving (s)                                0.00109331
time/training (s)                              4.33813
time/epoch (s)                                25.4846
time/total (s)                              3219.01
Epoch                                        126
---------------------------------------  -----------------
2023-08-05 01:15:12.922855 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 127 finished
---------------------------------------  -----------------
epoch                                        127
replay_buffer/size                        256000
trainer/QF Loss                                4.21397e+09
trainer/Policy Loss                      -343157
trainer/Raw Policy Loss                  -343157
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                279580
trainer/Q Predictions Std                  45792.6
trainer/Q Predictions Max                 468377
trainer/Q Predictions Min                    688.304
trainer/Q Targets Mean                    326129
trainer/Q Targets Std                      18098.3
trainer/Q Targets Max                     473852
trainer/Q Targets Min                     173425
trainer/Bellman Errors Mean                    4.21397e+09
trainer/Bellman Errors Std                     8.21129e+09
trainer/Bellman Errors Max                     1.02125e+11
trainer/Bellman Errors Min                   239.282
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      256000
expl/num paths total                        6400
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.355513
expl/Rewards Std                               0.589298
expl/Rewards Max                               1.57059
expl/Rewards Min                               0
expl/Returns Mean                             14.2205
expl/Returns Std                              18.6941
expl/Returns Max                              44.5868
expl/Returns Min                               0
expl/Actions Mean                              0.250158
expl/Actions Std                               0.816131
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          14.2205
expl/env_infos/final/reward_dist Mean          0.509493
expl/env_infos/final/reward_dist Std           0.725909
expl/env_infos/final/reward_dist Max           1.57059
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00159683
expl/env_infos/initial/reward_dist Std         0.00490538
expl/env_infos/initial/reward_dist Max         0.0236998
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.355513
expl/env_infos/reward_dist Std                 0.589298
expl/env_infos/reward_dist Max                 1.57059
expl/env_infos/reward_dist Min                 0
eval/num steps total                       51200
eval/num paths total                        1280
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.337295
eval/Rewards Std                               0.60548
eval/Rewards Max                               1.56835
eval/Rewards Min                               0
eval/Returns Mean                             13.4918
eval/Returns Std                              20.5495
eval/Returns Max                              45.903
eval/Returns Min                               0.000134087
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          13.4918
eval/env_infos/final/reward_dist Mean          0.470888
eval/env_infos/final/reward_dist Std           0.718138
eval/env_infos/final/reward_dist Max           1.56835
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00066021
eval/env_infos/initial/reward_dist Std         0.00107826
eval/env_infos/initial/reward_dist Max         0.00317713
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.337295
eval/env_infos/reward_dist Std                 0.60548
eval/env_infos/reward_dist Max                 1.56835
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00597265
time/evaluation sampling (s)                   3.56306
time/exploration sampling (s)                 17.9231
time/logging (s)                               0.00541169
time/saving (s)                                0.00100584
time/training (s)                              4.27387
time/epoch (s)                                25.7724
time/total (s)                              3244.78
Epoch                                        127
---------------------------------------  -----------------
2023-08-05 01:15:38.636252 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 128 finished
---------------------------------------  -----------------
epoch                                        128
replay_buffer/size                        258000
trainer/QF Loss                                4.31669e+09
trainer/Policy Loss                      -350663
trainer/Raw Policy Loss                  -350663
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                286139
trainer/Q Predictions Std                  46667.4
trainer/Q Predictions Max                 494060
trainer/Q Predictions Min                    651.298
trainer/Q Targets Mean                    333263
trainer/Q Targets Std                      17612.3
trainer/Q Targets Max                     487399
trainer/Q Targets Min                     180766
trainer/Bellman Errors Mean                    4.31669e+09
trainer/Bellman Errors Std                     8.44791e+09
trainer/Bellman Errors Max                     1.09509e+11
trainer/Bellman Errors Min                  4418.09
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      258000
expl/num paths total                        6450
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.408228
expl/Rewards Std                               0.62557
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             16.3291
expl/Returns Std                              20.0525
expl/Returns Max                              44.8509
expl/Returns Min                               0
expl/Actions Mean                              0.24979
expl/Actions Std                               0.814405
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.3291
expl/env_infos/final/reward_dist Mean          0.619469
expl/env_infos/final/reward_dist Std           0.759607
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00105709
expl/env_infos/initial/reward_dist Std         0.00364288
expl/env_infos/initial/reward_dist Max         0.0176408
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.408228
expl/env_infos/reward_dist Std                 0.62557
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       51600
eval/num paths total                        1290
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.112986
eval/Rewards Std                               0.381411
eval/Rewards Max                               1.56556
eval/Rewards Min                               0
eval/Returns Mean                              4.51945
eval/Returns Std                              13.3009
eval/Returns Max                              44.418
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                           4.51945
eval/env_infos/final/reward_dist Mean          0.164324
eval/env_infos/final/reward_dist Std           0.467651
eval/env_infos/final/reward_dist Max           1.56556
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.112986
eval/env_infos/reward_dist Std                 0.381411
eval/env_infos/reward_dist Max                 1.56556
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.005929
time/evaluation sampling (s)                   3.54841
time/exploration sampling (s)                 17.8772
time/logging (s)                               0.00744221
time/saving (s)                                0.00961811
time/training (s)                              4.26402
time/epoch (s)                                25.7127
time/total (s)                              3270.5
Epoch                                        128
---------------------------------------  -----------------
2023-08-05 01:16:04.106503 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 129 finished
---------------------------------------  -----------------
epoch                                        129
replay_buffer/size                        260000
trainer/QF Loss                                4.56393e+09
trainer/Policy Loss                      -358543
trainer/Raw Policy Loss                  -358543
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                291903
trainer/Q Predictions Std                  48305.2
trainer/Q Predictions Max                 492434
trainer/Q Predictions Min                    652.557
trainer/Q Targets Mean                    340514
trainer/Q Targets Std                      18656.3
trainer/Q Targets Max                     478288
trainer/Q Targets Min                     185087
trainer/Bellman Errors Mean                    4.56393e+09
trainer/Bellman Errors Std                     9.18139e+09
trainer/Bellman Errors Max                     1.11423e+11
trainer/Bellman Errors Min                   356.266
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      260000
expl/num paths total                        6500
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.403458
expl/Rewards Std                               0.616551
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             16.1383
expl/Returns Std                              19.0715
expl/Returns Max                              43.1312
expl/Returns Min                               0
expl/Actions Mean                              0.265975
expl/Actions Std                               0.807627
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.1383
expl/env_infos/final/reward_dist Mean          0.633177
expl/env_infos/final/reward_dist Std           0.761783
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000528437
expl/env_infos/initial/reward_dist Std         0.00277452
expl/env_infos/initial/reward_dist Max         0.0190568
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.403458
expl/env_infos/reward_dist Std                 0.616551
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       52000
eval/num paths total                        1300
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.656319
eval/Rewards Std                               0.704019
eval/Rewards Max                               1.57077
eval/Rewards Min                               0
eval/Returns Mean                             26.2528
eval/Returns Std                              21.5218
eval/Returns Max                              46.4414
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.2528
eval/env_infos/final/reward_dist Mean          0.934136
eval/env_infos/final/reward_dist Std           0.762762
eval/env_infos/final/reward_dist Max           1.57077
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00113844
eval/env_infos/initial/reward_dist Std         0.00244919
eval/env_infos/initial/reward_dist Max         0.00771008
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.656319
eval/env_infos/reward_dist Std                 0.704019
eval/env_infos/reward_dist Max                 1.57077
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0059322
time/evaluation sampling (s)                   3.47063
time/exploration sampling (s)                 17.8068
time/logging (s)                               0.00532716
time/saving (s)                                0.00100289
time/training (s)                              4.17425
time/epoch (s)                                25.464
time/total (s)                              3295.96
Epoch                                        129
---------------------------------------  -----------------
2023-08-05 01:16:30.229705 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 130 finished
---------------------------------------  -----------------
epoch                                        130
replay_buffer/size                        262000
trainer/QF Loss                                4.6206e+09
trainer/Policy Loss                      -366015
trainer/Raw Policy Loss                  -366015
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                298173
trainer/Q Predictions Std                  47490.5
trainer/Q Predictions Max                 504770
trainer/Q Predictions Min                   1502.89
trainer/Q Targets Mean                    347610
trainer/Q Targets Std                      19510.8
trainer/Q Targets Max                     506083
trainer/Q Targets Min                     189203
trainer/Bellman Errors Mean                    4.6206e+09
trainer/Bellman Errors Std                     8.43035e+09
trainer/Bellman Errors Max                     1.18909e+11
trainer/Bellman Errors Min                    12.6914
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      262000
expl/num paths total                        6550
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.460525
expl/Rewards Std                               0.639462
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             18.421
expl/Returns Std                              19.6476
expl/Returns Max                              44.4122
expl/Returns Min                               0
expl/Actions Mean                              0.267472
expl/Actions Std                               0.802889
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.421
expl/env_infos/final/reward_dist Mean          0.686282
expl/env_infos/final/reward_dist Std           0.774372
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00107716
expl/env_infos/initial/reward_dist Std         0.00313587
expl/env_infos/initial/reward_dist Max         0.0146847
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.460525
expl/env_infos/reward_dist Std                 0.639462
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       52400
eval/num paths total                        1310
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.673316
eval/Rewards Std                               0.709559
eval/Rewards Max                               1.57038
eval/Rewards Min                               0
eval/Returns Mean                             26.9326
eval/Returns Std                              21.8114
eval/Returns Max                              45.0268
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.9326
eval/env_infos/final/reward_dist Mean          0.951759
eval/env_infos/final/reward_dist Std           0.756384
eval/env_infos/final/reward_dist Max           1.57038
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000735553
eval/env_infos/initial/reward_dist Std         0.00153122
eval/env_infos/initial/reward_dist Max         0.00508979
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.673316
eval/env_infos/reward_dist Std                 0.709559
eval/env_infos/reward_dist Max                 1.57038
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00595419
time/evaluation sampling (s)                   3.49917
time/exploration sampling (s)                 18.3315
time/logging (s)                               0.00741925
time/saving (s)                                0.00108269
time/training (s)                              4.27743
time/epoch (s)                                26.1225
time/total (s)                              3322.09
Epoch                                        130
---------------------------------------  -----------------
2023-08-05 01:16:56.395369 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 131 finished
---------------------------------------  -----------------
epoch                                        131
replay_buffer/size                        264000
trainer/QF Loss                                5.09105e+09
trainer/Policy Loss                      -373888
trainer/Raw Policy Loss                  -373888
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                304070
trainer/Q Predictions Std                  51133.9
trainer/Q Predictions Max                 533349
trainer/Q Predictions Min                    753.32
trainer/Q Targets Mean                    354871
trainer/Q Targets Std                      19476.7
trainer/Q Targets Max                     496404
trainer/Q Targets Min                     194269
trainer/Bellman Errors Mean                    5.09105e+09
trainer/Bellman Errors Std                     1.04919e+10
trainer/Bellman Errors Max                     1.22833e+11
trainer/Bellman Errors Min                  4380.78
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      264000
expl/num paths total                        6600
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.348949
expl/Rewards Std                               0.597476
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             13.958
expl/Returns Std                              19.5297
expl/Returns Max                              44.4691
expl/Returns Min                               0
expl/Actions Mean                              0.257586
expl/Actions Std                               0.800037
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          13.958
expl/env_infos/final/reward_dist Mean          0.514553
expl/env_infos/final/reward_dist Std           0.728281
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00054029
expl/env_infos/initial/reward_dist Std         0.00219817
expl/env_infos/initial/reward_dist Max         0.0119964
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.348949
expl/env_infos/reward_dist Std                 0.597476
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       52800
eval/num paths total                        1320
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.0924742
eval/Rewards Std                               0.339787
eval/Rewards Max                               1.56931
eval/Rewards Min                               0
eval/Returns Mean                              3.69897
eval/Returns Std                              11.0518
eval/Returns Max                              36.8543
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                           3.69897
eval/env_infos/final/reward_dist Mean          0.156795
eval/env_infos/final/reward_dist Std           0.470384
eval/env_infos/final/reward_dist Max           1.56795
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.0924742
eval/env_infos/reward_dist Std                 0.339787
eval/env_infos/reward_dist Max                 1.56931
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0060868
time/evaluation sampling (s)                   3.74494
time/exploration sampling (s)                 18.014
time/logging (s)                               0.00536007
time/saving (s)                                0.000982163
time/training (s)                              4.38783
time/epoch (s)                                26.1592
time/total (s)                              3348.25
Epoch                                        131
---------------------------------------  -----------------
2023-08-05 01:17:21.498930 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 132 finished
---------------------------------------  -----------------
epoch                                        132
replay_buffer/size                        266000
trainer/QF Loss                                5.07625e+09
trainer/Policy Loss                      -381745
trainer/Raw Policy Loss                  -381745
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                311167
trainer/Q Predictions Std                  50778.9
trainer/Q Predictions Max                 465823
trainer/Q Predictions Min                    596.354
trainer/Q Targets Mean                    362527
trainer/Q Targets Std                      19975.8
trainer/Q Targets Max                     519760
trainer/Q Targets Min                     198522
trainer/Bellman Errors Mean                    5.07625e+09
trainer/Bellman Errors Std                     9.94289e+09
trainer/Bellman Errors Max                     1.28224e+11
trainer/Bellman Errors Min                     1
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      266000
expl/num paths total                        6650
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.457367
expl/Rewards Std                               0.628647
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             18.2947
expl/Returns Std                              18.9889
expl/Returns Max                              46.4597
expl/Returns Min                               0
expl/Actions Mean                              0.259186
expl/Actions Std                               0.801922
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.2947
expl/env_infos/final/reward_dist Mean          0.676465
expl/env_infos/final/reward_dist Std           0.766647
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00135771
expl/env_infos/initial/reward_dist Std         0.00446712
expl/env_infos/initial/reward_dist Max         0.0278836
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.457367
expl/env_infos/reward_dist Std                 0.628647
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       53200
eval/num paths total                        1330
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.45351
eval/Rewards Std                               0.654024
eval/Rewards Max                               1.57044
eval/Rewards Min                               0
eval/Returns Mean                             18.1404
eval/Returns Std                              21.4253
eval/Returns Max                              45.2481
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          18.1404
eval/env_infos/final/reward_dist Mean          0.660409
eval/env_infos/final/reward_dist Std           0.746859
eval/env_infos/final/reward_dist Max           1.57044
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000944059
eval/env_infos/initial/reward_dist Std         0.00283218
eval/env_infos/initial/reward_dist Max         0.00944059
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.45351
eval/env_infos/reward_dist Std                 0.654024
eval/env_infos/reward_dist Max                 1.57044
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0059461
time/evaluation sampling (s)                   3.41399
time/exploration sampling (s)                 17.304
time/logging (s)                               0.00743666
time/saving (s)                                0.00108883
time/training (s)                              4.37003
time/epoch (s)                                25.1025
time/total (s)                              3373.36
Epoch                                        132
---------------------------------------  -----------------
2023-08-05 01:17:47.056623 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 133 finished
---------------------------------------  -----------------
epoch                                        133
replay_buffer/size                        268000
trainer/QF Loss                                5.15466e+09
trainer/Policy Loss                      -389556
trainer/Raw Policy Loss                  -389556
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                319538
trainer/Q Predictions Std                  51229.5
trainer/Q Predictions Max                 543595
trainer/Q Predictions Min                    735.747
trainer/Q Targets Mean                    370174
trainer/Q Targets Std                      21444.6
trainer/Q Targets Max                     557670
trainer/Q Targets Min                     201953
trainer/Bellman Errors Mean                    5.15466e+09
trainer/Bellman Errors Std                     1.07094e+10
trainer/Bellman Errors Max                     1.33358e+11
trainer/Bellman Errors Min                  1668.21
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      268000
expl/num paths total                        6700
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.547957
expl/Rewards Std                               0.670269
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             21.9183
expl/Returns Std                              20.3441
expl/Returns Max                              46.1368
expl/Returns Min                               0
expl/Actions Mean                              0.25072
expl/Actions Std                               0.802442
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          21.9183
expl/env_infos/final/reward_dist Mean          0.828395
expl/env_infos/final/reward_dist Std           0.769821
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.0018268
expl/env_infos/initial/reward_dist Std         0.00582901
expl/env_infos/initial/reward_dist Max         0.0265614
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.547957
expl/env_infos/reward_dist Std                 0.670269
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       53600
eval/num paths total                        1340
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.562038
eval/Rewards Std                               0.697126
eval/Rewards Max                               1.57065
eval/Rewards Min                               0
eval/Returns Mean                             22.4815
eval/Returns Std                              22.4595
eval/Returns Max                              45.6823
eval/Returns Min                               0.00317527
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.4815
eval/env_infos/final/reward_dist Mean          0.784501
eval/env_infos/final/reward_dist Std           0.784454
eval/env_infos/final/reward_dist Max           1.57065
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00386873
eval/env_infos/initial/reward_dist Std         0.00619331
eval/env_infos/initial/reward_dist Max         0.0170463
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.562038
eval/env_infos/reward_dist Std                 0.697126
eval/env_infos/reward_dist Max                 1.57065
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00589938
time/evaluation sampling (s)                   3.39909
time/exploration sampling (s)                 17.9243
time/logging (s)                               0.00741274
time/saving (s)                                0.0010871
time/training (s)                              4.2155
time/epoch (s)                                25.5533
time/total (s)                              3398.91
Epoch                                        133
---------------------------------------  -----------------
2023-08-05 01:18:12.982451 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 134 finished
---------------------------------------  -----------------
epoch                                        134
replay_buffer/size                        270000
trainer/QF Loss                                5.4913e+09
trainer/Policy Loss                      -398349
trainer/Raw Policy Loss                  -398349
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                324739
trainer/Q Predictions Std                  51847.7
trainer/Q Predictions Max                 570440
trainer/Q Predictions Min                    641.122
trainer/Q Targets Mean                    378471
trainer/Q Targets Std                      21152.4
trainer/Q Targets Max                     553815
trainer/Q Targets Min                     205179
trainer/Bellman Errors Mean                    5.4913e+09
trainer/Bellman Errors Std                     1.02879e+10
trainer/Bellman Errors Max                     1.39419e+11
trainer/Bellman Errors Min                  2075.94
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      270000
expl/num paths total                        6750
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.482562
expl/Rewards Std                               0.647216
expl/Rewards Max                               1.57074
expl/Rewards Min                               0
expl/Returns Mean                             19.3025
expl/Returns Std                              19.7875
expl/Returns Max                              44.8787
expl/Returns Min                               0
expl/Actions Mean                              0.25123
expl/Actions Std                               0.804091
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.3025
expl/env_infos/final/reward_dist Mean          0.77039
expl/env_infos/final/reward_dist Std           0.772171
expl/env_infos/final/reward_dist Max           1.57074
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000749159
expl/env_infos/initial/reward_dist Std         0.0031302
expl/env_infos/initial/reward_dist Max         0.0190624
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.482562
expl/env_infos/reward_dist Std                 0.647216
expl/env_infos/reward_dist Max                 1.57074
expl/env_infos/reward_dist Min                 0
eval/num steps total                       54000
eval/num paths total                        1350
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.669841
eval/Rewards Std                               0.71114
eval/Rewards Max                               1.57049
eval/Rewards Min                               0
eval/Returns Mean                             26.7936
eval/Returns Std                              21.8672
eval/Returns Max                              45.4141
eval/Returns Min                               0.00618691
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.7936
eval/env_infos/final/reward_dist Mean          0.94056
eval/env_infos/final/reward_dist Std           0.767967
eval/env_infos/final/reward_dist Max           1.57049
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00050564
eval/env_infos/initial/reward_dist Std         0.00127964
eval/env_infos/initial/reward_dist Max         0.00428148
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.669841
eval/env_infos/reward_dist Std                 0.71114
eval/env_infos/reward_dist Max                 1.57049
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00596444
time/evaluation sampling (s)                   3.35052
time/exploration sampling (s)                 18.1419
time/logging (s)                               0.00529188
time/saving (s)                                0.000985367
time/training (s)                              4.41466
time/epoch (s)                                25.9193
time/total (s)                              3424.83
Epoch                                        134
---------------------------------------  -----------------
2023-08-05 01:18:37.999487 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 135 finished
---------------------------------------  -----------------
epoch                                        135
replay_buffer/size                        272000
trainer/QF Loss                                5.83991e+09
trainer/Policy Loss                      -406302
trainer/Raw Policy Loss                  -406302
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                330706
trainer/Q Predictions Std                  55097.7
trainer/Q Predictions Max                 578812
trainer/Q Predictions Min                    620.483
trainer/Q Targets Mean                    385652
trainer/Q Targets Std                      21166.2
trainer/Q Targets Max                     527886
trainer/Q Targets Min                     212607
trainer/Bellman Errors Mean                    5.83991e+09
trainer/Bellman Errors Std                     1.17475e+10
trainer/Bellman Errors Max                     1.4376e+11
trainer/Bellman Errors Min                   278.473
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      272000
expl/num paths total                        6800
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.443194
expl/Rewards Std                               0.644895
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             17.7277
expl/Returns Std                              20.5284
expl/Returns Max                              45.8203
expl/Returns Min                               0
expl/Actions Mean                              0.257871
expl/Actions Std                               0.805281
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.7277
expl/env_infos/final/reward_dist Mean          0.658571
expl/env_infos/final/reward_dist Std           0.773895
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00153196
expl/env_infos/initial/reward_dist Std         0.00411468
expl/env_infos/initial/reward_dist Max         0.0186342
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.443194
expl/env_infos/reward_dist Std                 0.644895
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       54400
eval/num paths total                        1360
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.672531
eval/Rewards Std                               0.712385
eval/Rewards Max                               1.57065
eval/Rewards Min                               0
eval/Returns Mean                             26.9012
eval/Returns Std                              21.9659
eval/Returns Max                              46.2619
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.9012
eval/env_infos/final/reward_dist Mean          0.941035
eval/env_infos/final/reward_dist Std           0.768353
eval/env_infos/final/reward_dist Max           1.57065
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.0012839
eval/env_infos/initial/reward_dist Std         0.0038517
eval/env_infos/initial/reward_dist Max         0.012839
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.672531
eval/env_infos/reward_dist Std                 0.712385
eval/env_infos/reward_dist Max                 1.57065
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00596606
time/evaluation sampling (s)                   3.3309
time/exploration sampling (s)                 17.4344
time/logging (s)                               0.00534715
time/saving (s)                                0.00101608
time/training (s)                              4.23669
time/epoch (s)                                25.0143
time/total (s)                              3449.85
Epoch                                        135
---------------------------------------  -----------------
2023-08-05 01:19:04.083567 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 136 finished
---------------------------------------  -----------------
epoch                                        136
replay_buffer/size                        274000
trainer/QF Loss                                5.88449e+09
trainer/Policy Loss                      -414807
trainer/Raw Policy Loss                  -414807
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                339157
trainer/Q Predictions Std                  54703.7
trainer/Q Predictions Max                 552429
trainer/Q Predictions Min                    656.755
trainer/Q Targets Mean                    394133
trainer/Q Targets Std                      23044.7
trainer/Q Targets Max                     572728
trainer/Q Targets Min                     213427
trainer/Bellman Errors Mean                    5.88449e+09
trainer/Bellman Errors Std                     1.14026e+10
trainer/Bellman Errors Max                     1.5001e+11
trainer/Bellman Errors Min                  1205.39
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      274000
expl/num paths total                        6850
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.493822
expl/Rewards Std                               0.646925
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             19.7529
expl/Returns Std                              19.5372
expl/Returns Max                              44.7173
expl/Returns Min                               0
expl/Actions Mean                              0.26572
expl/Actions Std                               0.803488
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.7529
expl/env_infos/final/reward_dist Mean          0.760893
expl/env_infos/final/reward_dist Std           0.773037
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00204034
expl/env_infos/initial/reward_dist Std         0.00524532
expl/env_infos/initial/reward_dist Max         0.0212107
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.493822
expl/env_infos/reward_dist Std                 0.646925
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       54800
eval/num paths total                        1370
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.673535
eval/Rewards Std                               0.711805
eval/Rewards Max                               1.57059
eval/Rewards Min                               0
eval/Returns Mean                             26.9414
eval/Returns Std                              21.9826
eval/Returns Max                              45.134
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.9414
eval/env_infos/final/reward_dist Mean          0.941415
eval/env_infos/final/reward_dist Std           0.768663
eval/env_infos/final/reward_dist Max           1.57059
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00152411
eval/env_infos/initial/reward_dist Std         0.0029162
eval/env_infos/initial/reward_dist Max         0.00911282
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.673535
eval/env_infos/reward_dist Std                 0.711805
eval/env_infos/reward_dist Max                 1.57059
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00596226
time/evaluation sampling (s)                   3.46735
time/exploration sampling (s)                 18.126
time/logging (s)                               0.00535619
time/saving (s)                                0.000991751
time/training (s)                              4.47558
time/epoch (s)                                26.0813
time/total (s)                              3475.93
Epoch                                        136
---------------------------------------  -----------------
2023-08-05 01:19:30.122694 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 137 finished
---------------------------------------  -----------------
epoch                                        137
replay_buffer/size                        276000
trainer/QF Loss                                6.32018e+09
trainer/Policy Loss                      -423040
trainer/Raw Policy Loss                  -423040
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                344923
trainer/Q Predictions Std                  56024.1
trainer/Q Predictions Max                 516657
trainer/Q Predictions Min                    787.633
trainer/Q Targets Mean                    401890
trainer/Q Targets Std                      23206
trainer/Q Targets Max                     615115
trainer/Q Targets Min                     218728
trainer/Bellman Errors Mean                    6.32018e+09
trainer/Bellman Errors Std                     1.25473e+10
trainer/Bellman Errors Max                     1.58769e+11
trainer/Bellman Errors Min                   157.816
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      276000
expl/num paths total                        6900
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.462649
expl/Rewards Std                               0.626418
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             18.5059
expl/Returns Std                              18.8183
expl/Returns Max                              44.2421
expl/Returns Min                               0
expl/Actions Mean                              0.263109
expl/Actions Std                               0.8004
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.5059
expl/env_infos/final/reward_dist Mean          0.637575
expl/env_infos/final/reward_dist Std           0.761874
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00207562
expl/env_infos/initial/reward_dist Std         0.00557956
expl/env_infos/initial/reward_dist Max         0.02629
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.462649
expl/env_infos/reward_dist Std                 0.626418
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       55200
eval/num paths total                        1380
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.483503
eval/Rewards Std                               0.656839
eval/Rewards Max                               1.57004
eval/Rewards Min                               0
eval/Returns Mean                             19.3401
eval/Returns Std                              21.468
eval/Returns Max                              46.5573
eval/Returns Min                               1.2101e-05
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          19.3401
eval/env_infos/final/reward_dist Mean          0.741229
eval/env_infos/final/reward_dist Std           0.751045
eval/env_infos/final/reward_dist Max           1.57004
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00537325
eval/env_infos/initial/reward_dist Std         0.00861177
eval/env_infos/initial/reward_dist Max         0.0243249
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.483503
eval/env_infos/reward_dist Std                 0.656839
eval/env_infos/reward_dist Max                 1.57004
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00589868
time/evaluation sampling (s)                   3.54088
time/exploration sampling (s)                 18.0677
time/logging (s)                               0.00532802
time/saving (s)                                0.000985291
time/training (s)                              4.41552
time/epoch (s)                                26.0363
time/total (s)                              3501.97
Epoch                                        137
---------------------------------------  -----------------
2023-08-05 01:19:55.515178 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 138 finished
---------------------------------------  -----------------
epoch                                        138
replay_buffer/size                        278000
trainer/QF Loss                                6.31041e+09
trainer/Policy Loss                      -431631
trainer/Raw Policy Loss                  -431631
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                352277
trainer/Q Predictions Std                  56426.9
trainer/Q Predictions Max                 599543
trainer/Q Predictions Min                    769.791
trainer/Q Targets Mean                    409723
trainer/Q Targets Std                      23297.1
trainer/Q Targets Max                     550854
trainer/Q Targets Min                     223779
trainer/Bellman Errors Mean                    6.31041e+09
trainer/Bellman Errors Std                     1.20997e+10
trainer/Bellman Errors Max                     1.67579e+11
trainer/Bellman Errors Min                   193.384
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      278000
expl/num paths total                        6950
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.315739
expl/Rewards Std                               0.573098
expl/Rewards Max                               1.57073
expl/Rewards Min                               0
expl/Returns Mean                             12.6296
expl/Returns Std                              18.6771
expl/Returns Max                              44.9852
expl/Returns Min                               0
expl/Actions Mean                              0.257608
expl/Actions Std                               0.79629
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          12.6296
expl/env_infos/final/reward_dist Mean          0.477035
expl/env_infos/final/reward_dist Std           0.713123
expl/env_infos/final/reward_dist Max           1.57073
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00166467
expl/env_infos/initial/reward_dist Std         0.00512023
expl/env_infos/initial/reward_dist Max         0.0213747
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.315739
expl/env_infos/reward_dist Std                 0.573098
expl/env_infos/reward_dist Max                 1.57073
expl/env_infos/reward_dist Min                 0
eval/num steps total                       55600
eval/num paths total                        1390
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.42287
eval/Rewards Std                               0.640907
eval/Rewards Max                               1.57077
eval/Rewards Min                               0
eval/Returns Mean                             16.9148
eval/Returns Std                              20.8563
eval/Returns Max                              45.3937
eval/Returns Min                               0.000359072
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          16.9148
eval/env_infos/final/reward_dist Mean          0.619417
eval/env_infos/final/reward_dist Std           0.759001
eval/env_infos/final/reward_dist Max           1.57077
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        2.64076e-05
eval/env_infos/initial/reward_dist Std         7.92228e-05
eval/env_infos/initial/reward_dist Max         0.000264076
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.42287
eval/env_infos/reward_dist Std                 0.640907
eval/env_infos/reward_dist Max                 1.57077
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00604337
time/evaluation sampling (s)                   3.54767
time/exploration sampling (s)                 17.5275
time/logging (s)                               0.00538181
time/saving (s)                                0.00102885
time/training (s)                              4.30178
time/epoch (s)                                25.3894
time/total (s)                              3527.36
Epoch                                        138
---------------------------------------  -----------------
2023-08-05 01:20:22.050748 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 139 finished
---------------------------------------  -----------------
epoch                                        139
replay_buffer/size                        280000
trainer/QF Loss                                6.76254e+09
trainer/Policy Loss                      -440511
trainer/Raw Policy Loss                  -440511
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                359428
trainer/Q Predictions Std                  58145
trainer/Q Predictions Max                 544632
trainer/Q Predictions Min                    513.384
trainer/Q Targets Mean                    418478
trainer/Q Targets Std                      23053
trainer/Q Targets Max                     642359
trainer/Q Targets Min                     231069
trainer/Bellman Errors Mean                    6.76254e+09
trainer/Bellman Errors Std                     1.35677e+10
trainer/Bellman Errors Max                     1.72684e+11
trainer/Bellman Errors Min                  2832.24
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      280000
expl/num paths total                        7000
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.457444
expl/Rewards Std                               0.624039
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             18.2978
expl/Returns Std                              19.0008
expl/Returns Max                              44.1981
expl/Returns Min                               0
expl/Actions Mean                              0.267997
expl/Actions Std                               0.806302
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.2978
expl/env_infos/final/reward_dist Mean          0.698269
expl/env_infos/final/reward_dist Std           0.760183
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000891651
expl/env_infos/initial/reward_dist Std         0.00341763
expl/env_infos/initial/reward_dist Max         0.016464
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.457444
expl/env_infos/reward_dist Std                 0.624039
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       56000
eval/num paths total                        1400
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.452319
eval/Rewards Std                               0.659144
eval/Rewards Max                               1.57077
eval/Rewards Min                               0
eval/Returns Mean                             18.0927
eval/Returns Std                              21.7444
eval/Returns Max                              45.4041
eval/Returns Min                               0.00538101
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          18.0927
eval/env_infos/final/reward_dist Mean          0.645794
eval/env_infos/final/reward_dist Std           0.756765
eval/env_infos/final/reward_dist Max           1.57077
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00169643
eval/env_infos/initial/reward_dist Std         0.00508929
eval/env_infos/initial/reward_dist Max         0.0169643
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.452319
eval/env_infos/reward_dist Std                 0.659144
eval/env_infos/reward_dist Max                 1.57077
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00592794
time/evaluation sampling (s)                   3.61722
time/exploration sampling (s)                 18.4959
time/logging (s)                               0.00532664
time/saving (s)                                0.000970131
time/training (s)                              4.4074
time/epoch (s)                                26.5327
time/total (s)                              3553.9
Epoch                                        139
---------------------------------------  -----------------
2023-08-05 01:20:47.343768 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 140 finished
---------------------------------------  -----------------
epoch                                        140
replay_buffer/size                        282000
trainer/QF Loss                                6.80841e+09
trainer/Policy Loss                      -448653
trainer/Raw Policy Loss                  -448653
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                366848
trainer/Q Predictions Std                  58246.5
trainer/Q Predictions Max                 639810
trainer/Q Predictions Min                    667.992
trainer/Q Targets Mean                    425898
trainer/Q Targets Std                      22897.4
trainer/Q Targets Max                     618848
trainer/Q Targets Min                     231831
trainer/Bellman Errors Mean                    6.80841e+09
trainer/Bellman Errors Std                     1.32928e+10
trainer/Bellman Errors Max                     1.80257e+11
trainer/Bellman Errors Min                  5550.25
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      282000
expl/num paths total                        7050
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.408968
expl/Rewards Std                               0.620526
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             16.3587
expl/Returns Std                              19.6554
expl/Returns Max                              44.3759
expl/Returns Min                               0
expl/Actions Mean                              0.268596
expl/Actions Std                               0.798353
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.3587
expl/env_infos/final/reward_dist Mean          0.635293
expl/env_infos/final/reward_dist Std           0.760181
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00132808
expl/env_infos/initial/reward_dist Std         0.0046983
expl/env_infos/initial/reward_dist Max         0.0210334
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.408968
expl/env_infos/reward_dist Std                 0.620526
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       56400
eval/num paths total                        1410
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.336037
eval/Rewards Std                               0.605088
eval/Rewards Max                               1.57017
eval/Rewards Min                               0
eval/Returns Mean                             13.4415
eval/Returns Std                              20.5202
eval/Returns Max                              45.2975
eval/Returns Min                               0.00330107
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          13.4415
eval/env_infos/final/reward_dist Mean          0.470742
eval/env_infos/final/reward_dist Std           0.71907
eval/env_infos/final/reward_dist Max           1.57017
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000259646
eval/env_infos/initial/reward_dist Std         0.000778938
eval/env_infos/initial/reward_dist Max         0.00259646
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.336037
eval/env_infos/reward_dist Std                 0.605088
eval/env_infos/reward_dist Max                 1.57017
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00600409
time/evaluation sampling (s)                   3.4696
time/exploration sampling (s)                 17.6859
time/logging (s)                               0.00536124
time/saving (s)                                0.000980365
time/training (s)                              4.12233
time/epoch (s)                                25.2902
time/total (s)                              3579.19
Epoch                                        140
---------------------------------------  -----------------
2023-08-05 01:21:13.351923 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 141 finished
---------------------------------------  -----------------
epoch                                        141
replay_buffer/size                        284000
trainer/QF Loss                                7.06395e+09
trainer/Policy Loss                      -458095
trainer/Raw Policy Loss                  -458095
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                374032
trainer/Q Predictions Std                  59368.4
trainer/Q Predictions Max                 563228
trainer/Q Predictions Min                   1082.62
trainer/Q Targets Mean                    435197
trainer/Q Targets Std                      23732
trainer/Q Targets Max                     634194
trainer/Q Targets Min                     238661
trainer/Bellman Errors Mean                    7.06395e+09
trainer/Bellman Errors Std                     1.28894e+10
trainer/Bellman Errors Max                     1.86973e+11
trainer/Bellman Errors Min                   957.129
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      284000
expl/num paths total                        7100
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.473416
expl/Rewards Std                               0.648011
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             18.9366
expl/Returns Std                              19.9646
expl/Returns Max                              43.9621
expl/Returns Min                               0
expl/Actions Mean                              0.285375
expl/Actions Std                               0.808152
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.9366
expl/env_infos/final/reward_dist Mean          0.748158
expl/env_infos/final/reward_dist Std           0.770714
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00175748
expl/env_infos/initial/reward_dist Std         0.00451689
expl/env_infos/initial/reward_dist Max         0.0193211
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.473416
expl/env_infos/reward_dist Std                 0.648011
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       56800
eval/num paths total                        1420
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.666925
eval/Rewards Std                               0.711833
eval/Rewards Max                               1.57077
eval/Rewards Min                               0
eval/Returns Mean                             26.677
eval/Returns Std                              21.7761
eval/Returns Max                              45.237
eval/Returns Min                               0.00555957
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.677
eval/env_infos/final/reward_dist Mean          0.94103
eval/env_infos/final/reward_dist Std           0.768349
eval/env_infos/final/reward_dist Max           1.57077
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000153289
eval/env_infos/initial/reward_dist Std         0.000459867
eval/env_infos/initial/reward_dist Max         0.00153289
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.666925
eval/env_infos/reward_dist Std                 0.711833
eval/env_infos/reward_dist Max                 1.57077
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00595154
time/evaluation sampling (s)                   3.30857
time/exploration sampling (s)                 18.0551
time/logging (s)                               0.00529696
time/saving (s)                                0.00100734
time/training (s)                              4.62924
time/epoch (s)                                26.0052
time/total (s)                              3605.2
Epoch                                        141
---------------------------------------  -----------------
2023-08-05 01:21:38.524826 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 142 finished
---------------------------------------  -----------------
epoch                                        142
replay_buffer/size                        286000
trainer/QF Loss                                7.43329e+09
trainer/Policy Loss                      -468036
trainer/Raw Policy Loss                  -468036
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                382521
trainer/Q Predictions Std                  61122.2
trainer/Q Predictions Max                 622195
trainer/Q Predictions Min                    949.046
trainer/Q Targets Mean                    444424
trainer/Q Targets Std                      26053.3
trainer/Q Targets Max                     679077
trainer/Q Targets Min                     240276
trainer/Bellman Errors Mean                    7.43329e+09
trainer/Bellman Errors Std                     1.44668e+10
trainer/Bellman Errors Max                     1.95016e+11
trainer/Bellman Errors Min                   611.017
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      286000
expl/num paths total                        7150
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.464303
expl/Rewards Std                               0.632841
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             18.5721
expl/Returns Std                              18.9642
expl/Returns Max                              45.4789
expl/Returns Min                               0
expl/Actions Mean                              0.244597
expl/Actions Std                               0.800433
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.5721
expl/env_infos/final/reward_dist Mean          0.698114
expl/env_infos/final/reward_dist Std           0.77105
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.0013814
expl/env_infos/initial/reward_dist Std         0.00454376
expl/env_infos/initial/reward_dist Max         0.0258371
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.464303
expl/env_infos/reward_dist Std                 0.632841
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       57200
eval/num paths total                        1430
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.786422
eval/Rewards Std                               0.7095
eval/Rewards Max                               1.57078
eval/Rewards Min                               0
eval/Returns Mean                             31.4569
eval/Returns Std                              20.5898
eval/Returns Max                              46.2648
eval/Returns Min                               0.00683965
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          31.4569
eval/env_infos/final/reward_dist Mean          1.0982
eval/env_infos/final/reward_dist Std           0.71894
eval/env_infos/final/reward_dist Max           1.57078
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00154362
eval/env_infos/initial/reward_dist Std         0.00438742
eval/env_infos/initial/reward_dist Max         0.0146889
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.786422
eval/env_infos/reward_dist Std                 0.7095
eval/env_infos/reward_dist Max                 1.57078
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00594233
time/evaluation sampling (s)                   3.45067
time/exploration sampling (s)                 17.632
time/logging (s)                               0.00535652
time/saving (s)                                0.000995923
time/training (s)                              4.07513
time/epoch (s)                                25.1701
time/total (s)                              3630.37
Epoch                                        142
---------------------------------------  -----------------
2023-08-05 01:22:04.191557 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 143 finished
---------------------------------------  -----------------
epoch                                        143
replay_buffer/size                        288000
trainer/QF Loss                                7.74108e+09
trainer/Policy Loss                      -476537
trainer/Raw Policy Loss                  -476537
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                389940
trainer/Q Predictions Std                  62908.9
trainer/Q Predictions Max                 613442
trainer/Q Predictions Min                    972.291
trainer/Q Targets Mean                    452924
trainer/Q Targets Std                      24497.8
trainer/Q Targets Max                     612191
trainer/Q Targets Min                     244543
trainer/Bellman Errors Mean                    7.74108e+09
trainer/Bellman Errors Std                     1.51411e+10
trainer/Bellman Errors Max                     1.95864e+11
trainer/Bellman Errors Min                  1622.58
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      288000
expl/num paths total                        7200
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.607701
expl/Rewards Std                               0.672334
expl/Rewards Max                               1.57075
expl/Rewards Min                               0
expl/Returns Mean                             24.3081
expl/Returns Std                              19.1451
expl/Returns Max                              44.9058
expl/Returns Min                               0
expl/Actions Mean                              0.269198
expl/Actions Std                               0.797166
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          24.3081
expl/env_infos/final/reward_dist Mean          0.877198
expl/env_infos/final/reward_dist Std           0.777279
expl/env_infos/final/reward_dist Max           1.57075
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000791693
expl/env_infos/initial/reward_dist Std         0.00244049
expl/env_infos/initial/reward_dist Max         0.0121829
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.607701
expl/env_infos/reward_dist Std                 0.672334
expl/env_infos/reward_dist Max                 1.57075
expl/env_infos/reward_dist Min                 0
eval/num steps total                       57600
eval/num paths total                        1440
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.533617
eval/Rewards Std                               0.680946
eval/Rewards Max                               1.57041
eval/Rewards Min                               0
eval/Returns Mean                             21.3447
eval/Returns Std                              21.4112
eval/Returns Max                              44.9151
eval/Returns Min                               0.00383904
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          21.3447
eval/env_infos/final/reward_dist Mean          0.77635
eval/env_infos/final/reward_dist Std           0.776537
eval/env_infos/final/reward_dist Max           1.57041
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000529512
eval/env_infos/initial/reward_dist Std         0.00145935
eval/env_infos/initial/reward_dist Max         0.00489275
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.533617
eval/env_infos/reward_dist Std                 0.680946
eval/env_infos/reward_dist Max                 1.57041
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0059479
time/evaluation sampling (s)                   3.46254
time/exploration sampling (s)                 17.8824
time/logging (s)                               0.0054093
time/saving (s)                                0.00100354
time/training (s)                              4.30665
time/epoch (s)                                25.6639
time/total (s)                              3656.03
Epoch                                        143
---------------------------------------  -----------------
2023-08-05 01:22:30.014140 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 144 finished
---------------------------------------  -----------------
epoch                                        144
replay_buffer/size                        290000
trainer/QF Loss                                8.33745e+09
trainer/Policy Loss                      -485119
trainer/Raw Policy Loss                  -485119
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                395623
trainer/Q Predictions Std                  65222.6
trainer/Q Predictions Max                 674588
trainer/Q Predictions Min                    731.285
trainer/Q Targets Mean                    460602
trainer/Q Targets Std                      25713
trainer/Q Targets Max                     657888
trainer/Q Targets Min                     254196
trainer/Bellman Errors Mean                    8.33745e+09
trainer/Bellman Errors Std                     1.67992e+10
trainer/Bellman Errors Max                     2.05511e+11
trainer/Bellman Errors Min                   371.767
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      290000
expl/num paths total                        7250
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.519107
expl/Rewards Std                               0.665232
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             20.7643
expl/Returns Std                              20.0868
expl/Returns Max                              44.4186
expl/Returns Min                               0
expl/Actions Mean                              0.274728
expl/Actions Std                               0.812916
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          20.7643
expl/env_infos/final/reward_dist Mean          0.781682
expl/env_infos/final/reward_dist Std           0.781744
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000887682
expl/env_infos/initial/reward_dist Std         0.00319683
expl/env_infos/initial/reward_dist Max         0.01816
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.519107
expl/env_infos/reward_dist Std                 0.665232
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       58000
eval/num paths total                        1450
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.305505
eval/Rewards Std                               0.570371
eval/Rewards Max                               1.56853
eval/Rewards Min                               0
eval/Returns Mean                             12.2202
eval/Returns Std                              18.8771
eval/Returns Max                              44.8467
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          12.2202
eval/env_infos/final/reward_dist Mean          0.462249
eval/env_infos/final/reward_dist Std           0.705909
eval/env_infos/final/reward_dist Max           1.56853
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00101073
eval/env_infos/initial/reward_dist Std         0.00204825
eval/env_infos/initial/reward_dist Max         0.00579198
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.305505
eval/env_infos/reward_dist Std                 0.570371
eval/env_infos/reward_dist Max                 1.56853
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00596399
time/evaluation sampling (s)                   3.47894
time/exploration sampling (s)                 17.7716
time/logging (s)                               0.00531158
time/saving (s)                                0.000978463
time/training (s)                              4.55687
time/epoch (s)                                25.8197
time/total (s)                              3681.85
Epoch                                        144
---------------------------------------  -----------------
2023-08-05 01:22:55.649966 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 145 finished
---------------------------------------  -----------------
epoch                                        145
replay_buffer/size                        292000
trainer/QF Loss                                8.60901e+09
trainer/Policy Loss                      -495610
trainer/Raw Policy Loss                  -495610
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                403603
trainer/Q Predictions Std                  66136
trainer/Q Predictions Max                 634021
trainer/Q Predictions Min                   1194.01
trainer/Q Targets Mean                    470874
trainer/Q Targets Std                      27405.1
trainer/Q Targets Max                     687946
trainer/Q Targets Min                     258332
trainer/Bellman Errors Mean                    8.60901e+09
trainer/Bellman Errors Std                     1.68047e+10
trainer/Bellman Errors Max                     2.18895e+11
trainer/Bellman Errors Min                   335.348
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      292000
expl/num paths total                        7300
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.471412
expl/Rewards Std                               0.653287
expl/Rewards Max                               1.57074
expl/Rewards Min                               0
expl/Returns Mean                             18.8565
expl/Returns Std                              20.3486
expl/Returns Max                              44.5435
expl/Returns Min                               0
expl/Actions Mean                              0.270506
expl/Actions Std                               0.808662
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.8565
expl/env_infos/final/reward_dist Mean          0.718694
expl/env_infos/final/reward_dist Std           0.778728
expl/env_infos/final/reward_dist Max           1.57074
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00129222
expl/env_infos/initial/reward_dist Std         0.0036352
expl/env_infos/initial/reward_dist Max         0.0166432
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.471412
expl/env_infos/reward_dist Std                 0.653287
expl/env_infos/reward_dist Max                 1.57074
expl/env_infos/reward_dist Min                 0
eval/num steps total                       58400
eval/num paths total                        1460
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.781143
eval/Rewards Std                               0.708462
eval/Rewards Max                               1.57065
eval/Rewards Min                               0
eval/Returns Mean                             31.2457
eval/Returns Std                              20.4464
eval/Returns Max                              45.2261
eval/Returns Min                               0.00698074
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          31.2457
eval/env_infos/final/reward_dist Mean          1.09775
eval/env_infos/final/reward_dist Std           0.718649
eval/env_infos/final/reward_dist Max           1.57065
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.0028684
eval/env_infos/initial/reward_dist Std         0.00551152
eval/env_infos/initial/reward_dist Max         0.0172275
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.781143
eval/env_infos/reward_dist Std                 0.708462
eval/env_infos/reward_dist Max                 1.57065
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00597712
time/evaluation sampling (s)                   3.41444
time/exploration sampling (s)                 18.067
time/logging (s)                               0.00533022
time/saving (s)                                0.000970289
time/training (s)                              4.13921
time/epoch (s)                                25.633
time/total (s)                              3707.49
Epoch                                        145
---------------------------------------  -----------------
2023-08-05 01:23:21.336745 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 146 finished
---------------------------------------  -----------------
epoch                                        146
replay_buffer/size                        294000
trainer/QF Loss                                8.80322e+09
trainer/Policy Loss                      -505278
trainer/Raw Policy Loss                  -505278
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                413221
trainer/Q Predictions Std                  68198
trainer/Q Predictions Max                 647783
trainer/Q Predictions Min                    629.584
trainer/Q Targets Mean                    479988
trainer/Q Targets Std                      27134.9
trainer/Q Targets Max                     742346
trainer/Q Targets Min                     259996
trainer/Bellman Errors Mean                    8.80322e+09
trainer/Bellman Errors Std                     1.75793e+10
trainer/Bellman Errors Max                     2.22339e+11
trainer/Bellman Errors Min                  1521
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      294000
expl/num paths total                        7350
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.430484
expl/Rewards Std                               0.625858
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             17.2194
expl/Returns Std                              19.5515
expl/Returns Max                              44.675
expl/Returns Min                               0
expl/Actions Mean                              0.259419
expl/Actions Std                               0.809525
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.2194
expl/env_infos/final/reward_dist Mean          0.671616
expl/env_infos/final/reward_dist Std           0.762022
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000745089
expl/env_infos/initial/reward_dist Std         0.00248002
expl/env_infos/initial/reward_dist Max         0.0125809
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.430484
expl/env_infos/reward_dist Std                 0.625858
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       58800
eval/num paths total                        1470
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.49888
eval/Rewards Std                               0.659555
eval/Rewards Max                               1.56736
eval/Rewards Min                               0
eval/Returns Mean                             19.9552
eval/Returns Std                              20.4265
eval/Returns Max                              45.1745
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          19.9552
eval/env_infos/final/reward_dist Mean          0.77323
eval/env_infos/final/reward_dist Std           0.77361
eval/env_infos/final/reward_dist Max           1.56736
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000667704
eval/env_infos/initial/reward_dist Std         0.00169417
eval/env_infos/initial/reward_dist Max         0.00566971
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.49888
eval/env_infos/reward_dist Std                 0.659555
eval/env_infos/reward_dist Max                 1.56736
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00598243
time/evaluation sampling (s)                   3.35922
time/exploration sampling (s)                 18.0182
time/logging (s)                               0.00534883
time/saving (s)                                0.000977259
time/training (s)                              4.29419
time/epoch (s)                                25.6839
time/total (s)                              3733.18
Epoch                                        146
---------------------------------------  -----------------
2023-08-05 01:23:45.803457 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 147 finished
---------------------------------------  -----------------
epoch                                        147
replay_buffer/size                        296000
trainer/QF Loss                                8.81318e+09
trainer/Policy Loss                      -514086
trainer/Raw Policy Loss                  -514086
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                420696
trainer/Q Predictions Std                  66339.1
trainer/Q Predictions Max                 709295
trainer/Q Predictions Min                   1334.82
trainer/Q Targets Mean                    488338
trainer/Q Targets Std                      28652.9
trainer/Q Targets Max                     697376
trainer/Q Targets Min                     262832
trainer/Bellman Errors Mean                    8.81318e+09
trainer/Bellman Errors Std                     1.61265e+10
trainer/Bellman Errors Max                     2.27022e+11
trainer/Bellman Errors Min                    18.5977
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      296000
expl/num paths total                        7400
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.425982
expl/Rewards Std                               0.6206
expl/Rewards Max                               1.57071
expl/Rewards Min                               0
expl/Returns Mean                             17.0393
expl/Returns Std                              18.9949
expl/Returns Max                              44.7287
expl/Returns Min                               0
expl/Actions Mean                              0.250328
expl/Actions Std                               0.801203
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.0393
expl/env_infos/final/reward_dist Mean          0.656889
expl/env_infos/final/reward_dist Std           0.772003
expl/env_infos/final/reward_dist Max           1.57071
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000744246
expl/env_infos/initial/reward_dist Std         0.00342666
expl/env_infos/initial/reward_dist Max         0.0189227
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.425982
expl/env_infos/reward_dist Std                 0.6206
expl/env_infos/reward_dist Max                 1.57071
expl/env_infos/reward_dist Min                 0
eval/num steps total                       59200
eval/num paths total                        1480
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.88832
eval/Rewards Std                               0.691445
eval/Rewards Max                               1.57072
eval/Rewards Min                               0
eval/Returns Mean                             35.5328
eval/Returns Std                              17.7752
eval/Returns Max                              45.4959
eval/Returns Min                               1.61804e-05
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          35.5328
eval/env_infos/final/reward_dist Mean          1.25542
eval/env_infos/final/reward_dist Std           0.627712
eval/env_infos/final/reward_dist Max           1.57072
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00219382
eval/env_infos/initial/reward_dist Std         0.00600317
eval/env_infos/initial/reward_dist Max         0.0201306
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.88832
eval/env_infos/reward_dist Std                 0.691445
eval/env_infos/reward_dist Max                 1.57072
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00594768
time/evaluation sampling (s)                   3.36595
time/exploration sampling (s)                 17.4135
time/logging (s)                               0.00393216
time/saving (s)                                0.000760561
time/training (s)                              3.67223
time/epoch (s)                                24.4623
time/total (s)                              3757.64
Epoch                                        147
---------------------------------------  -----------------
2023-08-05 01:24:12.057754 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 148 finished
---------------------------------------  -----------------
epoch                                        148
replay_buffer/size                        298000
trainer/QF Loss                                9.94019e+09
trainer/Policy Loss                      -524169
trainer/Raw Policy Loss                  -524169
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                425959
trainer/Q Predictions Std                  70480.2
trainer/Q Predictions Max                 735947
trainer/Q Predictions Min                    741.797
trainer/Q Targets Mean                    497329
trainer/Q Targets Std                      27743.9
trainer/Q Targets Max                     706609
trainer/Q Targets Min                     269404
trainer/Bellman Errors Mean                    9.94019e+09
trainer/Bellman Errors Std                     1.93783e+10
trainer/Bellman Errors Max                     2.45163e+11
trainer/Bellman Errors Min                     0.472656
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      298000
expl/num paths total                        7450
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.336367
expl/Rewards Std                               0.578594
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             13.4547
expl/Returns Std                              18.5797
expl/Returns Max                              45.5112
expl/Returns Min                               0
expl/Actions Mean                              0.249494
expl/Actions Std                               0.798429
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          13.4547
expl/env_infos/final/reward_dist Mean          0.468737
expl/env_infos/final/reward_dist Std           0.716134
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.001074
expl/env_infos/initial/reward_dist Std         0.00411541
expl/env_infos/initial/reward_dist Max         0.0220382
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.336367
expl/env_infos/reward_dist Std                 0.578594
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       59600
eval/num paths total                        1490
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.561575
eval/Rewards Std                               0.696316
eval/Rewards Max                               1.57078
eval/Rewards Min                               0
eval/Returns Mean                             22.463
eval/Returns Std                              22.4466
eval/Returns Max                              45.3779
eval/Returns Min                               0.00151325
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.463
eval/env_infos/final/reward_dist Mean          0.7848
eval/env_infos/final/reward_dist Std           0.7848
eval/env_infos/final/reward_dist Max           1.57078
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00300155
eval/env_infos/initial/reward_dist Std         0.00586188
eval/env_infos/initial/reward_dist Max         0.016562
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.561575
eval/env_infos/reward_dist Std                 0.696316
eval/env_infos/reward_dist Max                 1.57078
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00588471
time/evaluation sampling (s)                   3.43359
time/exploration sampling (s)                 17.9823
time/logging (s)                               0.00532647
time/saving (s)                                0.00100178
time/training (s)                              4.82507
time/epoch (s)                                26.2532
time/total (s)                              3783.89
Epoch                                        148
---------------------------------------  -----------------
2023-08-05 01:24:37.571024 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 149 finished
---------------------------------------  -----------------
epoch                                        149
replay_buffer/size                        300000
trainer/QF Loss                                9.66978e+09
trainer/Policy Loss                      -533903
trainer/Raw Policy Loss                  -533903
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                435613
trainer/Q Predictions Std                  70176.2
trainer/Q Predictions Max                 755766
trainer/Q Predictions Min                   1642.47
trainer/Q Targets Mean                    506806
trainer/Q Targets Std                      27534.7
trainer/Q Targets Max                     688413
trainer/Q Targets Min                     273505
trainer/Bellman Errors Mean                    9.66978e+09
trainer/Bellman Errors Std                     1.80221e+10
trainer/Bellman Errors Max                     2.52386e+11
trainer/Bellman Errors Min                   229.712
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      300000
expl/num paths total                        7500
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.471036
expl/Rewards Std                               0.646007
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             18.8414
expl/Returns Std                              19.7597
expl/Returns Max                              45.9507
expl/Returns Min                               0
expl/Actions Mean                              0.25603
expl/Actions Std                               0.812404
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          18.8414
expl/env_infos/final/reward_dist Mean          0.721066
expl/env_infos/final/reward_dist Std           0.781266
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00202933
expl/env_infos/initial/reward_dist Std         0.00444213
expl/env_infos/initial/reward_dist Max         0.0195762
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.471036
expl/env_infos/reward_dist Std                 0.646007
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       60000
eval/num paths total                        1500
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.66828
eval/Rewards Std                               0.710641
eval/Rewards Max                               1.57076
eval/Rewards Min                               0
eval/Returns Mean                             26.7312
eval/Returns Std                              21.816
eval/Returns Max                              45.0959
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.7312
eval/env_infos/final/reward_dist Mean          0.94067
eval/env_infos/final/reward_dist Std           0.768056
eval/env_infos/final/reward_dist Max           1.57076
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00172908
eval/env_infos/initial/reward_dist Std         0.00518725
eval/env_infos/initial/reward_dist Max         0.0172908
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.66828
eval/env_infos/reward_dist Std                 0.710641
eval/env_infos/reward_dist Max                 1.57076
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00604937
time/evaluation sampling (s)                   3.33513
time/exploration sampling (s)                 17.7787
time/logging (s)                               0.00536332
time/saving (s)                                0.000997717
time/training (s)                              4.38426
time/epoch (s)                                25.5105
time/total (s)                              3809.41
Epoch                                        149
---------------------------------------  -----------------
2023-08-05 01:25:03.224881 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 150 finished
---------------------------------------  -----------------
epoch                                        150
replay_buffer/size                        302000
trainer/QF Loss                                1.04508e+10
trainer/Policy Loss                      -544007
trainer/Raw Policy Loss                  -544007
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                443819
trainer/Q Predictions Std                  73031.6
trainer/Q Predictions Max                 770102
trainer/Q Predictions Min                    637.751
trainer/Q Targets Mean                    516966
trainer/Q Targets Std                      28267.9
trainer/Q Targets Max                     772972
trainer/Q Targets Min                     279301
trainer/Bellman Errors Mean                    1.04508e+10
trainer/Bellman Errors Std                     2.13985e+10
trainer/Bellman Errors Max                     2.60223e+11
trainer/Bellman Errors Min                  2025
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      302000
expl/num paths total                        7550
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.325139
expl/Rewards Std                               0.567274
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             13.0056
expl/Returns Std                              17.998
expl/Returns Max                              44.9355
expl/Returns Min                               0
expl/Actions Mean                              0.265331
expl/Actions Std                               0.801719
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          13.0056
expl/env_infos/final/reward_dist Mean          0.497309
expl/env_infos/final/reward_dist Std           0.725006
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00147619
expl/env_infos/initial/reward_dist Std         0.00396689
expl/env_infos/initial/reward_dist Max         0.0198741
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.325139
expl/env_infos/reward_dist Std                 0.567274
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       60400
eval/num paths total                        1510
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.574722
eval/Rewards Std                               0.673044
eval/Rewards Max                               1.57029
eval/Rewards Min                               0
eval/Returns Mean                             22.9889
eval/Returns Std                              20.1755
eval/Returns Max                              45.0727
eval/Returns Min                               0.0101881
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.9889
eval/env_infos/final/reward_dist Mean          0.931698
eval/env_infos/final/reward_dist Std           0.761064
eval/env_infos/final/reward_dist Max           1.57029
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000121001
eval/env_infos/initial/reward_dist Std         0.000363004
eval/env_infos/initial/reward_dist Max         0.00121001
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.574722
eval/env_infos/reward_dist Std                 0.673044
eval/env_infos/reward_dist Max                 1.57029
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0059787
time/evaluation sampling (s)                   3.40905
time/exploration sampling (s)                 17.9393
time/logging (s)                               0.00531029
time/saving (s)                                0.000979285
time/training (s)                              4.2904
time/epoch (s)                                25.651
time/total (s)                              3835.06
Epoch                                        150
---------------------------------------  -----------------
2023-08-05 01:25:28.971073 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 151 finished
---------------------------------------  -----------------
epoch                                        151
replay_buffer/size                        304000
trainer/QF Loss                                1.09479e+10
trainer/Policy Loss                      -554030
trainer/Raw Policy Loss                  -554030
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                450699
trainer/Q Predictions Std                  74095
trainer/Q Predictions Max                 800575
trainer/Q Predictions Min                    713.001
trainer/Q Targets Mean                    526179
trainer/Q Targets Std                      27975.2
trainer/Q Targets Max                     762108
trainer/Q Targets Min                     284976
trainer/Bellman Errors Mean                    1.09479e+10
trainer/Bellman Errors Std                     2.18906e+10
trainer/Bellman Errors Max                     2.69582e+11
trainer/Bellman Errors Min                     6.56641
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      304000
expl/num paths total                        7600
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.504098
expl/Rewards Std                               0.656005
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             20.1639
expl/Returns Std                              19.8546
expl/Returns Max                              44.2403
expl/Returns Min                               0
expl/Actions Mean                              0.252646
expl/Actions Std                               0.804405
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          20.1639
expl/env_infos/final/reward_dist Mean          0.753075
expl/env_infos/final/reward_dist Std           0.783634
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00131671
expl/env_infos/initial/reward_dist Std         0.00454436
expl/env_infos/initial/reward_dist Max         0.0266925
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.504098
expl/env_infos/reward_dist Std                 0.656005
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       60800
eval/num paths total                        1520
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.559076
eval/Rewards Std                               0.696582
eval/Rewards Max                               1.57066
eval/Rewards Min                               0
eval/Returns Mean                             22.3631
eval/Returns Std                              22.3501
eval/Returns Max                              45.0848
eval/Returns Min                               0.00669947
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.3631
eval/env_infos/final/reward_dist Mean          0.785043
eval/env_infos/final/reward_dist Std           0.785044
eval/env_infos/final/reward_dist Max           1.57066
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00121707
eval/env_infos/initial/reward_dist Std         0.00324095
eval/env_infos/initial/reward_dist Max         0.0108701
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.559076
eval/env_infos/reward_dist Std                 0.696582
eval/env_infos/reward_dist Max                 1.57066
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00595956
time/evaluation sampling (s)                   3.43154
time/exploration sampling (s)                 17.8686
time/logging (s)                               0.00538234
time/saving (s)                                0.000988133
time/training (s)                              4.43085
time/epoch (s)                                25.7433
time/total (s)                              3860.8
Epoch                                        151
---------------------------------------  -----------------
2023-08-05 01:25:55.134590 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 152 finished
---------------------------------------  -----------------
epoch                                        152
replay_buffer/size                        306000
trainer/QF Loss                                1.12182e+10
trainer/Policy Loss                      -563570
trainer/Raw Policy Loss                  -563570
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                459800
trainer/Q Predictions Std                  74892.1
trainer/Q Predictions Max                 742099
trainer/Q Predictions Min                    651.542
trainer/Q Targets Mean                    534957
trainer/Q Targets Std                      29250
trainer/Q Targets Max                     707671
trainer/Q Targets Min                     289056
trainer/Bellman Errors Mean                    1.12182e+10
trainer/Bellman Errors Std                     2.2422e+10
trainer/Bellman Errors Max                     2.8216e+11
trainer/Bellman Errors Min                    30.9414
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      306000
expl/num paths total                        7650
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.395994
expl/Rewards Std                               0.611067
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             15.8397
expl/Returns Std                              18.8863
expl/Returns Max                              43.5458
expl/Returns Min                               0
expl/Actions Mean                              0.280726
expl/Actions Std                               0.798718
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          15.8397
expl/env_infos/final/reward_dist Mean          0.654317
expl/env_infos/final/reward_dist Std           0.768791
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00138311
expl/env_infos/initial/reward_dist Std         0.00455509
expl/env_infos/initial/reward_dist Max         0.0205183
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.395994
expl/env_infos/reward_dist Std                 0.611067
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       61200
eval/num paths total                        1530
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              1.07974
eval/Rewards Std                               0.597699
eval/Rewards Max                               1.57077
eval/Rewards Min                               0
eval/Returns Mean                             43.1896
eval/Returns Std                               3.18855
eval/Returns Max                              45.4966
eval/Returns Min                              33.7641
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          43.1896
eval/env_infos/final/reward_dist Mean          1.55918
eval/env_infos/final/reward_dist Std           0.023946
eval/env_infos/final/reward_dist Max           1.57077
eval/env_infos/final/reward_dist Min           1.48772
eval/env_infos/initial/reward_dist Mean        0.00223895
eval/env_infos/initial/reward_dist Std         0.00671686
eval/env_infos/initial/reward_dist Max         0.0223895
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                1.07974
eval/env_infos/reward_dist Std                 0.597699
eval/env_infos/reward_dist Max                 1.57077
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0060146
time/evaluation sampling (s)                   3.47622
time/exploration sampling (s)                 18.5955
time/logging (s)                               0.00532354
time/saving (s)                                0.000959977
time/training (s)                              4.07666
time/epoch (s)                                26.1607
time/total (s)                              3886.97
Epoch                                        152
---------------------------------------  -----------------
2023-08-05 01:26:19.943403 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 153 finished
---------------------------------------  -----------------
epoch                                        153
replay_buffer/size                        308000
trainer/QF Loss                                1.11732e+10
trainer/Policy Loss                      -574564
trainer/Raw Policy Loss                  -574564
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                468347
trainer/Q Predictions Std                  74250
trainer/Q Predictions Max                 763364
trainer/Q Predictions Min                    828.875
trainer/Q Targets Mean                    545814
trainer/Q Targets Std                      29365.2
trainer/Q Targets Max                     807640
trainer/Q Targets Min                     294846
trainer/Bellman Errors Mean                    1.11732e+10
trainer/Bellman Errors Std                     2.13464e+10
trainer/Bellman Errors Max                     2.9029e+11
trainer/Bellman Errors Min                    33.7852
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      308000
expl/num paths total                        7700
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.431391
expl/Rewards Std                               0.638854
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             17.2557
expl/Returns Std                              20.2227
expl/Returns Max                              44.3637
expl/Returns Min                               0
expl/Actions Mean                              0.244779
expl/Actions Std                               0.805654
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.2557
expl/env_infos/final/reward_dist Mean          0.659072
expl/env_infos/final/reward_dist Std           0.77431
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00142853
expl/env_infos/initial/reward_dist Std         0.00496328
expl/env_infos/initial/reward_dist Max         0.023904
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.431391
expl/env_infos/reward_dist Std                 0.638854
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       61600
eval/num paths total                        1540
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.872621
eval/Rewards Std                               0.6852
eval/Rewards Max                               1.57079
eval/Rewards Min                               0
eval/Returns Mean                             34.9048
eval/Returns Std                              17.6313
eval/Returns Max                              45.3229
eval/Returns Min                               0.00364298
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          34.9048
eval/env_infos/final/reward_dist Mean          1.24628
eval/env_infos/final/reward_dist Std           0.623593
eval/env_infos/final/reward_dist Max           1.57079
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.003417
eval/env_infos/initial/reward_dist Std         0.00548595
eval/env_infos/initial/reward_dist Max         0.0172658
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.872621
eval/env_infos/reward_dist Std                 0.6852
eval/env_infos/reward_dist Max                 1.57079
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00605344
time/evaluation sampling (s)                   3.39866
time/exploration sampling (s)                 17.1011
time/logging (s)                               0.00537034
time/saving (s)                                0.000983372
time/training (s)                              4.29375
time/epoch (s)                                24.8059
time/total (s)                              3911.77
Epoch                                        153
---------------------------------------  -----------------
2023-08-05 01:26:45.662546 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 154 finished
---------------------------------------  -----------------
epoch                                        154
replay_buffer/size                        310000
trainer/QF Loss                                1.2362e+10
trainer/Policy Loss                      -584142
trainer/Raw Policy Loss                  -584142
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                476123
trainer/Q Predictions Std                  79282.8
trainer/Q Predictions Max                 762890
trainer/Q Predictions Min                    432.399
trainer/Q Targets Mean                    555269
trainer/Q Targets Std                      31491.3
trainer/Q Targets Max                     831934
trainer/Q Targets Min                     303164
trainer/Bellman Errors Mean                    1.2362e+10
trainer/Bellman Errors Std                     2.53912e+10
trainer/Bellman Errors Max                     3.0319e+11
trainer/Bellman Errors Min                   289
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      310000
expl/num paths total                        7750
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.302334
expl/Rewards Std                               0.551965
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             12.0934
expl/Returns Std                              17.6881
expl/Returns Max                              44.9215
expl/Returns Min                               0
expl/Actions Mean                              0.267165
expl/Actions Std                               0.804105
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          12.0934
expl/env_infos/final/reward_dist Mean          0.453645
expl/env_infos/final/reward_dist Std           0.69464
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000854854
expl/env_infos/initial/reward_dist Std         0.00282412
expl/env_infos/initial/reward_dist Max         0.0136942
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.302334
expl/env_infos/reward_dist Std                 0.551965
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       62000
eval/num paths total                        1550
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.155202
eval/Rewards Std                               0.41122
eval/Rewards Max                               1.56936
eval/Rewards Min                               0
eval/Returns Mean                              6.20808
eval/Returns Std                              13.8292
eval/Returns Max                              45.1928
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                           6.20808
eval/env_infos/final/reward_dist Mean          0.315539
eval/env_infos/final/reward_dist Std           0.611725
eval/env_infos/final/reward_dist Max           1.56936
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000424571
eval/env_infos/initial/reward_dist Std         0.00127371
eval/env_infos/initial/reward_dist Max         0.00424571
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.155202
eval/env_infos/reward_dist Std                 0.41122
eval/env_infos/reward_dist Max                 1.56936
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00597714
time/evaluation sampling (s)                   3.40627
time/exploration sampling (s)                 17.8497
time/logging (s)                               0.0053201
time/saving (s)                                0.000991564
time/training (s)                              4.44798
time/epoch (s)                                25.7162
time/total (s)                              3937.49
Epoch                                        154
---------------------------------------  -----------------
2023-08-05 01:27:10.965534 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 155 finished
---------------------------------------  -----------------
epoch                                        155
replay_buffer/size                        312000
trainer/QF Loss                                1.17363e+10
trainer/Policy Loss                      -595359
trainer/Raw Policy Loss                  -595359
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                487719
trainer/Q Predictions Std                  77657.4
trainer/Q Predictions Max                 739775
trainer/Q Predictions Min                    564.551
trainer/Q Targets Mean                    565874
trainer/Q Targets Std                      30328.6
trainer/Q Targets Max                     811619
trainer/Q Targets Min                     313662
trainer/Bellman Errors Mean                    1.17363e+10
trainer/Bellman Errors Std                     2.35621e+10
trainer/Bellman Errors Max                     3.13971e+11
trainer/Bellman Errors Min                   274.316
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      312000
expl/num paths total                        7800
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.511005
expl/Rewards Std                               0.658235
expl/Rewards Max                               1.57063
expl/Rewards Min                               0
expl/Returns Mean                             20.4402
expl/Returns Std                              19.7727
expl/Returns Max                              46.3058
expl/Returns Min                               0
expl/Actions Mean                              0.272789
expl/Actions Std                               0.801144
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          20.4402
expl/env_infos/final/reward_dist Mean          0.784885
expl/env_infos/final/reward_dist Std           0.777092
expl/env_infos/final/reward_dist Max           1.57063
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00147426
expl/env_infos/initial/reward_dist Std         0.00400777
expl/env_infos/initial/reward_dist Max         0.0168064
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.511005
expl/env_infos/reward_dist Std                 0.658235
expl/env_infos/reward_dist Max                 1.57063
expl/env_infos/reward_dist Min                 0
eval/num steps total                       62400
eval/num paths total                        1560
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.390071
eval/Rewards Std                               0.617651
eval/Rewards Max                               1.57037
eval/Rewards Min                               0
eval/Returns Mean                             15.6028
eval/Returns Std                              20.0532
eval/Returns Max                              44.6995
eval/Returns Min                               3.44016e-05
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          15.6028
eval/env_infos/final/reward_dist Mean          0.622386
eval/env_infos/final/reward_dist Std           0.76237
eval/env_infos/final/reward_dist Max           1.57037
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.390071
eval/env_infos/reward_dist Std                 0.617651
eval/env_infos/reward_dist Max                 1.57037
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00597528
time/evaluation sampling (s)                   3.51721
time/exploration sampling (s)                 17.718
time/logging (s)                               0.00537074
time/saving (s)                                0.000982827
time/training (s)                              4.05261
time/epoch (s)                                25.3002
time/total (s)                              3962.79
Epoch                                        155
---------------------------------------  -----------------
2023-08-05 01:27:36.425789 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 156 finished
---------------------------------------  -----------------
epoch                                        156
replay_buffer/size                        314000
trainer/QF Loss                                1.23628e+10
trainer/Policy Loss                      -605211
trainer/Raw Policy Loss                  -605211
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                493736
trainer/Q Predictions Std                  78404
trainer/Q Predictions Max                 773321
trainer/Q Predictions Min                    744.343
trainer/Q Targets Mean                    574530
trainer/Q Targets Std                      29923.2
trainer/Q Targets Max                     823103
trainer/Q Targets Min                     315513
trainer/Bellman Errors Mean                    1.23628e+10
trainer/Bellman Errors Std                     2.40392e+10
trainer/Bellman Errors Max                     3.26383e+11
trainer/Bellman Errors Min                  1610.02
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      314000
expl/num paths total                        7850
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.559602
expl/Rewards Std                               0.677453
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             22.3841
expl/Returns Std                              20.2125
expl/Returns Max                              44.608
expl/Returns Min                               0
expl/Actions Mean                              0.246578
expl/Actions Std                               0.81044
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          22.3841
expl/env_infos/final/reward_dist Mean          0.847562
expl/env_infos/final/reward_dist Std           0.782043
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00072294
expl/env_infos/initial/reward_dist Std         0.003099
expl/env_infos/initial/reward_dist Max         0.0208932
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.559602
expl/env_infos/reward_dist Std                 0.677453
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       62800
eval/num paths total                        1570
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.336253
eval/Rewards Std                               0.604362
eval/Rewards Max                               1.57059
eval/Rewards Min                               0
eval/Returns Mean                             13.4501
eval/Returns Std                              20.5026
eval/Returns Max                              45.3943
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          13.4501
eval/env_infos/final/reward_dist Mean          0.470578
eval/env_infos/final/reward_dist Std           0.718821
eval/env_infos/final/reward_dist Max           1.57059
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00167373
eval/env_infos/initial/reward_dist Std         0.00502118
eval/env_infos/initial/reward_dist Max         0.0167373
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.336253
eval/env_infos/reward_dist Std                 0.604362
eval/env_infos/reward_dist Max                 1.57059
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00589194
time/evaluation sampling (s)                   3.40463
time/exploration sampling (s)                 17.5723
time/logging (s)                               0.00740673
time/saving (s)                                0.00109924
time/training (s)                              4.46802
time/epoch (s)                                25.4594
time/total (s)                              3988.26
Epoch                                        156
---------------------------------------  -----------------
2023-08-05 01:28:01.787393 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 157 finished
---------------------------------------  -----------------
epoch                                        157
replay_buffer/size                        316000
trainer/QF Loss                                1.26561e+10
trainer/Policy Loss                      -617747
trainer/Raw Policy Loss                  -617747
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                504752
trainer/Q Predictions Std                  80264
trainer/Q Predictions Max                 854596
trainer/Q Predictions Min                    882.448
trainer/Q Targets Mean                    585959
trainer/Q Targets Std                      33469.3
trainer/Q Targets Max                     800958
trainer/Q Targets Min                     318920
trainer/Bellman Errors Mean                    1.26560e+10
trainer/Bellman Errors Std                     2.36982e+10
trainer/Bellman Errors Max                     3.24215e+11
trainer/Bellman Errors Min                  2256.25
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      316000
expl/num paths total                        7900
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.424962
expl/Rewards Std                               0.628112
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             16.9985
expl/Returns Std                              19.7822
expl/Returns Max                              45.0825
expl/Returns Min                               0
expl/Actions Mean                              0.272186
expl/Actions Std                               0.795318
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.9985
expl/env_infos/final/reward_dist Mean          0.625264
expl/env_infos/final/reward_dist Std           0.765135
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.0015937
expl/env_infos/initial/reward_dist Std         0.00459667
expl/env_infos/initial/reward_dist Max         0.0193561
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.424962
expl/env_infos/reward_dist Std                 0.628112
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       63200
eval/num paths total                        1580
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.812205
eval/Rewards Std                               0.6812
eval/Rewards Max                               1.57076
eval/Rewards Min                               0
eval/Returns Mean                             32.4882
eval/Returns Std                              17.7772
eval/Returns Max                              45.1488
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          32.4882
eval/env_infos/final/reward_dist Mean          1.23889
eval/env_infos/final/reward_dist Std           0.620236
eval/env_infos/final/reward_dist Max           1.57076
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00342517
eval/env_infos/initial/reward_dist Std         0.00691626
eval/env_infos/initial/reward_dist Max         0.0192559
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.812205
eval/env_infos/reward_dist Std                 0.6812
eval/env_infos/reward_dist Max                 1.57076
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00593813
time/evaluation sampling (s)                   3.4708
time/exploration sampling (s)                 17.3988
time/logging (s)                               0.00533343
time/saving (s)                                0.000984622
time/training (s)                              4.47317
time/epoch (s)                                25.355
time/total (s)                              4013.61
Epoch                                        157
---------------------------------------  -----------------
2023-08-05 01:28:27.306542 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 158 finished
---------------------------------------  -----------------
epoch                                        158
replay_buffer/size                        318000
trainer/QF Loss                                1.41138e+10
trainer/Policy Loss                      -628098
trainer/Raw Policy Loss                  -628098
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                510255
trainer/Q Predictions Std                  82919.1
trainer/Q Predictions Max                 885056
trainer/Q Predictions Min                   1559.18
trainer/Q Targets Mean                    597104
trainer/Q Targets Std                      34160.7
trainer/Q Targets Max                     869285
trainer/Q Targets Min                     298166
trainer/Bellman Errors Mean                    1.41138e+10
trainer/Bellman Errors Std                     2.54995e+10
trainer/Bellman Errors Max                     3.47993e+11
trainer/Bellman Errors Min                  2244.39
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      318000
expl/num paths total                        7950
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.564232
expl/Rewards Std                               0.672518
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             22.5693
expl/Returns Std                              19.9742
expl/Returns Max                              44.8863
expl/Returns Min                               0
expl/Actions Mean                              0.26523
expl/Actions Std                               0.804315
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          22.5693
expl/env_infos/final/reward_dist Mean          0.861884
expl/env_infos/final/reward_dist Std           0.772566
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00148745
expl/env_infos/initial/reward_dist Std         0.00379601
expl/env_infos/initial/reward_dist Max         0.0203353
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.564232
expl/env_infos/reward_dist Std                 0.672518
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       63600
eval/num paths total                        1590
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.680223
eval/Rewards Std                               0.705901
eval/Rewards Max                               1.57025
eval/Rewards Min                               0
eval/Returns Mean                             27.2089
eval/Returns Std                              21.6358
eval/Returns Max                              45.2918
eval/Returns Min                               0.00180312
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          27.2089
eval/env_infos/final/reward_dist Mean          0.970577
eval/env_infos/final/reward_dist Std           0.736971
eval/env_infos/final/reward_dist Max           1.57025
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000567452
eval/env_infos/initial/reward_dist Std         0.000936586
eval/env_infos/initial/reward_dist Max         0.00237194
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.680223
eval/env_infos/reward_dist Std                 0.705901
eval/env_infos/reward_dist Max                 1.57025
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00591805
time/evaluation sampling (s)                   3.43133
time/exploration sampling (s)                 17.3702
time/logging (s)                               0.00532786
time/saving (s)                                0.000983987
time/training (s)                              4.70251
time/epoch (s)                                25.5163
time/total (s)                              4039.13
Epoch                                        158
---------------------------------------  -----------------
2023-08-05 01:28:52.584719 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 159 finished
---------------------------------------  -----------------
epoch                                        159
replay_buffer/size                        320000
trainer/QF Loss                                1.33721e+10
trainer/Policy Loss                      -639226
trainer/Raw Policy Loss                  -639226
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                523648
trainer/Q Predictions Std                  82104.4
trainer/Q Predictions Max                 877620
trainer/Q Predictions Min                    686.111
trainer/Q Targets Mean                    607261
trainer/Q Targets Std                      35296.9
trainer/Q Targets Max                     940984
trainer/Q Targets Min                     326152
trainer/Bellman Errors Mean                    1.33721e+10
trainer/Bellman Errors Std                     2.47941e+10
trainer/Bellman Errors Max                     3.54474e+11
trainer/Bellman Errors Min                     3.28516
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      320000
expl/num paths total                        8000
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.368132
expl/Rewards Std                               0.589822
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             14.7253
expl/Returns Std                              18.0969
expl/Returns Max                              44.0272
expl/Returns Min                               0
expl/Actions Mean                              0.267187
expl/Actions Std                               0.803711
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          14.7253
expl/env_infos/final/reward_dist Mean          0.531803
expl/env_infos/final/reward_dist Std           0.740988
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00119305
expl/env_infos/initial/reward_dist Std         0.00456823
expl/env_infos/initial/reward_dist Max         0.0232871
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.368132
expl/env_infos/reward_dist Std                 0.589822
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       64000
eval/num paths total                        1600
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.844321
eval/Rewards Std                               0.685456
eval/Rewards Max                               1.57074
eval/Rewards Min                               0
eval/Returns Mean                             33.7728
eval/Returns Std                              17.8483
eval/Returns Max                              45.4136
eval/Returns Min                               0.000130316
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          33.7728
eval/env_infos/final/reward_dist Mean          1.24711
eval/env_infos/final/reward_dist Std           0.623995
eval/env_infos/final/reward_dist Max           1.57074
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00278661
eval/env_infos/initial/reward_dist Std         0.00659128
eval/env_infos/initial/reward_dist Max         0.0222636
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.844321
eval/env_infos/reward_dist Std                 0.685456
eval/env_infos/reward_dist Max                 1.57074
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0059659
time/evaluation sampling (s)                   3.4608
time/exploration sampling (s)                 17.2356
time/logging (s)                               0.0078842
time/saving (s)                                0.00123917
time/training (s)                              4.56637
time/epoch (s)                                25.2778
time/total (s)                              4064.41
Epoch                                        159
---------------------------------------  -----------------
2023-08-05 01:29:18.228202 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 160 finished
---------------------------------------  -----------------
epoch                                        160
replay_buffer/size                        322000
trainer/QF Loss                                1.4346e+10
trainer/Policy Loss                      -649633
trainer/Raw Policy Loss                  -649633
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                529972
trainer/Q Predictions Std                  82907.7
trainer/Q Predictions Max                 802674
trainer/Q Predictions Min                    634.591
trainer/Q Targets Mean                    617461
trainer/Q Targets Std                      34761.8
trainer/Q Targets Max                     893959
trainer/Q Targets Min                     333200
trainer/Bellman Errors Mean                    1.4346e+10
trainer/Bellman Errors Std                     2.54542e+10
trainer/Bellman Errors Max                     3.75048e+11
trainer/Bellman Errors Min                    93.8477
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      322000
expl/num paths total                        8050
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.257952
expl/Rewards Std                               0.526742
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             10.3181
expl/Returns Std                              17.123
expl/Returns Max                              43.5456
expl/Returns Min                               0
expl/Actions Mean                              0.251234
expl/Actions Std                               0.808411
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          10.3181
expl/env_infos/final/reward_dist Mean          0.403274
expl/env_infos/final/reward_dist Std           0.680552
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000440692
expl/env_infos/initial/reward_dist Std         0.00168687
expl/env_infos/initial/reward_dist Max         0.00961643
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.257952
expl/env_infos/reward_dist Std                 0.526742
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       64400
eval/num paths total                        1610
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.435922
eval/Rewards Std                               0.648248
eval/Rewards Max                               1.57077
eval/Rewards Min                               0
eval/Returns Mean                             17.4369
eval/Returns Std                              21.3425
eval/Returns Max                              45.2021
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          17.4369
eval/env_infos/final/reward_dist Mean          0.620452
eval/env_infos/final/reward_dist Std           0.759331
eval/env_infos/final/reward_dist Max           1.57077
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00247492
eval/env_infos/initial/reward_dist Std         0.0043978
eval/env_infos/initial/reward_dist Max         0.0112512
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.435922
eval/env_infos/reward_dist Std                 0.648248
eval/env_infos/reward_dist Max                 1.57077
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00601322
time/evaluation sampling (s)                   3.49904
time/exploration sampling (s)                 17.6633
time/logging (s)                               0.00533334
time/saving (s)                                0.000989174
time/training (s)                              4.4616
time/epoch (s)                                25.6363
time/total (s)                              4090.05
Epoch                                        160
---------------------------------------  -----------------
2023-08-05 01:29:43.657101 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 161 finished
---------------------------------------  -----------------
epoch                                        161
replay_buffer/size                        324000
trainer/QF Loss                                1.48421e+10
trainer/Policy Loss                      -660289
trainer/Raw Policy Loss                  -660289
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                539931
trainer/Q Predictions Std                  86487.4
trainer/Q Predictions Max                 816573
trainer/Q Predictions Min                   1072.93
trainer/Q Targets Mean                    627647
trainer/Q Targets Std                      32623.9
trainer/Q Targets Max                     947542
trainer/Q Targets Min                     346980
trainer/Bellman Errors Mean                    1.48421e+10
trainer/Bellman Errors Std                     2.96654e+10
trainer/Bellman Errors Max                     3.94164e+11
trainer/Bellman Errors Min                  1415.64
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      324000
expl/num paths total                        8100
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.55996
expl/Rewards Std                               0.659063
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             22.3984
expl/Returns Std                              19.3984
expl/Returns Max                              44.4237
expl/Returns Min                               0
expl/Actions Mean                              0.255755
expl/Actions Std                               0.796073
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          22.3984
expl/env_infos/final/reward_dist Mean          0.860465
expl/env_infos/final/reward_dist Std           0.76475
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00180909
expl/env_infos/initial/reward_dist Std         0.00404587
expl/env_infos/initial/reward_dist Max         0.0139602
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.55996
expl/env_infos/reward_dist Std                 0.659063
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       64800
eval/num paths total                        1620
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.99382
eval/Rewards Std                               0.649245
eval/Rewards Max                               1.57075
eval/Rewards Min                               0
eval/Returns Mean                             39.7528
eval/Returns Std                              13.3208
eval/Returns Max                              45.2437
eval/Returns Min                               0.0140358
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          39.7528
eval/env_infos/final/reward_dist Mean          1.40528
eval/env_infos/final/reward_dist Std           0.468898
eval/env_infos/final/reward_dist Max           1.57075
eval/env_infos/final/reward_dist Min           0.000161518
eval/env_infos/initial/reward_dist Mean        0.00255097
eval/env_infos/initial/reward_dist Std         0.00414198
eval/env_infos/initial/reward_dist Max         0.0120006
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.99382
eval/env_infos/reward_dist Std                 0.649245
eval/env_infos/reward_dist Max                 1.57075
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00594051
time/evaluation sampling (s)                   3.46121
time/exploration sampling (s)                 17.7172
time/logging (s)                               0.00534088
time/saving (s)                                0.000975909
time/training (s)                              4.2354
time/epoch (s)                                25.426
time/total (s)                              4115.48
Epoch                                        161
---------------------------------------  -----------------
2023-08-05 01:30:09.555308 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 162 finished
---------------------------------------  -----------------
epoch                                        162
replay_buffer/size                        326000
trainer/QF Loss                                1.56308e+10
trainer/Policy Loss                      -672629
trainer/Raw Policy Loss                  -672629
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                549991
trainer/Q Predictions Std                  87835.4
trainer/Q Predictions Max                 965278
trainer/Q Predictions Min                    848.487
trainer/Q Targets Mean                    639564
trainer/Q Targets Std                      36883.9
trainer/Q Targets Max                     946425
trainer/Q Targets Min                     350630
trainer/Bellman Errors Mean                    1.56308e+10
trainer/Bellman Errors Std                     2.88034e+10
trainer/Bellman Errors Max                     3.94249e+11
trainer/Bellman Errors Min                     0.316406
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      326000
expl/num paths total                        8150
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.423875
expl/Rewards Std                               0.625558
expl/Rewards Max                               1.5708
expl/Rewards Min                               0
expl/Returns Mean                             16.955
expl/Returns Std                              19.8526
expl/Returns Max                              44.3649
expl/Returns Min                               0
expl/Actions Mean                              0.256933
expl/Actions Std                               0.803807
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.955
expl/env_infos/final/reward_dist Mean          0.640629
expl/env_infos/final/reward_dist Std           0.757581
expl/env_infos/final/reward_dist Max           1.5708
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00228094
expl/env_infos/initial/reward_dist Std         0.0058115
expl/env_infos/initial/reward_dist Max         0.0214304
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.423875
expl/env_infos/reward_dist Std                 0.625558
expl/env_infos/reward_dist Max                 1.5708
expl/env_infos/reward_dist Min                 0
eval/num steps total                       65200
eval/num paths total                        1630
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.778473
eval/Rewards Std                               0.709109
eval/Rewards Max                               1.57071
eval/Rewards Min                               0
eval/Returns Mean                             31.1389
eval/Returns Std                              20.3799
eval/Returns Max                              45.2374
eval/Returns Min                               0.000640199
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          31.1389
eval/env_infos/final/reward_dist Mean          1.09876
eval/env_infos/final/reward_dist Std           0.719307
eval/env_infos/final/reward_dist Max           1.57071
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00380597
eval/env_infos/initial/reward_dist Std         0.00602604
eval/env_infos/initial/reward_dist Max         0.0164386
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.778473
eval/env_infos/reward_dist Std                 0.709109
eval/env_infos/reward_dist Max                 1.57071
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00619934
time/evaluation sampling (s)                   3.42602
time/exploration sampling (s)                 18.0123
time/logging (s)                               0.00536659
time/saving (s)                                0.000978782
time/training (s)                              4.44448
time/epoch (s)                                25.8953
time/total (s)                              4141.37
Epoch                                        162
---------------------------------------  -----------------
2023-08-05 01:30:35.415803 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 163 finished
---------------------------------------  -----------------
epoch                                        163
replay_buffer/size                        328000
trainer/QF Loss                                1.64393e+10
trainer/Policy Loss                      -685297
trainer/Raw Policy Loss                  -685297
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                558041
trainer/Q Predictions Std                  90042.5
trainer/Q Predictions Max                 895964
trainer/Q Predictions Min                   1007.36
trainer/Q Targets Mean                    650672
trainer/Q Targets Std                      37408.3
trainer/Q Targets Max                     976976
trainer/Q Targets Min                     350262
trainer/Bellman Errors Mean                    1.64393e+10
trainer/Bellman Errors Std                     3.14844e+10
trainer/Bellman Errors Max                     4.16287e+11
trainer/Bellman Errors Min                   240.25
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      328000
expl/num paths total                        8200
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.414465
expl/Rewards Std                               0.61481
expl/Rewards Max                               1.57029
expl/Rewards Min                               0
expl/Returns Mean                             16.5786
expl/Returns Std                              18.7766
expl/Returns Max                              44.0504
expl/Returns Min                               0
expl/Actions Mean                              0.257246
expl/Actions Std                               0.811534
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.5786
expl/env_infos/final/reward_dist Mean          0.633808
expl/env_infos/final/reward_dist Std           0.762211
expl/env_infos/final/reward_dist Max           1.57029
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000913219
expl/env_infos/initial/reward_dist Std         0.00344234
expl/env_infos/initial/reward_dist Max         0.0169874
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.414465
expl/env_infos/reward_dist Std                 0.61481
expl/env_infos/reward_dist Max                 1.57029
expl/env_infos/reward_dist Min                 0
eval/num steps total                       65600
eval/num paths total                        1640
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.557185
eval/Rewards Std                               0.694825
eval/Rewards Max                               1.57066
eval/Rewards Min                               0
eval/Returns Mean                             22.2874
eval/Returns Std                              22.2766
eval/Returns Max                              45.0944
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.2874
eval/env_infos/final/reward_dist Mean          0.784712
eval/env_infos/final/reward_dist Std           0.784597
eval/env_infos/final/reward_dist Max           1.57066
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000622816
eval/env_infos/initial/reward_dist Std         0.00109756
eval/env_infos/initial/reward_dist Max         0.00348862
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.557185
eval/env_infos/reward_dist Std                 0.694825
eval/env_infos/reward_dist Max                 1.57066
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00588752
time/evaluation sampling (s)                   3.34961
time/exploration sampling (s)                 17.9903
time/logging (s)                               0.00536788
time/saving (s)                                0.000990262
time/training (s)                              4.50549
time/epoch (s)                                25.8576
time/total (s)                              4167.23
Epoch                                        163
---------------------------------------  -----------------
2023-08-05 01:31:00.821178 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 164 finished
---------------------------------------  -----------------
epoch                                        164
replay_buffer/size                        330000
trainer/QF Loss                                1.67497e+10
trainer/Policy Loss                      -696153
trainer/Raw Policy Loss                  -696153
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                569160
trainer/Q Predictions Std                  93823.5
trainer/Q Predictions Max                 998639
trainer/Q Predictions Min                   1331.32
trainer/Q Targets Mean                    662209
trainer/Q Targets Std                      36963.3
trainer/Q Targets Max                          1.02442e+06
trainer/Q Targets Min                     357213
trainer/Bellman Errors Mean                    1.67497e+10
trainer/Bellman Errors Std                     3.21764e+10
trainer/Bellman Errors Max                     4.78489e+11
trainer/Bellman Errors Min                  5634.38
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      330000
expl/num paths total                        8250
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.367796
expl/Rewards Std                               0.602849
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             14.7119
expl/Returns Std                              19.3577
expl/Returns Max                              44.5462
expl/Returns Min                               0
expl/Actions Mean                              0.2482
expl/Actions Std                               0.809119
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          14.7119
expl/env_infos/final/reward_dist Mean          0.563612
expl/env_infos/final/reward_dist Std           0.744912
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00071996
expl/env_infos/initial/reward_dist Std         0.00292449
expl/env_infos/initial/reward_dist Max         0.0149608
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.367796
expl/env_infos/reward_dist Std                 0.602849
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       66000
eval/num paths total                        1650
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.678185
eval/Rewards Std                               0.711801
eval/Rewards Max                               1.57073
eval/Rewards Min                               0
eval/Returns Mean                             27.1274
eval/Returns Std                              22.1465
eval/Returns Max                              46.0931
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          27.1274
eval/env_infos/final/reward_dist Mean          0.941822
eval/env_infos/final/reward_dist Std           0.768995
eval/env_infos/final/reward_dist Max           1.57073
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00670438
eval/env_infos/initial/reward_dist Std         0.00980238
eval/env_infos/initial/reward_dist Max         0.0246651
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.678185
eval/env_infos/reward_dist Std                 0.711801
eval/env_infos/reward_dist Max                 1.57073
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00591513
time/evaluation sampling (s)                   3.38557
time/exploration sampling (s)                 17.5833
time/logging (s)                               0.00540052
time/saving (s)                                0.001021
time/training (s)                              4.42129
time/epoch (s)                                25.4025
time/total (s)                              4192.64
Epoch                                        164
---------------------------------------  -----------------
2023-08-05 01:31:26.382242 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 165 finished
---------------------------------------  -----------------
epoch                                        165
replay_buffer/size                        332000
trainer/QF Loss                                1.6239e+10
trainer/Policy Loss                      -707500
trainer/Raw Policy Loss                  -707500
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                580370
trainer/Q Predictions Std                  88861.5
trainer/Q Predictions Max                      1.00372e+06
trainer/Q Predictions Min                    921.375
trainer/Q Targets Mean                    671796
trainer/Q Targets Std                      37546.1
trainer/Q Targets Max                          1.01088e+06
trainer/Q Targets Min                     368255
trainer/Bellman Errors Mean                    1.6239e+10
trainer/Bellman Errors Std                     3.04273e+10
trainer/Bellman Errors Max                     4.35777e+11
trainer/Bellman Errors Min                   621.879
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      332000
expl/num paths total                        8300
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.33977
expl/Rewards Std                               0.57342
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             13.5908
expl/Returns Std                              18.0921
expl/Returns Max                              43.8418
expl/Returns Min                               0
expl/Actions Mean                              0.258558
expl/Actions Std                               0.81025
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          13.5908
expl/env_infos/final/reward_dist Mean          0.526705
expl/env_infos/final/reward_dist Std           0.731405
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00161617
expl/env_infos/initial/reward_dist Std         0.00464579
expl/env_infos/initial/reward_dist Max         0.0216522
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.33977
expl/env_infos/reward_dist Std                 0.57342
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       66400
eval/num paths total                        1660
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.561588
eval/Rewards Std                               0.690318
eval/Rewards Max                               1.56958
eval/Rewards Min                               0
eval/Returns Mean                             22.4635
eval/Returns Std                              21.976
eval/Returns Max                              45.2882
eval/Returns Min                               0.00286661
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.4635
eval/env_infos/final/reward_dist Mean          0.809099
eval/env_infos/final/reward_dist Std           0.762516
eval/env_infos/final/reward_dist Max           1.56958
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00152883
eval/env_infos/initial/reward_dist Std         0.00383572
eval/env_infos/initial/reward_dist Max         0.0128227
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.561588
eval/env_infos/reward_dist Std                 0.690318
eval/env_infos/reward_dist Max                 1.56958
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00597144
time/evaluation sampling (s)                   3.3936
time/exploration sampling (s)                 17.7244
time/logging (s)                               0.00533894
time/saving (s)                                0.000976873
time/training (s)                              4.42778
time/epoch (s)                                25.558
time/total (s)                              4218.2
Epoch                                        165
---------------------------------------  -----------------
2023-08-05 01:31:51.173365 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 166 finished
---------------------------------------  -----------------
epoch                                        166
replay_buffer/size                        334000
trainer/QF Loss                                1.83113e+10
trainer/Policy Loss                      -719567
trainer/Raw Policy Loss                  -719567
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                586934
trainer/Q Predictions Std                  96898.1
trainer/Q Predictions Max                 961022
trainer/Q Predictions Min                    636.415
trainer/Q Targets Mean                    683854
trainer/Q Targets Std                      39727.8
trainer/Q Targets Max                          1.01581e+06
trainer/Q Targets Min                     368209
trainer/Bellman Errors Mean                    1.83113e+10
trainer/Bellman Errors Std                     3.57588e+10
trainer/Bellman Errors Max                     4.59973e+11
trainer/Bellman Errors Min                  1048.14
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      334000
expl/num paths total                        8350
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.566877
expl/Rewards Std                               0.677369
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             22.6751
expl/Returns Std                              20.2975
expl/Returns Max                              45.4326
expl/Returns Min                               0
expl/Actions Mean                              0.258788
expl/Actions Std                               0.812559
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          22.6751
expl/env_infos/final/reward_dist Mean          0.86074
expl/env_infos/final/reward_dist Std           0.772972
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00232983
expl/env_infos/initial/reward_dist Std         0.00543007
expl/env_infos/initial/reward_dist Max         0.0200016
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.566877
expl/env_infos/reward_dist Std                 0.677369
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       66800
eval/num paths total                        1670
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.447443
eval/Rewards Std                               0.662732
eval/Rewards Max                               1.57056
eval/Rewards Min                               0
eval/Returns Mean                             17.8977
eval/Returns Std                              21.9108
eval/Returns Max                              46.0316
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          17.8977
eval/env_infos/final/reward_dist Mean          0.627969
eval/env_infos/final/reward_dist Std           0.769102
eval/env_infos/final/reward_dist Max           1.57056
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.447443
eval/env_infos/reward_dist Std                 0.662732
eval/env_infos/reward_dist Max                 1.57056
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0060559
time/evaluation sampling (s)                   3.31799
time/exploration sampling (s)                 17.2215
time/logging (s)                               0.00536246
time/saving (s)                                0.000959141
time/training (s)                              4.23634
time/epoch (s)                                24.7882
time/total (s)                              4242.99
Epoch                                        166
---------------------------------------  -----------------
2023-08-05 01:32:16.788226 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 167 finished
---------------------------------------  -----------------
epoch                                        167
replay_buffer/size                        336000
trainer/QF Loss                                1.84621e+10
trainer/Policy Loss                      -732518
trainer/Raw Policy Loss                  -732518
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                597698
trainer/Q Predictions Std                  95865.9
trainer/Q Predictions Max                 939119
trainer/Q Predictions Min                    473.328
trainer/Q Targets Mean                    696712
trainer/Q Targets Std                      38889.7
trainer/Q Targets Max                          1.06084e+06
trainer/Q Targets Min                     382158
trainer/Bellman Errors Mean                    1.84621e+10
trainer/Bellman Errors Std                     3.43428e+10
trainer/Bellman Errors Max                     4.74699e+11
trainer/Bellman Errors Min                  1064.39
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      336000
expl/num paths total                        8400
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.342193
expl/Rewards Std                               0.577493
expl/Rewards Max                               1.57052
expl/Rewards Min                               0
expl/Returns Mean                             13.6877
expl/Returns Std                              18.1059
expl/Returns Max                              44.0666
expl/Returns Min                               0
expl/Actions Mean                              0.263492
expl/Actions Std                               0.804743
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          13.6877
expl/env_infos/final/reward_dist Mean          0.554116
expl/env_infos/final/reward_dist Std           0.739671
expl/env_infos/final/reward_dist Max           1.57052
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00017598
expl/env_infos/initial/reward_dist Std         0.00123186
expl/env_infos/initial/reward_dist Max         0.00879902
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.342193
expl/env_infos/reward_dist Std                 0.577493
expl/env_infos/reward_dist Max                 1.57052
expl/env_infos/reward_dist Min                 0
eval/num steps total                       67200
eval/num paths total                        1680
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.784955
eval/Rewards Std                               0.708391
eval/Rewards Max                               1.56992
eval/Rewards Min                               0
eval/Returns Mean                             31.3982
eval/Returns Std                              20.5552
eval/Returns Max                              45.3372
eval/Returns Min                               0.00137661
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          31.3982
eval/env_infos/final/reward_dist Mean          1.09728
eval/env_infos/final/reward_dist Std           0.718342
eval/env_infos/final/reward_dist Max           1.56992
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00323874
eval/env_infos/initial/reward_dist Std         0.00436551
eval/env_infos/initial/reward_dist Max         0.0121858
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.784955
eval/env_infos/reward_dist Std                 0.708391
eval/env_infos/reward_dist Max                 1.56992
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00597869
time/evaluation sampling (s)                   3.38035
time/exploration sampling (s)                 17.9179
time/logging (s)                               0.00536524
time/saving (s)                                0.000980843
time/training (s)                              4.30144
time/epoch (s)                                25.612
time/total (s)                              4268.6
Epoch                                        167
---------------------------------------  -----------------
2023-08-05 01:32:43.418759 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 168 finished
---------------------------------------  -----------------
epoch                                        168
replay_buffer/size                        338000
trainer/QF Loss                                1.83485e+10
trainer/Policy Loss                      -744986
trainer/Raw Policy Loss                  -744986
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                610045
trainer/Q Predictions Std                  94995.8
trainer/Q Predictions Max                      1.04611e+06
trainer/Q Predictions Min                    678.505
trainer/Q Targets Mean                    707815
trainer/Q Targets Std                      40622.9
trainer/Q Targets Max                          1.03045e+06
trainer/Q Targets Min                     372953
trainer/Bellman Errors Mean                    1.83485e+10
trainer/Bellman Errors Std                     3.39041e+10
trainer/Bellman Errors Max                     4.93829e+11
trainer/Bellman Errors Min                    36
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      338000
expl/num paths total                        8450
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.379758
expl/Rewards Std                               0.607051
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             15.1903
expl/Returns Std                              19.1716
expl/Returns Max                              44.7959
expl/Returns Min                               0
expl/Actions Mean                              0.254466
expl/Actions Std                               0.805787
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          15.1903
expl/env_infos/final/reward_dist Mean          0.566658
expl/env_infos/final/reward_dist Std           0.749225
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00219571
expl/env_infos/initial/reward_dist Std         0.00591959
expl/env_infos/initial/reward_dist Max         0.022612
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.379758
expl/env_infos/reward_dist Std                 0.607051
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       67600
eval/num paths total                        1690
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.44556
eval/Rewards Std                               0.659085
eval/Rewards Max                               1.56993
eval/Rewards Min                               0
eval/Returns Mean                             17.8224
eval/Returns Std                              21.7886
eval/Returns Max                              44.9482
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          17.8224
eval/env_infos/final/reward_dist Mean          0.626929
eval/env_infos/final/reward_dist Std           0.767585
eval/env_infos/final/reward_dist Max           1.56993
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000920994
eval/env_infos/initial/reward_dist Std         0.0017377
eval/env_infos/initial/reward_dist Max         0.00566545
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.44556
eval/env_infos/reward_dist Std                 0.659085
eval/env_infos/reward_dist Max                 1.56993
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0060846
time/evaluation sampling (s)                   3.39409
time/exploration sampling (s)                 18.6373
time/logging (s)                               0.00531212
time/saving (s)                                0.000972987
time/training (s)                              4.58386
time/epoch (s)                                26.6276
time/total (s)                              4295.23
Epoch                                        168
---------------------------------------  -----------------
2023-08-05 01:33:09.501313 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 169 finished
---------------------------------------  -----------------
epoch                                        169
replay_buffer/size                        340000
trainer/QF Loss                                1.85614e+10
trainer/Policy Loss                      -756534
trainer/Raw Policy Loss                  -756534
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                620698
trainer/Q Predictions Std                  96985.8
trainer/Q Predictions Max                      1.25774e+06
trainer/Q Predictions Min                   1601.47
trainer/Q Targets Mean                    719614
trainer/Q Targets Std                      39150.5
trainer/Q Targets Max                          1.28372e+06
trainer/Q Targets Min                     386873
trainer/Bellman Errors Mean                    1.85614e+10
trainer/Bellman Errors Std                     3.24812e+10
trainer/Bellman Errors Max                     5.0186e+11
trainer/Bellman Errors Min                   643.891
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      340000
expl/num paths total                        8500
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.506268
expl/Rewards Std                               0.65704
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             20.2507
expl/Returns Std                              20.0053
expl/Returns Max                              44.0469
expl/Returns Min                               0
expl/Actions Mean                              0.267568
expl/Actions Std                               0.81366
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          20.2507
expl/env_infos/final/reward_dist Mean          0.803434
expl/env_infos/final/reward_dist Std           0.773205
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000305993
expl/env_infos/initial/reward_dist Std         0.0010581
expl/env_infos/initial/reward_dist Max         0.00574188
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.506268
expl/env_infos/reward_dist Std                 0.65704
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       68000
eval/num paths total                        1700
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.555498
eval/Rewards Std                               0.694458
eval/Rewards Max                               1.56952
eval/Rewards Min                               0
eval/Returns Mean                             22.2199
eval/Returns Std                              22.2158
eval/Returns Max                              45.1922
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.2199
eval/env_infos/final/reward_dist Mean          0.78331
eval/env_infos/final/reward_dist Std           0.783316
eval/env_infos/final/reward_dist Max           1.56952
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        6.41916e-05
eval/env_infos/initial/reward_dist Std         0.000192575
eval/env_infos/initial/reward_dist Max         0.000641916
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.555498
eval/env_infos/reward_dist Std                 0.694458
eval/env_infos/reward_dist Max                 1.56952
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00587244
time/evaluation sampling (s)                   3.43407
time/exploration sampling (s)                 18.1531
time/logging (s)                               0.00536752
time/saving (s)                                0.000957679
time/training (s)                              4.48032
time/epoch (s)                                26.0797
time/total (s)                              4321.31
Epoch                                        169
---------------------------------------  -----------------
2023-08-05 01:33:35.194987 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 170 finished
---------------------------------------  -----------------
epoch                                        170
replay_buffer/size                        342000
trainer/QF Loss                                2.02844e+10
trainer/Policy Loss                      -769384
trainer/Raw Policy Loss                  -769384
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                628390
trainer/Q Predictions Std                 101818
trainer/Q Predictions Max                      1.02492e+06
trainer/Q Predictions Min                    847.965
trainer/Q Targets Mean                    731179
trainer/Q Targets Std                      40805.9
trainer/Q Targets Max                          1.14424e+06
trainer/Q Targets Min                     395677
trainer/Bellman Errors Mean                    2.02844e+10
trainer/Bellman Errors Std                     3.88679e+10
trainer/Bellman Errors Max                     5.13078e+11
trainer/Bellman Errors Min                   907.516
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      342000
expl/num paths total                        8550
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.624669
expl/Rewards Std                               0.674939
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             24.9868
expl/Returns Std                              19.4167
expl/Returns Max                              45.7035
expl/Returns Min                               0
expl/Actions Mean                              0.260719
expl/Actions Std                               0.809623
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          24.9868
expl/env_infos/final/reward_dist Mean          0.902022
expl/env_infos/final/reward_dist Std           0.768579
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.002401
expl/env_infos/initial/reward_dist Std         0.00601221
expl/env_infos/initial/reward_dist Max         0.0346648
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.624669
expl/env_infos/reward_dist Std                 0.674939
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       68400
eval/num paths total                        1710
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.33362
eval/Rewards Std                               0.58961
eval/Rewards Max                               1.57065
eval/Rewards Min                               0
eval/Returns Mean                             13.3448
eval/Returns Std                              19.7899
eval/Returns Max                              44.6255
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          13.3448
eval/env_infos/final/reward_dist Mean          0.487502
eval/env_infos/final/reward_dist Std           0.693956
eval/env_infos/final/reward_dist Max           1.57065
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000427354
eval/env_infos/initial/reward_dist Std         0.00128206
eval/env_infos/initial/reward_dist Max         0.00427354
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.33362
eval/env_infos/reward_dist Std                 0.58961
eval/env_infos/reward_dist Max                 1.57065
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00598721
time/evaluation sampling (s)                   3.48398
time/exploration sampling (s)                 17.706
time/logging (s)                               0.00536359
time/saving (s)                                0.00103218
time/training (s)                              4.48831
time/epoch (s)                                25.6906
time/total (s)                              4347
Epoch                                        170
---------------------------------------  -----------------
2023-08-05 01:34:01.728180 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 171 finished
---------------------------------------  -----------------
epoch                                        171
replay_buffer/size                        344000
trainer/QF Loss                                1.92299e+10
trainer/Policy Loss                      -782775
trainer/Raw Policy Loss                  -782775
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                642819
trainer/Q Predictions Std                  97398
trainer/Q Predictions Max                 938374
trainer/Q Predictions Min                   1064.76
trainer/Q Targets Mean                    743202
trainer/Q Targets Std                      44401.7
trainer/Q Targets Max                          1.09344e+06
trainer/Q Targets Min                     400204
trainer/Bellman Errors Mean                    1.92299e+10
trainer/Bellman Errors Std                     3.40701e+10
trainer/Bellman Errors Max                     5.27064e+11
trainer/Bellman Errors Min                  1816.89
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      344000
expl/num paths total                        8600
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.5974
expl/Rewards Std                               0.67838
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             23.896
expl/Returns Std                              20.112
expl/Returns Max                              44.4249
expl/Returns Min                               0
expl/Actions Mean                              0.26075
expl/Actions Std                               0.812466
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          23.896
expl/env_infos/final/reward_dist Mean          0.909952
expl/env_infos/final/reward_dist Std           0.774022
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00238487
expl/env_infos/initial/reward_dist Std         0.00556748
expl/env_infos/initial/reward_dist Max         0.0242645
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.5974
expl/env_infos/reward_dist Std                 0.67838
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       68800
eval/num paths total                        1720
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.663406
eval/Rewards Std                               0.710743
eval/Rewards Max                               1.57062
eval/Rewards Min                               0
eval/Returns Mean                             26.5363
eval/Returns Std                              21.6456
eval/Returns Max                              44.8017
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.5363
eval/env_infos/final/reward_dist Mean          0.941678
eval/env_infos/final/reward_dist Std           0.768389
eval/env_infos/final/reward_dist Max           1.57062
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000218901
eval/env_infos/initial/reward_dist Std         0.000656703
eval/env_infos/initial/reward_dist Max         0.00218901
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.663406
eval/env_infos/reward_dist Std                 0.710743
eval/env_infos/reward_dist Max                 1.57062
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00592373
time/evaluation sampling (s)                   3.46608
time/exploration sampling (s)                 18.8165
time/logging (s)                               0.0053542
time/saving (s)                                0.000987848
time/training (s)                              4.23549
time/epoch (s)                                26.5303
time/total (s)                              4373.54
Epoch                                        171
---------------------------------------  -----------------
2023-08-05 01:34:26.917481 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 172 finished
---------------------------------------  -----------------
epoch                                        172
replay_buffer/size                        346000
trainer/QF Loss                                2.06595e+10
trainer/Policy Loss                      -794676
trainer/Raw Policy Loss                  -794676
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                651936
trainer/Q Predictions Std                 101679
trainer/Q Predictions Max                      1.06366e+06
trainer/Q Predictions Min                    613.087
trainer/Q Targets Mean                    756361
trainer/Q Targets Std                      42369.3
trainer/Q Targets Max                          1.14344e+06
trainer/Q Targets Min                     414109
trainer/Bellman Errors Mean                    2.06595e+10
trainer/Bellman Errors Std                     3.79023e+10
trainer/Bellman Errors Max                     5.55428e+11
trainer/Bellman Errors Min                 11342.2
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      346000
expl/num paths total                        8650
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.443322
expl/Rewards Std                               0.632695
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             17.7329
expl/Returns Std                              19.7032
expl/Returns Max                              44.4763
expl/Returns Min                               0
expl/Actions Mean                              0.252575
expl/Actions Std                               0.796053
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.7329
expl/env_infos/final/reward_dist Mean          0.627699
expl/env_infos/final/reward_dist Std           0.768118
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000958878
expl/env_infos/initial/reward_dist Std         0.00333782
expl/env_infos/initial/reward_dist Max         0.0166989
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.443322
expl/env_infos/reward_dist Std                 0.632695
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       69200
eval/num paths total                        1730
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.810891
eval/Rewards Std                               0.689749
eval/Rewards Max                               1.57054
eval/Rewards Min                               0
eval/Returns Mean                             32.4356
eval/Returns Std                              18.9483
eval/Returns Max                              45.3686
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          32.4356
eval/env_infos/final/reward_dist Mean          1.20709
eval/env_infos/final/reward_dist Std           0.620439
eval/env_infos/final/reward_dist Max           1.57054
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00202378
eval/env_infos/initial/reward_dist Std         0.00535367
eval/env_infos/initial/reward_dist Max         0.0180307
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.810891
eval/env_infos/reward_dist Std                 0.689749
eval/env_infos/reward_dist Max                 1.57054
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00590776
time/evaluation sampling (s)                   3.44962
time/exploration sampling (s)                 17.6824
time/logging (s)                               0.00533997
time/saving (s)                                0.00100333
time/training (s)                              4.042
time/epoch (s)                                25.1863
time/total (s)                              4398.72
Epoch                                        172
---------------------------------------  -----------------
2023-08-05 01:34:52.453695 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 173 finished
---------------------------------------  -----------------
epoch                                        173
replay_buffer/size                        348000
trainer/QF Loss                                2.15217e+10
trainer/Policy Loss                      -808612
trainer/Raw Policy Loss                  -808612
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                661093
trainer/Q Predictions Std                 101849
trainer/Q Predictions Max                      1.01018e+06
trainer/Q Predictions Min                   2252.65
trainer/Q Targets Mean                    767986
trainer/Q Targets Std                      42498.9
trainer/Q Targets Max                          1.05432e+06
trainer/Q Targets Min                     410712
trainer/Bellman Errors Mean                    2.15217e+10
trainer/Bellman Errors Std                     3.6964e+10
trainer/Bellman Errors Max                     5.56936e+11
trainer/Bellman Errors Min                    28.2227
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      348000
expl/num paths total                        8700
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.669342
expl/Rewards Std                               0.690853
expl/Rewards Max                               1.5708
expl/Rewards Min                               0
expl/Returns Mean                             26.7737
expl/Returns Std                              19.488
expl/Returns Max                              45.2153
expl/Returns Min                               0
expl/Actions Mean                              0.263639
expl/Actions Std                               0.79833
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          26.7737
expl/env_infos/final/reward_dist Mean          1.03333
expl/env_infos/final/reward_dist Std           0.741771
expl/env_infos/final/reward_dist Max           1.5708
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00304781
expl/env_infos/initial/reward_dist Std         0.00633064
expl/env_infos/initial/reward_dist Max         0.0216139
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.669342
expl/env_infos/reward_dist Std                 0.690853
expl/env_infos/reward_dist Max                 1.5708
expl/env_infos/reward_dist Min                 0
eval/num steps total                       69600
eval/num paths total                        1740
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.666884
eval/Rewards Std                               0.711477
eval/Rewards Max                               1.5707
eval/Rewards Min                               0
eval/Returns Mean                             26.6754
eval/Returns Std                              21.7716
eval/Returns Max                              44.924
eval/Returns Min                               0.00282522
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.6754
eval/env_infos/final/reward_dist Mean          0.941284
eval/env_infos/final/reward_dist Std           0.768557
eval/env_infos/final/reward_dist Max           1.5707
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.666884
eval/env_infos/reward_dist Std                 0.711477
eval/env_infos/reward_dist Max                 1.5707
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00600833
time/evaluation sampling (s)                   3.37279
time/exploration sampling (s)                 17.94
time/logging (s)                               0.00537892
time/saving (s)                                0.000981544
time/training (s)                              4.20814
time/epoch (s)                                25.5333
time/total (s)                              4424.26
Epoch                                        173
---------------------------------------  -----------------
2023-08-05 01:35:19.266324 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 174 finished
---------------------------------------  -----------------
epoch                                        174
replay_buffer/size                        350000
trainer/QF Loss                                2.28019e+10
trainer/Policy Loss                      -821296
trainer/Raw Policy Loss                  -821296
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                671145
trainer/Q Predictions Std                 106637
trainer/Q Predictions Max                      1.05312e+06
trainer/Q Predictions Min                    629.671
trainer/Q Targets Mean                    780402
trainer/Q Targets Std                      43014.5
trainer/Q Targets Max                          1.16434e+06
trainer/Q Targets Min                     422025
trainer/Bellman Errors Mean                    2.28019e+10
trainer/Bellman Errors Std                     4.20371e+10
trainer/Bellman Errors Max                     5.84225e+11
trainer/Bellman Errors Min                     0.0625
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      350000
expl/num paths total                        8750
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.410833
expl/Rewards Std                               0.609538
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             16.4333
expl/Returns Std                              18.8352
expl/Returns Max                              44.6766
expl/Returns Min                               0
expl/Actions Mean                              0.266548
expl/Actions Std                               0.807414
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          16.4333
expl/env_infos/final/reward_dist Mean          0.640934
expl/env_infos/final/reward_dist Std           0.755247
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000581135
expl/env_infos/initial/reward_dist Std         0.00238489
expl/env_infos/initial/reward_dist Max         0.0141551
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.410833
expl/env_infos/reward_dist Std                 0.609538
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       70000
eval/num paths total                        1750
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.249006
eval/Rewards Std                               0.517443
eval/Rewards Max                               1.56817
eval/Rewards Min                               0
eval/Returns Mean                              9.96022
eval/Returns Std                              17.4934
eval/Returns Max                              44.9648
eval/Returns Min                               0.00236005
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                           9.96022
eval/env_infos/final/reward_dist Mean          0.408309
eval/env_infos/final/reward_dist Std           0.643634
eval/env_infos/final/reward_dist Max           1.56817
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        7.43775e-05
eval/env_infos/initial/reward_dist Std         0.000215787
eval/env_infos/initial/reward_dist Max         0.00072143
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.249006
eval/env_infos/reward_dist Std                 0.517443
eval/env_infos/reward_dist Max                 1.56817
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00593619
time/evaluation sampling (s)                   3.57791
time/exploration sampling (s)                 18.1534
time/logging (s)                               0.00530122
time/saving (s)                                0.000992003
time/training (s)                              5.06604
time/epoch (s)                                26.8095
time/total (s)                              4451.07
Epoch                                        174
---------------------------------------  -----------------
2023-08-05 01:35:45.090550 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 175 finished
---------------------------------------  -----------------
epoch                                        175
replay_buffer/size                        352000
trainer/QF Loss                                2.35258e+10
trainer/Policy Loss                      -834928
trainer/Raw Policy Loss                  -834928
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                682679
trainer/Q Predictions Std                 108725
trainer/Q Predictions Max                      1.04899e+06
trainer/Q Predictions Min                    681.442
trainer/Q Targets Mean                    793336
trainer/Q Targets Std                      42076.7
trainer/Q Targets Max                          1.07965e+06
trainer/Q Targets Min                     431910
trainer/Bellman Errors Mean                    2.35258e+10
trainer/Bellman Errors Std                     4.56276e+10
trainer/Bellman Errors Max                     6.05869e+11
trainer/Bellman Errors Min                    27.5625
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      352000
expl/num paths total                        8800
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.389861
expl/Rewards Std                               0.61058
expl/Rewards Max                               1.57073
expl/Rewards Min                               0
expl/Returns Mean                             15.5944
expl/Returns Std                              19.1472
expl/Returns Max                              43.6902
expl/Returns Min                               0
expl/Actions Mean                              0.264431
expl/Actions Std                               0.809
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          15.5944
expl/env_infos/final/reward_dist Mean          0.587683
expl/env_infos/final/reward_dist Std           0.751193
expl/env_infos/final/reward_dist Max           1.57073
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00169365
expl/env_infos/initial/reward_dist Std         0.00506699
expl/env_infos/initial/reward_dist Max         0.0234937
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.389861
expl/env_infos/reward_dist Std                 0.61058
expl/env_infos/reward_dist Max                 1.57073
expl/env_infos/reward_dist Min                 0
eval/num steps total                       70400
eval/num paths total                        1760
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.521614
eval/Rewards Std                               0.674714
eval/Rewards Max                               1.57044
eval/Rewards Min                               0
eval/Returns Mean                             20.8646
eval/Returns Std                              21.2254
eval/Returns Max                              45.484
eval/Returns Min                               0.000880231
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          20.8646
eval/env_infos/final/reward_dist Mean          0.774854
eval/env_infos/final/reward_dist Std           0.775314
eval/env_infos/final/reward_dist Max           1.57044
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000177193
eval/env_infos/initial/reward_dist Std         0.00053158
eval/env_infos/initial/reward_dist Max         0.00177193
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.521614
eval/env_infos/reward_dist Std                 0.674714
eval/env_infos/reward_dist Max                 1.57044
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00603529
time/evaluation sampling (s)                   3.32337
time/exploration sampling (s)                 18.0573
time/logging (s)                               0.00541543
time/saving (s)                                0.00098313
time/training (s)                              4.42826
time/epoch (s)                                25.8214
time/total (s)                              4476.89
Epoch                                        175
---------------------------------------  -----------------
2023-08-05 01:36:11.054830 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 176 finished
---------------------------------------  -----------------
epoch                                        176
replay_buffer/size                        354000
trainer/QF Loss                                2.44918e+10
trainer/Policy Loss                      -848385
trainer/Raw Policy Loss                  -848385
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                693521
trainer/Q Predictions Std                 110121
trainer/Q Predictions Max                      1.20266e+06
trainer/Q Predictions Min                    523.067
trainer/Q Targets Mean                    806708
trainer/Q Targets Std                      47353.3
trainer/Q Targets Max                          1.19708e+06
trainer/Q Targets Min                     430157
trainer/Bellman Errors Mean                    2.44918e+10
trainer/Bellman Errors Std                     4.66383e+10
trainer/Bellman Errors Max                     6.32725e+11
trainer/Bellman Errors Min                   503.441
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      354000
expl/num paths total                        8850
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.541646
expl/Rewards Std                               0.6643
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             21.6658
expl/Returns Std                              19.6672
expl/Returns Max                              44.7804
expl/Returns Min                               0
expl/Actions Mean                              0.248209
expl/Actions Std                               0.798638
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          21.6658
expl/env_infos/final/reward_dist Mean          0.813989
expl/env_infos/final/reward_dist Std           0.78194
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00166836
expl/env_infos/initial/reward_dist Std         0.00526197
expl/env_infos/initial/reward_dist Max         0.0235769
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.541646
expl/env_infos/reward_dist Std                 0.6643
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       70800
eval/num paths total                        1770
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.560801
eval/Rewards Std                               0.697451
eval/Rewards Max                               1.57062
eval/Rewards Min                               0
eval/Returns Mean                             22.432
eval/Returns Std                              22.4372
eval/Returns Max                              46.6451
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          22.432
eval/env_infos/final/reward_dist Mean          0.784335
eval/env_infos/final/reward_dist Std           0.784336
eval/env_infos/final/reward_dist Max           1.57062
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00144176
eval/env_infos/initial/reward_dist Std         0.00432529
eval/env_infos/initial/reward_dist Max         0.0144176
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.560801
eval/env_infos/reward_dist Std                 0.697451
eval/env_infos/reward_dist Max                 1.57062
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00598649
time/evaluation sampling (s)                   3.43288
time/exploration sampling (s)                 18.0526
time/logging (s)                               0.00535235
time/saving (s)                                0.000971571
time/training (s)                              4.46347
time/epoch (s)                                25.9613
time/total (s)                              4502.86
Epoch                                        176
---------------------------------------  -----------------
2023-08-05 01:36:37.103797 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 177 finished
---------------------------------------  -----------------
epoch                                        177
replay_buffer/size                        356000
trainer/QF Loss                                2.56348e+10
trainer/Policy Loss                      -861171
trainer/Raw Policy Loss                  -861171
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                702996
trainer/Q Predictions Std                 112575
trainer/Q Predictions Max                      1.16528e+06
trainer/Q Predictions Min                    633.607
trainer/Q Targets Mean                    818700
trainer/Q Targets Std                      45701.1
trainer/Q Targets Max                          1.20732e+06
trainer/Q Targets Min                     440312
trainer/Bellman Errors Mean                    2.56348e+10
trainer/Bellman Errors Std                     4.68715e+10
trainer/Bellman Errors Max                     6.60079e+11
trainer/Bellman Errors Min                    10.5625
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      356000
expl/num paths total                        8900
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.485194
expl/Rewards Std                               0.657208
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             19.4078
expl/Returns Std                              20.4623
expl/Returns Max                              46.0132
expl/Returns Min                               0
expl/Actions Mean                              0.252652
expl/Actions Std                               0.799034
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          19.4078
expl/env_infos/final/reward_dist Mean          0.747925
expl/env_infos/final/reward_dist Std           0.778971
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00133746
expl/env_infos/initial/reward_dist Std         0.00450528
expl/env_infos/initial/reward_dist Max         0.0236883
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.485194
expl/env_infos/reward_dist Std                 0.657208
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       71200
eval/num paths total                        1780
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.77426
eval/Rewards Std                               0.710575
eval/Rewards Max                               1.57048
eval/Rewards Min                               0
eval/Returns Mean                             30.9704
eval/Returns Std                              20.2745
eval/Returns Max                              44.6822
eval/Returns Min                               0.000757256
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          30.9704
eval/env_infos/final/reward_dist Mean          1.09747
eval/env_infos/final/reward_dist Std           0.718463
eval/env_infos/final/reward_dist Max           1.57048
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.77426
eval/env_infos/reward_dist Std                 0.710575
eval/env_infos/reward_dist Max                 1.57048
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00596847
time/evaluation sampling (s)                   3.40239
time/exploration sampling (s)                 18.1702
time/logging (s)                               0.00535213
time/saving (s)                                0.000989959
time/training (s)                              4.46118
time/epoch (s)                                26.046
time/total (s)                              4528.9
Epoch                                        177
---------------------------------------  -----------------
2023-08-05 01:37:02.844364 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 178 finished
---------------------------------------  -----------------
epoch                                        178
replay_buffer/size                        358000
trainer/QF Loss                                2.63536e+10
trainer/Policy Loss                      -874942
trainer/Raw Policy Loss                  -874942
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                714317
trainer/Q Predictions Std                 115808
trainer/Q Predictions Max                      1.33035e+06
trainer/Q Predictions Min                    567.366
trainer/Q Targets Mean                    831963
trainer/Q Targets Std                      45902.4
trainer/Q Targets Max                          1.50138e+06
trainer/Q Targets Min                     453632
trainer/Bellman Errors Mean                    2.63536e+10
trainer/Bellman Errors Std                     5.17509e+10
trainer/Bellman Errors Max                     6.71758e+11
trainer/Bellman Errors Min                  1359.77
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      358000
expl/num paths total                        8950
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.435304
expl/Rewards Std                               0.638653
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             17.4121
expl/Returns Std                              19.828
expl/Returns Max                              44.5834
expl/Returns Min                               0
expl/Actions Mean                              0.262916
expl/Actions Std                               0.805756
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          17.4121
expl/env_infos/final/reward_dist Mean          0.690311
expl/env_infos/final/reward_dist Std           0.777864
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00126132
expl/env_infos/initial/reward_dist Std         0.00479585
expl/env_infos/initial/reward_dist Max         0.0273102
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.435304
expl/env_infos/reward_dist Std                 0.638653
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       71600
eval/num paths total                        1790
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.304005
eval/Rewards Std                               0.575637
eval/Rewards Max                               1.56998
eval/Rewards Min                               0
eval/Returns Mean                             12.1602
eval/Returns Std                              18.7449
eval/Returns Max                              44.2185
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          12.1602
eval/env_infos/final/reward_dist Mean          0.469872
eval/env_infos/final/reward_dist Std           0.717743
eval/env_infos/final/reward_dist Max           1.56998
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.304005
eval/env_infos/reward_dist Std                 0.575637
eval/env_infos/reward_dist Max                 1.56998
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00603918
time/evaluation sampling (s)                   3.39036
time/exploration sampling (s)                 17.9407
time/logging (s)                               0.00742219
time/saving (s)                                0.00110183
time/training (s)                              4.39406
time/epoch (s)                                25.7397
time/total (s)                              4554.65
Epoch                                        178
---------------------------------------  -----------------
2023-08-05 01:37:28.468792 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 179 finished
---------------------------------------  -----------------
epoch                                        179
replay_buffer/size                        360000
trainer/QF Loss                                2.58322e+10
trainer/Policy Loss                      -888825
trainer/Raw Policy Loss                  -888825
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                727905
trainer/Q Predictions Std                 112736
trainer/Q Predictions Max                      1.21649e+06
trainer/Q Predictions Min                    711.181
trainer/Q Targets Mean                    845433
trainer/Q Targets Std                      45995.7
trainer/Q Targets Max                          1.27958e+06
trainer/Q Targets Min                     456058
trainer/Bellman Errors Mean                    2.58322e+10
trainer/Bellman Errors Std                     4.61988e+10
trainer/Bellman Errors Max                     6.93102e+11
trainer/Bellman Errors Min                  2437.89
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      360000
expl/num paths total                        9000
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.574469
expl/Rewards Std                               0.66964
expl/Rewards Max                               1.57076
expl/Rewards Min                               0
expl/Returns Mean                             22.9787
expl/Returns Std                              19.3884
expl/Returns Max                              44.3797
expl/Returns Min                               0
expl/Actions Mean                              0.259113
expl/Actions Std                               0.803724
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          22.9787
expl/env_infos/final/reward_dist Mean          0.847158
expl/env_infos/final/reward_dist Std           0.781689
expl/env_infos/final/reward_dist Max           1.57076
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00160105
expl/env_infos/initial/reward_dist Std         0.00454114
expl/env_infos/initial/reward_dist Max         0.0202033
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.574469
expl/env_infos/reward_dist Std                 0.66964
expl/env_infos/reward_dist Max                 1.57076
expl/env_infos/reward_dist Min                 0
eval/num steps total                       72000
eval/num paths total                        1800
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.446594
eval/Rewards Std                               0.660222
eval/Rewards Max                               1.56998
eval/Rewards Min                               0
eval/Returns Mean                             17.8638
eval/Returns Std                              21.8365
eval/Returns Max                              45.2786
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          17.8638
eval/env_infos/final/reward_dist Mean          0.627906
eval/env_infos/final/reward_dist Std           0.767889
eval/env_infos/final/reward_dist Max           1.56998
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00174641
eval/env_infos/initial/reward_dist Std         0.00521854
eval/env_infos/initial/reward_dist Max         0.0174019
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.446594
eval/env_infos/reward_dist Std                 0.660222
eval/env_infos/reward_dist Max                 1.56998
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00595175
time/evaluation sampling (s)                   3.39345
time/exploration sampling (s)                 18.0007
time/logging (s)                               0.00536944
time/saving (s)                                0.000991604
time/training (s)                              4.21118
time/epoch (s)                                25.6177
time/total (s)                              4580.27
Epoch                                        179
---------------------------------------  -----------------
2023-08-05 01:37:54.223694 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 180 finished
---------------------------------------  -----------------
epoch                                        180
replay_buffer/size                        362000
trainer/QF Loss                                2.63456e+10
trainer/Policy Loss                      -904252
trainer/Raw Policy Loss                  -904252
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                740532
trainer/Q Predictions Std                 115021
trainer/Q Predictions Max                      1.24999e+06
trainer/Q Predictions Min                    541.207
trainer/Q Targets Mean                    858921
trainer/Q Targets Std                      46346.9
trainer/Q Targets Max                          1.31623e+06
trainer/Q Targets Min                     478516
trainer/Bellman Errors Mean                    2.63456e+10
trainer/Bellman Errors Std                     4.88189e+10
trainer/Bellman Errors Max                     7.1989e+11
trainer/Bellman Errors Min                   114.223
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      362000
expl/num paths total                        9050
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.39149
expl/Rewards Std                               0.610574
expl/Rewards Max                               1.57074
expl/Rewards Min                               0
expl/Returns Mean                             15.6596
expl/Returns Std                              19.2338
expl/Returns Max                              44.96
expl/Returns Min                               0
expl/Actions Mean                              0.275089
expl/Actions Std                               0.792573
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          15.6596
expl/env_infos/final/reward_dist Mean          0.593054
expl/env_infos/final/reward_dist Std           0.754998
expl/env_infos/final/reward_dist Max           1.57074
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00131621
expl/env_infos/initial/reward_dist Std         0.00410952
expl/env_infos/initial/reward_dist Max         0.0232978
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.39149
expl/env_infos/reward_dist Std                 0.610574
expl/env_infos/reward_dist Max                 1.57074
expl/env_infos/reward_dist Min                 0
eval/num steps total                       72400
eval/num paths total                        1810
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.11372
eval/Rewards Std                               0.384192
eval/Rewards Max                               1.56889
eval/Rewards Min                               0
eval/Returns Mean                              4.54881
eval/Returns Std                              13.5071
eval/Returns Max                              45.0688
eval/Returns Min                               0.000592514
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                           4.54881
eval/env_infos/final/reward_dist Mean          0.158476
eval/env_infos/final/reward_dist Std           0.470161
eval/env_infos/final/reward_dist Max           1.56889
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.000307158
eval/env_infos/initial/reward_dist Std         0.000921474
eval/env_infos/initial/reward_dist Max         0.00307158
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.11372
eval/env_infos/reward_dist Std                 0.384192
eval/env_infos/reward_dist Max                 1.56889
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00592902
time/evaluation sampling (s)                   3.47334
time/exploration sampling (s)                 18.0546
time/logging (s)                               0.00544134
time/saving (s)                                0.00098114
time/training (s)                              4.21156
time/epoch (s)                                25.7519
time/total (s)                              4606.02
Epoch                                        180
---------------------------------------  -----------------
2023-08-05 01:38:20.763709 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 181 finished
---------------------------------------  -----------------
epoch                                        181
replay_buffer/size                        364000
trainer/QF Loss                                2.69011e+10
trainer/Policy Loss                      -916870
trainer/Raw Policy Loss                  -916870
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                751941
trainer/Q Predictions Std                 115018
trainer/Q Predictions Max                      1.12007e+06
trainer/Q Predictions Min                  31296.9
trainer/Q Targets Mean                    871626
trainer/Q Targets Std                      46456.4
trainer/Q Targets Max                          1.26292e+06
trainer/Q Targets Min                     463693
trainer/Bellman Errors Mean                    2.69011e+10
trainer/Bellman Errors Std                     4.67859e+10
trainer/Bellman Errors Max                     6.79681e+11
trainer/Bellman Errors Min                   791.016
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      364000
expl/num paths total                        9100
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.535321
expl/Rewards Std                               0.644272
expl/Rewards Max                               1.57078
expl/Rewards Min                               0
expl/Returns Mean                             21.4129
expl/Returns Std                              18.7064
expl/Returns Max                              44.311
expl/Returns Min                               0
expl/Actions Mean                              0.263099
expl/Actions Std                               0.808398
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          21.4129
expl/env_infos/final/reward_dist Mean          0.812051
expl/env_infos/final/reward_dist Std           0.753946
expl/env_infos/final/reward_dist Max           1.57078
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00172163
expl/env_infos/initial/reward_dist Std         0.00477065
expl/env_infos/initial/reward_dist Max         0.0204704
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.535321
expl/env_infos/reward_dist Std                 0.644272
expl/env_infos/reward_dist Max                 1.57078
expl/env_infos/reward_dist Min                 0
eval/num steps total                       72800
eval/num paths total                        1820
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.233261
eval/Rewards Std                               0.518181
eval/Rewards Max                               1.56783
eval/Rewards Min                               0
eval/Returns Mean                              9.33043
eval/Returns Std                              17.9742
eval/Returns Max                              45.3091
eval/Returns Min                               0.00105273
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                           9.33043
eval/env_infos/final/reward_dist Mean          0.336705
eval/env_infos/final/reward_dist Std           0.619255
eval/env_infos/final/reward_dist Max           1.56783
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00208939
eval/env_infos/initial/reward_dist Std         0.00514261
eval/env_infos/initial/reward_dist Max         0.0171493
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.233261
eval/env_infos/reward_dist Std                 0.518181
eval/env_infos/reward_dist Max                 1.56783
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.0060153
time/evaluation sampling (s)                   3.47469
time/exploration sampling (s)                 18.5323
time/logging (s)                               0.00742684
time/saving (s)                                0.00109132
time/training (s)                              4.51754
time/epoch (s)                                26.5391
time/total (s)                              4632.56
Epoch                                        181
---------------------------------------  -----------------
2023-08-05 01:38:46.205987 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 182 finished
---------------------------------------  -----------------
epoch                                        182
replay_buffer/size                        366000
trainer/QF Loss                                2.91385e+10
trainer/Policy Loss                      -931384
trainer/Raw Policy Loss                  -931384
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                761126
trainer/Q Predictions Std                 119931
trainer/Q Predictions Max                      1.17053e+06
trainer/Q Predictions Min                   1076.49
trainer/Q Targets Mean                    885234
trainer/Q Targets Std                      48365.7
trainer/Q Targets Max                          1.33528e+06
trainer/Q Targets Min                     472229
trainer/Bellman Errors Mean                    2.91385e+10
trainer/Bellman Errors Std                     5.41462e+10
trainer/Bellman Errors Max                     8.563e+11
trainer/Bellman Errors Min                    73.3164
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      366000
expl/num paths total                        9150
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.370389
expl/Rewards Std                               0.602448
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             14.8156
expl/Returns Std                              19.3923
expl/Returns Max                              44.4767
expl/Returns Min                               0
expl/Actions Mean                              0.260349
expl/Actions Std                               0.808107
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          14.8156
expl/env_infos/final/reward_dist Mean          0.539451
expl/env_infos/final/reward_dist Std           0.731369
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00140708
expl/env_infos/initial/reward_dist Std         0.00513724
expl/env_infos/initial/reward_dist Max         0.0256084
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.370389
expl/env_infos/reward_dist Std                 0.602448
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       73200
eval/num paths total                        1830
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.670805
eval/Rewards Std                               0.711976
eval/Rewards Max                               1.57068
eval/Rewards Min                               0
eval/Returns Mean                             26.8322
eval/Returns Std                              21.8898
eval/Returns Max                              45.0545
eval/Returns Min                               0.00929958
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          26.8322
eval/env_infos/final/reward_dist Mean          0.941681
eval/env_infos/final/reward_dist Std           0.76888
eval/env_infos/final/reward_dist Max           1.57068
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0
eval/env_infos/initial/reward_dist Std         0
eval/env_infos/initial/reward_dist Max         0
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.670805
eval/env_infos/reward_dist Std                 0.711976
eval/env_infos/reward_dist Max                 1.57068
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00602026
time/evaluation sampling (s)                   3.40423
time/exploration sampling (s)                 17.4832
time/logging (s)                               0.00537773
time/saving (s)                                0.000975708
time/training (s)                              4.53565
time/epoch (s)                                25.4354
time/total (s)                              4658
Epoch                                        182
---------------------------------------  -----------------
2023-08-05 01:39:12.479731 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 183 finished
---------------------------------------  -----------------
epoch                                        183
replay_buffer/size                        368000
trainer/QF Loss                                3.05747e+10
trainer/Policy Loss                      -945746
trainer/Raw Policy Loss                  -945746
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                770277
trainer/Q Predictions Std                 120534
trainer/Q Predictions Max                      1.39743e+06
trainer/Q Predictions Min                    534.763
trainer/Q Targets Mean                    899591
trainer/Q Targets Std                      53523.5
trainer/Q Targets Max                          1.50472e+06
trainer/Q Targets Min                     479090
trainer/Bellman Errors Mean                    3.05747e+10
trainer/Bellman Errors Std                     5.304e+10
trainer/Bellman Errors Max                     8.02468e+11
trainer/Bellman Errors Min                    58.1406
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      368000
expl/num paths total                        9200
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.539764
expl/Rewards Std                               0.665749
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             21.5905
expl/Returns Std                              20.0582
expl/Returns Max                              44.4063
expl/Returns Min                               0
expl/Actions Mean                              0.255259
expl/Actions Std                               0.813553
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          21.5905
expl/env_infos/final/reward_dist Mean          0.810451
expl/env_infos/final/reward_dist Std           0.778973
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00107696
expl/env_infos/initial/reward_dist Std         0.00318806
expl/env_infos/initial/reward_dist Max         0.019035
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.539764
expl/env_infos/reward_dist Std                 0.665749
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       73600
eval/num paths total                        1840
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.894126
eval/Rewards Std                               0.689698
eval/Rewards Max                               1.57075
eval/Rewards Min                               0
eval/Returns Mean                             35.7651
eval/Returns Std                              17.8844
eval/Returns Max                              45.47
eval/Returns Min                               0.00422155
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          35.7651
eval/env_infos/final/reward_dist Mean          1.25556
eval/env_infos/final/reward_dist Std           0.627779
eval/env_infos/final/reward_dist Max           1.57075
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00363319
eval/env_infos/initial/reward_dist Std         0.00709279
eval/env_infos/initial/reward_dist Max         0.0223659
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.894126
eval/env_infos/reward_dist Std                 0.689698
eval/env_infos/reward_dist Max                 1.57075
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00607731
time/evaluation sampling (s)                   3.45832
time/exploration sampling (s)                 18.294
time/logging (s)                               0.00549715
time/saving (s)                                0.000976152
time/training (s)                              4.50605
time/epoch (s)                                26.2709
time/total (s)                              4684.27
Epoch                                        183
---------------------------------------  -----------------
2023-08-05 01:39:39.459310 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 184 finished
---------------------------------------  -----------------
epoch                                        184
replay_buffer/size                        370000
trainer/QF Loss                                2.96963e+10
trainer/Policy Loss                      -960300
trainer/Raw Policy Loss                  -960300
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                787248
trainer/Q Predictions Std                 121250
trainer/Q Predictions Max                      1.24201e+06
trainer/Q Predictions Min                    834.316
trainer/Q Targets Mean                    912085
trainer/Q Targets Std                      52870.6
trainer/Q Targets Max                          1.36095e+06
trainer/Q Targets Min                     476275
trainer/Bellman Errors Mean                    2.96963e+10
trainer/Bellman Errors Std                     5.53072e+10
trainer/Bellman Errors Max                     8.2014e+11
trainer/Bellman Errors Min                   236.391
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      370000
expl/num paths total                        9250
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.38156
expl/Rewards Std                               0.611023
expl/Rewards Max                               1.57054
expl/Rewards Min                               0
expl/Returns Mean                             15.2624
expl/Returns Std                              19.4811
expl/Returns Max                              44.4088
expl/Returns Min                               0
expl/Actions Mean                              0.266317
expl/Actions Std                               0.80211
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          15.2624
expl/env_infos/final/reward_dist Mean          0.569204
expl/env_infos/final/reward_dist Std           0.747258
expl/env_infos/final/reward_dist Max           1.57054
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00121777
expl/env_infos/initial/reward_dist Std         0.00353913
expl/env_infos/initial/reward_dist Max         0.0146722
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.38156
expl/env_infos/reward_dist Std                 0.611023
expl/env_infos/reward_dist Max                 1.57054
expl/env_infos/reward_dist Min                 0
eval/num steps total                       74000
eval/num paths total                        1850
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.989991
eval/Rewards Std                               0.650608
eval/Rewards Max                               1.57075
eval/Rewards Min                               0
eval/Returns Mean                             39.5997
eval/Returns Std                              13.3561
eval/Returns Max                              45.3199
eval/Returns Min                               0.00228262
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          39.5997
eval/env_infos/final/reward_dist Mean          1.41183
eval/env_infos/final/reward_dist Std           0.47061
eval/env_infos/final/reward_dist Max           1.57075
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00478088
eval/env_infos/initial/reward_dist Std         0.00856718
eval/env_infos/initial/reward_dist Max         0.0219301
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.989991
eval/env_infos/reward_dist Std                 0.650608
eval/env_infos/reward_dist Max                 1.57075
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00597405
time/evaluation sampling (s)                   3.4615
time/exploration sampling (s)                 18.3758
time/logging (s)                               0.00787022
time/saving (s)                                0.00125032
time/training (s)                              5.12643
time/epoch (s)                                26.9788
time/total (s)                              4711.25
Epoch                                        184
---------------------------------------  -----------------
2023-08-05 01:40:05.114818 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 185 finished
---------------------------------------  -----------------
epoch                                        185
replay_buffer/size                        372000
trainer/QF Loss                                3.01369e+10
trainer/Policy Loss                      -974682
trainer/Raw Policy Loss                  -974682
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                798832
trainer/Q Predictions Std                 122780
trainer/Q Predictions Max                      1.32297e+06
trainer/Q Predictions Min                    937.036
trainer/Q Targets Mean                    924722
trainer/Q Targets Std                      51838.1
trainer/Q Targets Max                          1.36196e+06
trainer/Q Targets Min                     485030
trainer/Bellman Errors Mean                    3.01369e+10
trainer/Bellman Errors Std                     5.28698e+10
trainer/Bellman Errors Max                     8.28e+11
trainer/Bellman Errors Min                  1036.04
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      372000
expl/num paths total                        9300
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.555405
expl/Rewards Std                               0.670129
expl/Rewards Max                               1.57079
expl/Rewards Min                               0
expl/Returns Mean                             22.2162
expl/Returns Std                              20.0975
expl/Returns Max                              43.8465
expl/Returns Min                               0
expl/Actions Mean                              0.273124
expl/Actions Std                               0.807678
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          22.2162
expl/env_infos/final/reward_dist Mean          0.866851
expl/env_infos/final/reward_dist Std           0.769204
expl/env_infos/final/reward_dist Max           1.57079
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.00117799
expl/env_infos/initial/reward_dist Std         0.00329495
expl/env_infos/initial/reward_dist Max         0.0165154
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.555405
expl/env_infos/reward_dist Std                 0.670129
expl/env_infos/reward_dist Max                 1.57079
expl/env_infos/reward_dist Min                 0
eval/num steps total                       74400
eval/num paths total                        1860
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.493852
eval/Rewards Std                               0.661353
eval/Rewards Max                               1.57079
eval/Rewards Min                               0
eval/Returns Mean                             19.7541
eval/Returns Std                              20.9105
eval/Returns Max                              44.7642
eval/Returns Min                               0.00517677
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          19.7541
eval/env_infos/final/reward_dist Mean          0.77233
eval/env_infos/final/reward_dist Std           0.772867
eval/env_infos/final/reward_dist Max           1.57079
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00125008
eval/env_infos/initial/reward_dist Std         0.00375025
eval/env_infos/initial/reward_dist Max         0.0125008
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.493852
eval/env_infos/reward_dist Std                 0.661353
eval/env_infos/reward_dist Max                 1.57079
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00590839
time/evaluation sampling (s)                   3.46096
time/exploration sampling (s)                 18.2348
time/logging (s)                               0.00536859
time/saving (s)                                0.000967935
time/training (s)                              3.94016
time/epoch (s)                                25.6481
time/total (s)                              4736.9
Epoch                                        185
---------------------------------------  -----------------
2023-08-05 01:40:30.083176 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 186 finished
---------------------------------------  -----------------
epoch                                        186
replay_buffer/size                        374000
trainer/QF Loss                                3.32807e+10
trainer/Policy Loss                      -990980
trainer/Raw Policy Loss                  -990980
trainer/Preactivation Policy Loss              0
trainer/Q Predictions Mean                809773
trainer/Q Predictions Std                 129130
trainer/Q Predictions Max                      1.31647e+06
trainer/Q Predictions Min                    686.017
trainer/Q Targets Mean                    940924
trainer/Q Targets Std                      52753.2
trainer/Q Targets Max                          1.27633e+06
trainer/Q Targets Min                     501657
trainer/Bellman Errors Mean                    3.32807e+10
trainer/Bellman Errors Std                     6.252e+10
trainer/Bellman Errors Max                     8.59318e+11
trainer/Bellman Errors Min                 15860.3
trainer/Policy Action Mean                     0.333333
trainer/Policy Action Std                      0.942809
trainer/Policy Action Max                      1
trainer/Policy Action Min                     -1
expl/num steps total                      374000
expl/num paths total                        9350
expl/path length Mean                         40
expl/path length Std                           0
expl/path length Max                          40
expl/path length Min                          40
expl/Rewards Mean                              0.35186
expl/Rewards Std                               0.572497
expl/Rewards Max                               1.57077
expl/Rewards Min                               0
expl/Returns Mean                             14.0744
expl/Returns Std                              17.8351
expl/Returns Max                              44.5107
expl/Returns Min                               0
expl/Actions Mean                              0.258428
expl/Actions Std                               0.803654
expl/Actions Max                               1
expl/Actions Min                              -1
expl/Num Paths                                50
expl/Average Returns                          14.0744
expl/env_infos/final/reward_dist Mean          0.549036
expl/env_infos/final/reward_dist Std           0.717257
expl/env_infos/final/reward_dist Max           1.57077
expl/env_infos/final/reward_dist Min           0
expl/env_infos/initial/reward_dist Mean        0.000858057
expl/env_infos/initial/reward_dist Std         0.00346618
expl/env_infos/initial/reward_dist Max         0.021424
expl/env_infos/initial/reward_dist Min         0
expl/env_infos/reward_dist Mean                0.35186
expl/env_infos/reward_dist Std                 0.572497
expl/env_infos/reward_dist Max                 1.57077
expl/env_infos/reward_dist Min                 0
eval/num steps total                       74800
eval/num paths total                        1870
eval/path length Mean                         40
eval/path length Std                           0
eval/path length Max                          40
eval/path length Min                          40
eval/Rewards Mean                              0.538966
eval/Rewards Std                               0.681743
eval/Rewards Max                               1.57061
eval/Rewards Min                               0
eval/Returns Mean                             21.5586
eval/Returns Std                              21.7726
eval/Returns Max                              46.0434
eval/Returns Min                               0
eval/Actions Mean                              0.333333
eval/Actions Std                               0.942809
eval/Actions Max                               1
eval/Actions Min                              -1
eval/Num Paths                                10
eval/Average Returns                          21.5586
eval/env_infos/final/reward_dist Mean          0.775937
eval/env_infos/final/reward_dist Std           0.776325
eval/env_infos/final/reward_dist Max           1.57061
eval/env_infos/final/reward_dist Min           0
eval/env_infos/initial/reward_dist Mean        0.00322233
eval/env_infos/initial/reward_dist Std         0.00699517
eval/env_infos/initial/reward_dist Max         0.0234713
eval/env_infos/initial/reward_dist Min         0
eval/env_infos/reward_dist Mean                0.538966
eval/env_infos/reward_dist Std                 0.681743
eval/env_infos/reward_dist Max                 1.57061
eval/env_infos/reward_dist Min                 0
time/data storing (s)                          0.00592969
time/evaluation sampling (s)                   3.31974
time/exploration sampling (s)                 17.5609
time/logging (s)                               0.00536593
time/saving (s)                                0.00100168
time/training (s)                              4.07236
time/epoch (s)                                24.9653
time/total (s)                              4761.87
Epoch                                        186
---------------------------------------  -----------------
2023-08-05 01:40:56.211087 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 187 finished
---------------------------------------  ----------------
epoch                                       187
replay_buffer/size                       376000
trainer/QF Loss                               3.4215e+10
trainer/Policy Loss                          -1.00494e+06
trainer/Raw Policy Loss                      -1.00494e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               819991
trainer/Q Predictions Std                130397
trainer/Q Predictions Max                     1.29641e+06
trainer/Q Predictions Min                   756.103
trainer/Q Targets Mean                   954267
trainer/Q Targets Std                     52432.2
trainer/Q Targets Max                         1.26294e+06
trainer/Q Targets Min                    522793
trainer/Bellman Errors Mean                   3.4215e+10
trainer/Bellman Errors Std                    6.31029e+10
trainer/Bellman Errors Max                    8.97501e+11
trainer/Bellman Errors Min                 1024
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     376000
expl/num paths total                       9400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.319354
expl/Rewards Std                              0.570286
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            12.7742
expl/Returns Std                             18.4567
expl/Returns Max                             45.3744
expl/Returns Min                              0
expl/Actions Mean                             0.265052
expl/Actions Std                              0.81679
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.7742
expl/env_infos/final/reward_dist Mean         0.470996
expl/env_infos/final/reward_dist Std          0.707652
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00156208
expl/env_infos/initial/reward_dist Std        0.00528577
expl/env_infos/initial/reward_dist Max        0.0245233
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.319354
expl/env_infos/reward_dist Std                0.570286
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      75200
eval/num paths total                       1880
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.220045
eval/Rewards Std                              0.512342
eval/Rewards Max                              1.57014
eval/Rewards Min                              0
eval/Returns Mean                             8.80182
eval/Returns Std                             17.5734
eval/Returns Max                             45.0299
eval/Returns Min                              0.00673662
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          8.80182
eval/env_infos/final/reward_dist Mean         0.313844
eval/env_infos/final/reward_dist Std          0.627632
eval/env_infos/final/reward_dist Max          1.57014
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       8.02298e-05
eval/env_infos/initial/reward_dist Std        0.000240689
eval/env_infos/initial/reward_dist Max        0.000802298
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.220045
eval/env_infos/reward_dist Std                0.512342
eval/env_infos/reward_dist Max                1.57014
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593342
time/evaluation sampling (s)                  3.40104
time/exploration sampling (s)                18.2233
time/logging (s)                              0.00541358
time/saving (s)                               0.00102989
time/training (s)                             4.48813
time/epoch (s)                               26.1248
time/total (s)                             4788
Epoch                                       187
---------------------------------------  ----------------
2023-08-05 01:41:22.373232 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 188 finished
---------------------------------------  ----------------
epoch                                       188
replay_buffer/size                       378000
trainer/QF Loss                               3.40708e+10
trainer/Policy Loss                          -1.02148e+06
trainer/Raw Policy Loss                      -1.02148e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               837395
trainer/Q Predictions Std                130844
trainer/Q Predictions Max                     1.30912e+06
trainer/Q Predictions Min                  1531.25
trainer/Q Targets Mean                   971498
trainer/Q Targets Std                     52790.1
trainer/Q Targets Max                         1.44367e+06
trainer/Q Targets Min                    590616
trainer/Bellman Errors Mean                   3.40708e+10
trainer/Bellman Errors Std                    6.02184e+10
trainer/Bellman Errors Max                    8.81651e+11
trainer/Bellman Errors Min                 1229.38
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     378000
expl/num paths total                       9450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.335602
expl/Rewards Std                              0.581553
expl/Rewards Max                              1.57073
expl/Rewards Min                              0
expl/Returns Mean                            13.4241
expl/Returns Std                             18.482
expl/Returns Max                             44.6848
expl/Returns Min                              0
expl/Actions Mean                             0.273186
expl/Actions Std                              0.796241
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.4241
expl/env_infos/final/reward_dist Mean         0.530297
expl/env_infos/final/reward_dist Std          0.738417
expl/env_infos/final/reward_dist Max          1.57073
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000923768
expl/env_infos/initial/reward_dist Std        0.00357059
expl/env_infos/initial/reward_dist Max        0.0220318
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.335602
expl/env_infos/reward_dist Std                0.581553
expl/env_infos/reward_dist Max                1.57073
expl/env_infos/reward_dist Min                0
eval/num steps total                      75600
eval/num paths total                       1890
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.670482
eval/Rewards Std                              0.711145
eval/Rewards Max                              1.57023
eval/Rewards Min                              0
eval/Returns Mean                            26.8193
eval/Returns Std                             21.8916
eval/Returns Max                             45.4951
eval/Returns Min                              0.000324541
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.8193
eval/env_infos/final/reward_dist Mean         0.941339
eval/env_infos/final/reward_dist Std          0.768601
eval/env_infos/final/reward_dist Max          1.57023
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00519536
eval/env_infos/initial/reward_dist Std        0.00813228
eval/env_infos/initial/reward_dist Max        0.0212421
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.670482
eval/env_infos/reward_dist Std                0.711145
eval/env_infos/reward_dist Max                1.57023
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595466
time/evaluation sampling (s)                  3.41746
time/exploration sampling (s)                18.3439
time/logging (s)                              0.00535932
time/saving (s)                               0.000950362
time/training (s)                             4.38552
time/epoch (s)                               26.1591
time/total (s)                             4814.16
Epoch                                       188
---------------------------------------  ----------------
2023-08-05 01:41:47.880832 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 189 finished
---------------------------------------  ----------------
epoch                                       189
replay_buffer/size                       380000
trainer/QF Loss                               3.69563e+10
trainer/Policy Loss                          -1.03427e+06
trainer/Raw Policy Loss                      -1.03427e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               844733
trainer/Q Predictions Std                135414
trainer/Q Predictions Max                     1.27906e+06
trainer/Q Predictions Min                   957.109
trainer/Q Targets Mean                   983008
trainer/Q Targets Std                     54970.3
trainer/Q Targets Max                         1.38933e+06
trainer/Q Targets Min                    523311
trainer/Bellman Errors Mean                   3.69563e+10
trainer/Bellman Errors Std                    6.9495e+10
trainer/Bellman Errors Max                    9.50731e+11
trainer/Bellman Errors Min                 1458.29
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     380000
expl/num paths total                       9500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.600511
expl/Rewards Std                              0.677876
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            24.0204
expl/Returns Std                             19.4384
expl/Returns Max                             44.6304
expl/Returns Min                              0
expl/Actions Mean                             0.273967
expl/Actions Std                              0.802704
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.0204
expl/env_infos/final/reward_dist Mean         0.908207
expl/env_infos/final/reward_dist Std          0.772817
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00123861
expl/env_infos/initial/reward_dist Std        0.00404819
expl/env_infos/initial/reward_dist Max        0.0174756
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.600511
expl/env_infos/reward_dist Std                0.677876
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      76000
eval/num paths total                       1900
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.110776
eval/Rewards Std                              0.375715
eval/Rewards Max                              1.56656
eval/Rewards Min                              0
eval/Returns Mean                             4.43106
eval/Returns Std                             12.9381
eval/Returns Max                             43.235
eval/Returns Min                              0.000166764
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          4.43106
eval/env_infos/final/reward_dist Mean         0.169135
eval/env_infos/final/reward_dist Std          0.467281
eval/env_infos/final/reward_dist Max          1.56653
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       1.66764e-05
eval/env_infos/initial/reward_dist Std        5.00291e-05
eval/env_infos/initial/reward_dist Max        0.000166764
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.110776
eval/env_infos/reward_dist Std                0.375715
eval/env_infos/reward_dist Max                1.56656
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0059979
time/evaluation sampling (s)                  3.3827
time/exploration sampling (s)                17.7885
time/logging (s)                              0.0052926
time/saving (s)                               0.00101253
time/training (s)                             4.32088
time/epoch (s)                               25.5044
time/total (s)                             4839.66
Epoch                                       189
---------------------------------------  ----------------
2023-08-05 01:42:13.442287 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 190 finished
---------------------------------------  ----------------
epoch                                       190
replay_buffer/size                       382000
trainer/QF Loss                               3.80128e+10
trainer/Policy Loss                          -1.05265e+06
trainer/Raw Policy Loss                      -1.05265e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               857441
trainer/Q Predictions Std                136994
trainer/Q Predictions Max                     1.31964e+06
trainer/Q Predictions Min                  1125.65
trainer/Q Targets Mean                        1.00115e+06
trainer/Q Targets Std                     55973.9
trainer/Q Targets Max                         1.39871e+06
trainer/Q Targets Min                    532052
trainer/Bellman Errors Mean                   3.80128e+10
trainer/Bellman Errors Std                    6.98576e+10
trainer/Bellman Errors Max                    9.8207e+11
trainer/Bellman Errors Min                 7119.14
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     382000
expl/num paths total                       9550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.472593
expl/Rewards Std                              0.642589
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            18.9037
expl/Returns Std                             19.5986
expl/Returns Max                             45.3851
expl/Returns Min                              0
expl/Actions Mean                             0.258811
expl/Actions Std                              0.809557
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.9037
expl/env_infos/final/reward_dist Mean         0.71618
expl/env_infos/final/reward_dist Std          0.776184
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00120636
expl/env_infos/initial/reward_dist Std        0.00388482
expl/env_infos/initial/reward_dist Max        0.0165952
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.472593
expl/env_infos/reward_dist Std                0.642589
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      76400
eval/num paths total                       1910
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.622178
eval/Rewards Std                              0.694428
eval/Rewards Max                              1.57065
eval/Rewards Min                              0
eval/Returns Mean                            24.8871
eval/Returns Std                             21.0236
eval/Returns Max                             44.784
eval/Returns Min                              0.000209678
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.8871
eval/env_infos/final/reward_dist Mean         0.93294
eval/env_infos/final/reward_dist Std          0.762206
eval/env_infos/final/reward_dist Max          1.57065
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.622178
eval/env_infos/reward_dist Std                0.694428
eval/env_infos/reward_dist Max                1.57065
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00603761
time/evaluation sampling (s)                  3.45538
time/exploration sampling (s)                17.9613
time/logging (s)                              0.00542539
time/saving (s)                               0.00101041
time/training (s)                             4.12935
time/epoch (s)                               25.5586
time/total (s)                             4865.22
Epoch                                       190
---------------------------------------  ----------------
2023-08-05 01:42:39.889534 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 191 finished
---------------------------------------  ----------------
epoch                                       191
replay_buffer/size                       384000
trainer/QF Loss                               3.9114e+10
trainer/Policy Loss                          -1.06687e+06
trainer/Raw Policy Loss                      -1.06687e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               868059
trainer/Q Predictions Std                138596
trainer/Q Predictions Max                     1.44693e+06
trainer/Q Predictions Min                  2030.45
trainer/Q Targets Mean                        1.0135e+06
trainer/Q Targets Std                     58552.2
trainer/Q Targets Max                         1.53353e+06
trainer/Q Targets Min                    546150
trainer/Bellman Errors Mean                   3.9114e+10
trainer/Bellman Errors Std                    6.661e+10
trainer/Bellman Errors Max                    9.8547e+11
trainer/Bellman Errors Min                  412.598
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     384000
expl/num paths total                       9600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.41263
expl/Rewards Std                              0.623507
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            16.5052
expl/Returns Std                             19.374
expl/Returns Max                             43.6283
expl/Returns Min                              0
expl/Actions Mean                             0.253877
expl/Actions Std                              0.804686
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.5052
expl/env_infos/final/reward_dist Mean         0.625944
expl/env_infos/final/reward_dist Std          0.766551
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00107853
expl/env_infos/initial/reward_dist Std        0.00312758
expl/env_infos/initial/reward_dist Max        0.0139237
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.41263
expl/env_infos/reward_dist Std                0.623507
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      76800
eval/num paths total                       1920
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.223745
eval/Rewards Std                              0.517914
eval/Rewards Max                              1.56899
eval/Rewards Min                              0
eval/Returns Mean                             8.9498
eval/Returns Std                             17.868
eval/Returns Max                             44.9004
eval/Returns Min                              0.00138578
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          8.9498
eval/env_infos/final/reward_dist Mean         0.31354
eval/env_infos/final/reward_dist Std          0.627079
eval/env_infos/final/reward_dist Max          1.56899
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       7.89384e-05
eval/env_infos/initial/reward_dist Std        0.000236815
eval/env_infos/initial/reward_dist Max        0.000789384
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.223745
eval/env_infos/reward_dist Std                0.517914
eval/env_infos/reward_dist Max                1.56899
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00816672
time/evaluation sampling (s)                  3.41376
time/exploration sampling (s)                17.8907
time/logging (s)                              0.00790041
time/saving (s)                               0.00124083
time/training (s)                             5.12494
time/epoch (s)                               26.4467
time/total (s)                             4891.67
Epoch                                       191
---------------------------------------  ----------------
2023-08-05 01:43:05.127585 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 192 finished
---------------------------------------  ----------------
epoch                                       192
replay_buffer/size                       386000
trainer/QF Loss                               3.78713e+10
trainer/Policy Loss                          -1.08238e+06
trainer/Raw Policy Loss                      -1.08238e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               886381
trainer/Q Predictions Std                136007
trainer/Q Predictions Max                     1.52576e+06
trainer/Q Predictions Min                  1427.98
trainer/Q Targets Mean                        1.0288e+06
trainer/Q Targets Std                     57917.3
trainer/Q Targets Max                         1.4517e+06
trainer/Q Targets Min                    546026
trainer/Bellman Errors Mean                   3.78713e+10
trainer/Bellman Errors Std                    6.61763e+10
trainer/Bellman Errors Max                    1.0384e+12
trainer/Bellman Errors Min                  961
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     386000
expl/num paths total                       9650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.416049
expl/Rewards Std                              0.612148
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            16.642
expl/Returns Std                             18.966
expl/Returns Max                             43.3786
expl/Returns Min                              0
expl/Actions Mean                             0.253977
expl/Actions Std                              0.807138
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.642
expl/env_infos/final/reward_dist Mean         0.623763
expl/env_infos/final/reward_dist Std          0.749463
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000572313
expl/env_infos/initial/reward_dist Std        0.00168717
expl/env_infos/initial/reward_dist Max        0.0100673
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.416049
expl/env_infos/reward_dist Std                0.612148
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      77200
eval/num paths total                       1930
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.780401
eval/Rewards Std                              0.710309
eval/Rewards Max                              1.57062
eval/Rewards Min                              0
eval/Returns Mean                            31.216
eval/Returns Std                             20.4326
eval/Returns Max                             45.3336
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.216
eval/env_infos/final/reward_dist Mean         1.09942
eval/env_infos/final/reward_dist Std          0.717538
eval/env_infos/final/reward_dist Max          1.57062
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00252138
eval/env_infos/initial/reward_dist Std        0.0050431
eval/env_infos/initial/reward_dist Max        0.0127371
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.780401
eval/env_infos/reward_dist Std                0.710309
eval/env_infos/reward_dist Max                1.57062
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0060447
time/evaluation sampling (s)                  3.53514
time/exploration sampling (s)                17.5125
time/logging (s)                              0.00539494
time/saving (s)                               0.00101384
time/training (s)                             4.17059
time/epoch (s)                               25.2307
time/total (s)                             4916.91
Epoch                                       192
---------------------------------------  ----------------
2023-08-05 01:43:30.363918 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 193 finished
---------------------------------------  ----------------
epoch                                       193
replay_buffer/size                       388000
trainer/QF Loss                               4.04903e+10
trainer/Policy Loss                          -1.09675e+06
trainer/Raw Policy Loss                      -1.09675e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               895925
trainer/Q Predictions Std                138724
trainer/Q Predictions Max                     1.47983e+06
trainer/Q Predictions Min                   870.596
trainer/Q Targets Mean                        1.04213e+06
trainer/Q Targets Std                     58619.6
trainer/Q Targets Max                         1.61743e+06
trainer/Q Targets Min                    553250
trainer/Bellman Errors Mean                   4.04903e+10
trainer/Bellman Errors Std                    7.0507e+10
trainer/Bellman Errors Max                    1.04796e+12
trainer/Bellman Errors Min                  270.191
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     388000
expl/num paths total                       9700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.608477
expl/Rewards Std                              0.676399
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            24.3391
expl/Returns Std                             19.6338
expl/Returns Max                             45.0544
expl/Returns Min                              0
expl/Actions Mean                             0.272771
expl/Actions Std                              0.806364
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.3391
expl/env_infos/final/reward_dist Mean         0.907002
expl/env_infos/final/reward_dist Std          0.771996
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00196257
expl/env_infos/initial/reward_dist Std        0.00518937
expl/env_infos/initial/reward_dist Max        0.0230546
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.608477
expl/env_infos/reward_dist Std                0.676399
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      77600
eval/num paths total                       1940
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.416662
eval/Rewards Std                              0.637529
eval/Rewards Max                              1.56943
eval/Rewards Min                              0
eval/Returns Mean                            16.6665
eval/Returns Std                             20.5385
eval/Returns Max                             44.1886
eval/Returns Min                              0.00139113
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.6665
eval/env_infos/final/reward_dist Mean         0.618268
eval/env_infos/final/reward_dist Std          0.757628
eval/env_infos/final/reward_dist Max          1.56943
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000118245
eval/env_infos/initial/reward_dist Std        0.000354736
eval/env_infos/initial/reward_dist Max        0.00118245
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.416662
eval/env_infos/reward_dist Std                0.637529
eval/env_infos/reward_dist Max                1.56943
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00605889
time/evaluation sampling (s)                  3.43015
time/exploration sampling (s)                17.3459
time/logging (s)                              0.00535513
time/saving (s)                               0.000973182
time/training (s)                             4.44487
time/epoch (s)                               25.2333
time/total (s)                             4942.14
Epoch                                       193
---------------------------------------  ----------------
2023-08-05 01:43:55.701840 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 194 finished
---------------------------------------  ----------------
epoch                                       194
replay_buffer/size                       390000
trainer/QF Loss                               3.98161e+10
trainer/Policy Loss                          -1.11312e+06
trainer/Raw Policy Loss                      -1.11312e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               910759
trainer/Q Predictions Std                136568
trainer/Q Predictions Max                     1.45539e+06
trainer/Q Predictions Min                  2473.19
trainer/Q Targets Mean                        1.05753e+06
trainer/Q Targets Std                     56853.5
trainer/Q Targets Max                         1.54581e+06
trainer/Q Targets Min                    552346
trainer/Bellman Errors Mean                   3.98161e+10
trainer/Bellman Errors Std                    6.96225e+10
trainer/Bellman Errors Max                    1.22566e+12
trainer/Bellman Errors Min                  851.91
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     390000
expl/num paths total                       9750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.502958
expl/Rewards Std                              0.650098
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            20.1183
expl/Returns Std                             19.8436
expl/Returns Max                             44.6008
expl/Returns Min                              0
expl/Actions Mean                             0.263348
expl/Actions Std                              0.799857
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.1183
expl/env_infos/final/reward_dist Mean         0.720007
expl/env_infos/final/reward_dist Std          0.777011
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000578285
expl/env_infos/initial/reward_dist Std        0.00255608
expl/env_infos/initial/reward_dist Max        0.0177212
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.502958
expl/env_infos/reward_dist Std                0.650098
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      78000
eval/num paths total                       1950
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.749697
eval/Rewards Std                              0.700882
eval/Rewards Max                              1.57031
eval/Rewards Min                              0
eval/Returns Mean                            29.9879
eval/Returns Std                             19.987
eval/Returns Max                             45.2679
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         29.9879
eval/env_infos/final/reward_dist Mean         1.09078
eval/env_infos/final/reward_dist Std          0.713666
eval/env_infos/final/reward_dist Max          1.57031
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00149852
eval/env_infos/initial/reward_dist Std        0.00449556
eval/env_infos/initial/reward_dist Max        0.0149852
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.749697
eval/env_infos/reward_dist Std                0.700882
eval/env_infos/reward_dist Max                1.57031
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00824108
time/evaluation sampling (s)                  3.45958
time/exploration sampling (s)                17.6117
time/logging (s)                              0.0053216
time/saving (s)                               0.00100871
time/training (s)                             4.24902
time/epoch (s)                               25.3349
time/total (s)                             4967.48
Epoch                                       194
---------------------------------------  ----------------
2023-08-05 01:44:20.301601 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 195 finished
---------------------------------------  ----------------
epoch                                       195
replay_buffer/size                       392000
trainer/QF Loss                               4.5277e+10
trainer/Policy Loss                          -1.13066e+06
trainer/Raw Policy Loss                      -1.13066e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               919260
trainer/Q Predictions Std                148586
trainer/Q Predictions Max                     1.4805e+06
trainer/Q Predictions Min                   569.553
trainer/Q Targets Mean                        1.0749e+06
trainer/Q Targets Std                     58615.1
trainer/Q Targets Max                         1.66534e+06
trainer/Q Targets Min                    583121
trainer/Bellman Errors Mean                   4.5277e+10
trainer/Bellman Errors Std                    8.19592e+10
trainer/Bellman Errors Max                    1.12465e+12
trainer/Bellman Errors Min                 2150.64
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     392000
expl/num paths total                       9800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.558554
expl/Rewards Std                              0.661355
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            22.3422
expl/Returns Std                             19.7238
expl/Returns Max                             45.1923
expl/Returns Min                              0
expl/Actions Mean                             0.253056
expl/Actions Std                              0.804209
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.3422
expl/env_infos/final/reward_dist Mean         0.80236
expl/env_infos/final/reward_dist Std          0.772413
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00221098
expl/env_infos/initial/reward_dist Std        0.00581879
expl/env_infos/initial/reward_dist Max        0.0228807
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.558554
expl/env_infos/reward_dist Std                0.661355
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      78400
eval/num paths total                       1960
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.782646
eval/Rewards Std                              0.709349
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            31.3058
eval/Returns Std                             20.4998
eval/Returns Max                             46.5645
eval/Returns Min                              0.00804239
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.3058
eval/env_infos/final/reward_dist Mean         1.0974
eval/env_infos/final/reward_dist Std          0.718423
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00500019
eval/env_infos/initial/reward_dist Std        0.0097019
eval/env_infos/initial/reward_dist Max        0.0299701
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.782646
eval/env_infos/reward_dist Std                0.709349
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00823702
time/evaluation sampling (s)                  3.35377
time/exploration sampling (s)                16.941
time/logging (s)                              0.00399027
time/saving (s)                               0.000771485
time/training (s)                             4.28769
time/epoch (s)                               24.5954
time/total (s)                             4992.07
Epoch                                       195
---------------------------------------  ----------------
2023-08-05 01:44:45.374170 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 196 finished
---------------------------------------  ----------------
epoch                                       196
replay_buffer/size                       394000
trainer/QF Loss                               4.36292e+10
trainer/Policy Loss                          -1.14739e+06
trainer/Raw Policy Loss                      -1.14739e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               937184
trainer/Q Predictions Std                144683
trainer/Q Predictions Max                     1.57546e+06
trainer/Q Predictions Min                   651.043
trainer/Q Targets Mean                        1.09199e+06
trainer/Q Targets Std                     61211.6
trainer/Q Targets Max                         1.59851e+06
trainer/Q Targets Min                    576101
trainer/Bellman Errors Mean                   4.36292e+10
trainer/Bellman Errors Std                    7.68763e+10
trainer/Bellman Errors Max                    1.16966e+12
trainer/Bellman Errors Min                15221.4
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     394000
expl/num paths total                       9850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.483468
expl/Rewards Std                              0.655009
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            19.3387
expl/Returns Std                             20.2526
expl/Returns Max                             44.6493
expl/Returns Min                              0
expl/Actions Mean                             0.254052
expl/Actions Std                              0.807987
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.3387
expl/env_infos/final/reward_dist Mean         0.721522
expl/env_infos/final/reward_dist Std          0.781749
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00133245
expl/env_infos/initial/reward_dist Std        0.00316604
expl/env_infos/initial/reward_dist Max        0.0154124
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.483468
expl/env_infos/reward_dist Std                0.655009
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      78800
eval/num paths total                       1970
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.778176
eval/Rewards Std                              0.708862
eval/Rewards Max                              1.57055
eval/Rewards Min                              0
eval/Returns Mean                            31.127
eval/Returns Std                             20.3903
eval/Returns Max                             45.6252
eval/Returns Min                              4.95832e-05
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.127
eval/env_infos/final/reward_dist Mean         1.09685
eval/env_infos/final/reward_dist Std          0.718076
eval/env_infos/final/reward_dist Max          1.57055
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00223053
eval/env_infos/initial/reward_dist Std        0.00564344
eval/env_infos/initial/reward_dist Max        0.0188816
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.778176
eval/env_infos/reward_dist Std                0.708862
eval/env_infos/reward_dist Max                1.57055
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00613693
time/evaluation sampling (s)                  3.50485
time/exploration sampling (s)                17.1712
time/logging (s)                              0.00400791
time/saving (s)                               0.000766181
time/training (s)                             4.38294
time/epoch (s)                               25.0699
time/total (s)                             5017.15
Epoch                                       196
---------------------------------------  ----------------
2023-08-05 01:45:10.265442 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 197 finished
---------------------------------------  ----------------
epoch                                       197
replay_buffer/size                       396000
trainer/QF Loss                               4.54306e+10
trainer/Policy Loss                          -1.16326e+06
trainer/Raw Policy Loss                      -1.16326e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               950153
trainer/Q Predictions Std                149069
trainer/Q Predictions Max                     1.50729e+06
trainer/Q Predictions Min                   924.061
trainer/Q Targets Mean                        1.10558e+06
trainer/Q Targets Std                     62536.7
trainer/Q Targets Max                         1.68983e+06
trainer/Q Targets Min                    561883
trainer/Bellman Errors Mean                   4.54306e+10
trainer/Bellman Errors Std                    8.31852e+10
trainer/Bellman Errors Max                    1.18137e+12
trainer/Bellman Errors Min                 3495.77
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     396000
expl/num paths total                       9900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.597715
expl/Rewards Std                              0.68032
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            23.9086
expl/Returns Std                             20.0996
expl/Returns Max                             45.3614
expl/Returns Min                              0
expl/Actions Mean                             0.249488
expl/Actions Std                              0.806161
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         23.9086
expl/env_infos/final/reward_dist Mean         0.876946
expl/env_infos/final/reward_dist Std          0.777254
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00138383
expl/env_infos/initial/reward_dist Std        0.00420552
expl/env_infos/initial/reward_dist Max        0.0245582
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.597715
expl/env_infos/reward_dist Std                0.68032
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      79200
eval/num paths total                       1980
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.519458
eval/Rewards Std                              0.674158
eval/Rewards Max                              1.57047
eval/Rewards Min                              0
eval/Returns Mean                            20.7783
eval/Returns Std                             21.1594
eval/Returns Max                             45.215
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.7783
eval/env_infos/final/reward_dist Mean         0.775649
eval/env_infos/final/reward_dist Std          0.776069
eval/env_infos/final/reward_dist Max          1.57047
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00194768
eval/env_infos/initial/reward_dist Std        0.00584304
eval/env_infos/initial/reward_dist Max        0.0194768
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.519458
eval/env_infos/reward_dist Std                0.674158
eval/env_infos/reward_dist Max                1.57047
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591796
time/evaluation sampling (s)                  3.44121
time/exploration sampling (s)                17.2469
time/logging (s)                              0.00562121
time/saving (s)                               0.00102631
time/training (s)                             4.18929
time/epoch (s)                               24.89
time/total (s)                             5042.04
Epoch                                       197
---------------------------------------  ----------------
2023-08-05 01:45:35.717049 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 198 finished
---------------------------------------  ----------------
epoch                                       198
replay_buffer/size                       398000
trainer/QF Loss                               4.79036e+10
trainer/Policy Loss                          -1.18028e+06
trainer/Raw Policy Loss                      -1.18028e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               962445
trainer/Q Predictions Std                154693
trainer/Q Predictions Max                     1.78744e+06
trainer/Q Predictions Min                   815.762
trainer/Q Targets Mean                        1.12139e+06
trainer/Q Targets Std                     64829.2
trainer/Q Targets Max                         1.88867e+06
trainer/Q Targets Min                    594149
trainer/Bellman Errors Mean                   4.79036e+10
trainer/Bellman Errors Std                    8.80208e+10
trainer/Bellman Errors Max                    1.22388e+12
trainer/Bellman Errors Min                  570.016
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     398000
expl/num paths total                       9950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.609371
expl/Rewards Std                              0.679784
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            24.3748
expl/Returns Std                             19.7447
expl/Returns Max                             44.9731
expl/Returns Min                              0
expl/Actions Mean                             0.259421
expl/Actions Std                              0.804883
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.3748
expl/env_infos/final/reward_dist Mean         0.908325
expl/env_infos/final/reward_dist Std          0.772887
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00129277
expl/env_infos/initial/reward_dist Std        0.00393161
expl/env_infos/initial/reward_dist Max        0.0233356
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.609371
expl/env_infos/reward_dist Std                0.679784
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      79600
eval/num paths total                       1990
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.307035
eval/Rewards Std                              0.569446
eval/Rewards Max                              1.5699
eval/Rewards Min                              0
eval/Returns Mean                            12.2814
eval/Returns Std                             18.7536
eval/Returns Max                             45.1276
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         12.2814
eval/env_infos/final/reward_dist Mean         0.472797
eval/env_infos/final/reward_dist Std          0.698842
eval/env_infos/final/reward_dist Max          1.5699
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0010697
eval/env_infos/initial/reward_dist Std        0.00214552
eval/env_infos/initial/reward_dist Max        0.00571097
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.307035
eval/env_infos/reward_dist Std                0.569446
eval/env_infos/reward_dist Max                1.5699
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00602201
time/evaluation sampling (s)                  3.67325
time/exploration sampling (s)                17.5156
time/logging (s)                              0.00543082
time/saving (s)                               0.00107084
time/training (s)                             4.24678
time/epoch (s)                               25.4481
time/total (s)                             5067.49
Epoch                                       198
---------------------------------------  ----------------
2023-08-05 01:46:01.321772 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 199 finished
---------------------------------------  ----------------
epoch                                       199
replay_buffer/size                       400000
trainer/QF Loss                               4.87318e+10
trainer/Policy Loss                          -1.19672e+06
trainer/Raw Policy Loss                      -1.19672e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               975105
trainer/Q Predictions Std                153479
trainer/Q Predictions Max                     1.63185e+06
trainer/Q Predictions Min                  1574.85
trainer/Q Targets Mean                        1.13653e+06
trainer/Q Targets Std                     62277.1
trainer/Q Targets Max                         1.57536e+06
trainer/Q Targets Min                    609616
trainer/Bellman Errors Mean                   4.87318e+10
trainer/Bellman Errors Std                    8.98478e+10
trainer/Bellman Errors Max                    1.24967e+12
trainer/Bellman Errors Min                  337.641
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     400000
expl/num paths total                      10000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.529799
expl/Rewards Std                              0.663196
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            21.192
expl/Returns Std                             20.0459
expl/Returns Max                             44.2386
expl/Returns Min                              0
expl/Actions Mean                             0.275664
expl/Actions Std                              0.804792
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.192
expl/env_infos/final/reward_dist Mean         0.782385
expl/env_infos/final/reward_dist Std          0.782456
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00141667
expl/env_infos/initial/reward_dist Std        0.00440339
expl/env_infos/initial/reward_dist Max        0.0230645
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.529799
expl/env_infos/reward_dist Std                0.663196
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      80000
eval/num paths total                       2000
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.11377
eval/Rewards Std                              0.589119
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            44.5507
eval/Returns Std                              0.482992
eval/Returns Max                             45.1478
eval/Returns Min                             43.5915
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         44.5507
eval/env_infos/final/reward_dist Mean         1.5693
eval/env_infos/final/reward_dist Std          0.00231755
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          1.56283
eval/env_infos/initial/reward_dist Mean       0.00242315
eval/env_infos/initial/reward_dist Std        0.00402561
eval/env_infos/initial/reward_dist Max        0.0110491
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.11377
eval/env_infos/reward_dist Std                0.589119
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00826293
time/evaluation sampling (s)                  3.71402
time/exploration sampling (s)                17.4616
time/logging (s)                              0.00530103
time/saving (s)                               0.000988187
time/training (s)                             4.41059
time/epoch (s)                               25.6008
time/total (s)                             5093.09
Epoch                                       199
---------------------------------------  ----------------
2023-08-05 01:46:25.770035 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 200 finished
---------------------------------------  ----------------
epoch                                       200
replay_buffer/size                       402000
trainer/QF Loss                               5.09197e+10
trainer/Policy Loss                          -1.21282e+06
trainer/Raw Policy Loss                      -1.21282e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean               987824
trainer/Q Predictions Std                157698
trainer/Q Predictions Max                     1.5205e+06
trainer/Q Predictions Min                   809.569
trainer/Q Targets Mean                        1.15144e+06
trainer/Q Targets Std                     61857
trainer/Q Targets Max                         1.70198e+06
trainer/Q Targets Min                    614071
trainer/Bellman Errors Mean                   5.09197e+10
trainer/Bellman Errors Std                    9.42258e+10
trainer/Bellman Errors Max                    1.29992e+12
trainer/Bellman Errors Min                 1287.02
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     402000
expl/num paths total                      10050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.532215
expl/Rewards Std                              0.671923
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            21.2886
expl/Returns Std                             20.3829
expl/Returns Max                             43.2986
expl/Returns Min                              0
expl/Actions Mean                             0.251321
expl/Actions Std                              0.809753
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.2886
expl/env_infos/final/reward_dist Mean         0.814268
expl/env_infos/final/reward_dist Std          0.782266
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00147354
expl/env_infos/initial/reward_dist Std        0.00417133
expl/env_infos/initial/reward_dist Max        0.0197756
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.532215
expl/env_infos/reward_dist Std                0.671923
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      80400
eval/num paths total                       2010
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.659566
eval/Rewards Std                              0.705528
eval/Rewards Max                              1.5699
eval/Rewards Min                              0
eval/Returns Mean                            26.3827
eval/Returns Std                             21.5536
eval/Returns Max                             45.2617
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.3827
eval/env_infos/final/reward_dist Mean         0.940856
eval/env_infos/final/reward_dist Std          0.768207
eval/env_infos/final/reward_dist Max          1.5699
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00306932
eval/env_infos/initial/reward_dist Std        0.00620675
eval/env_infos/initial/reward_dist Max        0.0173969
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.659566
eval/env_infos/reward_dist Std                0.705528
eval/env_infos/reward_dist Max                1.5699
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593194
time/evaluation sampling (s)                  3.37701
time/exploration sampling (s)                16.9
time/logging (s)                              0.00549853
time/saving (s)                               0.00102397
time/training (s)                             4.15586
time/epoch (s)                               24.4454
time/total (s)                             5117.54
Epoch                                       200
---------------------------------------  ----------------
2023-08-05 01:46:50.580992 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 201 finished
---------------------------------------  ----------------
epoch                                       201
replay_buffer/size                       404000
trainer/QF Loss                               5.05402e+10
trainer/Policy Loss                          -1.23153e+06
trainer/Raw Policy Loss                      -1.23153e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.00684e+06
trainer/Q Predictions Std                157044
trainer/Q Predictions Max                     1.5886e+06
trainer/Q Predictions Min                  1595.94
trainer/Q Targets Mean                        1.16991e+06
trainer/Q Targets Std                     65106
trainer/Q Targets Max                         1.75317e+06
trainer/Q Targets Min                    573297
trainer/Bellman Errors Mean                   5.05402e+10
trainer/Bellman Errors Std                    8.94122e+10
trainer/Bellman Errors Max                    1.30178e+12
trainer/Bellman Errors Min                  534.766
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     404000
expl/num paths total                      10100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.629929
expl/Rewards Std                              0.680391
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            25.1971
expl/Returns Std                             19.6452
expl/Returns Max                             45.0712
expl/Returns Min                              0
expl/Actions Mean                             0.259662
expl/Actions Std                              0.811658
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.1971
expl/env_infos/final/reward_dist Mean         0.971518
expl/env_infos/final/reward_dist Std          0.743153
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00118154
expl/env_infos/initial/reward_dist Std        0.00404508
expl/env_infos/initial/reward_dist Max        0.0190727
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.629929
expl/env_infos/reward_dist Std                0.680391
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      80800
eval/num paths total                       2020
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.893464
eval/Rewards Std                              0.690591
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            35.7385
eval/Returns Std                             17.874
eval/Returns Max                             45.9221
eval/Returns Min                              0.00289328
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.7385
eval/env_infos/final/reward_dist Mean         1.25497
eval/env_infos/final/reward_dist Std          0.627485
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0018103
eval/env_infos/initial/reward_dist Std        0.00448586
eval/env_infos/initial/reward_dist Max        0.0151316
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.893464
eval/env_infos/reward_dist Std                0.690591
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00592232
time/evaluation sampling (s)                  3.40698
time/exploration sampling (s)                17.1122
time/logging (s)                              0.0054127
time/saving (s)                               0.00101163
time/training (s)                             4.27597
time/epoch (s)                               24.8075
time/total (s)                             5142.35
Epoch                                       201
---------------------------------------  ----------------
2023-08-05 01:47:15.675459 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 202 finished
---------------------------------------  ----------------
epoch                                       202
replay_buffer/size                       406000
trainer/QF Loss                               5.19589e+10
trainer/Policy Loss                          -1.24779e+06
trainer/Raw Policy Loss                      -1.24779e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.02234e+06
trainer/Q Predictions Std                160458
trainer/Q Predictions Max                     1.79427e+06
trainer/Q Predictions Min                   706.69
trainer/Q Targets Mean                        1.18643e+06
trainer/Q Targets Std                     64095.7
trainer/Q Targets Max                         1.66368e+06
trainer/Q Targets Min                    645004
trainer/Bellman Errors Mean                   5.19589e+10
trainer/Bellman Errors Std                    1.00127e+11
trainer/Bellman Errors Max                    1.36963e+12
trainer/Bellman Errors Min                  798.062
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     406000
expl/num paths total                      10150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.396365
expl/Rewards Std                              0.606998
expl/Rewards Max                              1.57068
expl/Rewards Min                              0
expl/Returns Mean                            15.8546
expl/Returns Std                             19.1612
expl/Returns Max                             44.2128
expl/Returns Min                              0
expl/Actions Mean                             0.261454
expl/Actions Std                              0.791534
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.8546
expl/env_infos/final/reward_dist Mean         0.585253
expl/env_infos/final/reward_dist Std          0.748498
expl/env_infos/final/reward_dist Max          1.57068
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000978486
expl/env_infos/initial/reward_dist Std        0.0031076
expl/env_infos/initial/reward_dist Max        0.0151309
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.396365
expl/env_infos/reward_dist Std                0.606998
expl/env_infos/reward_dist Max                1.57068
expl/env_infos/reward_dist Min                0
eval/num steps total                      81200
eval/num paths total                       2030
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.667948
eval/Rewards Std                              0.711575
eval/Rewards Max                              1.57033
eval/Rewards Min                              0
eval/Returns Mean                            26.7179
eval/Returns Std                             21.7938
eval/Returns Max                             44.9709
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.7179
eval/env_infos/final/reward_dist Mean         0.941088
eval/env_infos/final/reward_dist Std          0.768396
eval/env_infos/final/reward_dist Max          1.57033
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00156421
eval/env_infos/initial/reward_dist Std        0.00427152
eval/env_infos/initial/reward_dist Max        0.0143245
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.667948
eval/env_infos/reward_dist Std                0.711575
eval/env_infos/reward_dist Max                1.57033
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00597157
time/evaluation sampling (s)                  3.83326
time/exploration sampling (s)                16.9178
time/logging (s)                              0.00551146
time/saving (s)                               0.000994352
time/training (s)                             4.32713
time/epoch (s)                               25.0907
time/total (s)                             5167.44
Epoch                                       202
---------------------------------------  ----------------
2023-08-05 01:47:41.127321 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 203 finished
---------------------------------------  ----------------
epoch                                       203
replay_buffer/size                       408000
trainer/QF Loss                               5.58915e+10
trainer/Policy Loss                          -1.26505e+06
trainer/Raw Policy Loss                      -1.26505e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.03101e+06
trainer/Q Predictions Std                166849
trainer/Q Predictions Max                     1.70026e+06
trainer/Q Predictions Min                  5551.45
trainer/Q Targets Mean                        1.20272e+06
trainer/Q Targets Std                     63617.7
trainer/Q Targets Max                         1.68695e+06
trainer/Q Targets Min                    641532
trainer/Bellman Errors Mean                   5.58915e+10
trainer/Bellman Errors Std                    1.02179e+11
trainer/Bellman Errors Max                    1.39832e+12
trainer/Bellman Errors Min                   47.2656
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     408000
expl/num paths total                      10200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.407274
expl/Rewards Std                              0.611351
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            16.291
expl/Returns Std                             19.0691
expl/Returns Max                             44.5691
expl/Returns Min                              0
expl/Actions Mean                             0.260813
expl/Actions Std                              0.806814
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.291
expl/env_infos/final/reward_dist Mean         0.607949
expl/env_infos/final/reward_dist Std          0.754159
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00171219
expl/env_infos/initial/reward_dist Std        0.00519232
expl/env_infos/initial/reward_dist Max        0.0254669
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.407274
expl/env_infos/reward_dist Std                0.611351
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      81600
eval/num paths total                       2040
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.724086
eval/Rewards Std                              0.696167
eval/Rewards Max                              1.57018
eval/Rewards Min                              0
eval/Returns Mean                            28.9634
eval/Returns Std                             20.2616
eval/Returns Max                             45.4138
eval/Returns Min                              0.00102368
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.9634
eval/env_infos/final/reward_dist Mean         1.0895
eval/env_infos/final/reward_dist Std          0.713566
eval/env_infos/final/reward_dist Max          1.57018
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00292793
eval/env_infos/initial/reward_dist Std        0.00517041
eval/env_infos/initial/reward_dist Max        0.0132788
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.724086
eval/env_infos/reward_dist Std                0.696167
eval/env_infos/reward_dist Max                1.57018
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593595
time/evaluation sampling (s)                  4.29686
time/exploration sampling (s)                17.0878
time/logging (s)                              0.00546251
time/saving (s)                               0.000995504
time/training (s)                             4.05136
time/epoch (s)                               25.4484
time/total (s)                             5192.89
Epoch                                       203
---------------------------------------  ----------------
2023-08-05 01:48:06.242306 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 204 finished
---------------------------------------  ----------------
epoch                                       204
replay_buffer/size                       410000
trainer/QF Loss                               5.59913e+10
trainer/Policy Loss                          -1.28374e+06
trainer/Raw Policy Loss                      -1.28374e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.05076e+06
trainer/Q Predictions Std                168764
trainer/Q Predictions Max                     1.68691e+06
trainer/Q Predictions Min                  4443.82
trainer/Q Targets Mean                        1.22101e+06
trainer/Q Targets Std                     71942.6
trainer/Q Targets Max                         1.77773e+06
trainer/Q Targets Min                    643906
trainer/Bellman Errors Mean                   5.59913e+10
trainer/Bellman Errors Std                    1.02923e+11
trainer/Bellman Errors Max                    1.4294e+12
trainer/Bellman Errors Min                12628.1
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     410000
expl/num paths total                      10250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.585033
expl/Rewards Std                              0.675093
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            23.4013
expl/Returns Std                             19.8149
expl/Returns Max                             44.7138
expl/Returns Min                              0
expl/Actions Mean                             0.259785
expl/Actions Std                              0.799855
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         23.4013
expl/env_infos/final/reward_dist Mean         0.876962
expl/env_infos/final/reward_dist Std          0.777233
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00155639
expl/env_infos/initial/reward_dist Std        0.00392876
expl/env_infos/initial/reward_dist Max        0.0191655
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.585033
expl/env_infos/reward_dist Std                0.675093
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      82000
eval/num paths total                       2050
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.301796
eval/Rewards Std                              0.569749
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            12.0719
eval/Returns Std                             18.6637
eval/Returns Max                             44.3628
eval/Returns Min                              0.00326015
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         12.0719
eval/env_infos/final/reward_dist Mean         0.463562
eval/env_infos/final/reward_dist Std          0.708341
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.301796
eval/env_infos/reward_dist Std                0.569749
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00603442
time/evaluation sampling (s)                  3.90816
time/exploration sampling (s)                17.0221
time/logging (s)                              0.00545856
time/saving (s)                               0.00104543
time/training (s)                             4.16584
time/epoch (s)                               25.1087
time/total (s)                             5218.01
Epoch                                       204
---------------------------------------  ----------------
2023-08-05 01:48:31.756864 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 205 finished
---------------------------------------  ----------------
epoch                                       205
replay_buffer/size                       412000
trainer/QF Loss                               5.47437e+10
trainer/Policy Loss                          -1.3004e+06
trainer/Raw Policy Loss                      -1.3004e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.06506e+06
trainer/Q Predictions Std                163003
trainer/Q Predictions Max                     1.57172e+06
trainer/Q Predictions Min                  1533.08
trainer/Q Targets Mean                        1.23617e+06
trainer/Q Targets Std                     68252.9
trainer/Q Targets Max                         1.71144e+06
trainer/Q Targets Min                    653115
trainer/Bellman Errors Mean                   5.47437e+10
trainer/Bellman Errors Std                    9.9335e+10
trainer/Bellman Errors Max                    1.42152e+12
trainer/Bellman Errors Min                    1.89062
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     412000
expl/num paths total                      10300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.4465
expl/Rewards Std                              0.630935
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            17.86
expl/Returns Std                             19.301
expl/Returns Max                             44.2748
expl/Returns Min                              0
expl/Actions Mean                             0.257847
expl/Actions Std                              0.809471
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.86
expl/env_infos/final/reward_dist Mean         0.674225
expl/env_infos/final/reward_dist Std          0.768364
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00161171
expl/env_infos/initial/reward_dist Std        0.00443982
expl/env_infos/initial/reward_dist Max        0.017583
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.4465
expl/env_infos/reward_dist Std                0.630935
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      82400
eval/num paths total                       2060
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.7773
eval/Rewards Std                              0.709073
eval/Rewards Max                              1.57034
eval/Rewards Min                              0
eval/Returns Mean                            31.092
eval/Returns Std                             20.3512
eval/Returns Max                             45.2011
eval/Returns Min                              0.00118432
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.092
eval/env_infos/final/reward_dist Mean         1.09748
eval/env_infos/final/reward_dist Std          0.718474
eval/env_infos/final/reward_dist Max          1.57034
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00233546
eval/env_infos/initial/reward_dist Std        0.00397579
eval/env_infos/initial/reward_dist Max        0.0113663
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.7773
eval/env_infos/reward_dist Std                0.709073
eval/env_infos/reward_dist Max                1.57034
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0060537
time/evaluation sampling (s)                  4.03243
time/exploration sampling (s)                17.3912
time/logging (s)                              0.00540647
time/saving (s)                               0.000996497
time/training (s)                             4.07429
time/epoch (s)                               25.5103
time/total (s)                             5243.52
Epoch                                       205
---------------------------------------  ----------------
2023-08-05 01:48:57.213576 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 206 finished
---------------------------------------  ----------------
epoch                                       206
replay_buffer/size                       414000
trainer/QF Loss                               5.80986e+10
trainer/Policy Loss                          -1.3198e+06
trainer/Raw Policy Loss                      -1.3198e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.07855e+06
trainer/Q Predictions Std                168984
trainer/Q Predictions Max                     1.88031e+06
trainer/Q Predictions Min                  1746.46
trainer/Q Targets Mean                        1.25476e+06
trainer/Q Targets Std                     70083.2
trainer/Q Targets Max                         2.09926e+06
trainer/Q Targets Min                    683128
trainer/Bellman Errors Mean                   5.80986e+10
trainer/Bellman Errors Std                    1.05494e+11
trainer/Bellman Errors Max                    1.55983e+12
trainer/Bellman Errors Min                 1881.39
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     414000
expl/num paths total                      10350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.501589
expl/Rewards Std                              0.648292
expl/Rewards Max                              1.57069
expl/Rewards Min                              0
expl/Returns Mean                            20.0636
expl/Returns Std                             19.247
expl/Returns Max                             43.6599
expl/Returns Min                              0
expl/Actions Mean                             0.248187
expl/Actions Std                              0.799721
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.0636
expl/env_infos/final/reward_dist Mean         0.777295
expl/env_infos/final/reward_dist Std          0.778131
expl/env_infos/final/reward_dist Max          1.57069
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00109842
expl/env_infos/initial/reward_dist Std        0.00392449
expl/env_infos/initial/reward_dist Max        0.0213295
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.501589
expl/env_infos/reward_dist Std                0.648292
expl/env_infos/reward_dist Max                1.57069
expl/env_infos/reward_dist Min                0
eval/num steps total                      82800
eval/num paths total                       2070
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.52938
eval/Rewards Std                              0.678405
eval/Rewards Max                              1.57014
eval/Rewards Min                              0
eval/Returns Mean                            21.1752
eval/Returns Std                             21.2975
eval/Returns Max                             45.3367
eval/Returns Min                              0.000942585
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         21.1752
eval/env_infos/final/reward_dist Mean         0.775686
eval/env_infos/final/reward_dist Std          0.776077
eval/env_infos/final/reward_dist Max          1.57011
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00233719
eval/env_infos/initial/reward_dist Std        0.00585081
eval/env_infos/initial/reward_dist Max        0.0195543
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.52938
eval/env_infos/reward_dist Std                0.678405
eval/env_infos/reward_dist Max                1.57014
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00598481
time/evaluation sampling (s)                  4.10752
time/exploration sampling (s)                16.9287
time/logging (s)                              0.00541666
time/saving (s)                               0.00100172
time/training (s)                             4.40471
time/epoch (s)                               25.4533
time/total (s)                             5268.97
Epoch                                       206
---------------------------------------  ----------------
2023-08-05 01:49:23.479509 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 207 finished
---------------------------------------  ----------------
epoch                                       207
replay_buffer/size                       416000
trainer/QF Loss                               6.11435e+10
trainer/Policy Loss                          -1.33651e+06
trainer/Raw Policy Loss                      -1.33651e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.0905e+06
trainer/Q Predictions Std                173687
trainer/Q Predictions Max                     1.92334e+06
trainer/Q Predictions Min                   660.657
trainer/Q Targets Mean                        1.27073e+06
trainer/Q Targets Std                     71100.5
trainer/Q Targets Max                         1.80413e+06
trainer/Q Targets Min                    674932
trainer/Bellman Errors Mean                   6.11435e+10
trainer/Bellman Errors Std                    1.06974e+11
trainer/Bellman Errors Max                    1.57197e+12
trainer/Bellman Errors Min                   13.1406
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     416000
expl/num paths total                      10400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.638287
expl/Rewards Std                              0.685805
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            25.5315
expl/Returns Std                             19.5624
expl/Returns Max                             45.3092
expl/Returns Min                              0
expl/Actions Mean                             0.245183
expl/Actions Std                              0.792989
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.5315
expl/env_infos/final/reward_dist Mean         0.972788
expl/env_infos/final/reward_dist Std          0.761307
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00121515
expl/env_infos/initial/reward_dist Std        0.00470298
expl/env_infos/initial/reward_dist Max        0.0296083
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.638287
expl/env_infos/reward_dist Std                0.685805
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      83200
eval/num paths total                       2080
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.736286
eval/Rewards Std                              0.699079
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            29.4514
eval/Returns Std                             19.9863
eval/Returns Max                             45.0553
eval/Returns Min                              0.00262457
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         29.4514
eval/env_infos/final/reward_dist Mean         1.09004
eval/env_infos/final/reward_dist Std          0.713334
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       4.10672e-05
eval/env_infos/initial/reward_dist Std        0.000123202
eval/env_infos/initial/reward_dist Max        0.000410672
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.736286
eval/env_infos/reward_dist Std                0.699079
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590127
time/evaluation sampling (s)                  4.57908
time/exploration sampling (s)                17.3077
time/logging (s)                              0.00538575
time/saving (s)                               0.000980319
time/training (s)                             4.36329
time/epoch (s)                               26.2623
time/total (s)                             5295.24
Epoch                                       207
---------------------------------------  ----------------
2023-08-05 01:49:49.651365 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 208 finished
---------------------------------------  ----------------
epoch                                       208
replay_buffer/size                       418000
trainer/QF Loss                               6.13373e+10
trainer/Policy Loss                          -1.35474e+06
trainer/Raw Policy Loss                      -1.35474e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.10761e+06
trainer/Q Predictions Std                173367
trainer/Q Predictions Max                     1.81062e+06
trainer/Q Predictions Min                   729.186
trainer/Q Targets Mean                        1.28883e+06
trainer/Q Targets Std                     69782.6
trainer/Q Targets Max                         1.87022e+06
trainer/Q Targets Min                    697084
trainer/Bellman Errors Mean                   6.13373e+10
trainer/Bellman Errors Std                    1.11617e+11
trainer/Bellman Errors Max                    1.58417e+12
trainer/Bellman Errors Min                   12.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     418000
expl/num paths total                      10450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.364213
expl/Rewards Std                              0.602286
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            14.5685
expl/Returns Std                             19.3318
expl/Returns Max                             44.0342
expl/Returns Min                              0
expl/Actions Mean                             0.259184
expl/Actions Std                              0.803431
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.5685
expl/env_infos/final/reward_dist Mean         0.561989
expl/env_infos/final/reward_dist Std          0.749045
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00125955
expl/env_infos/initial/reward_dist Std        0.00372335
expl/env_infos/initial/reward_dist Max        0.0174635
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.364213
expl/env_infos/reward_dist Std                0.602286
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      83600
eval/num paths total                       2090
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.671746
eval/Rewards Std                              0.710806
eval/Rewards Max                              1.56968
eval/Rewards Min                              0
eval/Returns Mean                            26.8698
eval/Returns Std                             21.9395
eval/Returns Max                             45.4402
eval/Returns Min                              0.00244225
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.8698
eval/env_infos/final/reward_dist Mean         0.940562
eval/env_infos/final/reward_dist Std          0.767952
eval/env_infos/final/reward_dist Max          1.56968
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00402029
eval/env_infos/initial/reward_dist Std        0.00779443
eval/env_infos/initial/reward_dist Max        0.0216571
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.671746
eval/env_infos/reward_dist Std                0.710806
eval/env_infos/reward_dist Max                1.56968
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596802
time/evaluation sampling (s)                  4.29723
time/exploration sampling (s)                17.2786
time/logging (s)                              0.00537026
time/saving (s)                               0.000988009
time/training (s)                             4.58024
time/epoch (s)                               26.1684
time/total (s)                             5321.41
Epoch                                       208
---------------------------------------  ----------------
2023-08-05 01:50:15.086033 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 209 finished
---------------------------------------  ----------------
epoch                                       209
replay_buffer/size                       420000
trainer/QF Loss                               6.20288e+10
trainer/Policy Loss                          -1.37482e+06
trainer/Raw Policy Loss                      -1.37482e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.12522e+06
trainer/Q Predictions Std                175720
trainer/Q Predictions Max                     1.72527e+06
trainer/Q Predictions Min                  1404.12
trainer/Q Targets Mean                        1.30749e+06
trainer/Q Targets Std                     70919
trainer/Q Targets Max                         1.85791e+06
trainer/Q Targets Min                    663052
trainer/Bellman Errors Mean                   6.20288e+10
trainer/Bellman Errors Std                    1.1163e+11
trainer/Bellman Errors Max                    1.59912e+12
trainer/Bellman Errors Min                 2537.64
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     420000
expl/num paths total                      10500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.611157
expl/Rewards Std                              0.681716
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            24.4463
expl/Returns Std                             19.7334
expl/Returns Max                             44.5093
expl/Returns Min                              0
expl/Actions Mean                             0.275912
expl/Actions Std                              0.800548
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.4463
expl/env_infos/final/reward_dist Mean         0.91012
expl/env_infos/final/reward_dist Std          0.774337
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00209851
expl/env_infos/initial/reward_dist Std        0.00508093
expl/env_infos/initial/reward_dist Max        0.0227724
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.611157
expl/env_infos/reward_dist Std                0.681716
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      84000
eval/num paths total                       2100
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.560521
eval/Rewards Std                              0.695974
eval/Rewards Max                              1.57061
eval/Rewards Min                              0
eval/Returns Mean                            22.4209
eval/Returns Std                             22.4002
eval/Returns Max                             45.3649
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.4209
eval/env_infos/final/reward_dist Mean         0.784389
eval/env_infos/final/reward_dist Std          0.784392
eval/env_infos/final/reward_dist Max          1.57061
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00294176
eval/env_infos/initial/reward_dist Std        0.00597273
eval/env_infos/initial/reward_dist Max        0.0170085
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.560521
eval/env_infos/reward_dist Std                0.695974
eval/env_infos/reward_dist Max                1.57061
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00598274
time/evaluation sampling (s)                  3.99034
time/exploration sampling (s)                17.1442
time/logging (s)                              0.00548306
time/saving (s)                               0.0010173
time/training (s)                             4.28443
time/epoch (s)                               25.4315
time/total (s)                             5346.84
Epoch                                       209
---------------------------------------  ----------------
2023-08-05 01:50:40.055338 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 210 finished
---------------------------------------  ----------------
epoch                                       210
replay_buffer/size                       422000
trainer/QF Loss                               6.23102e+10
trainer/Policy Loss                          -1.39226e+06
trainer/Raw Policy Loss                      -1.39226e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.14342e+06
trainer/Q Predictions Std                176451
trainer/Q Predictions Max                     1.74482e+06
trainer/Q Predictions Min                  8455.51
trainer/Q Targets Mean                        1.32353e+06
trainer/Q Targets Std                     76532
trainer/Q Targets Max                         2.01338e+06
trainer/Q Targets Min                    701146
trainer/Bellman Errors Mean                   6.23102e+10
trainer/Bellman Errors Std                    1.11244e+11
trainer/Bellman Errors Max                    1.64545e+12
trainer/Bellman Errors Min                28985.1
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     422000
expl/num paths total                      10550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.473322
expl/Rewards Std                              0.650626
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            18.9329
expl/Returns Std                             20.2458
expl/Returns Max                             44.8243
expl/Returns Min                              0
expl/Actions Mean                             0.258679
expl/Actions Std                              0.799904
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.9329
expl/env_infos/final/reward_dist Mean         0.686008
expl/env_infos/final/reward_dist Std          0.774525
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000979307
expl/env_infos/initial/reward_dist Std        0.00316726
expl/env_infos/initial/reward_dist Max        0.0150192
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.473322
expl/env_infos/reward_dist Std                0.650626
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      84400
eval/num paths total                       2110
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.454299
eval/Rewards Std                              0.657441
eval/Rewards Max                              1.57032
eval/Rewards Min                              0
eval/Returns Mean                            18.172
eval/Returns Std                             21.653
eval/Returns Max                             44.7788
eval/Returns Min                              0.00259952
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         18.172
eval/env_infos/final/reward_dist Mean         0.657879
eval/env_infos/final/reward_dist Std          0.748787
eval/env_infos/final/reward_dist Max          1.57032
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00055055
eval/env_infos/initial/reward_dist Std        0.00165165
eval/env_infos/initial/reward_dist Max        0.0055055
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.454299
eval/env_infos/reward_dist Std                0.657441
eval/env_infos/reward_dist Max                1.57032
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00604253
time/evaluation sampling (s)                  3.61335
time/exploration sampling (s)                16.8938
time/logging (s)                              0.00547347
time/saving (s)                               0.00102255
time/training (s)                             4.44596
time/epoch (s)                               24.9656
time/total (s)                             5371.81
Epoch                                       210
---------------------------------------  ----------------
2023-08-05 01:51:05.288103 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 211 finished
---------------------------------------  ----------------
epoch                                       211
replay_buffer/size                       424000
trainer/QF Loss                               6.73588e+10
trainer/Policy Loss                          -1.41165e+06
trainer/Raw Policy Loss                      -1.41165e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.15398e+06
trainer/Q Predictions Std                183672
trainer/Q Predictions Max                     1.93954e+06
trainer/Q Predictions Min                  1083.8
trainer/Q Targets Mean                        1.34235e+06
trainer/Q Targets Std                     74910.9
trainer/Q Targets Max                         1.97951e+06
trainer/Q Targets Min                    713714
trainer/Bellman Errors Mean                   6.73588e+10
trainer/Bellman Errors Std                    1.26203e+11
trainer/Bellman Errors Max                    1.72795e+12
trainer/Bellman Errors Min                  375.391
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     424000
expl/num paths total                      10600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.572223
expl/Rewards Std                              0.667694
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            22.8889
expl/Returns Std                             19.6761
expl/Returns Max                             44.8115
expl/Returns Min                              0
expl/Actions Mean                             0.25906
expl/Actions Std                              0.806524
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.8889
expl/env_infos/final/reward_dist Mean         0.855153
expl/env_infos/final/reward_dist Std          0.763081
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00142115
expl/env_infos/initial/reward_dist Std        0.00456884
expl/env_infos/initial/reward_dist Max        0.0213888
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.572223
expl/env_infos/reward_dist Std                0.667694
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      84800
eval/num paths total                       2120
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.552915
eval/Rewards Std                              0.68527
eval/Rewards Max                              1.57068
eval/Rewards Min                              0
eval/Returns Mean                            22.1166
eval/Returns Std                             21.6645
eval/Returns Max                             45.0784
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.1166
eval/env_infos/final/reward_dist Mean         0.806134
eval/env_infos/final/reward_dist Std          0.765876
eval/env_infos/final/reward_dist Max          1.57068
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00213106
eval/env_infos/initial/reward_dist Std        0.00295828
eval/env_infos/initial/reward_dist Max        0.00894916
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.552915
eval/env_infos/reward_dist Std                0.68527
eval/env_infos/reward_dist Max                1.57068
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593472
time/evaluation sampling (s)                  3.58773
time/exploration sampling (s)                17.3432
time/logging (s)                              0.00555574
time/saving (s)                               0.000955631
time/training (s)                             4.2856
time/epoch (s)                               25.2289
time/total (s)                             5397.04
Epoch                                       211
---------------------------------------  ----------------
2023-08-05 01:51:30.369838 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 212 finished
---------------------------------------  ----------------
epoch                                       212
replay_buffer/size                       426000
trainer/QF Loss                               6.57274e+10
trainer/Policy Loss                          -1.4302e+06
trainer/Raw Policy Loss                      -1.4302e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.17057e+06
trainer/Q Predictions Std                178927
trainer/Q Predictions Max                     1.89792e+06
trainer/Q Predictions Min                   666.266
trainer/Q Targets Mean                        1.35861e+06
trainer/Q Targets Std                     78582.5
trainer/Q Targets Max                         2.0473e+06
trainer/Q Targets Min                    718299
trainer/Bellman Errors Mean                   6.57274e+10
trainer/Bellman Errors Std                    1.13874e+11
trainer/Bellman Errors Max                    1.80166e+12
trainer/Bellman Errors Min                 9168.06
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     426000
expl/num paths total                      10650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.372123
expl/Rewards Std                              0.607066
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            14.8849
expl/Returns Std                             19.5476
expl/Returns Max                             45.0549
expl/Returns Min                              0
expl/Actions Mean                             0.275081
expl/Actions Std                              0.808237
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.8849
expl/env_infos/final/reward_dist Mean         0.552392
expl/env_infos/final/reward_dist Std          0.735101
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00151872
expl/env_infos/initial/reward_dist Std        0.00505837
expl/env_infos/initial/reward_dist Max        0.0272164
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.372123
expl/env_infos/reward_dist Std                0.607066
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      85200
eval/num paths total                       2130
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.673824
eval/Rewards Std                              0.712236
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            26.953
eval/Returns Std                             21.9907
eval/Returns Max                             46.3385
eval/Returns Min                              0.00258048
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.953
eval/env_infos/final/reward_dist Mean         0.941218
eval/env_infos/final/reward_dist Std          0.768503
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00395607
eval/env_infos/initial/reward_dist Std        0.00724612
eval/env_infos/initial/reward_dist Max        0.023096
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.673824
eval/env_infos/reward_dist Std                0.712236
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00606259
time/evaluation sampling (s)                  3.60625
time/exploration sampling (s)                17.0786
time/logging (s)                              0.00539831
time/saving (s)                               0.0010425
time/training (s)                             4.37972
time/epoch (s)                               25.0771
time/total (s)                             5422.12
Epoch                                       212
---------------------------------------  ----------------
2023-08-05 01:51:55.591481 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 213 finished
---------------------------------------  ----------------
epoch                                       213
replay_buffer/size                       428000
trainer/QF Loss                               7.30892e+10
trainer/Policy Loss                          -1.4477e+06
trainer/Raw Policy Loss                      -1.4477e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.17971e+06
trainer/Q Predictions Std                186847
trainer/Q Predictions Max                     1.80447e+06
trainer/Q Predictions Min                  1349.81
trainer/Q Targets Mean                        1.37586e+06
trainer/Q Targets Std                     78032.3
trainer/Q Targets Max                         2.01124e+06
trainer/Q Targets Min                    732747
trainer/Bellman Errors Mean                   7.30892e+10
trainer/Bellman Errors Std                    1.35074e+11
trainer/Bellman Errors Max                    1.86644e+12
trainer/Bellman Errors Min                 3451.56
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     428000
expl/num paths total                      10700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.507471
expl/Rewards Std                              0.656011
expl/Rewards Max                              1.57072
expl/Rewards Min                              0
expl/Returns Mean                            20.2988
expl/Returns Std                             19.5597
expl/Returns Max                             44.553
expl/Returns Min                              0
expl/Actions Mean                             0.244541
expl/Actions Std                              0.807834
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.2988
expl/env_infos/final/reward_dist Mean         0.752368
expl/env_infos/final/reward_dist Std          0.782473
expl/env_infos/final/reward_dist Max          1.57072
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00100659
expl/env_infos/initial/reward_dist Std        0.00273518
expl/env_infos/initial/reward_dist Max        0.0114093
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.507471
expl/env_infos/reward_dist Std                0.656011
expl/env_infos/reward_dist Max                1.57072
expl/env_infos/reward_dist Min                0
eval/num steps total                      85600
eval/num paths total                       2140
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.665627
eval/Rewards Std                              0.711127
eval/Rewards Max                              1.57043
eval/Rewards Min                              0
eval/Returns Mean                            26.6251
eval/Returns Std                             21.7226
eval/Returns Max                             44.8301
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.6251
eval/env_infos/final/reward_dist Mean         0.941058
eval/env_infos/final/reward_dist Std          0.768373
eval/env_infos/final/reward_dist Max          1.57043
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00122565
eval/env_infos/initial/reward_dist Std        0.00367696
eval/env_infos/initial/reward_dist Max        0.0122565
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.665627
eval/env_infos/reward_dist Std                0.711127
eval/env_infos/reward_dist Max                1.57043
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00597229
time/evaluation sampling (s)                  3.54733
time/exploration sampling (s)                17.1365
time/logging (s)                              0.00727641
time/saving (s)                               0.00126706
time/training (s)                             4.52087
time/epoch (s)                               25.2192
time/total (s)                             5447.34
Epoch                                       213
---------------------------------------  ----------------
2023-08-05 01:52:21.500631 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 214 finished
---------------------------------------  ----------------
epoch                                       214
replay_buffer/size                       430000
trainer/QF Loss                               7.02224e+10
trainer/Policy Loss                          -1.46749e+06
trainer/Raw Policy Loss                      -1.46749e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.20655e+06
trainer/Q Predictions Std                186404
trainer/Q Predictions Max                     2.23299e+06
trainer/Q Predictions Min                   678.14
trainer/Q Targets Mean                        1.39497e+06
trainer/Q Targets Std                     80468.2
trainer/Q Targets Max                         2.52132e+06
trainer/Q Targets Min                    724242
trainer/Bellman Errors Mean                   7.02224e+10
trainer/Bellman Errors Std                    1.31784e+11
trainer/Bellman Errors Max                    1.85527e+12
trainer/Bellman Errors Min                 4064.06
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     430000
expl/num paths total                      10750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.554576
expl/Rewards Std                              0.659039
expl/Rewards Max                              1.57074
expl/Rewards Min                              0
expl/Returns Mean                            22.183
expl/Returns Std                             19.3805
expl/Returns Max                             44.383
expl/Returns Min                              0
expl/Actions Mean                             0.254348
expl/Actions Std                              0.807522
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.183
expl/env_infos/final/reward_dist Mean         0.803751
expl/env_infos/final/reward_dist Std          0.7756
expl/env_infos/final/reward_dist Max          1.57074
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00162578
expl/env_infos/initial/reward_dist Std        0.00491662
expl/env_infos/initial/reward_dist Max        0.0235018
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.554576
expl/env_infos/reward_dist Std                0.659039
expl/env_infos/reward_dist Max                1.57074
expl/env_infos/reward_dist Min                0
eval/num steps total                      86000
eval/num paths total                       2150
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.555956
eval/Rewards Std                              0.694461
eval/Rewards Max                              1.5706
eval/Rewards Min                              0
eval/Returns Mean                            22.2382
eval/Returns Std                             22.2199
eval/Returns Max                             44.7477
eval/Returns Min                              0.00360427
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.2382
eval/env_infos/final/reward_dist Mean         0.783553
eval/env_infos/final/reward_dist Std          0.783557
eval/env_infos/final/reward_dist Max          1.5706
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000273445
eval/env_infos/initial/reward_dist Std        0.000820334
eval/env_infos/initial/reward_dist Max        0.00273445
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.555956
eval/env_infos/reward_dist Std                0.694461
eval/env_infos/reward_dist Max                1.5706
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595079
time/evaluation sampling (s)                  4.25111
time/exploration sampling (s)                17.4064
time/logging (s)                              0.00552703
time/saving (s)                               0.00101976
time/training (s)                             4.23213
time/epoch (s)                               25.9021
time/total (s)                             5473.25
Epoch                                       214
---------------------------------------  ----------------
2023-08-05 01:52:46.946910 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 215 finished
---------------------------------------  ----------------
epoch                                       215
replay_buffer/size                       432000
trainer/QF Loss                               7.30081e+10
trainer/Policy Loss                          -1.48774e+06
trainer/Raw Policy Loss                      -1.48774e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.21827e+06
trainer/Q Predictions Std                189999
trainer/Q Predictions Max                     2.31371e+06
trainer/Q Predictions Min                  1248.76
trainer/Q Targets Mean                        1.41307e+06
trainer/Q Targets Std                     80126.9
trainer/Q Targets Max                         2.34334e+06
trainer/Q Targets Min                    762222
trainer/Bellman Errors Mean                   7.30081e+10
trainer/Bellman Errors Std                    1.34173e+11
trainer/Bellman Errors Max                    1.95833e+12
trainer/Bellman Errors Min                24336
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     432000
expl/num paths total                      10800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.499354
expl/Rewards Std                              0.651096
expl/Rewards Max                              1.57072
expl/Rewards Min                              0
expl/Returns Mean                            19.9742
expl/Returns Std                             19.7184
expl/Returns Max                             44.1082
expl/Returns Min                              0
expl/Actions Mean                             0.270396
expl/Actions Std                              0.792402
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.9742
expl/env_infos/final/reward_dist Mean         0.751795
expl/env_infos/final/reward_dist Std          0.779069
expl/env_infos/final/reward_dist Max          1.57072
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00205563
expl/env_infos/initial/reward_dist Std        0.00586226
expl/env_infos/initial/reward_dist Max        0.0282276
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.499354
expl/env_infos/reward_dist Std                0.651096
expl/env_infos/reward_dist Max                1.57072
expl/env_infos/reward_dist Min                0
eval/num steps total                      86400
eval/num paths total                       2160
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.781373
eval/Rewards Std                              0.709913
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            31.2549
eval/Returns Std                             20.4598
eval/Returns Max                             45.2706
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.2549
eval/env_infos/final/reward_dist Mean         1.09855
eval/env_infos/final/reward_dist Std          0.71917
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00132615
eval/env_infos/initial/reward_dist Std        0.00359522
eval/env_infos/initial/reward_dist Max        0.012058
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.781373
eval/env_infos/reward_dist Std                0.709913
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595448
time/evaluation sampling (s)                  3.87982
time/exploration sampling (s)                17.3453
time/logging (s)                              0.00553568
time/saving (s)                               0.00100274
time/training (s)                             4.20517
time/epoch (s)                               25.4428
time/total (s)                             5498.69
Epoch                                       215
---------------------------------------  ----------------
2023-08-05 01:53:12.627807 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 216 finished
---------------------------------------  ----------------
epoch                                       216
replay_buffer/size                       434000
trainer/QF Loss                               7.5573e+10
trainer/Policy Loss                          -1.50742e+06
trainer/Raw Policy Loss                      -1.50742e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.23473e+06
trainer/Q Predictions Std                196402
trainer/Q Predictions Max                     1.98519e+06
trainer/Q Predictions Min                   690.115
trainer/Q Targets Mean                        1.43369e+06
trainer/Q Targets Std                     78586.4
trainer/Q Targets Max                         2.14861e+06
trainer/Q Targets Min                    768518
trainer/Bellman Errors Mean                   7.5573e+10
trainer/Bellman Errors Std                    1.50206e+11
trainer/Bellman Errors Max                    2.00717e+12
trainer/Bellman Errors Min                   66.0156
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     434000
expl/num paths total                      10850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.360387
expl/Rewards Std                              0.577194
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            14.4155
expl/Returns Std                             17.8282
expl/Returns Max                             44.2026
expl/Returns Min                              0
expl/Actions Mean                             0.244206
expl/Actions Std                              0.804013
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.4155
expl/env_infos/final/reward_dist Mean         0.564966
expl/env_infos/final/reward_dist Std          0.73547
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000753894
expl/env_infos/initial/reward_dist Std        0.0035531
expl/env_infos/initial/reward_dist Max        0.0225397
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.360387
expl/env_infos/reward_dist Std                0.577194
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      86800
eval/num paths total                       2170
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.666782
eval/Rewards Std                              0.711503
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            26.6713
eval/Returns Std                             21.7731
eval/Returns Max                             44.8786
eval/Returns Min                              0.00125084
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.6713
eval/env_infos/final/reward_dist Mean         0.941178
eval/env_infos/final/reward_dist Std          0.768469
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000873253
eval/env_infos/initial/reward_dist Std        0.00261976
eval/env_infos/initial/reward_dist Max        0.00873253
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.666782
eval/env_infos/reward_dist Std                0.711503
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596796
time/evaluation sampling (s)                  3.86062
time/exploration sampling (s)                17.3809
time/logging (s)                              0.0054495
time/saving (s)                               0.00100436
time/training (s)                             4.42047
time/epoch (s)                               25.6744
time/total (s)                             5524.37
Epoch                                       216
---------------------------------------  ----------------
2023-08-05 01:53:37.801331 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 217 finished
---------------------------------------  ----------------
epoch                                       217
replay_buffer/size                       436000
trainer/QF Loss                               7.56964e+10
trainer/Policy Loss                          -1.52851e+06
trainer/Raw Policy Loss                      -1.52851e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.25589e+06
trainer/Q Predictions Std                198843
trainer/Q Predictions Max                     2.08999e+06
trainer/Q Predictions Min                   796.236
trainer/Q Targets Mean                        1.45278e+06
trainer/Q Targets Std                     79765
trainer/Q Targets Max                         2.20898e+06
trainer/Q Targets Min                    810669
trainer/Bellman Errors Mean                   7.56964e+10
trainer/Bellman Errors Std                    1.51307e+11
trainer/Bellman Errors Max                    2.08745e+12
trainer/Bellman Errors Min                 9168.06
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     436000
expl/num paths total                      10900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.441407
expl/Rewards Std                              0.62125
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            17.6563
expl/Returns Std                             18.6649
expl/Returns Max                             44.2129
expl/Returns Min                              0
expl/Actions Mean                             0.256736
expl/Actions Std                              0.807658
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.6563
expl/env_infos/final/reward_dist Mean         0.654007
expl/env_infos/final/reward_dist Std          0.761663
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000978216
expl/env_infos/initial/reward_dist Std        0.00329389
expl/env_infos/initial/reward_dist Max        0.0192927
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.441407
expl/env_infos/reward_dist Std                0.62125
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      87200
eval/num paths total                       2180
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.895473
eval/Rewards Std                              0.687134
eval/Rewards Max                              1.56996
eval/Rewards Min                              0
eval/Returns Mean                            35.8189
eval/Returns Std                             17.9065
eval/Returns Max                             45.2969
eval/Returns Min                              0.00625623
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.8189
eval/env_infos/final/reward_dist Mean         1.25228
eval/env_infos/final/reward_dist Std          0.626163
eval/env_infos/final/reward_dist Max          1.56996
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00248901
eval/env_infos/initial/reward_dist Std        0.00569759
eval/env_infos/initial/reward_dist Max        0.0192209
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.895473
eval/env_infos/reward_dist Std                0.687134
eval/env_infos/reward_dist Max                1.56996
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595211
time/evaluation sampling (s)                  3.66088
time/exploration sampling (s)                17.1944
time/logging (s)                              0.00541763
time/saving (s)                               0.0010264
time/training (s)                             4.30252
time/epoch (s)                               25.1702
time/total (s)                             5549.55
Epoch                                       217
---------------------------------------  ----------------
2023-08-05 01:54:02.661098 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 218 finished
---------------------------------------  ----------------
epoch                                       218
replay_buffer/size                       438000
trainer/QF Loss                               7.73700e+10
trainer/Policy Loss                          -1.54649e+06
trainer/Raw Policy Loss                      -1.54649e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.26529e+06
trainer/Q Predictions Std                192006
trainer/Q Predictions Max                     2.01173e+06
trainer/Q Predictions Min                  1637.45
trainer/Q Targets Mean                        1.47122e+06
trainer/Q Targets Std                     79323
trainer/Q Targets Max                         2.20513e+06
trainer/Q Targets Min                    789199
trainer/Bellman Errors Mean                   7.73700e+10
trainer/Bellman Errors Std                    1.30133e+11
trainer/Bellman Errors Max                    2.11893e+12
trainer/Bellman Errors Min                 3585.02
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     438000
expl/num paths total                      10950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.495946
expl/Rewards Std                              0.645381
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            19.8378
expl/Returns Std                             19.2859
expl/Returns Max                             44.5468
expl/Returns Min                              0
expl/Actions Mean                             0.273383
expl/Actions Std                              0.813885
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.8378
expl/env_infos/final/reward_dist Mean         0.718117
expl/env_infos/final/reward_dist Std          0.777975
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00128712
expl/env_infos/initial/reward_dist Std        0.0032544
expl/env_infos/initial/reward_dist Max        0.0160374
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.495946
expl/env_infos/reward_dist Std                0.645381
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      87600
eval/num paths total                       2190
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.664342
eval/Rewards Std                              0.710414
eval/Rewards Max                              1.57076
eval/Rewards Min                              0
eval/Returns Mean                            26.5737
eval/Returns Std                             21.6751
eval/Returns Max                             45.1311
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.5737
eval/env_infos/final/reward_dist Mean         0.942081
eval/env_infos/final/reward_dist Std          0.769206
eval/env_infos/final/reward_dist Max          1.57076
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00332414
eval/env_infos/initial/reward_dist Std        0.00720397
eval/env_infos/initial/reward_dist Max        0.0235801
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.664342
eval/env_infos/reward_dist Std                0.710414
eval/env_infos/reward_dist Max                1.57076
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595614
time/evaluation sampling (s)                  4.03931
time/exploration sampling (s)                16.9669
time/logging (s)                              0.00548984
time/saving (s)                               0.00105649
time/training (s)                             3.83767
time/epoch (s)                               24.8563
time/total (s)                             5574.4
Epoch                                       218
---------------------------------------  ----------------
2023-08-05 01:54:28.055117 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 219 finished
---------------------------------------  ----------------
epoch                                       219
replay_buffer/size                       440000
trainer/QF Loss                               8.42708e+10
trainer/Policy Loss                          -1.56705e+06
trainer/Raw Policy Loss                      -1.56705e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.2799e+06
trainer/Q Predictions Std                206039
trainer/Q Predictions Max                     2.23249e+06
trainer/Q Predictions Min                  3308.11
trainer/Q Targets Mean                        1.48988e+06
trainer/Q Targets Std                     82439
trainer/Q Targets Max                         2.2339e+06
trainer/Q Targets Min                    794049
trainer/Bellman Errors Mean                   8.42708e+10
trainer/Bellman Errors Std                    1.52092e+11
trainer/Bellman Errors Max                    2.15457e+12
trainer/Bellman Errors Min                 1251.39
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     440000
expl/num paths total                      11000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.375687
expl/Rewards Std                              0.610612
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            15.0275
expl/Returns Std                             19.475
expl/Returns Max                             44.5188
expl/Returns Min                              0
expl/Actions Mean                             0.23828
expl/Actions Std                              0.807923
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.0275
expl/env_infos/final/reward_dist Mean         0.568178
expl/env_infos/final/reward_dist Std          0.750629
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000434599
expl/env_infos/initial/reward_dist Std        0.00133276
expl/env_infos/initial/reward_dist Max        0.00571902
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.375687
expl/env_infos/reward_dist Std                0.610612
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      88000
eval/num paths total                       2200
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.636162
eval/Rewards Std                              0.697416
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            25.4465
eval/Returns Std                             21.2104
eval/Returns Max                             46.2137
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.4465
eval/env_infos/final/reward_dist Mean         0.932505
eval/env_infos/final/reward_dist Std          0.761704
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00107462
eval/env_infos/initial/reward_dist Std        0.00224058
eval/env_infos/initial/reward_dist Max        0.00678904
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.636162
eval/env_infos/reward_dist Std                0.697416
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00603128
time/evaluation sampling (s)                  3.92312
time/exploration sampling (s)                17.2846
time/logging (s)                              0.00538938
time/saving (s)                               0.000965689
time/training (s)                             4.17011
time/epoch (s)                               25.3903
time/total (s)                             5599.8
Epoch                                       219
---------------------------------------  ----------------
2023-08-05 01:54:54.241104 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 220 finished
---------------------------------------  ----------------
epoch                                       220
replay_buffer/size                       442000
trainer/QF Loss                               8.00954e+10
trainer/Policy Loss                          -1.59007e+06
trainer/Raw Policy Loss                      -1.59007e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.30584e+06
trainer/Q Predictions Std                199423
trainer/Q Predictions Max                     1.95381e+06
trainer/Q Predictions Min                 69035.5
trainer/Q Targets Mean                        1.51019e+06
trainer/Q Targets Std                     87493.9
trainer/Q Targets Max                         2.35327e+06
trainer/Q Targets Min                    781745
trainer/Bellman Errors Mean                   8.00954e+10
trainer/Bellman Errors Std                    1.37871e+11
trainer/Bellman Errors Max                    2.01651e+12
trainer/Bellman Errors Min                20988.8
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     442000
expl/num paths total                      11050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.391237
expl/Rewards Std                              0.621415
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            15.6495
expl/Returns Std                             20.1147
expl/Returns Max                             44.7005
expl/Returns Min                              0
expl/Actions Mean                             0.256125
expl/Actions Std                              0.799281
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.6495
expl/env_infos/final/reward_dist Mean         0.567212
expl/env_infos/final/reward_dist Std          0.751064
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00168671
expl/env_infos/initial/reward_dist Std        0.00521173
expl/env_infos/initial/reward_dist Max        0.0269437
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.391237
expl/env_infos/reward_dist Std                0.621415
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      88400
eval/num paths total                       2210
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.885804
eval/Rewards Std                              0.691214
eval/Rewards Max                              1.57066
eval/Rewards Min                              0
eval/Returns Mean                            35.4322
eval/Returns Std                             17.7192
eval/Returns Max                             45.4411
eval/Returns Min                              0.000890913
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.4322
eval/env_infos/final/reward_dist Mean         1.25435
eval/env_infos/final/reward_dist Std          0.62718
eval/env_infos/final/reward_dist Max          1.57066
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00205549
eval/env_infos/initial/reward_dist Std        0.00616648
eval/env_infos/initial/reward_dist Max        0.0205549
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.885804
eval/env_infos/reward_dist Std                0.691214
eval/env_infos/reward_dist Max                1.57066
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596016
time/evaluation sampling (s)                  4.82396
time/exploration sampling (s)                17.0908
time/logging (s)                              0.00549015
time/saving (s)                               0.00102825
time/training (s)                             4.25453
time/epoch (s)                               26.1818
time/total (s)                             5625.98
Epoch                                       220
---------------------------------------  ----------------
2023-08-05 01:55:18.910335 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 221 finished
---------------------------------------  ----------------
epoch                                       221
replay_buffer/size                       444000
trainer/QF Loss                               8.48254e+10
trainer/Policy Loss                          -1.60706e+06
trainer/Raw Policy Loss                      -1.60706e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.31549e+06
trainer/Q Predictions Std                204239
trainer/Q Predictions Max                     2.22607e+06
trainer/Q Predictions Min                   720.5
trainer/Q Targets Mean                        1.5285e+06
trainer/Q Targets Std                     81904.3
trainer/Q Targets Max                         2.18024e+06
trainer/Q Targets Min                    811947
trainer/Bellman Errors Mean                   8.48254e+10
trainer/Bellman Errors Std                    1.53826e+11
trainer/Bellman Errors Max                    2.30181e+12
trainer/Bellman Errors Min                    0.5625
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     444000
expl/num paths total                      11100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.448845
expl/Rewards Std                              0.636595
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            17.9538
expl/Returns Std                             19.7295
expl/Returns Max                             43.5944
expl/Returns Min                              0
expl/Actions Mean                             0.264984
expl/Actions Std                              0.799606
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.9538
expl/env_infos/final/reward_dist Mean         0.685561
expl/env_infos/final/reward_dist Std          0.771615
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000623154
expl/env_infos/initial/reward_dist Std        0.00234309
expl/env_infos/initial/reward_dist Max        0.0143423
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.448845
expl/env_infos/reward_dist Std                0.636595
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      88800
eval/num paths total                       2220
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.607716
eval/Rewards Std                              0.689393
eval/Rewards Max                              1.56961
eval/Rewards Min                              0
eval/Returns Mean                            24.3086
eval/Returns Std                             21.0411
eval/Returns Max                             45.2707
eval/Returns Min                              0.00123105
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.3086
eval/env_infos/final/reward_dist Mean         0.930515
eval/env_infos/final/reward_dist Std          0.76025
eval/env_infos/final/reward_dist Max          1.56961
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000191054
eval/env_infos/initial/reward_dist Std        0.000544251
eval/env_infos/initial/reward_dist Max        0.00182188
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.607716
eval/env_infos/reward_dist Std                0.689393
eval/env_infos/reward_dist Max                1.56961
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593967
time/evaluation sampling (s)                  3.52493
time/exploration sampling (s)                17.0081
time/logging (s)                              0.0055321
time/saving (s)                               0.00101944
time/training (s)                             4.12023
time/epoch (s)                               24.6658
time/total (s)                             5650.65
Epoch                                       221
---------------------------------------  ----------------
2023-08-05 01:55:45.290976 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 222 finished
---------------------------------------  ----------------
epoch                                       222
replay_buffer/size                       446000
trainer/QF Loss                               8.93878e+10
trainer/Policy Loss                          -1.62982e+06
trainer/Raw Policy Loss                      -1.62982e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.32945e+06
trainer/Q Predictions Std                206332
trainer/Q Predictions Max                     2.53335e+06
trainer/Q Predictions Min                  1348.72
trainer/Q Targets Mean                        1.55013e+06
trainer/Q Targets Std                     89725.3
trainer/Q Targets Max                         2.56585e+06
trainer/Q Targets Min                    838817
trainer/Bellman Errors Mean                   8.93878e+10
trainer/Bellman Errors Std                    1.5647e+11
trainer/Bellman Errors Max                    2.25518e+12
trainer/Bellman Errors Min               120583
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     446000
expl/num paths total                      11150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.608497
expl/Rewards Std                              0.680197
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            24.3399
expl/Returns Std                             19.7419
expl/Returns Max                             45.2284
expl/Returns Min                              0
expl/Actions Mean                             0.263569
expl/Actions Std                              0.804796
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.3399
expl/env_infos/final/reward_dist Mean         0.955986
expl/env_infos/final/reward_dist Std          0.757491
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00128234
expl/env_infos/initial/reward_dist Std        0.00483394
expl/env_infos/initial/reward_dist Max        0.0256304
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.608497
expl/env_infos/reward_dist Std                0.680197
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      89200
eval/num paths total                       2230
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.66867
eval/Rewards Std                              0.710407
eval/Rewards Max                              1.57042
eval/Rewards Min                              0
eval/Returns Mean                            26.7468
eval/Returns Std                             21.8286
eval/Returns Max                             45.1833
eval/Returns Min                              0.00186343
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.7468
eval/env_infos/final/reward_dist Mean         0.939863
eval/env_infos/final/reward_dist Std          0.767401
eval/env_infos/final/reward_dist Max          1.57042
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00282677
eval/env_infos/initial/reward_dist Std        0.00580671
eval/env_infos/initial/reward_dist Max        0.0170964
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.66867
eval/env_infos/reward_dist Std                0.710407
eval/env_infos/reward_dist Max                1.57042
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589758
time/evaluation sampling (s)                  4.53634
time/exploration sampling (s)                16.9558
time/logging (s)                              0.00785705
time/saving (s)                               0.00134905
time/training (s)                             4.87235
time/epoch (s)                               26.3796
time/total (s)                             5677.03
Epoch                                       222
---------------------------------------  ----------------
2023-08-05 01:56:10.437127 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 223 finished
---------------------------------------  ----------------
epoch                                       223
replay_buffer/size                       448000
trainer/QF Loss                               8.53452e+10
trainer/Policy Loss                          -1.65012e+06
trainer/Raw Policy Loss                      -1.65012e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.3537e+06
trainer/Q Predictions Std                202760
trainer/Q Predictions Max                     2.45976e+06
trainer/Q Predictions Min                   732.837
trainer/Q Targets Mean                        1.56881e+06
trainer/Q Targets Std                     81426.1
trainer/Q Targets Max                         2.21291e+06
trainer/Q Targets Min                    961552
trainer/Bellman Errors Mean                   8.53452e+10
trainer/Bellman Errors Std                    1.46818e+11
trainer/Bellman Errors Max                    2.42726e+12
trainer/Bellman Errors Min                  206.641
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     448000
expl/num paths total                      11200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.535957
expl/Rewards Std                              0.673839
expl/Rewards Max                              1.57072
expl/Rewards Min                              0
expl/Returns Mean                            21.4383
expl/Returns Std                             20.6791
expl/Returns Max                             44.0034
expl/Returns Min                              0
expl/Actions Mean                             0.267431
expl/Actions Std                              0.802632
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.4383
expl/env_infos/final/reward_dist Mean         0.815794
expl/env_infos/final/reward_dist Std          0.783368
expl/env_infos/final/reward_dist Max          1.57072
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00185333
expl/env_infos/initial/reward_dist Std        0.00412102
expl/env_infos/initial/reward_dist Max        0.0172455
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.535957
expl/env_infos/reward_dist Std                0.673839
expl/env_infos/reward_dist Max                1.57072
expl/env_infos/reward_dist Min                0
eval/num steps total                      89600
eval/num paths total                       2240
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.447777
eval/Rewards Std                              0.630385
eval/Rewards Max                              1.57068
eval/Rewards Min                              0
eval/Returns Mean                            17.9111
eval/Returns Std                             19.5244
eval/Returns Max                             45.3317
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.9111
eval/env_infos/final/reward_dist Mean         0.767127
eval/env_infos/final/reward_dist Std          0.767763
eval/env_infos/final/reward_dist Max          1.57068
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00220184
eval/env_infos/initial/reward_dist Std        0.00660551
eval/env_infos/initial/reward_dist Max        0.0220184
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.447777
eval/env_infos/reward_dist Std                0.630385
eval/env_infos/reward_dist Max                1.57068
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00600769
time/evaluation sampling (s)                  3.63934
time/exploration sampling (s)                17.2305
time/logging (s)                              0.0057486
time/saving (s)                               0.00101586
time/training (s)                             4.25564
time/epoch (s)                               25.1382
time/total (s)                             5702.17
Epoch                                       223
---------------------------------------  ----------------
2023-08-05 01:56:36.008673 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 224 finished
---------------------------------------  ----------------
epoch                                       224
replay_buffer/size                       450000
trainer/QF Loss                               9.47375e+10
trainer/Policy Loss                          -1.67341e+06
trainer/Raw Policy Loss                      -1.67341e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.36831e+06
trainer/Q Predictions Std                217968
trainer/Q Predictions Max                     2.77839e+06
trainer/Q Predictions Min                  2588.85
trainer/Q Targets Mean                        1.59041e+06
trainer/Q Targets Std                     93932.1
trainer/Q Targets Max                         2.83676e+06
trainer/Q Targets Min                    839813
trainer/Bellman Errors Mean                   9.47375e+10
trainer/Bellman Errors Std                    1.78017e+11
trainer/Bellman Errors Max                    2.68762e+12
trainer/Bellman Errors Min                 3797.64
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     450000
expl/num paths total                      11250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.433683
expl/Rewards Std                              0.639984
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            17.3473
expl/Returns Std                             20.2461
expl/Returns Max                             44.2306
expl/Returns Min                              0
expl/Actions Mean                             0.259677
expl/Actions Std                              0.808499
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.3473
expl/env_infos/final/reward_dist Mean         0.670882
expl/env_infos/final/reward_dist Std          0.763721
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000349952
expl/env_infos/initial/reward_dist Std        0.00159747
expl/env_infos/initial/reward_dist Max        0.0103713
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.433683
expl/env_infos/reward_dist Std                0.639984
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      90000
eval/num paths total                       2250
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.274729
eval/Rewards Std                              0.540284
eval/Rewards Max                              1.5701
eval/Rewards Min                              0
eval/Returns Mean                            10.9892
eval/Returns Std                             17.3173
eval/Returns Max                             44.8079
eval/Returns Min                              0.0032583
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         10.9892
eval/env_infos/final/reward_dist Mean         0.464651
eval/env_infos/final/reward_dist Std          0.708848
eval/env_infos/final/reward_dist Max          1.5701
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000193686
eval/env_infos/initial/reward_dist Std        0.000581057
eval/env_infos/initial/reward_dist Max        0.00193686
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.274729
eval/env_infos/reward_dist Std                0.540284
eval/env_infos/reward_dist Max                1.5701
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593248
time/evaluation sampling (s)                  3.75654
time/exploration sampling (s)                17.3339
time/logging (s)                              0.00538013
time/saving (s)                               0.000996868
time/training (s)                             4.46185
time/epoch (s)                               25.5646
time/total (s)                             5727.74
Epoch                                       224
---------------------------------------  ----------------
2023-08-05 01:57:01.030843 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 225 finished
---------------------------------------  ----------------
epoch                                       225
replay_buffer/size                       452000
trainer/QF Loss                               9.3025e+10
trainer/Policy Loss                          -1.69383e+06
trainer/Raw Policy Loss                      -1.69383e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.38371e+06
trainer/Q Predictions Std                213195
trainer/Q Predictions Max                     2.41003e+06
trainer/Q Predictions Min                  1829.76
trainer/Q Targets Mean                        1.6089e+06
trainer/Q Targets Std                     90407.6
trainer/Q Targets Max                         2.49681e+06
trainer/Q Targets Min                    848334
trainer/Bellman Errors Mean                   9.3025e+10
trainer/Bellman Errors Std                    1.58197e+11
trainer/Bellman Errors Max                    2.52707e+12
trainer/Bellman Errors Min                 3675.39
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     452000
expl/num paths total                      11300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.496975
expl/Rewards Std                              0.645878
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            19.879
expl/Returns Std                             19.3346
expl/Returns Max                             44.2925
expl/Returns Min                              0
expl/Actions Mean                             0.250727
expl/Actions Std                              0.797311
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.879
expl/env_infos/final/reward_dist Mean         0.721838
expl/env_infos/final/reward_dist Std          0.781818
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00143124
expl/env_infos/initial/reward_dist Std        0.00399449
expl/env_infos/initial/reward_dist Max        0.0175594
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.496975
expl/env_infos/reward_dist Std                0.645878
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      90400
eval/num paths total                       2260
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.230352
eval/Rewards Std                              0.524152
eval/Rewards Max                              1.57054
eval/Rewards Min                              0
eval/Returns Mean                             9.21408
eval/Returns Std                             18.2638
eval/Returns Max                             46.0969
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          9.21408
eval/env_infos/final/reward_dist Mean         0.321268
eval/env_infos/final/reward_dist Std          0.624894
eval/env_infos/final/reward_dist Max          1.57054
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00097296
eval/env_infos/initial/reward_dist Std        0.00195006
eval/env_infos/initial/reward_dist Max        0.00514862
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.230352
eval/env_infos/reward_dist Std                0.524152
eval/env_infos/reward_dist Max                1.57054
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00694863
time/evaluation sampling (s)                  3.53609
time/exploration sampling (s)                17.0402
time/logging (s)                              0.00536487
time/saving (s)                               0.000969207
time/training (s)                             4.42904
time/epoch (s)                               25.0186
time/total (s)                             5752.76
Epoch                                       225
---------------------------------------  ----------------
2023-08-05 01:57:26.332423 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 226 finished
---------------------------------------  ----------------
epoch                                       226
replay_buffer/size                       454000
trainer/QF Loss                               9.63224e+10
trainer/Policy Loss                          -1.71612e+06
trainer/Raw Policy Loss                      -1.71612e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.40722e+06
trainer/Q Predictions Std                222419
trainer/Q Predictions Max                     2.27607e+06
trainer/Q Predictions Min                  2083.73
trainer/Q Targets Mean                        1.63123e+06
trainer/Q Targets Std                     92381.4
trainer/Q Targets Max                         2.3313e+06
trainer/Q Targets Min                    876277
trainer/Bellman Errors Mean                   9.63224e+10
trainer/Bellman Errors Std                    1.76371e+11
trainer/Bellman Errors Max                    2.53023e+12
trainer/Bellman Errors Min                64579.5
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     454000
expl/num paths total                      11350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.439961
expl/Rewards Std                              0.638461
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            17.5984
expl/Returns Std                             20.3898
expl/Returns Max                             44.8734
expl/Returns Min                              0
expl/Actions Mean                             0.26951
expl/Actions Std                              0.8009
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.5984
expl/env_infos/final/reward_dist Mean         0.643157
expl/env_infos/final/reward_dist Std          0.763823
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00170124
expl/env_infos/initial/reward_dist Std        0.00487642
expl/env_infos/initial/reward_dist Max        0.0224574
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.439961
expl/env_infos/reward_dist Std                0.638461
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      90800
eval/num paths total                       2270
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.797956
eval/Rewards Std                              0.692132
eval/Rewards Max                              1.57058
eval/Rewards Min                              0
eval/Returns Mean                            31.9183
eval/Returns Std                             18.9664
eval/Returns Max                             44.6725
eval/Returns Min                              0.00697209
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.9183
eval/env_infos/final/reward_dist Mean         1.18332
eval/env_infos/final/reward_dist Std          0.629225
eval/env_infos/final/reward_dist Max          1.57058
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.797956
eval/env_infos/reward_dist Std                0.692132
eval/env_infos/reward_dist Max                1.57058
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590459
time/evaluation sampling (s)                  4.01555
time/exploration sampling (s)                16.9348
time/logging (s)                              0.00546898
time/saving (s)                               0.00109062
time/training (s)                             4.33498
time/epoch (s)                               25.2978
time/total (s)                             5778.06
Epoch                                       226
---------------------------------------  ----------------
2023-08-05 01:57:51.830816 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 227 finished
---------------------------------------  ----------------
epoch                                       227
replay_buffer/size                       456000
trainer/QF Loss                               9.89155e+10
trainer/Policy Loss                          -1.73616e+06
trainer/Raw Policy Loss                      -1.73616e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.41895e+06
trainer/Q Predictions Std                220440
trainer/Q Predictions Max                     2.13844e+06
trainer/Q Predictions Min                  1836.85
trainer/Q Targets Mean                        1.64707e+06
trainer/Q Targets Std                     97716.6
trainer/Q Targets Max                         2.56018e+06
trainer/Q Targets Min                    893808
trainer/Bellman Errors Mean                   9.89155e+10
trainer/Bellman Errors Std                    1.7123e+11
trainer/Bellman Errors Max                    2.65698e+12
trainer/Bellman Errors Min                26244
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     456000
expl/num paths total                      11400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.331919
expl/Rewards Std                              0.571716
expl/Rewards Max                              1.57062
expl/Rewards Min                              0
expl/Returns Mean                            13.2768
expl/Returns Std                             18.2528
expl/Returns Max                             44.7933
expl/Returns Min                              0
expl/Actions Mean                             0.254246
expl/Actions Std                              0.804863
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.2768
expl/env_infos/final/reward_dist Mean         0.530365
expl/env_infos/final/reward_dist Std          0.715435
expl/env_infos/final/reward_dist Max          1.57062
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000901967
expl/env_infos/initial/reward_dist Std        0.00350501
expl/env_infos/initial/reward_dist Max        0.0205798
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.331919
expl/env_infos/reward_dist Std                0.571716
expl/env_infos/reward_dist Max                1.57062
expl/env_infos/reward_dist Min                0
eval/num steps total                      91200
eval/num paths total                       2280
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.556779
eval/Rewards Std                              0.695615
eval/Rewards Max                              1.57028
eval/Rewards Min                              0
eval/Returns Mean                            22.2712
eval/Returns Std                             22.2642
eval/Returns Max                             44.9219
eval/Returns Min                              0.00156208
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.2712
eval/env_infos/final/reward_dist Mean         0.7843
eval/env_infos/final/reward_dist Std          0.784301
eval/env_infos/final/reward_dist Max          1.57028
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000581079
eval/env_infos/initial/reward_dist Std        0.00174324
eval/env_infos/initial/reward_dist Max        0.00581079
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.556779
eval/env_infos/reward_dist Std                0.695615
eval/env_infos/reward_dist Max                1.57028
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593998
time/evaluation sampling (s)                  4.16468
time/exploration sampling (s)                17.0161
time/logging (s)                              0.00542127
time/saving (s)                               0.00101108
time/training (s)                             4.2985
time/epoch (s)                               25.4917
time/total (s)                             5803.56
Epoch                                       227
---------------------------------------  ----------------
2023-08-05 01:58:18.424242 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 228 finished
---------------------------------------  ----------------
epoch                                       228
replay_buffer/size                       458000
trainer/QF Loss                               1.05332e+11
trainer/Policy Loss                          -1.75717e+06
trainer/Raw Policy Loss                      -1.75717e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.43801e+06
trainer/Q Predictions Std                230405
trainer/Q Predictions Max                     2.43955e+06
trainer/Q Predictions Min                  1042.94
trainer/Q Targets Mean                        1.67159e+06
trainer/Q Targets Std                     95657.8
trainer/Q Targets Max                         2.38986e+06
trainer/Q Targets Min                    885009
trainer/Bellman Errors Mean                   1.05332e+11
trainer/Bellman Errors Std                    2.06645e+11
trainer/Bellman Errors Max                    2.7826e+12
trainer/Bellman Errors Min                 1000.14
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     458000
expl/num paths total                      11450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.511125
expl/Rewards Std                              0.661588
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            20.445
expl/Returns Std                             20.0867
expl/Returns Max                             44.823
expl/Returns Min                              0
expl/Actions Mean                             0.268223
expl/Actions Std                              0.805615
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.445
expl/env_infos/final/reward_dist Mean         0.77171
expl/env_infos/final/reward_dist Std          0.776098
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00123328
expl/env_infos/initial/reward_dist Std        0.00423862
expl/env_infos/initial/reward_dist Max        0.024432
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.511125
expl/env_infos/reward_dist Std                0.661588
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      91600
eval/num paths total                       2290
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.556987
eval/Rewards Std                              0.694482
eval/Rewards Max                              1.57019
eval/Rewards Min                              0
eval/Returns Mean                            22.2795
eval/Returns Std                             22.2701
eval/Returns Max                             45.313
eval/Returns Min                              0.00502239
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.2795
eval/env_infos/final/reward_dist Mean         0.784213
eval/env_infos/final/reward_dist Std          0.784062
eval/env_infos/final/reward_dist Max          1.57019
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00355454
eval/env_infos/initial/reward_dist Std        0.00713935
eval/env_infos/initial/reward_dist Max        0.0220676
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.556987
eval/env_infos/reward_dist Std                0.694482
eval/env_infos/reward_dist Max                1.57019
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588421
time/evaluation sampling (s)                  4.62117
time/exploration sampling (s)                17.5984
time/logging (s)                              0.00545157
time/saving (s)                               0.00107004
time/training (s)                             4.35788
time/epoch (s)                               26.5899
time/total (s)                             5830.15
Epoch                                       228
---------------------------------------  ----------------
2023-08-05 01:58:44.060617 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 229 finished
---------------------------------------  ----------------
epoch                                       229
replay_buffer/size                       460000
trainer/QF Loss                               1.02608e+11
trainer/Policy Loss                          -1.77665e+06
trainer/Raw Policy Loss                      -1.77665e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.45357e+06
trainer/Q Predictions Std                223986
trainer/Q Predictions Max                     2.3009e+06
trainer/Q Predictions Min                   770.462
trainer/Q Targets Mean                        1.6889e+06
trainer/Q Targets Std                     92815
trainer/Q Targets Max                         2.4308e+06
trainer/Q Targets Min                    897598
trainer/Bellman Errors Mean                   1.02608e+11
trainer/Bellman Errors Std                    1.82325e+11
trainer/Bellman Errors Max                    2.75661e+12
trainer/Bellman Errors Min                12376.6
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     460000
expl/num paths total                      11500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.519389
expl/Rewards Std                              0.654083
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            20.7756
expl/Returns Std                             19.6354
expl/Returns Max                             44.1519
expl/Returns Min                              0
expl/Actions Mean                             0.266183
expl/Actions Std                              0.798319
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.7756
expl/env_infos/final/reward_dist Mean         0.773851
expl/env_infos/final/reward_dist Std          0.774519
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000856835
expl/env_infos/initial/reward_dist Std        0.00383378
expl/env_infos/initial/reward_dist Max        0.0264816
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.519389
expl/env_infos/reward_dist Std                0.654083
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      92000
eval/num paths total                       2300
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.607696
eval/Rewards Std                              0.689885
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            24.3079
eval/Returns Std                             21.1268
eval/Returns Max                             45.5825
eval/Returns Min                              0.00121441
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.3079
eval/env_infos/final/reward_dist Mean         0.940855
eval/env_infos/final/reward_dist Std          0.768209
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00217352
eval/env_infos/initial/reward_dist Std        0.00652057
eval/env_infos/initial/reward_dist Max        0.0217352
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.607696
eval/env_infos/reward_dist Std                0.689885
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594052
time/evaluation sampling (s)                  4.15405
time/exploration sampling (s)                17.1392
time/logging (s)                              0.00536893
time/saving (s)                               0.000962624
time/training (s)                             4.32726
time/epoch (s)                               25.6328
time/total (s)                             5855.79
Epoch                                       229
---------------------------------------  ----------------
2023-08-05 01:59:08.957267 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 230 finished
---------------------------------------  ----------------
epoch                                       230
replay_buffer/size                       462000
trainer/QF Loss                               1.09726e+11
trainer/Policy Loss                          -1.80034e+06
trainer/Raw Policy Loss                      -1.80034e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.46886e+06
trainer/Q Predictions Std                234798
trainer/Q Predictions Max                     2.54621e+06
trainer/Q Predictions Min                   776.823
trainer/Q Targets Mean                        1.71458e+06
trainer/Q Targets Std                     87631.5
trainer/Q Targets Max                         2.56585e+06
trainer/Q Targets Min                         1.04133e+06
trainer/Bellman Errors Mean                   1.09726e+11
trainer/Bellman Errors Std                    1.9893e+11
trainer/Bellman Errors Max                    2.89582e+12
trainer/Bellman Errors Min                  319.516
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     462000
expl/num paths total                      11550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.298388
expl/Rewards Std                              0.561817
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            11.9355
expl/Returns Std                             18.5105
expl/Returns Max                             43.6551
expl/Returns Min                              0
expl/Actions Mean                             0.271882
expl/Actions Std                              0.789636
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         11.9355
expl/env_infos/final/reward_dist Mean         0.459549
expl/env_infos/final/reward_dist Std          0.699007
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00115435
expl/env_infos/initial/reward_dist Std        0.00354873
expl/env_infos/initial/reward_dist Max        0.0183734
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.298388
expl/env_infos/reward_dist Std                0.561817
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      92400
eval/num paths total                       2310
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.468744
eval/Rewards Std                              0.641295
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            18.7498
eval/Returns Std                             19.991
eval/Returns Max                             45.7203
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         18.7498
eval/env_infos/final/reward_dist Mean         0.769247
eval/env_infos/final/reward_dist Std          0.769726
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0027152
eval/env_infos/initial/reward_dist Std        0.00731114
eval/env_infos/initial/reward_dist Max        0.0245899
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.468744
eval/env_infos/reward_dist Std                0.641295
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596709
time/evaluation sampling (s)                  3.90627
time/exploration sampling (s)                16.9494
time/logging (s)                              0.00542675
time/saving (s)                               0.00105957
time/training (s)                             4.02463
time/epoch (s)                               24.8927
time/total (s)                             5880.68
Epoch                                       230
---------------------------------------  ----------------
2023-08-05 01:59:34.599337 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 231 finished
---------------------------------------  ----------------
epoch                                       231
replay_buffer/size                       464000
trainer/QF Loss                               1.09333e+11
trainer/Policy Loss                          -1.82268e+06
trainer/Raw Policy Loss                      -1.82268e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.49276e+06
trainer/Q Predictions Std                232658
trainer/Q Predictions Max                     2.5184e+06
trainer/Q Predictions Min                  1735.63
trainer/Q Targets Mean                        1.73254e+06
trainer/Q Targets Std                     99918.4
trainer/Q Targets Max                         2.57812e+06
trainer/Q Targets Min                    937317
trainer/Bellman Errors Mean                   1.09333e+11
trainer/Bellman Errors Std                    2.0734e+11
trainer/Bellman Errors Max                    2.83508e+12
trainer/Bellman Errors Min                 7182.56
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     464000
expl/num paths total                      11600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.618152
expl/Rewards Std                              0.679489
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            24.7261
expl/Returns Std                             19.5367
expl/Returns Max                             44.5842
expl/Returns Min                              0
expl/Actions Mean                             0.26046
expl/Actions Std                              0.807351
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.7261
expl/env_infos/final/reward_dist Mean         0.935731
expl/env_infos/final/reward_dist Std          0.76451
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000863371
expl/env_infos/initial/reward_dist Std        0.00294151
expl/env_infos/initial/reward_dist Max        0.0145107
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.618152
expl/env_infos/reward_dist Std                0.679489
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      92800
eval/num paths total                       2320
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.781853
eval/Rewards Std                              0.710538
eval/Rewards Max                              1.57055
eval/Rewards Min                              0
eval/Returns Mean                            31.2741
eval/Returns Std                             20.4703
eval/Returns Max                             45.6943
eval/Returns Min                              0.00221133
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.2741
eval/env_infos/final/reward_dist Mean         1.09849
eval/env_infos/final/reward_dist Std          0.719131
eval/env_infos/final/reward_dist Max          1.57055
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00075628
eval/env_infos/initial/reward_dist Std        0.00226884
eval/env_infos/initial/reward_dist Max        0.0075628
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.781853
eval/env_infos/reward_dist Std                0.710538
eval/env_infos/reward_dist Max                1.57055
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00600101
time/evaluation sampling (s)                  3.9898
time/exploration sampling (s)                17.2027
time/logging (s)                              0.00546545
time/saving (s)                               0.0010355
time/training (s)                             4.43297
time/epoch (s)                               25.638
time/total (s)                             5906.32
Epoch                                       231
---------------------------------------  ----------------
2023-08-05 02:00:00.344941 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 232 finished
---------------------------------------  ----------------
epoch                                       232
replay_buffer/size                       466000
trainer/QF Loss                               1.10718e+11
trainer/Policy Loss                          -1.84502e+06
trainer/Raw Policy Loss                      -1.84502e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.51501e+06
trainer/Q Predictions Std                234424
trainer/Q Predictions Max                     2.47e+06
trainer/Q Predictions Min                   789.621
trainer/Q Targets Mean                        1.75376e+06
trainer/Q Targets Std                     95122.7
trainer/Q Targets Max                         2.72139e+06
trainer/Q Targets Min                    953138
trainer/Bellman Errors Mean                   1.10718e+11
trainer/Bellman Errors Std                    2.09248e+11
trainer/Bellman Errors Max                    3.02918e+12
trainer/Bellman Errors Min                 5606.27
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     466000
expl/num paths total                      11650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.447493
expl/Rewards Std                              0.628352
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            17.8997
expl/Returns Std                             19.414
expl/Returns Max                             44.8658
expl/Returns Min                              0
expl/Actions Mean                             0.249073
expl/Actions Std                              0.806884
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.8997
expl/env_infos/final/reward_dist Mean         0.706215
expl/env_infos/final/reward_dist Std          0.770024
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00104185
expl/env_infos/initial/reward_dist Std        0.00296377
expl/env_infos/initial/reward_dist Max        0.0124055
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.447493
expl/env_infos/reward_dist Std                0.628352
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      93200
eval/num paths total                       2330
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.45354
eval/Rewards Std                              0.663238
eval/Rewards Max                              1.56922
eval/Rewards Min                              0
eval/Returns Mean                            18.1416
eval/Returns Std                             22.2191
eval/Returns Max                             46.6026
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         18.1416
eval/env_infos/final/reward_dist Mean         0.625959
eval/env_infos/final/reward_dist Std          0.766649
eval/env_infos/final/reward_dist Max          1.56922
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00663701
eval/env_infos/initial/reward_dist Std        0.0108339
eval/env_infos/initial/reward_dist Max        0.0291948
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.45354
eval/env_infos/reward_dist Std                0.663238
eval/env_infos/reward_dist Max                1.56922
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00600799
time/evaluation sampling (s)                  4.01565
time/exploration sampling (s)                17.4192
time/logging (s)                              0.00546334
time/saving (s)                               0.000977073
time/training (s)                             4.29403
time/epoch (s)                               25.7413
time/total (s)                             5932.07
Epoch                                       232
---------------------------------------  ----------------
2023-08-05 02:00:25.435207 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 233 finished
---------------------------------------  ----------------
epoch                                       233
replay_buffer/size                       468000
trainer/QF Loss                               1.13909e+11
trainer/Policy Loss                          -1.86704e+06
trainer/Raw Policy Loss                      -1.86704e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.52847e+06
trainer/Q Predictions Std                233284
trainer/Q Predictions Max                     2.52839e+06
trainer/Q Predictions Min                   796.057
trainer/Q Targets Mean                        1.7751e+06
trainer/Q Targets Std                     99398.6
trainer/Q Targets Max                         2.6204e+06
trainer/Q Targets Min                    936574
trainer/Bellman Errors Mean                   1.13909e+11
trainer/Bellman Errors Std                    1.9758e+11
trainer/Bellman Errors Max                    3.01692e+12
trainer/Bellman Errors Min                 1732.64
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     468000
expl/num paths total                      11700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.531613
expl/Rewards Std                              0.659523
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            21.2645
expl/Returns Std                             19.634
expl/Returns Max                             44.7821
expl/Returns Min                              0
expl/Actions Mean                             0.265502
expl/Actions Std                              0.798203
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.2645
expl/env_infos/final/reward_dist Mean         0.81049
expl/env_infos/final/reward_dist Std          0.779578
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00112648
expl/env_infos/initial/reward_dist Std        0.00340647
expl/env_infos/initial/reward_dist Max        0.0162698
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.531613
expl/env_infos/reward_dist Std                0.659523
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      93600
eval/num paths total                       2340
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.625532
eval/Rewards Std                              0.691476
eval/Rewards Max                              1.57042
eval/Rewards Min                              0
eval/Returns Mean                            25.0213
eval/Returns Std                             20.781
eval/Returns Max                             45.1193
eval/Returns Min                              0.000485091
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.0213
eval/env_infos/final/reward_dist Mean         0.932702
eval/env_infos/final/reward_dist Std          0.761757
eval/env_infos/final/reward_dist Max          1.57042
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00226162
eval/env_infos/initial/reward_dist Std        0.00633693
eval/env_infos/initial/reward_dist Max        0.0212395
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.625532
eval/env_infos/reward_dist Std                0.691476
eval/env_infos/reward_dist Max                1.57042
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00609914
time/evaluation sampling (s)                  3.57303
time/exploration sampling (s)                17.1302
time/logging (s)                              0.00543919
time/saving (s)                               0.000989248
time/training (s)                             4.37007
time/epoch (s)                               25.0858
time/total (s)                             5957.15
Epoch                                       233
---------------------------------------  ----------------
2023-08-05 02:00:50.364128 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 234 finished
---------------------------------------  ----------------
epoch                                       234
replay_buffer/size                       470000
trainer/QF Loss                               1.17972e+11
trainer/Policy Loss                          -1.89036e+06
trainer/Raw Policy Loss                      -1.89036e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.54724e+06
trainer/Q Predictions Std                241050
trainer/Q Predictions Max                     2.6666e+06
trainer/Q Predictions Min                  1381.81
trainer/Q Targets Mean                        1.79564e+06
trainer/Q Targets Std                    100712
trainer/Q Targets Max                         2.6536e+06
trainer/Q Targets Min                    975916
trainer/Bellman Errors Mean                   1.17972e+11
trainer/Bellman Errors Std                    2.12896e+11
trainer/Bellman Errors Max                    3.23127e+12
trainer/Bellman Errors Min                  156.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     470000
expl/num paths total                      11750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.536746
expl/Rewards Std                              0.661224
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            21.4698
expl/Returns Std                             19.6038
expl/Returns Max                             44.7419
expl/Returns Min                              0
expl/Actions Mean                             0.259311
expl/Actions Std                              0.798423
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.4698
expl/env_infos/final/reward_dist Mean         0.813912
expl/env_infos/final/reward_dist Std          0.781621
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00197801
expl/env_infos/initial/reward_dist Std        0.00474881
expl/env_infos/initial/reward_dist Max        0.0217265
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.536746
expl/env_infos/reward_dist Std                0.661224
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      94000
eval/num paths total                       2350
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.448311
eval/Rewards Std                              0.661775
eval/Rewards Max                              1.57048
eval/Rewards Min                              0
eval/Returns Mean                            17.9324
eval/Returns Std                             21.9166
eval/Returns Max                             45.4468
eval/Returns Min                              0.0014075
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.9324
eval/env_infos/final/reward_dist Mean         0.628285
eval/env_infos/final/reward_dist Std          0.767749
eval/env_infos/final/reward_dist Max          1.57048
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000149536
eval/env_infos/initial/reward_dist Std        0.000448607
eval/env_infos/initial/reward_dist Max        0.00149536
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.448311
eval/env_infos/reward_dist Std                0.661775
eval/env_infos/reward_dist Max                1.57048
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00607508
time/evaluation sampling (s)                  3.6161
time/exploration sampling (s)                17.0024
time/logging (s)                              0.00535604
time/saving (s)                               0.00101858
time/training (s)                             4.2944
time/epoch (s)                               24.9253
time/total (s)                             5982.08
Epoch                                       234
---------------------------------------  ----------------
2023-08-05 02:01:15.422318 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 235 finished
---------------------------------------  ----------------
epoch                                       235
replay_buffer/size                       472000
trainer/QF Loss                               1.22425e+11
trainer/Policy Loss                          -1.91584e+06
trainer/Raw Policy Loss                      -1.91584e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.56702e+06
trainer/Q Predictions Std                246482
trainer/Q Predictions Max                     2.63166e+06
trainer/Q Predictions Min                  3230.1
trainer/Q Targets Mean                        1.82286e+06
trainer/Q Targets Std                    103374
trainer/Q Targets Max                         2.67059e+06
trainer/Q Targets Min                    980248
trainer/Bellman Errors Mean                   1.22425e+11
trainer/Bellman Errors Std                    2.25788e+11
trainer/Bellman Errors Max                    3.07638e+12
trainer/Bellman Errors Min                    5.64062
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     472000
expl/num paths total                      11800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.479457
expl/Rewards Std                              0.642296
expl/Rewards Max                              1.57062
expl/Rewards Min                              0
expl/Returns Mean                            19.1783
expl/Returns Std                             19.6339
expl/Returns Max                             44.223
expl/Returns Min                              0
expl/Actions Mean                             0.265825
expl/Actions Std                              0.805473
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.1783
expl/env_infos/final/reward_dist Mean         0.744253
expl/env_infos/final/reward_dist Std          0.76197
expl/env_infos/final/reward_dist Max          1.57062
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00124067
expl/env_infos/initial/reward_dist Std        0.00403723
expl/env_infos/initial/reward_dist Max        0.0213861
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.479457
expl/env_infos/reward_dist Std                0.642296
expl/env_infos/reward_dist Max                1.57062
expl/env_infos/reward_dist Min                0
eval/num steps total                      94400
eval/num paths total                       2360
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.0081
eval/Rewards Std                              0.649155
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            40.3241
eval/Returns Std                             13.4486
eval/Returns Max                             45.5103
eval/Returns Min                              0.00491516
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         40.3241
eval/env_infos/final/reward_dist Mean         1.41254
eval/env_infos/final/reward_dist Std          0.470849
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00687788
eval/env_infos/initial/reward_dist Std        0.0086034
eval/env_infos/initial/reward_dist Max        0.0217807
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.0081
eval/env_infos/reward_dist Std                0.649155
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00606804
time/evaluation sampling (s)                  3.58771
time/exploration sampling (s)                17.2345
time/logging (s)                              0.00535309
time/saving (s)                               0.000985327
time/training (s)                             4.22038
time/epoch (s)                               25.055
time/total (s)                             6007.14
Epoch                                       235
---------------------------------------  ----------------
2023-08-05 02:01:40.799296 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 236 finished
---------------------------------------  ----------------
epoch                                       236
replay_buffer/size                       474000
trainer/QF Loss                               1.23589e+11
trainer/Policy Loss                          -1.93664e+06
trainer/Raw Policy Loss                      -1.93664e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.58488e+06
trainer/Q Predictions Std                246556
trainer/Q Predictions Max                     2.76157e+06
trainer/Q Predictions Min                  1476.17
trainer/Q Targets Mean                        1.84386e+06
trainer/Q Targets Std                     98821.8
trainer/Q Targets Max                         2.89882e+06
trainer/Q Targets Min                    974542
trainer/Bellman Errors Mean                   1.23589e+11
trainer/Bellman Errors Std                    2.20895e+11
trainer/Bellman Errors Max                    3.28645e+12
trainer/Bellman Errors Min                16480.1
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     474000
expl/num paths total                      11850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.456567
expl/Rewards Std                              0.637575
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            18.2627
expl/Returns Std                             19.6783
expl/Returns Max                             44.1726
expl/Returns Min                              0
expl/Actions Mean                             0.257667
expl/Actions Std                              0.79644
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.2627
expl/env_infos/final/reward_dist Mean         0.705566
expl/env_infos/final/reward_dist Std          0.767557
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00186106
expl/env_infos/initial/reward_dist Std        0.00479537
expl/env_infos/initial/reward_dist Max        0.021193
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.456567
expl/env_infos/reward_dist Std                0.637575
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      94800
eval/num paths total                       2370
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.509282
eval/Rewards Std                              0.66313
eval/Rewards Max                              1.57026
eval/Rewards Min                              0
eval/Returns Mean                            20.3713
eval/Returns Std                             20.7254
eval/Returns Max                             45.1167
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.3713
eval/env_infos/final/reward_dist Mean         0.76977
eval/env_infos/final/reward_dist Std          0.770132
eval/env_infos/final/reward_dist Max          1.57026
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00136226
eval/env_infos/initial/reward_dist Std        0.00408678
eval/env_infos/initial/reward_dist Max        0.0136226
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.509282
eval/env_infos/reward_dist Std                0.66313
eval/env_infos/reward_dist Max                1.57026
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0059663
time/evaluation sampling (s)                  3.73334
time/exploration sampling (s)                17.4129
time/logging (s)                              0.00535351
time/saving (s)                               0.000977845
time/training (s)                             4.21517
time/epoch (s)                               25.3737
time/total (s)                             6032.51
Epoch                                       236
---------------------------------------  ----------------
2023-08-05 02:02:06.213763 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 237 finished
---------------------------------------  ----------------
epoch                                       237
replay_buffer/size                       476000
trainer/QF Loss                               1.25987e+11
trainer/Policy Loss                          -1.96148e+06
trainer/Raw Policy Loss                      -1.96148e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.60379e+06
trainer/Q Predictions Std                248133
trainer/Q Predictions Max                     2.60519e+06
trainer/Q Predictions Min                  1288.57
trainer/Q Targets Mean                        1.86173e+06
trainer/Q Targets Std                    104139
trainer/Q Targets Max                         2.74357e+06
trainer/Q Targets Min                    987880
trainer/Bellman Errors Mean                   1.25987e+11
trainer/Bellman Errors Std                    2.22945e+11
trainer/Bellman Errors Max                    3.30352e+12
trainer/Bellman Errors Min                57240.6
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     476000
expl/num paths total                      11900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.516851
expl/Rewards Std                              0.666566
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            20.674
expl/Returns Std                             20.0946
expl/Returns Max                             44.2367
expl/Returns Min                              0
expl/Actions Mean                             0.268381
expl/Actions Std                              0.804968
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.674
expl/env_infos/final/reward_dist Mean         0.784055
expl/env_infos/final/reward_dist Std          0.783817
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000297344
expl/env_infos/initial/reward_dist Std        0.00127481
expl/env_infos/initial/reward_dist Max        0.00729724
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.516851
expl/env_infos/reward_dist Std                0.666566
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      95200
eval/num paths total                       2380
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.657121
eval/Rewards Std                              0.70308
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            26.2849
eval/Returns Std                             21.5296
eval/Returns Max                             45.2842
eval/Returns Min                              5.15043e-05
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.2849
eval/env_infos/final/reward_dist Mean         0.933152
eval/env_infos/final/reward_dist Std          0.762241
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00110374
eval/env_infos/initial/reward_dist Std        0.0020167
eval/env_infos/initial/reward_dist Max        0.00653572
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.657121
eval/env_infos/reward_dist Std                0.70308
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591388
time/evaluation sampling (s)                  3.92638
time/exploration sampling (s)                17.516
time/logging (s)                              0.00538803
time/saving (s)                               0.00102755
time/training (s)                             3.95661
time/epoch (s)                               25.4113
time/total (s)                             6057.93
Epoch                                       237
---------------------------------------  ----------------
2023-08-05 02:02:31.447797 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 238 finished
---------------------------------------  ----------------
epoch                                       238
replay_buffer/size                       478000
trainer/QF Loss                               1.26766e+11
trainer/Policy Loss                          -1.98625e+06
trainer/Raw Policy Loss                      -1.98625e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.62529e+06
trainer/Q Predictions Std                250399
trainer/Q Predictions Max                     2.43779e+06
trainer/Q Predictions Min                   828.632
trainer/Q Targets Mean                        1.88542e+06
trainer/Q Targets Std                    103817
trainer/Q Targets Max                         2.66408e+06
trainer/Q Targets Min                    999896
trainer/Bellman Errors Mean                   1.26766e+11
trainer/Bellman Errors Std                    2.11929e+11
trainer/Bellman Errors Max                    3.39414e+12
trainer/Bellman Errors Min                  118.266
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     478000
expl/num paths total                      11950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.449327
expl/Rewards Std                              0.63245
expl/Rewards Max                              1.57073
expl/Rewards Min                              0
expl/Returns Mean                            17.9731
expl/Returns Std                             19.5995
expl/Returns Max                             44.7882
expl/Returns Min                              0
expl/Actions Mean                             0.250476
expl/Actions Std                              0.805036
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.9731
expl/env_infos/final/reward_dist Mean         0.692959
expl/env_infos/final/reward_dist Std          0.763433
expl/env_infos/final/reward_dist Max          1.57073
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000716311
expl/env_infos/initial/reward_dist Std        0.00284487
expl/env_infos/initial/reward_dist Max        0.0173934
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.449327
expl/env_infos/reward_dist Std                0.63245
expl/env_infos/reward_dist Max                1.57073
expl/env_infos/reward_dist Min                0
eval/num steps total                      95600
eval/num paths total                       2390
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.00651
eval/Rewards Std                              0.647838
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            40.2604
eval/Returns Std                             13.4236
eval/Returns Max                             45.1188
eval/Returns Min                              0.00979251
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         40.2604
eval/env_infos/final/reward_dist Mean         1.4111
eval/env_infos/final/reward_dist Std          0.470377
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00443078
eval/env_infos/initial/reward_dist Std        0.0067303
eval/env_infos/initial/reward_dist Max        0.0173191
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.00651
eval/env_infos/reward_dist Std                0.647838
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594589
time/evaluation sampling (s)                  3.51798
time/exploration sampling (s)                17.5213
time/logging (s)                              0.00536023
time/saving (s)                               0.000968354
time/training (s)                             4.17923
time/epoch (s)                               25.2308
time/total (s)                             6083.16
Epoch                                       238
---------------------------------------  ----------------
2023-08-05 02:02:57.103611 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 239 finished
---------------------------------------  ----------------
epoch                                       239
replay_buffer/size                       480000
trainer/QF Loss                               1.33057e+11
trainer/Policy Loss                          -2.0086e+06
trainer/Raw Policy Loss                      -2.0086e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.64224e+06
trainer/Q Predictions Std                258506
trainer/Q Predictions Max                     2.55193e+06
trainer/Q Predictions Min                  1691.13
trainer/Q Targets Mean                        1.90956e+06
trainer/Q Targets Std                    107624
trainer/Q Targets Max                         2.76128e+06
trainer/Q Targets Min                         1.0075e+06
trainer/Bellman Errors Mean                   1.33057e+11
trainer/Bellman Errors Std                    2.4005e+11
trainer/Bellman Errors Max                    3.49296e+12
trainer/Bellman Errors Min                16867.5
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     480000
expl/num paths total                      12000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.34014
expl/Rewards Std                              0.582619
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            13.6056
expl/Returns Std                             18.6866
expl/Returns Max                             43.832
expl/Returns Min                              0
expl/Actions Mean                             0.249804
expl/Actions Std                              0.810705
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.6056
expl/env_infos/final/reward_dist Mean         0.499586
expl/env_infos/final/reward_dist Std          0.72306
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000849083
expl/env_infos/initial/reward_dist Std        0.00277034
expl/env_infos/initial/reward_dist Max        0.0142876
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.34014
expl/env_infos/reward_dist Std                0.582619
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      96000
eval/num paths total                       2400
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.553044
eval/Rewards Std                              0.69415
eval/Rewards Max                              1.57004
eval/Rewards Min                              0
eval/Returns Mean                            22.1218
eval/Returns Std                             22.1062
eval/Returns Max                             45.0971
eval/Returns Min                              0.00213328
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.1218
eval/env_infos/final/reward_dist Mean         0.784416
eval/env_infos/final/reward_dist Std          0.784417
eval/env_infos/final/reward_dist Max          1.57004
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00190545
eval/env_infos/initial/reward_dist Std        0.00504549
eval/env_infos/initial/reward_dist Max        0.0169212
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.553044
eval/env_infos/reward_dist Std                0.69415
eval/env_infos/reward_dist Max                1.57004
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0059582
time/evaluation sampling (s)                  3.50061
time/exploration sampling (s)                17.7307
time/logging (s)                              0.00538482
time/saving (s)                               0.000968897
time/training (s)                             4.40893
time/epoch (s)                               25.6526
time/total (s)                             6108.81
Epoch                                       239
---------------------------------------  ----------------
2023-08-05 02:03:22.847768 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 240 finished
---------------------------------------  ----------------
epoch                                       240
replay_buffer/size                       482000
trainer/QF Loss                               1.35867e+11
trainer/Policy Loss                          -2.03038e+06
trainer/Raw Policy Loss                      -2.03038e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.66288e+06
trainer/Q Predictions Std                256203
trainer/Q Predictions Max                     2.60895e+06
trainer/Q Predictions Min                  2257.16
trainer/Q Targets Mean                        1.93239e+06
trainer/Q Targets Std                    105410
trainer/Q Targets Max                         2.77046e+06
trainer/Q Targets Min                         1.00523e+06
trainer/Bellman Errors Mean                   1.35867e+11
trainer/Bellman Errors Std                    2.45697e+11
trainer/Bellman Errors Max                    3.56046e+12
trainer/Bellman Errors Min                36672.2
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     482000
expl/num paths total                      12050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.473798
expl/Rewards Std                              0.656438
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            18.9519
expl/Returns Std                             20.8711
expl/Returns Max                             44.6462
expl/Returns Min                              0
expl/Actions Mean                             0.26141
expl/Actions Std                              0.803611
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.9519
expl/env_infos/final/reward_dist Mean         0.690386
expl/env_infos/final/reward_dist Std          0.778633
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00141901
expl/env_infos/initial/reward_dist Std        0.0046887
expl/env_infos/initial/reward_dist Max        0.0205826
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.473798
expl/env_infos/reward_dist Std                0.656438
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      96400
eval/num paths total                       2410
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.66975
eval/Rewards Std                              0.711477
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            26.79
eval/Returns Std                             21.8564
eval/Returns Max                             45.2609
eval/Returns Min                              0.000525714
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.79
eval/env_infos/final/reward_dist Mean         0.941637
eval/env_infos/final/reward_dist Std          0.768844
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00193237
eval/env_infos/initial/reward_dist Std        0.00357455
eval/env_infos/initial/reward_dist Max        0.0118658
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.66975
eval/env_infos/reward_dist Std                0.711477
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588109
time/evaluation sampling (s)                  3.42103
time/exploration sampling (s)                17.8122
time/logging (s)                              0.00437633
time/saving (s)                               0.00998159
time/training (s)                             4.48644
time/epoch (s)                               25.7399
time/total (s)                             6134.55
Epoch                                       240
---------------------------------------  ----------------
2023-08-05 02:03:48.632577 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 241 finished
---------------------------------------  ----------------
epoch                                       241
replay_buffer/size                       484000
trainer/QF Loss                               1.37451e+11
trainer/Policy Loss                          -2.05543e+06
trainer/Raw Policy Loss                      -2.05543e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.68038e+06
trainer/Q Predictions Std                253896
trainer/Q Predictions Max                     2.85931e+06
trainer/Q Predictions Min                   848.488
trainer/Q Targets Mean                        1.95312e+06
trainer/Q Targets Std                    110742
trainer/Q Targets Max                         2.90436e+06
trainer/Q Targets Min                         1.02598e+06
trainer/Bellman Errors Mean                   1.37451e+11
trainer/Bellman Errors Std                    2.26158e+11
trainer/Bellman Errors Max                    3.63528e+12
trainer/Bellman Errors Min                 7460.64
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     484000
expl/num paths total                      12100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.602365
expl/Rewards Std                              0.673173
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            24.0946
expl/Returns Std                             19.4801
expl/Returns Max                             45.0181
expl/Returns Min                              0
expl/Actions Mean                             0.258308
expl/Actions Std                              0.796692
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.0946
expl/env_infos/final/reward_dist Mean         0.899157
expl/env_infos/final/reward_dist Std          0.767898
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00164352
expl/env_infos/initial/reward_dist Std        0.00457341
expl/env_infos/initial/reward_dist Max        0.0210091
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.602365
expl/env_infos/reward_dist Std                0.673173
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      96800
eval/num paths total                       2420
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.704058
eval/Rewards Std                              0.695879
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            28.1623
eval/Returns Std                             20.7114
eval/Returns Max                             46.2861
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.1623
eval/env_infos/final/reward_dist Mean         1.06191
eval/env_infos/final/reward_dist Std          0.703128
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00178222
eval/env_infos/initial/reward_dist Std        0.00282653
eval/env_infos/initial/reward_dist Max        0.0088253
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.704058
eval/env_infos/reward_dist Std                0.695879
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594059
time/evaluation sampling (s)                  3.55266
time/exploration sampling (s)                17.82
time/logging (s)                              0.00744498
time/saving (s)                               0.00109438
time/training (s)                             4.39786
time/epoch (s)                               25.785
time/total (s)                             6160.34
Epoch                                       241
---------------------------------------  ----------------
2023-08-05 02:04:13.865957 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 242 finished
---------------------------------------  ----------------
epoch                                       242
replay_buffer/size                       486000
trainer/QF Loss                               1.42424e+11
trainer/Policy Loss                          -2.08227e+06
trainer/Raw Policy Loss                      -2.08227e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.70486e+06
trainer/Q Predictions Std                261061
trainer/Q Predictions Max                     2.67313e+06
trainer/Q Predictions Min                   855.156
trainer/Q Targets Mean                        1.98134e+06
trainer/Q Targets Std                    112512
trainer/Q Targets Max                         2.99652e+06
trainer/Q Targets Min                         1.07789e+06
trainer/Bellman Errors Mean                   1.42424e+11
trainer/Bellman Errors Std                    2.37942e+11
trainer/Bellman Errors Max                    3.6537e+12
trainer/Bellman Errors Min                 1260.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     486000
expl/num paths total                      12150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.434697
expl/Rewards Std                              0.635093
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            17.3879
expl/Returns Std                             19.8048
expl/Returns Max                             44.6347
expl/Returns Min                              0
expl/Actions Mean                             0.265492
expl/Actions Std                              0.811666
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.3879
expl/env_infos/final/reward_dist Mean         0.659272
expl/env_infos/final/reward_dist Std          0.773799
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000564579
expl/env_infos/initial/reward_dist Std        0.00218335
expl/env_infos/initial/reward_dist Max        0.0107796
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.434697
expl/env_infos/reward_dist Std                0.635093
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      97200
eval/num paths total                       2430
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.250422
eval/Rewards Std                              0.509528
eval/Rewards Max                              1.57007
eval/Rewards Min                              0
eval/Returns Mean                            10.0169
eval/Returns Std                             15.7842
eval/Returns Max                             43.6536
eval/Returns Min                              0.00157844
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         10.0169
eval/env_infos/final/reward_dist Mean         0.461783
eval/env_infos/final/reward_dist Std          0.705174
eval/env_infos/final/reward_dist Max          1.57007
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000248521
eval/env_infos/initial/reward_dist Std        0.000745562
eval/env_infos/initial/reward_dist Max        0.00248521
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.250422
eval/env_infos/reward_dist Std                0.509528
eval/env_infos/reward_dist Max                1.57007
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0059432
time/evaluation sampling (s)                  3.36636
time/exploration sampling (s)                17.8336
time/logging (s)                              0.00537629
time/saving (s)                               0.000947669
time/training (s)                             4.01382
time/epoch (s)                               25.2261
time/total (s)                             6185.57
Epoch                                       242
---------------------------------------  ----------------
2023-08-05 02:04:38.636176 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 243 finished
---------------------------------------  ----------------
epoch                                       243
replay_buffer/size                       488000
trainer/QF Loss                               1.40145e+11
trainer/Policy Loss                          -2.10382e+06
trainer/Raw Policy Loss                      -2.10382e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.72697e+06
trainer/Q Predictions Std                262011
trainer/Q Predictions Max                     3.0408e+06
trainer/Q Predictions Min                   861.848
trainer/Q Targets Mean                        1.99947e+06
trainer/Q Targets Std                    115218
trainer/Q Targets Max                         3.58774e+06
trainer/Q Targets Min                         1.05946e+06
trainer/Bellman Errors Mean                   1.40145e+11
trainer/Bellman Errors Std                    2.5162e+11
trainer/Bellman Errors Max                    3.91771e+12
trainer/Bellman Errors Min                10075.1
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     488000
expl/num paths total                      12200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.349634
expl/Rewards Std                              0.58788
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            13.9854
expl/Returns Std                             18.5557
expl/Returns Max                             45.3708
expl/Returns Min                              0
expl/Actions Mean                             0.260287
expl/Actions Std                              0.804422
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.9854
expl/env_infos/final/reward_dist Mean         0.530613
expl/env_infos/final/reward_dist Std          0.739419
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0005341
expl/env_infos/initial/reward_dist Std        0.00274408
expl/env_infos/initial/reward_dist Max        0.0187376
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.349634
expl/env_infos/reward_dist Std                0.58788
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      97600
eval/num paths total                       2440
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.44072
eval/Rewards Std                              0.656518
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            17.6288
eval/Returns Std                             21.5796
eval/Returns Max                             44.9106
eval/Returns Min                              0.00230399
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.6288
eval/env_infos/final/reward_dist Mean         0.62791
eval/env_infos/final/reward_dist Std          0.768923
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000136688
eval/env_infos/initial/reward_dist Std        0.000410064
eval/env_infos/initial/reward_dist Max        0.00136688
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.44072
eval/env_infos/reward_dist Std                0.656518
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00600951
time/evaluation sampling (s)                  3.35879
time/exploration sampling (s)                17.2206
time/logging (s)                              0.0053824
time/saving (s)                               0.00101321
time/training (s)                             4.17516
time/epoch (s)                               24.7669
time/total (s)                             6210.34
Epoch                                       243
---------------------------------------  ----------------
2023-08-05 02:05:04.459483 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 244 finished
---------------------------------------  ----------------
epoch                                       244
replay_buffer/size                       490000
trainer/QF Loss                               1.45153e+11
trainer/Policy Loss                          -2.13405e+06
trainer/Raw Policy Loss                      -2.13405e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.75078e+06
trainer/Q Predictions Std                267608
trainer/Q Predictions Max                     2.88337e+06
trainer/Q Predictions Min                   868.566
trainer/Q Targets Mean                        2.0273e+06
trainer/Q Targets Std                    114506
trainer/Q Targets Max                         2.98388e+06
trainer/Q Targets Min                         1.08389e+06
trainer/Bellman Errors Mean                   1.45153e+11
trainer/Bellman Errors Std                    2.51617e+11
trainer/Bellman Errors Max                    3.99432e+12
trainer/Bellman Errors Min                 2116
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     490000
expl/num paths total                      12250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.497999
expl/Rewards Std                              0.654168
expl/Rewards Max                              1.57057
expl/Rewards Min                              0
expl/Returns Mean                            19.9199
expl/Returns Std                             20.1094
expl/Returns Max                             44.7146
expl/Returns Min                              0
expl/Actions Mean                             0.266622
expl/Actions Std                              0.805153
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.9199
expl/env_infos/final/reward_dist Mean         0.727336
expl/env_infos/final/reward_dist Std          0.769268
expl/env_infos/final/reward_dist Max          1.57057
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00111778
expl/env_infos/initial/reward_dist Std        0.00436201
expl/env_infos/initial/reward_dist Max        0.0259442
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.497999
expl/env_infos/reward_dist Std                0.654168
expl/env_infos/reward_dist Max                1.57057
expl/env_infos/reward_dist Min                0
eval/num steps total                      98000
eval/num paths total                       2450
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.401474
eval/Rewards Std                              0.626205
eval/Rewards Max                              1.57066
eval/Rewards Min                              0
eval/Returns Mean                            16.059
eval/Returns Std                             20.0957
eval/Returns Max                             44.2675
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.059
eval/env_infos/final/reward_dist Mean         0.618202
eval/env_infos/final/reward_dist Std          0.757547
eval/env_infos/final/reward_dist Max          1.57066
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.401474
eval/env_infos/reward_dist Std                0.626205
eval/env_infos/reward_dist Max                1.57066
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590801
time/evaluation sampling (s)                  3.45789
time/exploration sampling (s)                17.6087
time/logging (s)                              0.00779093
time/saving (s)                               0.00125639
time/training (s)                             4.74094
time/epoch (s)                               25.8225
time/total (s)                             6236.16
Epoch                                       244
---------------------------------------  ----------------
2023-08-05 02:05:30.432469 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 245 finished
---------------------------------------  ----------------
epoch                                       245
replay_buffer/size                       492000
trainer/QF Loss                               1.51798e+11
trainer/Policy Loss                          -2.15534e+06
trainer/Raw Policy Loss                      -2.15534e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.7685e+06
trainer/Q Predictions Std                277131
trainer/Q Predictions Max                     2.88532e+06
trainer/Q Predictions Min                   875.306
trainer/Q Targets Mean                        2.0494e+06
trainer/Q Targets Std                    119035
trainer/Q Targets Max                         3.10718e+06
trainer/Q Targets Min                         1.07663e+06
trainer/Bellman Errors Mean                   1.51798e+11
trainer/Bellman Errors Std                    2.83466e+11
trainer/Bellman Errors Max                    4.06727e+12
trainer/Bellman Errors Min                  199.516
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     492000
expl/num paths total                      12300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.476168
expl/Rewards Std                              0.649301
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            19.0467
expl/Returns Std                             20.0552
expl/Returns Max                             44.4091
expl/Returns Min                              0
expl/Actions Mean                             0.25457
expl/Actions Std                              0.806003
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.0467
expl/env_infos/final/reward_dist Mean         0.719554
expl/env_infos/final/reward_dist Std          0.779557
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00098282
expl/env_infos/initial/reward_dist Std        0.00291278
expl/env_infos/initial/reward_dist Max        0.0121139
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.476168
expl/env_infos/reward_dist Std                0.649301
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      98400
eval/num paths total                       2460
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.625687
eval/Rewards Std                              0.694252
eval/Rewards Max                              1.57026
eval/Rewards Min                              0
eval/Returns Mean                            25.0275
eval/Returns Std                             20.7148
eval/Returns Max                             45.0952
eval/Returns Min                              0.000317587
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.0275
eval/env_infos/final/reward_dist Mean         0.93235
eval/env_infos/final/reward_dist Std          0.760864
eval/env_infos/final/reward_dist Max          1.57026
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0007594
eval/env_infos/initial/reward_dist Std        0.0022782
eval/env_infos/initial/reward_dist Max        0.007594
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.625687
eval/env_infos/reward_dist Std                0.694252
eval/env_infos/reward_dist Max                1.57026
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0060927
time/evaluation sampling (s)                  3.45527
time/exploration sampling (s)                18.0011
time/logging (s)                              0.00542594
time/saving (s)                               0.00101965
time/training (s)                             4.49645
time/epoch (s)                               25.9653
time/total (s)                             6262.13
Epoch                                       245
---------------------------------------  ----------------
2023-08-05 02:05:56.115097 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 246 finished
---------------------------------------  ----------------
epoch                                       246
replay_buffer/size                       494000
trainer/QF Loss                               1.5713e+11
trainer/Policy Loss                          -2.17919e+06
trainer/Raw Policy Loss                      -2.17919e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.78216e+06
trainer/Q Predictions Std                274469
trainer/Q Predictions Max                     3.14414e+06
trainer/Q Predictions Min                   882.074
trainer/Q Targets Mean                        2.07215e+06
trainer/Q Targets Std                    114989
trainer/Q Targets Max                         3.06461e+06
trainer/Q Targets Min                         1.09752e+06
trainer/Bellman Errors Mean                   1.5713e+11
trainer/Bellman Errors Std                    2.81795e+11
trainer/Bellman Errors Max                    4.34513e+12
trainer/Bellman Errors Min                53072.6
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     494000
expl/num paths total                      12350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.480276
expl/Rewards Std                              0.645563
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            19.211
expl/Returns Std                             19.681
expl/Returns Max                             44.5058
expl/Returns Min                              0
expl/Actions Mean                             0.268029
expl/Actions Std                              0.805943
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.211
expl/env_infos/final/reward_dist Mean         0.718826
expl/env_infos/final/reward_dist Std          0.778727
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00114386
expl/env_infos/initial/reward_dist Std        0.00394981
expl/env_infos/initial/reward_dist Max        0.0215507
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.480276
expl/env_infos/reward_dist Std                0.645563
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      98800
eval/num paths total                       2470
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.782406
eval/Rewards Std                              0.709671
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            31.2963
eval/Returns Std                             20.4819
eval/Returns Max                             45.0499
eval/Returns Min                              0.00314017
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.2963
eval/env_infos/final/reward_dist Mean         1.09885
eval/env_infos/final/reward_dist Std          0.719367
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00118898
eval/env_infos/initial/reward_dist Std        0.00211005
eval/env_infos/initial/reward_dist Max        0.00564763
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.782406
eval/env_infos/reward_dist Std                0.709671
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00597393
time/evaluation sampling (s)                  3.3873
time/exploration sampling (s)                17.8049
time/logging (s)                              0.00537791
time/saving (s)                               0.000991397
time/training (s)                             4.47475
time/epoch (s)                               25.6793
time/total (s)                             6287.81
Epoch                                       246
---------------------------------------  ----------------
2023-08-05 02:06:21.555951 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 247 finished
---------------------------------------  ----------------
epoch                                       247
replay_buffer/size                       496000
trainer/QF Loss                               1.64377e+11
trainer/Policy Loss                          -2.20553e+06
trainer/Raw Policy Loss                      -2.20553e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.80513e+06
trainer/Q Predictions Std                289670
trainer/Q Predictions Max                     3.35639e+06
trainer/Q Predictions Min                   888.873
trainer/Q Targets Mean                        2.09807e+06
trainer/Q Targets Std                    122085
trainer/Q Targets Max                         3.5648e+06
trainer/Q Targets Min                         1.10868e+06
trainer/Bellman Errors Mean                   1.64377e+11
trainer/Bellman Errors Std                    2.97585e+11
trainer/Bellman Errors Max                    4.25419e+12
trainer/Bellman Errors Min                 3038.77
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     496000
expl/num paths total                      12400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.455803
expl/Rewards Std                              0.637844
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            18.2321
expl/Returns Std                             19.5795
expl/Returns Max                             44.3852
expl/Returns Min                              0
expl/Actions Mean                             0.257963
expl/Actions Std                              0.800975
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.2321
expl/env_infos/final/reward_dist Mean         0.68915
expl/env_infos/final/reward_dist Std          0.777487
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00143847
expl/env_infos/initial/reward_dist Std        0.00444573
expl/env_infos/initial/reward_dist Max        0.02176
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.455803
expl/env_infos/reward_dist Std                0.637844
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      99200
eval/num paths total                       2480
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.430411
eval/Rewards Std                              0.645546
eval/Rewards Max                              1.56806
eval/Rewards Min                              0
eval/Returns Mean                            17.2164
eval/Returns Std                             21.123
eval/Returns Max                             44.952
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.2164
eval/env_infos/final/reward_dist Mean         0.61837
eval/env_infos/final/reward_dist Std          0.757712
eval/env_infos/final/reward_dist Max          1.56806
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0014617
eval/env_infos/initial/reward_dist Std        0.00438511
eval/env_infos/initial/reward_dist Max        0.014617
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.430411
eval/env_infos/reward_dist Std                0.645546
eval/env_infos/reward_dist Max                1.56806
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593763
time/evaluation sampling (s)                  3.42549
time/exploration sampling (s)                17.3038
time/logging (s)                              0.00795816
time/saving (s)                               0.0012781
time/training (s)                             4.69579
time/epoch (s)                               25.4402
time/total (s)                             6313.25
Epoch                                       247
---------------------------------------  ----------------
2023-08-05 02:06:47.006931 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 248 finished
---------------------------------------  ----------------
epoch                                       248
replay_buffer/size                       498000
trainer/QF Loss                               1.59406e+11
trainer/Policy Loss                          -2.23367e+06
trainer/Raw Policy Loss                      -2.23367e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.83009e+06
trainer/Q Predictions Std                279551
trainer/Q Predictions Max                     2.96306e+06
trainer/Q Predictions Min                 38368.7
trainer/Q Targets Mean                        2.1227e+06
trainer/Q Targets Std                    121096
trainer/Q Targets Max                         3.20911e+06
trainer/Q Targets Min                         1.12842e+06
trainer/Bellman Errors Mean                   1.59406e+11
trainer/Bellman Errors Std                    2.61722e+11
trainer/Bellman Errors Max                    4.14359e+12
trainer/Bellman Errors Min                94864
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     498000
expl/num paths total                      12450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.423364
expl/Rewards Std                              0.61238
expl/Rewards Max                              1.5705
expl/Rewards Min                              0
expl/Returns Mean                            16.9345
expl/Returns Std                             18.6575
expl/Returns Max                             45.1714
expl/Returns Min                              0
expl/Actions Mean                             0.252449
expl/Actions Std                              0.817331
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.9345
expl/env_infos/final/reward_dist Mean         0.62288
expl/env_infos/final/reward_dist Std          0.762779
expl/env_infos/final/reward_dist Max          1.5705
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00113761
expl/env_infos/initial/reward_dist Std        0.00437748
expl/env_infos/initial/reward_dist Max        0.0257112
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.423364
expl/env_infos/reward_dist Std                0.61238
expl/env_infos/reward_dist Max                1.5705
expl/env_infos/reward_dist Min                0
eval/num steps total                      99600
eval/num paths total                       2490
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.625868
eval/Rewards Std                              0.689708
eval/Rewards Max                              1.57043
eval/Rewards Min                              0
eval/Returns Mean                            25.0347
eval/Returns Std                             20.651
eval/Returns Max                             44.6781
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.0347
eval/env_infos/final/reward_dist Mean         0.924611
eval/env_infos/final/reward_dist Std          0.755596
eval/env_infos/final/reward_dist Max          1.57043
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.625868
eval/env_infos/reward_dist Std                0.689708
eval/env_infos/reward_dist Max                1.57043
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587755
time/evaluation sampling (s)                  3.51588
time/exploration sampling (s)                17.4645
time/logging (s)                              0.00532613
time/saving (s)                               0.00100243
time/training (s)                             4.45038
time/epoch (s)                               25.443
time/total (s)                             6338.7
Epoch                                       248
---------------------------------------  ----------------
2023-08-05 02:07:11.949595 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 249 finished
---------------------------------------  ----------------
epoch                                       249
replay_buffer/size                       500000
trainer/QF Loss                               1.67456e+11
trainer/Policy Loss                          -2.26018e+06
trainer/Raw Policy Loss                      -2.26018e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.85144e+06
trainer/Q Predictions Std                290063
trainer/Q Predictions Max                     3.42009e+06
trainer/Q Predictions Min                  2736.79
trainer/Q Targets Mean                        2.14569e+06
trainer/Q Targets Std                    123644
trainer/Q Targets Max                         3.61528e+06
trainer/Q Targets Min                         1.07655e+06
trainer/Bellman Errors Mean                   1.67456e+11
trainer/Bellman Errors Std                    3.17716e+11
trainer/Bellman Errors Max                    4.35728e+12
trainer/Bellman Errors Min                 2626.56
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     500000
expl/num paths total                      12500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.5432
expl/Rewards Std                              0.666267
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            21.728
expl/Returns Std                             19.8376
expl/Returns Max                             45.1358
expl/Returns Min                              0
expl/Actions Mean                             0.251949
expl/Actions Std                              0.806424
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.728
expl/env_infos/final/reward_dist Mean         0.814886
expl/env_infos/final/reward_dist Std          0.782937
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00164596
expl/env_infos/initial/reward_dist Std        0.00415827
expl/env_infos/initial/reward_dist Max        0.0135058
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.5432
expl/env_infos/reward_dist Std                0.666267
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                     100000
eval/num paths total                       2500
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.510011
eval/Rewards Std                              0.663598
eval/Rewards Max                              1.57048
eval/Rewards Min                              0
eval/Returns Mean                            20.4004
eval/Returns Std                             20.7499
eval/Returns Max                             45.2971
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.4004
eval/env_infos/final/reward_dist Mean         0.769365
eval/env_infos/final/reward_dist Std          0.769823
eval/env_infos/final/reward_dist Max          1.57048
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0026711
eval/env_infos/initial/reward_dist Std        0.00606405
eval/env_infos/initial/reward_dist Max        0.0197717
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.510011
eval/env_infos/reward_dist Std                0.663598
eval/env_infos/reward_dist Max                1.57048
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00622053
time/evaluation sampling (s)                  3.42044
time/exploration sampling (s)                17.6155
time/logging (s)                              0.00535345
time/saving (s)                               0.00100095
time/training (s)                             3.89082
time/epoch (s)                               24.9394
time/total (s)                             6363.64
Epoch                                       249
---------------------------------------  ----------------
2023-08-05 02:07:37.789206 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 250 finished
---------------------------------------  ----------------
epoch                                       250
replay_buffer/size                       502000
trainer/QF Loss                               1.70897e+11
trainer/Policy Loss                          -2.2817e+06
trainer/Raw Policy Loss                      -2.2817e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.86688e+06
trainer/Q Predictions Std                290085
trainer/Q Predictions Max                     3.2299e+06
trainer/Q Predictions Min                   909.396
trainer/Q Targets Mean                        2.16917e+06
trainer/Q Targets Std                    118577
trainer/Q Targets Max                         3.32958e+06
trainer/Q Targets Min                         1.09925e+06
trainer/Bellman Errors Mean                   1.70897e+11
trainer/Bellman Errors Std                    3.13602e+11
trainer/Bellman Errors Max                    4.49161e+12
trainer/Bellman Errors Min                19182.2
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     502000
expl/num paths total                      12550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.471394
expl/Rewards Std                              0.648796
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            18.8558
expl/Returns Std                             20.1393
expl/Returns Max                             44.3989
expl/Returns Min                              0
expl/Actions Mean                             0.254514
expl/Actions Std                              0.80518
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.8558
expl/env_infos/final/reward_dist Mean         0.714053
expl/env_infos/final/reward_dist Std          0.772294
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000609816
expl/env_infos/initial/reward_dist Std        0.00221532
expl/env_infos/initial/reward_dist Max        0.0115646
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.471394
expl/env_infos/reward_dist Std                0.648796
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                     100400
eval/num paths total                       2510
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.559076
eval/Rewards Std                              0.695688
eval/Rewards Max                              1.56943
eval/Rewards Min                              0
eval/Returns Mean                            22.363
eval/Returns Std                             22.3471
eval/Returns Max                             45.356
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.363
eval/env_infos/final/reward_dist Mean         0.783855
eval/env_infos/final/reward_dist Std          0.783857
eval/env_infos/final/reward_dist Max          1.56943
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00260916
eval/env_infos/initial/reward_dist Std        0.00552598
eval/env_infos/initial/reward_dist Max        0.0171113
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.559076
eval/env_infos/reward_dist Std                0.695688
eval/env_infos/reward_dist Max                1.56943
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588149
time/evaluation sampling (s)                  3.45322
time/exploration sampling (s)                17.9038
time/logging (s)                              0.0053312
time/saving (s)                               0.000968122
time/training (s)                             4.46713
time/epoch (s)                               25.8363
time/total (s)                             6389.48
Epoch                                       250
---------------------------------------  ----------------
2023-08-05 02:08:02.723521 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 251 finished
---------------------------------------  ----------------
epoch                                       251
replay_buffer/size                       504000
trainer/QF Loss                               1.76745e+11
trainer/Policy Loss                          -2.30884e+06
trainer/Raw Policy Loss                      -2.30884e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.88865e+06
trainer/Q Predictions Std                292679
trainer/Q Predictions Max                     3.03128e+06
trainer/Q Predictions Min                   916.298
trainer/Q Targets Mean                        2.1953e+06
trainer/Q Targets Std                    121509
trainer/Q Targets Max                         3.18371e+06
trainer/Q Targets Min                         1.17981e+06
trainer/Bellman Errors Mean                   1.76745e+11
trainer/Bellman Errors Std                    3.18151e+11
trainer/Bellman Errors Max                    4.69206e+12
trainer/Bellman Errors Min                 2070.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     504000
expl/num paths total                      12600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.459902
expl/Rewards Std                              0.640442
expl/Rewards Max                              1.57067
expl/Rewards Min                              0
expl/Returns Mean                            18.3961
expl/Returns Std                             19.7268
expl/Returns Max                             45.0241
expl/Returns Min                              0
expl/Actions Mean                             0.272649
expl/Actions Std                              0.796534
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.3961
expl/env_infos/final/reward_dist Mean         0.701187
expl/env_infos/final/reward_dist Std          0.766847
expl/env_infos/final/reward_dist Max          1.57067
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.001015
expl/env_infos/initial/reward_dist Std        0.00366191
expl/env_infos/initial/reward_dist Max        0.0199929
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.459902
expl/env_infos/reward_dist Std                0.640442
expl/env_infos/reward_dist Max                1.57067
expl/env_infos/reward_dist Min                0
eval/num steps total                     100800
eval/num paths total                       2520
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.392921
eval/Rewards Std                              0.619791
eval/Rewards Max                              1.57019
eval/Rewards Min                              0
eval/Returns Mean                            15.7168
eval/Returns Std                             20.3472
eval/Returns Max                             45.7438
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         15.7168
eval/env_infos/final/reward_dist Mean         0.619451
eval/env_infos/final/reward_dist Std          0.758996
eval/env_infos/final/reward_dist Max          1.57019
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00463294
eval/env_infos/initial/reward_dist Std        0.00901429
eval/env_infos/initial/reward_dist Max        0.0268577
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.392921
eval/env_infos/reward_dist Std                0.619791
eval/env_infos/reward_dist Max                1.57019
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589383
time/evaluation sampling (s)                  3.43753
time/exploration sampling (s)                17.2627
time/logging (s)                              0.005346
time/saving (s)                               0.000958655
time/training (s)                             4.21858
time/epoch (s)                               24.931
time/total (s)                             6414.41
Epoch                                       251
---------------------------------------  ----------------
2023-08-05 02:08:28.585579 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 252 finished
---------------------------------------  ----------------
epoch                                       252
replay_buffer/size                       506000
trainer/QF Loss                               1.80543e+11
trainer/Policy Loss                          -2.33421e+06
trainer/Raw Policy Loss                      -2.33421e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.9137e+06
trainer/Q Predictions Std                302888
trainer/Q Predictions Max                     2.99735e+06
trainer/Q Predictions Min                  1878.03
trainer/Q Targets Mean                        2.22001e+06
trainer/Q Targets Std                    128828
trainer/Q Targets Max                         3.30829e+06
trainer/Q Targets Min                         1.12383e+06
trainer/Bellman Errors Mean                   1.80543e+11
trainer/Bellman Errors Std                    3.33364e+11
trainer/Bellman Errors Max                    4.91543e+12
trainer/Bellman Errors Min                91809
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     506000
expl/num paths total                      12650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.484778
expl/Rewards Std                              0.650784
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            19.3911
expl/Returns Std                             19.8602
expl/Returns Max                             44.2864
expl/Returns Min                              0
expl/Actions Mean                             0.257636
expl/Actions Std                              0.79446
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.3911
expl/env_infos/final/reward_dist Mean         0.768333
expl/env_infos/final/reward_dist Std          0.775014
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000464557
expl/env_infos/initial/reward_dist Std        0.00177749
expl/env_infos/initial/reward_dist Max        0.00925688
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.484778
expl/env_infos/reward_dist Std                0.650784
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     101200
eval/num paths total                       2530
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.788486
eval/Rewards Std                              0.70908
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            31.5395
eval/Returns Std                             20.6474
eval/Returns Max                             46.5415
eval/Returns Min                              0.0102989
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.5395
eval/env_infos/final/reward_dist Mean         1.09813
eval/env_infos/final/reward_dist Std          0.718897
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00527045
eval/env_infos/initial/reward_dist Std        0.00675667
eval/env_infos/initial/reward_dist Max        0.0176472
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.788486
eval/env_infos/reward_dist Std                0.70908
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00608602
time/evaluation sampling (s)                  3.42663
time/exploration sampling (s)                18.1521
time/logging (s)                              0.00743335
time/saving (s)                               0.00108923
time/training (s)                             4.26743
time/epoch (s)                               25.8608
time/total (s)                             6440.28
Epoch                                       252
---------------------------------------  ----------------
2023-08-05 02:08:54.355120 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 253 finished
---------------------------------------  ----------------
epoch                                       253
replay_buffer/size                       508000
trainer/QF Loss                               1.80337e+11
trainer/Policy Loss                          -2.36306e+06
trainer/Raw Policy Loss                      -2.36306e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.93518e+06
trainer/Q Predictions Std                299982
trainer/Q Predictions Max                     3.19568e+06
trainer/Q Predictions Min                   930.18
trainer/Q Targets Mean                        2.24592e+06
trainer/Q Targets Std                    125493
trainer/Q Targets Max                         3.31206e+06
trainer/Q Targets Min                         1.24411e+06
trainer/Bellman Errors Mean                   1.80337e+11
trainer/Bellman Errors Std                    3.14204e+11
trainer/Bellman Errors Max                    4.83217e+12
trainer/Bellman Errors Min                44205.1
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     508000
expl/num paths total                      12700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.316962
expl/Rewards Std                              0.559504
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            12.6785
expl/Returns Std                             17.4814
expl/Returns Max                             45.46
expl/Returns Min                              0
expl/Actions Mean                             0.253124
expl/Actions Std                              0.799006
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.6785
expl/env_infos/final/reward_dist Mean         0.46956
expl/env_infos/final/reward_dist Std          0.715501
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00141946
expl/env_infos/initial/reward_dist Std        0.00437956
expl/env_infos/initial/reward_dist Max        0.0204665
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.316962
expl/env_infos/reward_dist Std                0.559504
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     101600
eval/num paths total                       2540
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.515417
eval/Rewards Std                              0.671915
eval/Rewards Max                              1.57071
eval/Rewards Min                              0
eval/Returns Mean                            20.6167
eval/Returns Std                             21.0822
eval/Returns Max                             44.7615
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.6167
eval/env_infos/final/reward_dist Mean         0.774896
eval/env_infos/final/reward_dist Std          0.775369
eval/env_infos/final/reward_dist Max          1.57071
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.515417
eval/env_infos/reward_dist Std                0.671915
eval/env_infos/reward_dist Max                1.57071
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594804
time/evaluation sampling (s)                  3.41806
time/exploration sampling (s)                17.8042
time/logging (s)                              0.0079026
time/saving (s)                               0.00123472
time/training (s)                             4.52735
time/epoch (s)                               25.7647
time/total (s)                             6466.04
Epoch                                       253
---------------------------------------  ----------------
2023-08-05 02:09:19.691737 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 254 finished
---------------------------------------  ----------------
epoch                                       254
replay_buffer/size                       510000
trainer/QF Loss                               1.80006e+11
trainer/Policy Loss                          -2.38727e+06
trainer/Raw Policy Loss                      -2.38727e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.96246e+06
trainer/Q Predictions Std                297230
trainer/Q Predictions Max                     3.06678e+06
trainer/Q Predictions Min                101270
trainer/Q Targets Mean                        2.2717e+06
trainer/Q Targets Std                    125308
trainer/Q Targets Max                         3.42927e+06
trainer/Q Targets Min                         1.23033e+06
trainer/Bellman Errors Mean                   1.80006e+11
trainer/Bellman Errors Std                    2.97875e+11
trainer/Bellman Errors Max                    4.52309e+12
trainer/Bellman Errors Min                40100.1
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     510000
expl/num paths total                      12750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.322241
expl/Rewards Std                              0.57331
expl/Rewards Max                              1.57069
expl/Rewards Min                              0
expl/Returns Mean                            12.8896
expl/Returns Std                             18.523
expl/Returns Max                             45.0674
expl/Returns Min                              0
expl/Actions Mean                             0.255237
expl/Actions Std                              0.811543
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.8896
expl/env_infos/final/reward_dist Mean         0.468973
expl/env_infos/final/reward_dist Std          0.716433
expl/env_infos/final/reward_dist Max          1.57069
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00160634
expl/env_infos/initial/reward_dist Std        0.00531022
expl/env_infos/initial/reward_dist Max        0.0308377
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.322241
expl/env_infos/reward_dist Std                0.57331
expl/env_infos/reward_dist Max                1.57069
expl/env_infos/reward_dist Min                0
eval/num steps total                     102000
eval/num paths total                       2550
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.00431
eval/Rewards Std                              0.649289
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            40.1726
eval/Returns Std                             13.3964
eval/Returns Max                             45.4683
eval/Returns Min                              0.017764
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         40.1726
eval/env_infos/final/reward_dist Mean         1.41115
eval/env_infos/final/reward_dist Std          0.470389
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00471506
eval/env_infos/initial/reward_dist Std        0.00740875
eval/env_infos/initial/reward_dist Max        0.0209205
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.00431
eval/env_infos/reward_dist Std                0.649289
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0058465
time/evaluation sampling (s)                  3.4379
time/exploration sampling (s)                17.3274
time/logging (s)                              0.0074463
time/saving (s)                               0.00110232
time/training (s)                             4.55098
time/epoch (s)                               25.3307
time/total (s)                             6491.38
Epoch                                       254
---------------------------------------  ----------------
2023-08-05 02:09:46.686043 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 255 finished
---------------------------------------  ----------------
epoch                                       255
replay_buffer/size                       512000
trainer/QF Loss                               1.90794e+11
trainer/Policy Loss                          -2.41575e+06
trainer/Raw Policy Loss                      -2.41575e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.97482e+06
trainer/Q Predictions Std                307024
trainer/Q Predictions Max                     3.70561e+06
trainer/Q Predictions Min                   944.156
trainer/Q Targets Mean                        2.29783e+06
trainer/Q Targets Std                    128976
trainer/Q Targets Max                         3.82696e+06
trainer/Q Targets Min                         1.217e+06
trainer/Bellman Errors Mean                   1.90794e+11
trainer/Bellman Errors Std                    3.37314e+11
trainer/Bellman Errors Max                    5.11748e+12
trainer/Bellman Errors Min                30276
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     512000
expl/num paths total                      12800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.541054
expl/Rewards Std                              0.666508
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            21.6422
expl/Returns Std                             20.2113
expl/Returns Max                             46.0829
expl/Returns Min                              0
expl/Actions Mean                             0.278343
expl/Actions Std                              0.802011
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.6422
expl/env_infos/final/reward_dist Mean         0.784955
expl/env_infos/final/reward_dist Std          0.784117
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00280431
expl/env_infos/initial/reward_dist Std        0.00704736
expl/env_infos/initial/reward_dist Max        0.0348065
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.541054
expl/env_infos/reward_dist Std                0.666508
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     102400
eval/num paths total                       2560
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.302123
eval/Rewards Std                              0.562885
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            12.0849
eval/Returns Std                             18.4892
eval/Returns Max                             43.9195
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         12.0849
eval/env_infos/final/reward_dist Mean         0.455535
eval/env_infos/final/reward_dist Std          0.695401
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000461274
eval/env_infos/initial/reward_dist Std        0.00138382
eval/env_infos/initial/reward_dist Max        0.00461274
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.302123
eval/env_infos/reward_dist Std                0.562885
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00610767
time/evaluation sampling (s)                  3.46776
time/exploration sampling (s)                19.102
time/logging (s)                              0.00747132
time/saving (s)                               0.0096363
time/training (s)                             4.396
time/epoch (s)                               26.989
time/total (s)                             6518.37
Epoch                                       255
---------------------------------------  ----------------
2023-08-05 02:10:12.644872 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 256 finished
---------------------------------------  ----------------
epoch                                       256
replay_buffer/size                       514000
trainer/QF Loss                               1.98061e+11
trainer/Policy Loss                          -2.44263e+06
trainer/Raw Policy Loss                      -2.44263e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    1.9963e+06
trainer/Q Predictions Std                311727
trainer/Q Predictions Max                     3.07967e+06
trainer/Q Predictions Min                  1859.25
trainer/Q Targets Mean                        2.32121e+06
trainer/Q Targets Std                    130179
trainer/Q Targets Max                         3.46573e+06
trainer/Q Targets Min                         1.18394e+06
trainer/Bellman Errors Mean                   1.98061e+11
trainer/Bellman Errors Std                    3.48799e+11
trainer/Bellman Errors Max                    5.30266e+12
trainer/Bellman Errors Min                 1278.06
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     514000
expl/num paths total                      12850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.378382
expl/Rewards Std                              0.607856
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            15.1353
expl/Returns Std                             19.242
expl/Returns Max                             44.7905
expl/Returns Min                              0
expl/Actions Mean                             0.25289
expl/Actions Std                              0.802862
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.1353
expl/env_infos/final/reward_dist Mean         0.563565
expl/env_infos/final/reward_dist Std          0.750913
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000398408
expl/env_infos/initial/reward_dist Std        0.00172898
expl/env_infos/initial/reward_dist Max        0.0110214
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.378382
expl/env_infos/reward_dist Std                0.607856
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                     102800
eval/num paths total                       2570
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.42813
eval/Rewards Std                              0.647702
eval/Rewards Max                              1.56891
eval/Rewards Min                              0
eval/Returns Mean                            17.1252
eval/Returns Std                             21.0265
eval/Returns Max                             44.9631
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.1252
eval/env_infos/final/reward_dist Mean         0.625877
eval/env_infos/final/reward_dist Std          0.765564
eval/env_infos/final/reward_dist Max          1.56891
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000227867
eval/env_infos/initial/reward_dist Std        0.000683602
eval/env_infos/initial/reward_dist Max        0.00227867
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.42813
eval/env_infos/reward_dist Std                0.647702
eval/env_infos/reward_dist Max                1.56891
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595741
time/evaluation sampling (s)                  3.51079
time/exploration sampling (s)                18.2062
time/logging (s)                              0.00745692
time/saving (s)                               0.00110649
time/training (s)                             4.22221
time/epoch (s)                               25.9537
time/total (s)                             6544.32
Epoch                                       256
---------------------------------------  ----------------
2023-08-05 02:10:38.154786 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 257 finished
---------------------------------------  ----------------
epoch                                       257
replay_buffer/size                       516000
trainer/QF Loss                               2.05813e+11
trainer/Policy Loss                          -2.46961e+06
trainer/Raw Policy Loss                      -2.46961e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.01475e+06
trainer/Q Predictions Std                316527
trainer/Q Predictions Max                     3.23321e+06
trainer/Q Predictions Min                  1101.08
trainer/Q Targets Mean                        2.34647e+06
trainer/Q Targets Std                    128596
trainer/Q Targets Max                         3.16508e+06
trainer/Q Targets Min                         1.21913e+06
trainer/Bellman Errors Mean                   2.05813e+11
trainer/Bellman Errors Std                    3.67516e+11
trainer/Bellman Errors Max                    5.41436e+12
trainer/Bellman Errors Min                14161
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     516000
expl/num paths total                      12900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.519185
expl/Rewards Std                              0.662642
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            20.7674
expl/Returns Std                             20.1529
expl/Returns Max                             44.2585
expl/Returns Min                              0
expl/Actions Mean                             0.255801
expl/Actions Std                              0.805151
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.7674
expl/env_infos/final/reward_dist Mean         0.807985
expl/env_infos/final/reward_dist Std          0.776729
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00154511
expl/env_infos/initial/reward_dist Std        0.00467145
expl/env_infos/initial/reward_dist Max        0.0211105
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.519185
expl/env_infos/reward_dist Std                0.662642
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     103200
eval/num paths total                       2580
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.485225
eval/Rewards Std                              0.657155
eval/Rewards Max                              1.57023
eval/Rewards Min                              0
eval/Returns Mean                            19.409
eval/Returns Std                             21.2354
eval/Returns Max                             45.2248
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         19.409
eval/env_infos/final/reward_dist Mean         0.766212
eval/env_infos/final/reward_dist Std          0.767809
eval/env_infos/final/reward_dist Max          1.57023
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00121241
eval/env_infos/initial/reward_dist Std        0.0027103
eval/env_infos/initial/reward_dist Max        0.00914289
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.485225
eval/env_infos/reward_dist Std                0.657155
eval/env_infos/reward_dist Max                1.57023
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00604007
time/evaluation sampling (s)                  3.48831
time/exploration sampling (s)                17.6477
time/logging (s)                              0.00541679
time/saving (s)                               0.000978666
time/training (s)                             4.35406
time/epoch (s)                               25.5025
time/total (s)                             6569.83
Epoch                                       257
---------------------------------------  ----------------
2023-08-05 02:11:04.054005 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 258 finished
---------------------------------------  ----------------
epoch                                       258
replay_buffer/size                       518000
trainer/QF Loss                               1.9989e+11
trainer/Policy Loss                          -2.5025e+06
trainer/Raw Policy Loss                      -2.5025e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.04967e+06
trainer/Q Predictions Std                310231
trainer/Q Predictions Max                     3.32285e+06
trainer/Q Predictions Min                155935
trainer/Q Targets Mean                        2.37612e+06
trainer/Q Targets Std                    143690
trainer/Q Targets Max                         3.49484e+06
trainer/Q Targets Min                         1.27356e+06
trainer/Bellman Errors Mean                   1.9989e+11
trainer/Bellman Errors Std                    3.29831e+11
trainer/Bellman Errors Max                    4.95695e+12
trainer/Bellman Errors Min                  210.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     518000
expl/num paths total                      12950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.508642
expl/Rewards Std                              0.663872
expl/Rewards Max                              1.57073
expl/Rewards Min                              0
expl/Returns Mean                            20.3457
expl/Returns Std                             20.2947
expl/Returns Max                             43.5964
expl/Returns Min                              0
expl/Actions Mean                             0.266118
expl/Actions Std                              0.807064
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.3457
expl/env_infos/final/reward_dist Mean         0.751263
expl/env_infos/final/reward_dist Std          0.782004
expl/env_infos/final/reward_dist Max          1.57073
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00118453
expl/env_infos/initial/reward_dist Std        0.00381927
expl/env_infos/initial/reward_dist Max        0.0232302
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.508642
expl/env_infos/reward_dist Std                0.663872
expl/env_infos/reward_dist Max                1.57073
expl/env_infos/reward_dist Min                0
eval/num steps total                     103600
eval/num paths total                       2590
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.224611
eval/Rewards Std                              0.519073
eval/Rewards Max                              1.56836
eval/Rewards Min                              0
eval/Returns Mean                             8.98445
eval/Returns Std                             17.9524
eval/Returns Max                             45.186
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          8.98445
eval/env_infos/final/reward_dist Mean         0.313596
eval/env_infos/final/reward_dist Std          0.627192
eval/env_infos/final/reward_dist Max          1.56836
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000788325
eval/env_infos/initial/reward_dist Std        0.00236498
eval/env_infos/initial/reward_dist Max        0.00788325
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.224611
eval/env_infos/reward_dist Std                0.519073
eval/env_infos/reward_dist Max                1.56836
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591068
time/evaluation sampling (s)                  3.30026
time/exploration sampling (s)                18.2487
time/logging (s)                              0.00537789
time/saving (s)                               0.00099438
time/training (s)                             4.33467
time/epoch (s)                               25.8959
time/total (s)                             6595.73
Epoch                                       258
---------------------------------------  ----------------
2023-08-05 02:11:29.068093 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 259 finished
---------------------------------------  ----------------
epoch                                       259
replay_buffer/size                       520000
trainer/QF Loss                               2.11075e+11
trainer/Policy Loss                          -2.52607e+06
trainer/Raw Policy Loss                      -2.52607e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.06742e+06
trainer/Q Predictions Std                324354
trainer/Q Predictions Max                     3.86333e+06
trainer/Q Predictions Min                   972.389
trainer/Q Targets Mean                        2.40322e+06
trainer/Q Targets Std                    135925
trainer/Q Targets Max                         3.64955e+06
trainer/Q Targets Min                         1.27479e+06
trainer/Bellman Errors Mean                   2.11075e+11
trainer/Bellman Errors Std                    3.90241e+11
trainer/Bellman Errors Max                    5.69362e+12
trainer/Bellman Errors Min                28985.1
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     520000
expl/num paths total                      13000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.480223
expl/Rewards Std                              0.647285
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            19.2089
expl/Returns Std                             20.1138
expl/Returns Max                             44.6764
expl/Returns Min                              0
expl/Actions Mean                             0.264975
expl/Actions Std                              0.79636
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.2089
expl/env_infos/final/reward_dist Mean         0.719191
expl/env_infos/final/reward_dist Std          0.776855
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00116013
expl/env_infos/initial/reward_dist Std        0.00380178
expl/env_infos/initial/reward_dist Max        0.0188856
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.480223
expl/env_infos/reward_dist Std                0.647285
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     104000
eval/num paths total                       2600
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.527168
eval/Rewards Std                              0.67748
eval/Rewards Max                              1.56905
eval/Rewards Min                              0
eval/Returns Mean                            21.0867
eval/Returns Std                             21.4243
eval/Returns Max                             45.7821
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         21.0867
eval/env_infos/final/reward_dist Mean         0.776113
eval/env_infos/final/reward_dist Std          0.775883
eval/env_infos/final/reward_dist Max          1.56905
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.001781
eval/env_infos/initial/reward_dist Std        0.00372859
eval/env_infos/initial/reward_dist Max        0.0113693
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.527168
eval/env_infos/reward_dist Std                0.67748
eval/env_infos/reward_dist Max                1.56905
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00598314
time/evaluation sampling (s)                  3.40543
time/exploration sampling (s)                17.2321
time/logging (s)                              0.00541495
time/saving (s)                               0.00101426
time/training (s)                             4.36083
time/epoch (s)                               25.0108
time/total (s)                             6620.74
Epoch                                       259
---------------------------------------  ----------------
2023-08-05 02:11:54.061574 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 260 finished
---------------------------------------  ----------------
epoch                                       260
replay_buffer/size                       522000
trainer/QF Loss                               2.12912e+11
trainer/Policy Loss                          -2.55623e+06
trainer/Raw Policy Loss                      -2.55623e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.09214e+06
trainer/Q Predictions Std                320643
trainer/Q Predictions Max                     3.50893e+06
trainer/Q Predictions Min                   979.518
trainer/Q Targets Mean                        2.43088e+06
trainer/Q Targets Std                    138478
trainer/Q Targets Max                         3.66266e+06
trainer/Q Targets Min                         1.30045e+06
trainer/Bellman Errors Mean                   2.12912e+11
trainer/Bellman Errors Std                    3.53177e+11
trainer/Bellman Errors Max                    5.78982e+12
trainer/Bellman Errors Min                 2328.06
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     522000
expl/num paths total                      13050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.480209
expl/Rewards Std                              0.655086
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            19.2084
expl/Returns Std                             20.5069
expl/Returns Max                             45.0904
expl/Returns Min                              0
expl/Actions Mean                             0.260277
expl/Actions Std                              0.803708
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.2084
expl/env_infos/final/reward_dist Mean         0.739698
expl/env_infos/final/reward_dist Std          0.773967
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00203083
expl/env_infos/initial/reward_dist Std        0.00477779
expl/env_infos/initial/reward_dist Max        0.0167932
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.480209
expl/env_infos/reward_dist Std                0.655086
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     104400
eval/num paths total                       2610
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.554244
eval/Rewards Std                              0.695091
eval/Rewards Max                              1.57061
eval/Rewards Min                              0
eval/Returns Mean                            22.1698
eval/Returns Std                             22.1677
eval/Returns Max                             45.19
eval/Returns Min                              0.00123906
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.1698
eval/env_infos/final/reward_dist Mean         0.784494
eval/env_infos/final/reward_dist Std          0.784495
eval/env_infos/final/reward_dist Max          1.57061
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.554244
eval/env_infos/reward_dist Std                0.695091
eval/env_infos/reward_dist Max                1.57061
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596138
time/evaluation sampling (s)                  3.33282
time/exploration sampling (s)                17.5789
time/logging (s)                              0.00538069
time/saving (s)                               0.00101399
time/training (s)                             4.06606
time/epoch (s)                               24.9901
time/total (s)                             6645.73
Epoch                                       260
---------------------------------------  ----------------
2023-08-05 02:12:20.500940 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 261 finished
---------------------------------------  ----------------
epoch                                       261
replay_buffer/size                       524000
trainer/QF Loss                               2.15233e+11
trainer/Policy Loss                          -2.58109e+06
trainer/Raw Policy Loss                      -2.58109e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.10888e+06
trainer/Q Predictions Std                316305
trainer/Q Predictions Max                     3.25351e+06
trainer/Q Predictions Min                  8407.63
trainer/Q Targets Mean                        2.45125e+06
trainer/Q Targets Std                    132444
trainer/Q Targets Max                         3.3979e+06
trainer/Q Targets Min                         1.30231e+06
trainer/Bellman Errors Mean                   2.15233e+11
trainer/Bellman Errors Std                    3.5829e+11
trainer/Bellman Errors Max                    5.68788e+12
trainer/Bellman Errors Min                 2352.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     524000
expl/num paths total                      13100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.526188
expl/Rewards Std                              0.65582
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            21.0475
expl/Returns Std                             19.9006
expl/Returns Max                             44.5157
expl/Returns Min                              0
expl/Actions Mean                             0.258346
expl/Actions Std                              0.803096
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.0475
expl/env_infos/final/reward_dist Mean         0.751348
expl/env_infos/final/reward_dist Std          0.771427
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00272963
expl/env_infos/initial/reward_dist Std        0.00631254
expl/env_infos/initial/reward_dist Max        0.0254251
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.526188
expl/env_infos/reward_dist Std                0.65582
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     104800
eval/num paths total                       2620
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.287386
eval/Rewards Std                              0.554946
eval/Rewards Max                              1.57021
eval/Rewards Min                              0
eval/Returns Mean                            11.4954
eval/Returns Std                             18.3848
eval/Returns Max                             45.4507
eval/Returns Min                              0.0015602
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.4954
eval/env_infos/final/reward_dist Mean         0.462211
eval/env_infos/final/reward_dist Std          0.706406
eval/env_infos/final/reward_dist Max          1.57021
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00157863
eval/env_infos/initial/reward_dist Std        0.00323845
eval/env_infos/initial/reward_dist Max        0.00950453
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.287386
eval/env_infos/reward_dist Std                0.554946
eval/env_infos/reward_dist Max                1.57021
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00597655
time/evaluation sampling (s)                  3.40186
time/exploration sampling (s)                17.8303
time/logging (s)                              0.00784681
time/saving (s)                               0.00119729
time/training (s)                             5.19127
time/epoch (s)                               26.4385
time/total (s)                             6672.17
Epoch                                       261
---------------------------------------  ----------------
2023-08-05 02:12:45.958921 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 262 finished
---------------------------------------  ----------------
epoch                                       262
replay_buffer/size                       526000
trainer/QF Loss                               2.28563e+11
trainer/Policy Loss                          -2.60394e+06
trainer/Raw Policy Loss                      -2.60394e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.12637e+06
trainer/Q Predictions Std                327489
trainer/Q Predictions Max                     3.28054e+06
trainer/Q Predictions Min                  2398.28
trainer/Q Targets Mean                        2.47692e+06
trainer/Q Targets Std                    134495
trainer/Q Targets Max                         3.61425e+06
trainer/Q Targets Min                         1.30266e+06
trainer/Bellman Errors Mean                   2.28563e+11
trainer/Bellman Errors Std                    3.94717e+11
trainer/Bellman Errors Max                    5.8337e+12
trainer/Bellman Errors Min                17622.6
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     526000
expl/num paths total                      13150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.501039
expl/Rewards Std                              0.649419
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            20.0416
expl/Returns Std                             19.7536
expl/Returns Max                             44.2627
expl/Returns Min                              0
expl/Actions Mean                             0.271031
expl/Actions Std                              0.797381
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.0416
expl/env_infos/final/reward_dist Mean         0.74689
expl/env_infos/final/reward_dist Std          0.777827
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00241852
expl/env_infos/initial/reward_dist Std        0.00610195
expl/env_infos/initial/reward_dist Max        0.025122
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.501039
expl/env_infos/reward_dist Std                0.649419
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                     105200
eval/num paths total                       2630
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.489518
eval/Rewards Std                              0.65201
eval/Rewards Max                              1.57064
eval/Rewards Min                              0
eval/Returns Mean                            19.5807
eval/Returns Std                             20.2358
eval/Returns Max                             45.4225
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         19.5807
eval/env_infos/final/reward_dist Mean         0.766263
eval/env_infos/final/reward_dist Std          0.76694
eval/env_infos/final/reward_dist Max          1.57064
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00176935
eval/env_infos/initial/reward_dist Std        0.00479839
eval/env_infos/initial/reward_dist Max        0.0160932
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.489518
eval/env_infos/reward_dist Std                0.65201
eval/env_infos/reward_dist Max                1.57064
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0059306
time/evaluation sampling (s)                  3.45524
time/exploration sampling (s)                17.5415
time/logging (s)                              0.00743869
time/saving (s)                               0.00110906
time/training (s)                             4.44083
time/epoch (s)                               25.4521
time/total (s)                             6697.63
Epoch                                       262
---------------------------------------  ----------------
2023-08-05 02:13:10.601591 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 263 finished
---------------------------------------  ----------------
epoch                                       263
replay_buffer/size                       528000
trainer/QF Loss                               2.18479e+11
trainer/Policy Loss                          -2.63983e+06
trainer/Raw Policy Loss                      -2.63983e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.16591e+06
trainer/Q Predictions Std                330959
trainer/Q Predictions Max                     4.23075e+06
trainer/Q Predictions Min                  1001.05
trainer/Q Targets Mean                        2.50663e+06
trainer/Q Targets Std                    146690
trainer/Q Targets Max                         4.53829e+06
trainer/Q Targets Min                         1.32988e+06
trainer/Bellman Errors Mean                   2.18479e+11
trainer/Bellman Errors Std                    3.70464e+11
trainer/Bellman Errors Max                    6.26524e+12
trainer/Bellman Errors Min                  742.562
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     528000
expl/num paths total                      13200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.495383
expl/Rewards Std                              0.644976
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            19.8153
expl/Returns Std                             19.3413
expl/Returns Max                             45.9334
expl/Returns Min                              0
expl/Actions Mean                             0.273208
expl/Actions Std                              0.807701
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.8153
expl/env_infos/final/reward_dist Mean         0.779305
expl/env_infos/final/reward_dist Std          0.779561
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00132553
expl/env_infos/initial/reward_dist Std        0.00404755
expl/env_infos/initial/reward_dist Max        0.0204464
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.495383
expl/env_infos/reward_dist Std                0.644976
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     105600
eval/num paths total                       2640
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.405582
eval/Rewards Std                              0.627687
eval/Rewards Max                              1.57017
eval/Rewards Min                              0
eval/Returns Mean                            16.2233
eval/Returns Std                             20.3938
eval/Returns Max                             45.1059
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.2233
eval/env_infos/final/reward_dist Mean         0.619804
eval/env_infos/final/reward_dist Std          0.758282
eval/env_infos/final/reward_dist Max          1.57017
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00214746
eval/env_infos/initial/reward_dist Std        0.00644237
eval/env_infos/initial/reward_dist Max        0.0214746
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.405582
eval/env_infos/reward_dist Std                0.627687
eval/env_infos/reward_dist Max                1.57017
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595262
time/evaluation sampling (s)                  3.49922
time/exploration sampling (s)                17.6309
time/logging (s)                              0.00537694
time/saving (s)                               0.000992575
time/training (s)                             3.49279
time/epoch (s)                               24.6352
time/total (s)                             6722.27
Epoch                                       263
---------------------------------------  ----------------
2023-08-05 02:13:36.091962 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 264 finished
---------------------------------------  ----------------
epoch                                       264
replay_buffer/size                       530000
trainer/QF Loss                               2.34122e+11
trainer/Policy Loss                          -2.66689e+06
trainer/Raw Policy Loss                      -2.66689e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.18185e+06
trainer/Q Predictions Std                332430
trainer/Q Predictions Max                     3.43795e+06
trainer/Q Predictions Min                  1008.27
trainer/Q Targets Mean                        2.53685e+06
trainer/Q Targets Std                    151687
trainer/Q Targets Max                         3.80579e+06
trainer/Q Targets Min                         1.33452e+06
trainer/Bellman Errors Mean                   2.34122e+11
trainer/Bellman Errors Std                    4.0539e+11
trainer/Bellman Errors Max                    6.15762e+12
trainer/Bellman Errors Min                 8190.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     530000
expl/num paths total                      13250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.424924
expl/Rewards Std                              0.620827
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            16.9969
expl/Returns Std                             19.4919
expl/Returns Max                             44.5998
expl/Returns Min                              0
expl/Actions Mean                             0.254008
expl/Actions Std                              0.807318
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.9969
expl/env_infos/final/reward_dist Mean         0.641236
expl/env_infos/final/reward_dist Std          0.755464
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       1.41832e-05
expl/env_infos/initial/reward_dist Std        9.92823e-05
expl/env_infos/initial/reward_dist Max        0.000709159
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.424924
expl/env_infos/reward_dist Std                0.620827
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     106000
eval/num paths total                       2650
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.49723
eval/Rewards Std                              0.658243
eval/Rewards Max                              1.56983
eval/Rewards Min                              0
eval/Returns Mean                            19.8892
eval/Returns Std                             20.4749
eval/Returns Max                             44.9761
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         19.8892
eval/env_infos/final/reward_dist Mean         0.767414
eval/env_infos/final/reward_dist Std          0.767952
eval/env_infos/final/reward_dist Max          1.56983
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000211982
eval/env_infos/initial/reward_dist Std        0.000536822
eval/env_infos/initial/reward_dist Max        0.00179622
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.49723
eval/env_infos/reward_dist Std                0.658243
eval/env_infos/reward_dist Max                1.56983
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00643896
time/evaluation sampling (s)                  3.53248
time/exploration sampling (s)                17.3769
time/logging (s)                              0.00539889
time/saving (s)                               0.00103767
time/training (s)                             4.56485
time/epoch (s)                               25.4871
time/total (s)                             6747.75
Epoch                                       264
---------------------------------------  ----------------
2023-08-05 02:14:01.803565 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 265 finished
---------------------------------------  ----------------
epoch                                       265
replay_buffer/size                       532000
trainer/QF Loss                               2.44909e+11
trainer/Policy Loss                          -2.69307e+06
trainer/Raw Policy Loss                      -2.69307e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.20058e+06
trainer/Q Predictions Std                343938
trainer/Q Predictions Max                     3.71322e+06
trainer/Q Predictions Min                  1015.51
trainer/Q Targets Mean                        2.56191e+06
trainer/Q Targets Std                    146742
trainer/Q Targets Max                         3.74689e+06
trainer/Q Targets Min                         1.33335e+06
trainer/Bellman Errors Mean                   2.44909e+11
trainer/Bellman Errors Std                    4.2902e+11
trainer/Bellman Errors Max                    6.37879e+12
trainer/Bellman Errors Min                 4522.56
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     532000
expl/num paths total                      13300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.511138
expl/Rewards Std                              0.654763
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            20.4455
expl/Returns Std                             19.4603
expl/Returns Max                             43.6011
expl/Returns Min                              0
expl/Actions Mean                             0.257987
expl/Actions Std                              0.804539
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.4455
expl/env_infos/final/reward_dist Mean         0.815046
expl/env_infos/final/reward_dist Std          0.774876
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000128132
expl/env_infos/initial/reward_dist Std        0.000624012
expl/env_infos/initial/reward_dist Max        0.00425854
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.511138
expl/env_infos/reward_dist Std                0.654763
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                     106400
eval/num paths total                       2660
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.122802
eval/Rewards Std                              0.389017
eval/Rewards Max                              1.56557
eval/Rewards Min                              0
eval/Returns Mean                             4.91209
eval/Returns Std                             13.8037
eval/Returns Max                             46.2511
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          4.91209
eval/env_infos/final/reward_dist Mean         0.184901
eval/env_infos/final/reward_dist Std          0.467918
eval/env_infos/final/reward_dist Max          1.56557
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00208711
eval/env_infos/initial/reward_dist Std        0.00626134
eval/env_infos/initial/reward_dist Max        0.0208711
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.122802
eval/env_infos/reward_dist Std                0.389017
eval/env_infos/reward_dist Max                1.56557
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00827209
time/evaluation sampling (s)                  3.46672
time/exploration sampling (s)                17.7112
time/logging (s)                              0.00534615
time/saving (s)                               0.00102247
time/training (s)                             4.51569
time/epoch (s)                               25.7083
time/total (s)                             6773.46
Epoch                                       265
---------------------------------------  ----------------
2023-08-05 02:14:27.316037 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 266 finished
---------------------------------------  ----------------
epoch                                       266
replay_buffer/size                       534000
trainer/QF Loss                               2.37544e+11
trainer/Policy Loss                          -2.72152e+06
trainer/Raw Policy Loss                      -2.72152e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.23061e+06
trainer/Q Predictions Std                336537
trainer/Q Predictions Max                     3.92666e+06
trainer/Q Predictions Min                272895
trainer/Q Targets Mean                        2.5881e+06
trainer/Q Targets Std                    146906
trainer/Q Targets Max                         4.64264e+06
trainer/Q Targets Min                         1.54493e+06
trainer/Bellman Errors Mean                   2.37544e+11
trainer/Bellman Errors Std                    3.7753e+11
trainer/Bellman Errors Max                    5.09632e+12
trainer/Bellman Errors Min                74120.1
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     534000
expl/num paths total                      13350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.539083
expl/Rewards Std                              0.671169
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            21.5633
expl/Returns Std                             20.451
expl/Returns Max                             44.0067
expl/Returns Min                              0
expl/Actions Mean                             0.26601
expl/Actions Std                              0.801921
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.5633
expl/env_infos/final/reward_dist Mean         0.822814
expl/env_infos/final/reward_dist Std          0.775007
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00111602
expl/env_infos/initial/reward_dist Std        0.0045296
expl/env_infos/initial/reward_dist Max        0.025732
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.539083
expl/env_infos/reward_dist Std                0.671169
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     106800
eval/num paths total                       2670
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.5241
eval/Rewards Std                              0.673435
eval/Rewards Max                              1.56955
eval/Rewards Min                              0
eval/Returns Mean                            20.964
eval/Returns Std                             21.047
eval/Returns Max                             44.9675
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.964
eval/env_infos/final/reward_dist Mean         0.775548
eval/env_infos/final/reward_dist Std          0.775347
eval/env_infos/final/reward_dist Max          1.56955
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000183237
eval/env_infos/initial/reward_dist Std        0.000549711
eval/env_infos/initial/reward_dist Max        0.00183237
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.5241
eval/env_infos/reward_dist Std                0.673435
eval/env_infos/reward_dist Max                1.56955
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00610577
time/evaluation sampling (s)                  3.51726
time/exploration sampling (s)                17.4323
time/logging (s)                              0.00538422
time/saving (s)                               0.00100623
time/training (s)                             4.54719
time/epoch (s)                               25.5092
time/total (s)                             6798.97
Epoch                                       266
---------------------------------------  ----------------
2023-08-05 02:14:54.136277 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 267 finished
---------------------------------------  ----------------
epoch                                       267
replay_buffer/size                       536000
trainer/QF Loss                               2.59143e+11
trainer/Policy Loss                          -2.75667e+06
trainer/Raw Policy Loss                      -2.75667e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.25077e+06
trainer/Q Predictions Std                358771
trainer/Q Predictions Max                     3.65411e+06
trainer/Q Predictions Min                  1463.23
trainer/Q Targets Mean                        2.62277e+06
trainer/Q Targets Std                    150110
trainer/Q Targets Max                         3.59168e+06
trainer/Q Targets Min                         1.42284e+06
trainer/Bellman Errors Mean                   2.59143e+11
trainer/Bellman Errors Std                    4.71346e+11
trainer/Bellman Errors Max                    6.56336e+12
trainer/Bellman Errors Min               188356
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     536000
expl/num paths total                      13400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.517256
expl/Rewards Std                              0.656992
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            20.6902
expl/Returns Std                             19.862
expl/Returns Max                             43.6183
expl/Returns Min                              0
expl/Actions Mean                             0.25945
expl/Actions Std                              0.810254
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.6902
expl/env_infos/final/reward_dist Mean         0.788517
expl/env_infos/final/reward_dist Std          0.774513
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0011218
expl/env_infos/initial/reward_dist Std        0.00374082
expl/env_infos/initial/reward_dist Max        0.0207633
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.517256
expl/env_infos/reward_dist Std                0.656992
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     107200
eval/num paths total                       2680
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.6391
eval/Rewards Std                              0.70037
eval/Rewards Max                              1.57049
eval/Rewards Min                              0
eval/Returns Mean                            25.564
eval/Returns Std                             21.0187
eval/Returns Max                             45.1775
eval/Returns Min                              0.0121477
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.564
eval/env_infos/final/reward_dist Mean         0.939201
eval/env_infos/final/reward_dist Std          0.766861
eval/env_infos/final/reward_dist Max          1.57049
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000699613
eval/env_infos/initial/reward_dist Std        0.00209884
eval/env_infos/initial/reward_dist Max        0.00699613
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.6391
eval/env_infos/reward_dist Std                0.70037
eval/env_infos/reward_dist Max                1.57049
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00934888
time/evaluation sampling (s)                  3.46243
time/exploration sampling (s)                18.0513
time/logging (s)                              0.00537096
time/saving (s)                               0.00102341
time/training (s)                             5.28738
time/epoch (s)                               26.8168
time/total (s)                             6825.79
Epoch                                       267
---------------------------------------  ----------------
2023-08-05 02:15:19.402203 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 268 finished
---------------------------------------  ----------------
epoch                                       268
replay_buffer/size                       538000
trainer/QF Loss                               2.52218e+11
trainer/Policy Loss                          -2.78195e+06
trainer/Raw Policy Loss                      -2.78195e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.27948e+06
trainer/Q Predictions Std                349926
trainer/Q Predictions Max                     3.52195e+06
trainer/Q Predictions Min                  1194.51
trainer/Q Targets Mean                        2.64339e+06
trainer/Q Targets Std                    151262
trainer/Q Targets Max                         4.14401e+06
trainer/Q Targets Min                         1.42636e+06
trainer/Bellman Errors Mean                   2.52218e+11
trainer/Bellman Errors Std                    4.53619e+11
trainer/Bellman Errors Max                    6.91825e+12
trainer/Bellman Errors Min                27390.2
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     538000
expl/num paths total                      13450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.349085
expl/Rewards Std                              0.586639
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            13.9634
expl/Returns Std                             18.5515
expl/Returns Max                             44.5053
expl/Returns Min                              0
expl/Actions Mean                             0.245596
expl/Actions Std                              0.805188
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.9634
expl/env_infos/final/reward_dist Mean         0.498369
expl/env_infos/final/reward_dist Std          0.726949
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00181202
expl/env_infos/initial/reward_dist Std        0.00632257
expl/env_infos/initial/reward_dist Max        0.0291902
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.349085
expl/env_infos/reward_dist Std                0.586639
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     107600
eval/num paths total                       2690
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.64013
eval/Rewards Std                              0.696958
eval/Rewards Max                              1.57018
eval/Rewards Min                              0
eval/Returns Mean                            25.6052
eval/Returns Std                             21.2955
eval/Returns Max                             45.3311
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.6052
eval/env_infos/final/reward_dist Mean         0.933679
eval/env_infos/final/reward_dist Std          0.762664
eval/env_infos/final/reward_dist Max          1.57018
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00345837
eval/env_infos/initial/reward_dist Std        0.00624502
eval/env_infos/initial/reward_dist Max        0.0196031
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.64013
eval/env_infos/reward_dist Std                0.696958
eval/env_infos/reward_dist Max                1.57018
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00606355
time/evaluation sampling (s)                  3.58171
time/exploration sampling (s)                17.1652
time/logging (s)                              0.00539265
time/saving (s)                               0.00100871
time/training (s)                             4.503
time/epoch (s)                               25.2624
time/total (s)                             6851.06
Epoch                                       268
---------------------------------------  ----------------
2023-08-05 02:15:44.527436 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 269 finished
---------------------------------------  ----------------
epoch                                       269
replay_buffer/size                       540000
trainer/QF Loss                               2.54519e+11
trainer/Policy Loss                          -2.80882e+06
trainer/Raw Policy Loss                      -2.80882e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.30402e+06
trainer/Q Predictions Std                353953
trainer/Q Predictions Max                     3.59028e+06
trainer/Q Predictions Min                  4825.17
trainer/Q Targets Mean                        2.67081e+06
trainer/Q Targets Std                    142808
trainer/Q Targets Max                         3.75201e+06
trainer/Q Targets Min                         1.45159e+06
trainer/Bellman Errors Mean                   2.54519e+11
trainer/Bellman Errors Std                    4.37105e+11
trainer/Bellman Errors Max                    6.86764e+12
trainer/Bellman Errors Min                  430.562
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     540000
expl/num paths total                      13500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.385792
expl/Rewards Std                              0.603589
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            15.4317
expl/Returns Std                             18.9774
expl/Returns Max                             43.7439
expl/Returns Min                              0
expl/Actions Mean                             0.262938
expl/Actions Std                              0.796336
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.4317
expl/env_infos/final/reward_dist Mean         0.590929
expl/env_infos/final/reward_dist Std          0.740718
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000456783
expl/env_infos/initial/reward_dist Std        0.00207381
expl/env_infos/initial/reward_dist Max        0.0118873
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.385792
expl/env_infos/reward_dist Std                0.603589
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     108000
eval/num paths total                       2700
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.560696
eval/Rewards Std                              0.697316
eval/Rewards Max                              1.57071
eval/Rewards Min                              0
eval/Returns Mean                            22.4278
eval/Returns Std                             22.4178
eval/Returns Max                             46.1785
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.4278
eval/env_infos/final/reward_dist Mean         0.784801
eval/env_infos/final/reward_dist Std          0.784802
eval/env_infos/final/reward_dist Max          1.57071
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00126105
eval/env_infos/initial/reward_dist Std        0.00378245
eval/env_infos/initial/reward_dist Max        0.0126084
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.560696
eval/env_infos/reward_dist Std                0.697316
eval/env_infos/reward_dist Max                1.57071
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00609876
time/evaluation sampling (s)                  3.35753
time/exploration sampling (s)                17.2812
time/logging (s)                              0.00539802
time/saving (s)                               0.00101237
time/training (s)                             4.47064
time/epoch (s)                               25.1219
time/total (s)                             6876.18
Epoch                                       269
---------------------------------------  ----------------
2023-08-05 02:16:09.112327 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 270 finished
---------------------------------------  ----------------
epoch                                       270
replay_buffer/size                       542000
trainer/QF Loss                               2.71292e+11
trainer/Policy Loss                          -2.84221e+06
trainer/Raw Policy Loss                      -2.84221e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.32141e+06
trainer/Q Predictions Std                361780
trainer/Q Predictions Max                     3.90835e+06
trainer/Q Predictions Min                  2692.12
trainer/Q Targets Mean                        2.70324e+06
trainer/Q Targets Std                    149706
trainer/Q Targets Max                         4.23289e+06
trainer/Q Targets Min                         1.4298e+06
trainer/Bellman Errors Mean                   2.71292e+11
trainer/Bellman Errors Std                    4.58441e+11
trainer/Bellman Errors Max                    6.95283e+12
trainer/Bellman Errors Min                 9409
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     542000
expl/num paths total                      13550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.503581
expl/Rewards Std                              0.656957
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            20.1432
expl/Returns Std                             20.0732
expl/Returns Max                             44.8785
expl/Returns Min                              0
expl/Actions Mean                             0.27438
expl/Actions Std                              0.795947
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.1432
expl/env_infos/final/reward_dist Mean         0.721227
expl/env_infos/final/reward_dist Std          0.781433
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0018894
expl/env_infos/initial/reward_dist Std        0.00474481
expl/env_infos/initial/reward_dist Max        0.021702
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.503581
expl/env_infos/reward_dist Std                0.656957
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     108400
eval/num paths total                       2710
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.674131
eval/Rewards Std                              0.710245
eval/Rewards Max                              1.57037
eval/Rewards Min                              0
eval/Returns Mean                            26.9652
eval/Returns Std                             21.8949
eval/Returns Max                             46.5853
eval/Returns Min                              8.01664e-05
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.9652
eval/env_infos/final/reward_dist Mean         0.946245
eval/env_infos/final/reward_dist Std          0.761471
eval/env_infos/final/reward_dist Max          1.57037
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00286914
eval/env_infos/initial/reward_dist Std        0.00835668
eval/env_infos/initial/reward_dist Max        0.0279299
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.674131
eval/env_infos/reward_dist Std                0.710245
eval/env_infos/reward_dist Max                1.57037
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0059571
time/evaluation sampling (s)                  3.35055
time/exploration sampling (s)                16.8908
time/logging (s)                              0.00551163
time/saving (s)                               0.0010565
time/training (s)                             4.32779
time/epoch (s)                               24.5817
time/total (s)                             6900.76
Epoch                                       270
---------------------------------------  ----------------
2023-08-05 02:16:34.149776 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 271 finished
---------------------------------------  ----------------
epoch                                       271
replay_buffer/size                       544000
trainer/QF Loss                               2.67205e+11
trainer/Policy Loss                          -2.87431e+06
trainer/Raw Policy Loss                      -2.87431e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.35082e+06
trainer/Q Predictions Std                358175
trainer/Q Predictions Max                     4.36803e+06
trainer/Q Predictions Min                  7110.4
trainer/Q Targets Mean                        2.73095e+06
trainer/Q Targets Std                    156469
trainer/Q Targets Max                         4.93519e+06
trainer/Q Targets Min                         1.45207e+06
trainer/Bellman Errors Mean                   2.67205e+11
trainer/Bellman Errors Std                    4.47103e+11
trainer/Bellman Errors Max                    7.18547e+12
trainer/Bellman Errors Min                70357.6
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     544000
expl/num paths total                      13600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.611498
expl/Rewards Std                              0.680447
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            24.4599
expl/Returns Std                             19.781
expl/Returns Max                             44.6793
expl/Returns Min                              0
expl/Actions Mean                             0.271424
expl/Actions Std                              0.806405
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.4599
expl/env_infos/final/reward_dist Mean         0.936456
expl/env_infos/final/reward_dist Std          0.765092
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00176566
expl/env_infos/initial/reward_dist Std        0.00435386
expl/env_infos/initial/reward_dist Max        0.0185847
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.611498
expl/env_infos/reward_dist Std                0.680447
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     108800
eval/num paths total                       2720
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.660571
eval/Rewards Std                              0.707522
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            26.4228
eval/Returns Std                             21.6507
eval/Returns Max                             45.3572
eval/Returns Min                              2.12997e-05
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.4228
eval/env_infos/final/reward_dist Mean         0.941117
eval/env_infos/final/reward_dist Std          0.76842
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00364394
eval/env_infos/initial/reward_dist Std        0.00581845
eval/env_infos/initial/reward_dist Max        0.0173107
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.660571
eval/env_infos/reward_dist Std                0.707522
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591566
time/evaluation sampling (s)                  3.41755
time/exploration sampling (s)                17.1595
time/logging (s)                              0.00543647
time/saving (s)                               0.000960145
time/training (s)                             4.44139
time/epoch (s)                               25.0307
time/total (s)                             6925.8
Epoch                                       271
---------------------------------------  ----------------
2023-08-05 02:16:58.687436 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 272 finished
---------------------------------------  ----------------
epoch                                       272
replay_buffer/size                       546000
trainer/QF Loss                               2.7781e+11
trainer/Policy Loss                          -2.90741e+06
trainer/Raw Policy Loss                      -2.90741e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.37884e+06
trainer/Q Predictions Std                368180
trainer/Q Predictions Max                     3.81613e+06
trainer/Q Predictions Min                  1067.01
trainer/Q Targets Mean                        2.76296e+06
trainer/Q Targets Std                    159797
trainer/Q Targets Max                         4.1552e+06
trainer/Q Targets Min                         1.48554e+06
trainer/Bellman Errors Mean                   2.7781e+11
trainer/Bellman Errors Std                    4.79707e+11
trainer/Bellman Errors Max                    7.45759e+12
trainer/Bellman Errors Min                    0
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     546000
expl/num paths total                      13650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.481426
expl/Rewards Std                              0.65429
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            19.2571
expl/Returns Std                             20.3233
expl/Returns Max                             45.013
expl/Returns Min                              0
expl/Actions Mean                             0.267877
expl/Actions Std                              0.800137
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.2571
expl/env_infos/final/reward_dist Mean         0.73114
expl/env_infos/final/reward_dist Std          0.775312
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00198432
expl/env_infos/initial/reward_dist Std        0.00477074
expl/env_infos/initial/reward_dist Max        0.0177752
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.481426
expl/env_infos/reward_dist Std                0.65429
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     109200
eval/num paths total                       2730
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.561738
eval/Rewards Std                              0.696903
eval/Rewards Max                              1.56976
eval/Rewards Min                              0
eval/Returns Mean                            22.4695
eval/Returns Std                             22.4666
eval/Returns Max                             46.0787
eval/Returns Min                              0.00293971
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.4695
eval/env_infos/final/reward_dist Mean         0.783797
eval/env_infos/final/reward_dist Std          0.783799
eval/env_infos/final/reward_dist Max          1.56976
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00303705
eval/env_infos/initial/reward_dist Std        0.00579857
eval/env_infos/initial/reward_dist Max        0.0177993
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.561738
eval/env_infos/reward_dist Std                0.696903
eval/env_infos/reward_dist Max                1.56976
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596081
time/evaluation sampling (s)                  3.55336
time/exploration sampling (s)                17.0715
time/logging (s)                              0.00546826
time/saving (s)                               0.00103196
time/training (s)                             3.89607
time/epoch (s)                               24.5334
time/total (s)                             6950.34
Epoch                                       272
---------------------------------------  ----------------
2023-08-05 02:17:24.472333 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 273 finished
---------------------------------------  ----------------
epoch                                       273
replay_buffer/size                       548000
trainer/QF Loss                               2.71761e+11
trainer/Policy Loss                          -2.93144e+06
trainer/Raw Policy Loss                      -2.93144e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.40287e+06
trainer/Q Predictions Std                357985
trainer/Q Predictions Max                     4.12566e+06
trainer/Q Predictions Min                  1074.46
trainer/Q Targets Mean                        2.78406e+06
trainer/Q Targets Std                    150903
trainer/Q Targets Max                         4.40672e+06
trainer/Q Targets Min                         1.47071e+06
trainer/Bellman Errors Mean                   2.71761e+11
trainer/Bellman Errors Std                    4.68689e+11
trainer/Bellman Errors Max                    7.40814e+12
trainer/Bellman Errors Min                43160.1
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     548000
expl/num paths total                      13700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.320406
expl/Rewards Std                              0.564467
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            12.8163
expl/Returns Std                             17.8268
expl/Returns Max                             45.2628
expl/Returns Min                              0
expl/Actions Mean                             0.249794
expl/Actions Std                              0.802017
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.8163
expl/env_infos/final/reward_dist Mean         0.499665
expl/env_infos/final/reward_dist Std          0.72359
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00143516
expl/env_infos/initial/reward_dist Std        0.00509605
expl/env_infos/initial/reward_dist Max        0.0248639
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.320406
expl/env_infos/reward_dist Std                0.564467
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                     109600
eval/num paths total                       2740
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.429907
eval/Rewards Std                              0.621086
eval/Rewards Max                              1.57064
eval/Rewards Min                              0
eval/Returns Mean                            17.1963
eval/Returns Std                             19.4083
eval/Returns Max                             44.2632
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.1963
eval/env_infos/final/reward_dist Mean         0.721784
eval/env_infos/final/reward_dist Std          0.735106
eval/env_infos/final/reward_dist Max          1.57064
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.429907
eval/env_infos/reward_dist Std                0.621086
eval/env_infos/reward_dist Max                1.57064
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594456
time/evaluation sampling (s)                  4.16593
time/exploration sampling (s)                17.162
time/logging (s)                              0.00544696
time/saving (s)                               0.00101736
time/training (s)                             4.43962
time/epoch (s)                               25.78
time/total (s)                             6976.12
Epoch                                       273
---------------------------------------  ----------------
2023-08-05 02:17:50.229902 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 274 finished
---------------------------------------  ----------------
epoch                                       274
replay_buffer/size                       550000
trainer/QF Loss                               2.93265e+11
trainer/Policy Loss                          -2.9692e+06
trainer/Raw Policy Loss                      -2.9692e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.42253e+06
trainer/Q Predictions Std                378740
trainer/Q Predictions Max                     4.54283e+06
trainer/Q Predictions Min                  1081.94
trainer/Q Targets Mean                        2.8224e+06
trainer/Q Targets Std                    155143
trainer/Q Targets Max                         4.10568e+06
trainer/Q Targets Min                         1.69196e+06
trainer/Bellman Errors Mean                   2.93265e+11
trainer/Bellman Errors Std                    5.12454e+11
trainer/Bellman Errors Max                    7.54e+12
trainer/Bellman Errors Min                22052.2
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     550000
expl/num paths total                      13750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.399877
expl/Rewards Std                              0.622123
expl/Rewards Max                              1.57074
expl/Rewards Min                              0
expl/Returns Mean                            15.9951
expl/Returns Std                             19.8068
expl/Returns Max                             44.0869
expl/Returns Min                              0
expl/Actions Mean                             0.273783
expl/Actions Std                              0.817236
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.9951
expl/env_infos/final/reward_dist Mean         0.564799
expl/env_infos/final/reward_dist Std          0.752714
expl/env_infos/final/reward_dist Max          1.57072
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000935825
expl/env_infos/initial/reward_dist Std        0.00360487
expl/env_infos/initial/reward_dist Max        0.0228213
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.399877
expl/env_infos/reward_dist Std                0.622123
expl/env_infos/reward_dist Max                1.57074
expl/env_infos/reward_dist Min                0
eval/num steps total                     110000
eval/num paths total                       2750
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.555534
eval/Rewards Std                              0.695045
eval/Rewards Max                              1.56788
eval/Rewards Min                              0
eval/Returns Mean                            22.2213
eval/Returns Std                             22.2131
eval/Returns Max                             45.4985
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.2213
eval/env_infos/final/reward_dist Mean         0.783774
eval/env_infos/final/reward_dist Std          0.783774
eval/env_infos/final/reward_dist Max          1.56788
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00126456
eval/env_infos/initial/reward_dist Std        0.00379367
eval/env_infos/initial/reward_dist Max        0.0126456
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.555534
eval/env_infos/reward_dist Std                0.695045
eval/env_infos/reward_dist Max                1.56788
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593883
time/evaluation sampling (s)                  4.17397
time/exploration sampling (s)                17.2599
time/logging (s)                              0.00535406
time/saving (s)                               0.000999981
time/training (s)                             4.30681
time/epoch (s)                               25.753
time/total (s)                             7001.88
Epoch                                       274
---------------------------------------  ----------------
2023-08-05 02:18:15.196826 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 275 finished
---------------------------------------  ----------------
epoch                                       275
replay_buffer/size                       552000
trainer/QF Loss                               2.91546e+11
trainer/Policy Loss                          -2.99261e+06
trainer/Raw Policy Loss                      -2.99261e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.44909e+06
trainer/Q Predictions Std                373958
trainer/Q Predictions Max                     3.67032e+06
trainer/Q Predictions Min                  1089.43
trainer/Q Targets Mean                        2.84798e+06
trainer/Q Targets Std                    154236
trainer/Q Targets Max                         4.04851e+06
trainer/Q Targets Min                         1.51864e+06
trainer/Bellman Errors Mean                   2.91546e+11
trainer/Bellman Errors Std                    5.10905e+11
trainer/Bellman Errors Max                    7.86984e+12
trainer/Bellman Errors Min                  210.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     552000
expl/num paths total                      13800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.446703
expl/Rewards Std                              0.631395
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            17.8681
expl/Returns Std                             19.3634
expl/Returns Max                             44.3817
expl/Returns Min                              0
expl/Actions Mean                             0.257534
expl/Actions Std                              0.808128
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.8681
expl/env_infos/final/reward_dist Mean         0.703235
expl/env_infos/final/reward_dist Std          0.76953
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00125788
expl/env_infos/initial/reward_dist Std        0.00371436
expl/env_infos/initial/reward_dist Max        0.0159034
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.446703
expl/env_infos/reward_dist Std                0.631395
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                     110400
eval/num paths total                       2760
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.640172
eval/Rewards Std                              0.700406
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            25.6069
eval/Returns Std                             21.2282
eval/Returns Max                             45.4285
eval/Returns Min                              0.00280486
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.6069
eval/env_infos/final/reward_dist Mean         0.940319
eval/env_infos/final/reward_dist Std          0.767778
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00275194
eval/env_infos/initial/reward_dist Std        0.00582495
eval/env_infos/initial/reward_dist Max        0.0191512
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.640172
eval/env_infos/reward_dist Std                0.700406
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593043
time/evaluation sampling (s)                  3.55403
time/exploration sampling (s)                17.1705
time/logging (s)                              0.00531924
time/saving (s)                               0.000974626
time/training (s)                             4.22583
time/epoch (s)                               24.9626
time/total (s)                             7026.84
Epoch                                       275
---------------------------------------  ----------------
2023-08-05 02:18:40.462646 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 276 finished
---------------------------------------  ----------------
epoch                                       276
replay_buffer/size                       554000
trainer/QF Loss                               3.12658e+11
trainer/Policy Loss                          -3.02435e+06
trainer/Raw Policy Loss                      -3.02435e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.46495e+06
trainer/Q Predictions Std                386903
trainer/Q Predictions Max                     4.19183e+06
trainer/Q Predictions Min                  2781.37
trainer/Q Targets Mean                        2.87666e+06
trainer/Q Targets Std                    162558
trainer/Q Targets Max                         4.39211e+06
trainer/Q Targets Min                         1.47513e+06
trainer/Bellman Errors Mean                   3.12658e+11
trainer/Bellman Errors Std                    5.36264e+11
trainer/Bellman Errors Max                    7.88312e+12
trainer/Bellman Errors Min                11289.1
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     554000
expl/num paths total                      13850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.357282
expl/Rewards Std                              0.595441
expl/Rewards Max                              1.57072
expl/Rewards Min                              0
expl/Returns Mean                            14.2913
expl/Returns Std                             18.9386
expl/Returns Max                             44.2812
expl/Returns Min                              0
expl/Actions Mean                             0.247654
expl/Actions Std                              0.802363
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.2913
expl/env_infos/final/reward_dist Mean         0.530895
expl/env_infos/final/reward_dist Std          0.738528
expl/env_infos/final/reward_dist Max          1.57072
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000500773
expl/env_infos/initial/reward_dist Std        0.00261588
expl/env_infos/initial/reward_dist Max        0.0170588
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.357282
expl/env_infos/reward_dist Std                0.595441
expl/env_infos/reward_dist Max                1.57072
expl/env_infos/reward_dist Min                0
eval/num steps total                     110800
eval/num paths total                       2770
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.783087
eval/Rewards Std                              0.709097
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            31.3235
eval/Returns Std                             20.5002
eval/Returns Max                             45.1998
eval/Returns Min                              0.00380371
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.3235
eval/env_infos/final/reward_dist Mean         1.09814
eval/env_infos/final/reward_dist Std          0.7189
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00267025
eval/env_infos/initial/reward_dist Std        0.00422777
eval/env_infos/initial/reward_dist Max        0.0114662
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.783087
eval/env_infos/reward_dist Std                0.709097
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595729
time/evaluation sampling (s)                  3.63604
time/exploration sampling (s)                17.1517
time/logging (s)                              0.00536624
time/saving (s)                               0.000958974
time/training (s)                             4.46231
time/epoch (s)                               25.2623
time/total (s)                             7052.1
Epoch                                       276
---------------------------------------  ----------------
2023-08-05 02:19:05.814318 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 277 finished
---------------------------------------  ----------------
epoch                                       277
replay_buffer/size                       556000
trainer/QF Loss                               3.08469e+11
trainer/Policy Loss                          -3.0545e+06
trainer/Raw Policy Loss                      -3.0545e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.49746e+06
trainer/Q Predictions Std                388090
trainer/Q Predictions Max                     4.20922e+06
trainer/Q Predictions Min                  1104.52
trainer/Q Targets Mean                        2.90236e+06
trainer/Q Targets Std                    157961
trainer/Q Targets Max                         3.9907e+06
trainer/Q Targets Min                         1.4411e+06
trainer/Bellman Errors Mean                   3.08469e+11
trainer/Bellman Errors Std                    5.60759e+11
trainer/Bellman Errors Max                    8.37806e+12
trainer/Bellman Errors Min                21682.6
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     556000
expl/num paths total                      13900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.423521
expl/Rewards Std                              0.63477
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            16.9408
expl/Returns Std                             20.0555
expl/Returns Max                             44.6056
expl/Returns Min                              2.22078e-06
expl/Actions Mean                             0.26074
expl/Actions Std                              0.819819
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.9408
expl/env_infos/final/reward_dist Mean         0.626172
expl/env_infos/final/reward_dist Std          0.766836
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00030142
expl/env_infos/initial/reward_dist Std        0.00142474
expl/env_infos/initial/reward_dist Max        0.0093928
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.423521
expl/env_infos/reward_dist Std                0.63477
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                     111200
eval/num paths total                       2780
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.673176
eval/Rewards Std                              0.712069
eval/Rewards Max                              1.57022
eval/Rewards Min                              0
eval/Returns Mean                            26.927
eval/Returns Std                             21.9745
eval/Returns Max                             45.8069
eval/Returns Min                              0.0105913
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.927
eval/env_infos/final/reward_dist Mean         0.941259
eval/env_infos/final/reward_dist Std          0.76844
eval/env_infos/final/reward_dist Max          1.57022
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00270741
eval/env_infos/initial/reward_dist Std        0.0054548
eval/env_infos/initial/reward_dist Max        0.015011
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.673176
eval/env_infos/reward_dist Std                0.712069
eval/env_infos/reward_dist Max                1.57022
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591704
time/evaluation sampling (s)                  3.62558
time/exploration sampling (s)                17.2182
time/logging (s)                              0.00537476
time/saving (s)                               0.00100931
time/training (s)                             4.49228
time/epoch (s)                               25.3483
time/total (s)                             7077.45
Epoch                                       277
---------------------------------------  ----------------
2023-08-05 02:19:31.848994 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 278 finished
---------------------------------------  ----------------
epoch                                       278
replay_buffer/size                       558000
trainer/QF Loss                               3.2093e+11
trainer/Policy Loss                          -3.08529e+06
trainer/Raw Policy Loss                      -3.08529e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.51959e+06
trainer/Q Predictions Std                385599
trainer/Q Predictions Max                     4.71420e+06
trainer/Q Predictions Min                  2189.83
trainer/Q Targets Mean                        2.93605e+06
trainer/Q Targets Std                    171693
trainer/Q Targets Max                         4.34261e+06
trainer/Q Targets Min                         1.53291e+06
trainer/Bellman Errors Mean                   3.2093e+11
trainer/Bellman Errors Std                    5.44236e+11
trainer/Bellman Errors Max                    8.66814e+12
trainer/Bellman Errors Min                  841
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     558000
expl/num paths total                      13950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.305695
expl/Rewards Std                              0.550837
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            12.2278
expl/Returns Std                             17.523
expl/Returns Max                             45.5827
expl/Returns Min                              0
expl/Actions Mean                             0.252051
expl/Actions Std                              0.798329
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.2278
expl/env_infos/final/reward_dist Mean         0.474573
expl/env_infos/final/reward_dist Std          0.702759
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000568842
expl/env_infos/initial/reward_dist Std        0.00269
expl/env_infos/initial/reward_dist Max        0.0162299
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.305695
expl/env_infos/reward_dist Std                0.550837
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     111600
eval/num paths total                       2790
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.540654
eval/Rewards Std                              0.683476
eval/Rewards Max                              1.57048
eval/Rewards Min                              0
eval/Returns Mean                            21.6262
eval/Returns Std                             21.7107
eval/Returns Max                             45.2476
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         21.6262
eval/env_infos/final/reward_dist Mean         0.777224
eval/env_infos/final/reward_dist Std          0.777523
eval/env_infos/final/reward_dist Max          1.57048
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00081937
eval/env_infos/initial/reward_dist Std        0.00245811
eval/env_infos/initial/reward_dist Max        0.0081937
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.540654
eval/env_infos/reward_dist Std                0.683476
eval/env_infos/reward_dist Max                1.57048
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585681
time/evaluation sampling (s)                  3.6441
time/exploration sampling (s)                17.9431
time/logging (s)                              0.00531045
time/saving (s)                               0.00102989
time/training (s)                             4.43178
time/epoch (s)                               26.0312
time/total (s)                             7103.49
Epoch                                       278
---------------------------------------  ----------------
2023-08-05 02:19:56.649602 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 279 finished
---------------------------------------  ----------------
epoch                                       279
replay_buffer/size                       560000
trainer/QF Loss                               3.17088e+11
trainer/Policy Loss                          -3.12678e+06
trainer/Raw Policy Loss                      -3.12678e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.56435e+06
trainer/Q Predictions Std                394780
trainer/Q Predictions Max                     4.1159e+06
trainer/Q Predictions Min                  1119.7
trainer/Q Targets Mean                        2.97661e+06
trainer/Q Targets Std                    170859
trainer/Q Targets Max                         4.50910e+06
trainer/Q Targets Min                         1.58037e+06
trainer/Bellman Errors Mean                   3.17088e+11
trainer/Bellman Errors Std                    5.59165e+11
trainer/Bellman Errors Max                    8.61394e+12
trainer/Bellman Errors Min                 3481
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     560000
expl/num paths total                      14000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.421987
expl/Rewards Std                              0.627025
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            16.8795
expl/Returns Std                             19.5831
expl/Returns Max                             47.5151
expl/Returns Min                              0
expl/Actions Mean                             0.253153
expl/Actions Std                              0.800587
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.8795
expl/env_infos/final/reward_dist Mean         0.651288
expl/env_infos/final/reward_dist Std          0.766023
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00150738
expl/env_infos/initial/reward_dist Std        0.00607181
expl/env_infos/initial/reward_dist Max        0.0342301
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.421987
expl/env_infos/reward_dist Std                0.627025
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     112000
eval/num paths total                       2800
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.781762
eval/Rewards Std                              0.710524
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            31.2705
eval/Returns Std                             20.4626
eval/Returns Max                             45.9646
eval/Returns Min                              0.00512024
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.2705
eval/env_infos/final/reward_dist Mean         1.09865
eval/env_infos/final/reward_dist Std          0.719236
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00161237
eval/env_infos/initial/reward_dist Std        0.00419432
eval/env_infos/initial/reward_dist Max        0.0140591
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.781762
eval/env_infos/reward_dist Std                0.710524
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00610782
time/evaluation sampling (s)                  3.42833
time/exploration sampling (s)                17.1628
time/logging (s)                              0.00536503
time/saving (s)                               0.000968469
time/training (s)                             4.19372
time/epoch (s)                               24.7972
time/total (s)                             7128.29
Epoch                                       279
---------------------------------------  ----------------
2023-08-05 02:20:22.832351 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 280 finished
---------------------------------------  ----------------
epoch                                       280
replay_buffer/size                       562000
trainer/QF Loss                               3.28775e+11
trainer/Policy Loss                          -3.15036e+06
trainer/Raw Policy Loss                      -3.15036e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.57943e+06
trainer/Q Predictions Std                404409
trainer/Q Predictions Max                     4.27894e+06
trainer/Q Predictions Min                171369
trainer/Q Targets Mean                        2.99614e+06
trainer/Q Targets Std                    165062
trainer/Q Targets Max                         5.09799e+06
trainer/Q Targets Min                         1.51599e+06
trainer/Bellman Errors Mean                   3.28775e+11
trainer/Bellman Errors Std                    5.50733e+11
trainer/Bellman Errors Max                    7.66838e+12
trainer/Bellman Errors Min               122500
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     562000
expl/num paths total                      14050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.458316
expl/Rewards Std                              0.630835
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            18.3326
expl/Returns Std                             19.0555
expl/Returns Max                             43.6483
expl/Returns Min                              0
expl/Actions Mean                             0.247685
expl/Actions Std                              0.805312
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.3326
expl/env_infos/final/reward_dist Mean         0.690045
expl/env_infos/final/reward_dist Std          0.76848
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00107189
expl/env_infos/initial/reward_dist Std        0.00309458
expl/env_infos/initial/reward_dist Max        0.0141217
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.458316
expl/env_infos/reward_dist Std                0.630835
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     112400
eval/num paths total                       2810
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.789552
eval/Rewards Std                              0.706656
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            31.5821
eval/Returns Std                             20.659
eval/Returns Max                             45.4224
eval/Returns Min                              0.00905863
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.5821
eval/env_infos/final/reward_dist Mean         1.0988
eval/env_infos/final/reward_dist Std          0.719025
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0120357
eval/env_infos/initial/reward_dist Std        0.0087495
eval/env_infos/initial/reward_dist Max        0.0219658
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.789552
eval/env_infos/reward_dist Std                0.706656
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591955
time/evaluation sampling (s)                  3.44606
time/exploration sampling (s)                18.2035
time/logging (s)                              0.00539559
time/saving (s)                               0.000991738
time/training (s)                             4.51747
time/epoch (s)                               26.1793
time/total (s)                             7154.47
Epoch                                       280
---------------------------------------  ----------------
2023-08-05 02:20:48.455780 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 281 finished
---------------------------------------  ----------------
epoch                                       281
replay_buffer/size                       564000
trainer/QF Loss                               3.32642e+11
trainer/Policy Loss                          -3.18193e+06
trainer/Raw Policy Loss                      -3.18193e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.61081e+06
trainer/Q Predictions Std                403456
trainer/Q Predictions Max                     4.05111e+06
trainer/Q Predictions Min                  1134.98
trainer/Q Targets Mean                        3.02777e+06
trainer/Q Targets Std                    166728
trainer/Q Targets Max                         4.37081e+06
trainer/Q Targets Min                         1.59938e+06
trainer/Bellman Errors Mean                   3.32642e+11
trainer/Bellman Errors Std                    5.95206e+11
trainer/Bellman Errors Max                    9.11315e+12
trainer/Bellman Errors Min                   10.5625
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     564000
expl/num paths total                      14100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.267596
expl/Rewards Std                              0.525811
expl/Rewards Max                              1.57049
expl/Rewards Min                              0
expl/Returns Mean                            10.7038
expl/Returns Std                             16.9281
expl/Returns Max                             43.8222
expl/Returns Min                              0
expl/Actions Mean                             0.258622
expl/Actions Std                              0.809852
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         10.7038
expl/env_infos/final/reward_dist Mean         0.403553
expl/env_infos/final/reward_dist Std          0.670111
expl/env_infos/final/reward_dist Max          1.57049
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000358855
expl/env_infos/initial/reward_dist Std        0.00183573
expl/env_infos/initial/reward_dist Max        0.0116136
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.267596
expl/env_infos/reward_dist Std                0.525811
expl/env_infos/reward_dist Max                1.57049
expl/env_infos/reward_dist Min                0
eval/num steps total                     112800
eval/num paths total                       2820
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.887148
eval/Rewards Std                              0.684741
eval/Rewards Max                              1.57007
eval/Rewards Min                              0
eval/Returns Mean                            35.4859
eval/Returns Std                             17.4351
eval/Returns Max                             45.3191
eval/Returns Min                              0.0100532
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.4859
eval/env_infos/final/reward_dist Mean         1.25389
eval/env_infos/final/reward_dist Std          0.626951
eval/env_infos/final/reward_dist Max          1.57007
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00483984
eval/env_infos/initial/reward_dist Std        0.00780867
eval/env_infos/initial/reward_dist Max        0.0218199
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.887148
eval/env_infos/reward_dist Std                0.684741
eval/env_infos/reward_dist Max                1.57007
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594966
time/evaluation sampling (s)                  3.42014
time/exploration sampling (s)                18.1607
time/logging (s)                              0.00537514
time/saving (s)                               0.000972182
time/training (s)                             4.02695
time/epoch (s)                               25.6201
time/total (s)                             7180.09
Epoch                                       281
---------------------------------------  ----------------
2023-08-05 02:21:13.918525 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 282 finished
---------------------------------------  ----------------
epoch                                       282
replay_buffer/size                       566000
trainer/QF Loss                               3.28775e+11
trainer/Policy Loss                          -3.21657e+06
trainer/Raw Policy Loss                      -3.21657e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.63821e+06
trainer/Q Predictions Std                401427
trainer/Q Predictions Max                     4.65908e+06
trainer/Q Predictions Min                 31168.6
trainer/Q Targets Mean                        3.05839e+06
trainer/Q Targets Std                    164772
trainer/Q Targets Max                         5.20681e+06
trainer/Q Targets Min                         1.62943e+06
trainer/Bellman Errors Mean                   3.28775e+11
trainer/Bellman Errors Std                    5.74146e+11
trainer/Bellman Errors Max                    8.97627e+12
trainer/Bellman Errors Min                 3875.06
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     566000
expl/num paths total                      14150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.445644
expl/Rewards Std                              0.636746
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            17.8258
expl/Returns Std                             19.681
expl/Returns Max                             44.0685
expl/Returns Min                              0
expl/Actions Mean                             0.267701
expl/Actions Std                              0.801616
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.8258
expl/env_infos/final/reward_dist Mean         0.684389
expl/env_infos/final/reward_dist Std          0.772538
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000959047
expl/env_infos/initial/reward_dist Std        0.00365091
expl/env_infos/initial/reward_dist Max        0.0184399
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.445644
expl/env_infos/reward_dist Std                0.636746
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     113200
eval/num paths total                       2830
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.424376
eval/Rewards Std                              0.646496
eval/Rewards Max                              1.56987
eval/Rewards Min                              0
eval/Returns Mean                            16.9751
eval/Returns Std                             20.8532
eval/Returns Max                             44.9797
eval/Returns Min                              0.00142738
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.9751
eval/env_infos/final/reward_dist Mean         0.627713
eval/env_infos/final/reward_dist Std          0.76813
eval/env_infos/final/reward_dist Max          1.56987
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000131855
eval/env_infos/initial/reward_dist Std        0.000395564
eval/env_infos/initial/reward_dist Max        0.00131855
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.424376
eval/env_infos/reward_dist Std                0.646496
eval/env_infos/reward_dist Max                1.56987
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594401
time/evaluation sampling (s)                  3.43591
time/exploration sampling (s)                17.7376
time/logging (s)                              0.00536363
time/saving (s)                               0.000988732
time/training (s)                             4.27343
time/epoch (s)                               25.4593
time/total (s)                             7205.55
Epoch                                       282
---------------------------------------  ----------------
2023-08-05 02:21:39.264569 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 283 finished
---------------------------------------  ----------------
epoch                                       283
replay_buffer/size                       568000
trainer/QF Loss                               3.42864e+11
trainer/Policy Loss                          -3.25241e+06
trainer/Raw Policy Loss                      -3.25241e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.66038e+06
trainer/Q Predictions Std                404315
trainer/Q Predictions Max                     4.34708e+06
trainer/Q Predictions Min                185775
trainer/Q Targets Mean                        3.09347e+06
trainer/Q Targets Std                    171535
trainer/Q Targets Max                         4.47942e+06
trainer/Q Targets Min                         1.63765e+06
trainer/Bellman Errors Mean                   3.42864e+11
trainer/Bellman Errors Std                    5.66016e+11
trainer/Bellman Errors Max                    7.84275e+12
trainer/Bellman Errors Min                 5852.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     568000
expl/num paths total                      14200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.336746
expl/Rewards Std                              0.588799
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            13.4698
expl/Returns Std                             19.2533
expl/Returns Max                             44.3193
expl/Returns Min                              0
expl/Actions Mean                             0.257779
expl/Actions Std                              0.810024
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.4698
expl/env_infos/final/reward_dist Mean         0.515266
expl/env_infos/final/reward_dist Std          0.725144
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00143182
expl/env_infos/initial/reward_dist Std        0.00487192
expl/env_infos/initial/reward_dist Max        0.0243598
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.336746
expl/env_infos/reward_dist Std                0.588799
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     113600
eval/num paths total                       2840
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.336788
eval/Rewards Std                              0.571672
eval/Rewards Max                              1.56966
eval/Rewards Min                              0
eval/Returns Mean                            13.4715
eval/Returns Std                             18.4908
eval/Returns Max                             45.2909
eval/Returns Min                              0.000659
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         13.4715
eval/env_infos/final/reward_dist Mean         0.567652
eval/env_infos/final/reward_dist Std          0.707845
eval/env_infos/final/reward_dist Max          1.56966
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00143307
eval/env_infos/initial/reward_dist Std        0.00429921
eval/env_infos/initial/reward_dist Max        0.0143307
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.336788
eval/env_infos/reward_dist Std                0.571672
eval/env_infos/reward_dist Max                1.56966
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00683514
time/evaluation sampling (s)                  3.50258
time/exploration sampling (s)                17.7123
time/logging (s)                              0.0054297
time/saving (s)                               0.00101192
time/training (s)                             4.11456
time/epoch (s)                               25.3428
time/total (s)                             7230.89
Epoch                                       283
---------------------------------------  ----------------
2023-08-05 02:22:04.953097 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 284 finished
---------------------------------------  ----------------
epoch                                       284
replay_buffer/size                       570000
trainer/QF Loss                               3.45755e+11
trainer/Policy Loss                          -3.28081e+06
trainer/Raw Policy Loss                      -3.28081e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.68974e+06
trainer/Q Predictions Std                412491
trainer/Q Predictions Max                     4.09522e+06
trainer/Q Predictions Min                  1158.09
trainer/Q Targets Mean                        3.11972e+06
trainer/Q Targets Std                    165516
trainer/Q Targets Max                         4.32602e+06
trainer/Q Targets Min                         1.69028e+06
trainer/Bellman Errors Mean                   3.45755e+11
trainer/Bellman Errors Std                    6.35804e+11
trainer/Bellman Errors Max                    9.69851e+12
trainer/Bellman Errors Min                23409
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     570000
expl/num paths total                      14250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.606006
expl/Rewards Std                              0.675949
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            24.2402
expl/Returns Std                             19.4878
expl/Returns Max                             44.5082
expl/Returns Min                              0
expl/Actions Mean                             0.252594
expl/Actions Std                              0.806433
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.2402
expl/env_infos/final/reward_dist Mean         0.95186
expl/env_infos/final/reward_dist Std          0.750856
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00139605
expl/env_infos/initial/reward_dist Std        0.0042599
expl/env_infos/initial/reward_dist Max        0.0195279
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.606006
expl/env_infos/reward_dist Std                0.675949
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     114000
eval/num paths total                       2850
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.670137
eval/Rewards Std                              0.710633
eval/Rewards Max                              1.56976
eval/Rewards Min                              0
eval/Returns Mean                            26.8055
eval/Returns Std                             21.8791
eval/Returns Max                             45.3053
eval/Returns Min                              0.00160453
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.8055
eval/env_infos/final/reward_dist Mean         0.939303
eval/env_infos/final/reward_dist Std          0.766956
eval/env_infos/final/reward_dist Max          1.56976
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00151396
eval/env_infos/initial/reward_dist Std        0.00395199
eval/env_infos/initial/reward_dist Max        0.0132487
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.670137
eval/env_infos/reward_dist Std                0.710633
eval/env_infos/reward_dist Max                1.56976
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00603299
time/evaluation sampling (s)                  3.3943
time/exploration sampling (s)                17.9263
time/logging (s)                              0.00539642
time/saving (s)                               0.00104086
time/training (s)                             4.35169
time/epoch (s)                               25.6848
time/total (s)                             7256.58
Epoch                                       284
---------------------------------------  ----------------
2023-08-05 02:22:30.893775 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 285 finished
---------------------------------------  ----------------
epoch                                       285
replay_buffer/size                       572000
trainer/QF Loss                               3.56599e+11
trainer/Policy Loss                          -3.3195e+06
trainer/Raw Policy Loss                      -3.3195e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.71975e+06
trainer/Q Predictions Std                420549
trainer/Q Predictions Max                     5.04727e+06
trainer/Q Predictions Min                  6308.89
trainer/Q Targets Mean                        3.1575e+06
trainer/Q Targets Std                    175086
trainer/Q Targets Max                         4.47888e+06
trainer/Q Targets Min                         1.72026e+06
trainer/Bellman Errors Mean                   3.566e+11
trainer/Bellman Errors Std                    6.17904e+11
trainer/Bellman Errors Max                    9.3631e+12
trainer/Bellman Errors Min                 4624
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     572000
expl/num paths total                      14300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.634246
expl/Rewards Std                              0.68961
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            25.3699
expl/Returns Std                             20.0775
expl/Returns Max                             46.1797
expl/Returns Min                              0
expl/Actions Mean                             0.273615
expl/Actions Std                              0.803241
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.3699
expl/env_infos/final/reward_dist Mean         0.970873
expl/env_infos/final/reward_dist Std          0.760167
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00266439
expl/env_infos/initial/reward_dist Std        0.00674569
expl/env_infos/initial/reward_dist Max        0.0358446
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.634246
expl/env_infos/reward_dist Std                0.68961
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                     114400
eval/num paths total                       2860
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.506111
eval/Rewards Std                              0.668334
eval/Rewards Max                              1.5704
eval/Rewards Min                              0
eval/Returns Mean                            20.2444
eval/Returns Std                             20.9602
eval/Returns Max                             45.1912
eval/Returns Min                              0.000329488
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.2444
eval/env_infos/final/reward_dist Mean         0.77449
eval/env_infos/final/reward_dist Std          0.775018
eval/env_infos/final/reward_dist Max          1.5704
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000660915
eval/env_infos/initial/reward_dist Std        0.00198274
eval/env_infos/initial/reward_dist Max        0.00660915
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.506111
eval/env_infos/reward_dist Std                0.668334
eval/env_infos/reward_dist Max                1.5704
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591538
time/evaluation sampling (s)                  3.41814
time/exploration sampling (s)                18.1706
time/logging (s)                              0.00536684
time/saving (s)                               0.00100747
time/training (s)                             4.33614
time/epoch (s)                               25.9372
time/total (s)                             7282.52
Epoch                                       285
---------------------------------------  ----------------
2023-08-05 02:22:56.520290 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 286 finished
---------------------------------------  ----------------
epoch                                       286
replay_buffer/size                       574000
trainer/QF Loss                               3.59248e+11
trainer/Policy Loss                          -3.34746e+06
trainer/Raw Policy Loss                      -3.34746e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.7453e+06
trainer/Q Predictions Std                414329
trainer/Q Predictions Max                     4.57428e+06
trainer/Q Predictions Min                  1388.08
trainer/Q Targets Mean                        3.1833e+06
trainer/Q Targets Std                    175757
trainer/Q Targets Max                         4.73414e+06
trainer/Q Targets Min                         1.765e+06
trainer/Bellman Errors Mean                   3.59248e+11
trainer/Bellman Errors Std                    5.96099e+11
trainer/Bellman Errors Max                    9.58089e+12
trainer/Bellman Errors Min               141564
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     574000
expl/num paths total                      14350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.562938
expl/Rewards Std                              0.657747
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            22.5175
expl/Returns Std                             19.4478
expl/Returns Max                             44.5736
expl/Returns Min                              0
expl/Actions Mean                             0.259538
expl/Actions Std                              0.799698
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.5175
expl/env_infos/final/reward_dist Mean         0.835237
expl/env_infos/final/reward_dist Std          0.760698
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000967222
expl/env_infos/initial/reward_dist Std        0.00246884
expl/env_infos/initial/reward_dist Max        0.010212
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.562938
expl/env_infos/reward_dist Std                0.657747
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     114800
eval/num paths total                       2870
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.750729
eval/Rewards Std                              0.705479
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            30.0292
eval/Returns Std                             19.8462
eval/Returns Max                             44.7997
eval/Returns Min                              0.00448202
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.0292
eval/env_infos/final/reward_dist Mean         1.09799
eval/env_infos/final/reward_dist Std          0.71881
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.750729
eval/env_infos/reward_dist Std                0.705479
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596726
time/evaluation sampling (s)                  3.46917
time/exploration sampling (s)                17.6438
time/logging (s)                              0.00537788
time/saving (s)                               0.00101225
time/training (s)                             4.49785
time/epoch (s)                               25.6231
time/total (s)                             7308.15
Epoch                                       286
---------------------------------------  ----------------
2023-08-05 02:23:21.949279 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 287 finished
---------------------------------------  ----------------
epoch                                       287
replay_buffer/size                       576000
trainer/QF Loss                               3.67044e+11
trainer/Policy Loss                          -3.38521e+06
trainer/Raw Policy Loss                      -3.38521e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.77677e+06
trainer/Q Predictions Std                422401
trainer/Q Predictions Max                     4.9047e+06
trainer/Q Predictions Min                114161
trainer/Q Targets Mean                        3.21648e+06
trainer/Q Targets Std                    191172
trainer/Q Targets Max                         4.57969e+06
trainer/Q Targets Min                         1.7078e+06
trainer/Bellman Errors Mean                   3.67044e+11
trainer/Bellman Errors Std                    5.89428e+11
trainer/Bellman Errors Max                    9.15449e+12
trainer/Bellman Errors Min                 1521
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     576000
expl/num paths total                      14400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.470803
expl/Rewards Std                              0.641267
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            18.8321
expl/Returns Std                             19.5393
expl/Returns Max                             45.3152
expl/Returns Min                              0
expl/Actions Mean                             0.258237
expl/Actions Std                              0.80859
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.8321
expl/env_infos/final/reward_dist Mean         0.736864
expl/env_infos/final/reward_dist Std          0.769602
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000574559
expl/env_infos/initial/reward_dist Std        0.00313917
expl/env_infos/initial/reward_dist Max        0.0220684
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.470803
expl/env_infos/reward_dist Std                0.641267
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     115200
eval/num paths total                       2880
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.873331
eval/Rewards Std                              0.685822
eval/Rewards Max                              1.57067
eval/Rewards Min                              0
eval/Returns Mean                            34.9332
eval/Returns Std                             17.6023
eval/Returns Max                             45.42
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         34.9332
eval/env_infos/final/reward_dist Mean         1.24749
eval/env_infos/final/reward_dist Std          0.624064
eval/env_infos/final/reward_dist Max          1.57067
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00338019
eval/env_infos/initial/reward_dist Std        0.00615405
eval/env_infos/initial/reward_dist Max        0.020462
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.873331
eval/env_infos/reward_dist Std                0.685822
eval/env_infos/reward_dist Max                1.57067
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593504
time/evaluation sampling (s)                  3.46365
time/exploration sampling (s)                17.5577
time/logging (s)                              0.00745053
time/saving (s)                               0.00110258
time/training (s)                             4.39181
time/epoch (s)                               25.4276
time/total (s)                             7333.57
Epoch                                       287
---------------------------------------  ----------------
2023-08-05 02:23:48.483576 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 288 finished
---------------------------------------  ----------------
epoch                                       288
replay_buffer/size                       578000
trainer/QF Loss                               3.70565e+11
trainer/Policy Loss                          -3.41723e+06
trainer/Raw Policy Loss                      -3.41723e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.8014e+06
trainer/Q Predictions Std                423529
trainer/Q Predictions Max                     4.82162e+06
trainer/Q Predictions Min                  3169.23
trainer/Q Targets Mean                        3.24915e+06
trainer/Q Targets Std                    170022
trainer/Q Targets Max                         4.61361e+06
trainer/Q Targets Min                         1.75076e+06
trainer/Bellman Errors Mean                   3.70565e+11
trainer/Bellman Errors Std                    6.35868e+11
trainer/Bellman Errors Max                    9.92898e+12
trainer/Bellman Errors Min                  462.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     578000
expl/num paths total                      14450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.476258
expl/Rewards Std                              0.648516
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            19.0503
expl/Returns Std                             20.0491
expl/Returns Max                             44.4574
expl/Returns Min                              0
expl/Actions Mean                             0.256426
expl/Actions Std                              0.809333
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.0503
expl/env_infos/final/reward_dist Mean         0.715522
expl/env_infos/final/reward_dist Std          0.775698
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00164622
expl/env_infos/initial/reward_dist Std        0.00419806
expl/env_infos/initial/reward_dist Max        0.0164681
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.476258
expl/env_infos/reward_dist Std                0.648516
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     115600
eval/num paths total                       2890
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.893247
eval/Rewards Std                              0.689312
eval/Rewards Max                              1.57064
eval/Rewards Min                              0
eval/Returns Mean                            35.7299
eval/Returns Std                             17.8674
eval/Returns Max                             45.3435
eval/Returns Min                              0.000976155
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.7299
eval/env_infos/final/reward_dist Mean         1.25493
eval/env_infos/final/reward_dist Std          0.627468
eval/env_infos/final/reward_dist Max          1.57064
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00277314
eval/env_infos/initial/reward_dist Std        0.00713403
eval/env_infos/initial/reward_dist Max        0.0238989
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.893247
eval/env_infos/reward_dist Std                0.689312
eval/env_infos/reward_dist Max                1.57064
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0059302
time/evaluation sampling (s)                  3.52058
time/exploration sampling (s)                18.6758
time/logging (s)                              0.00541517
time/saving (s)                               0.00101609
time/training (s)                             4.31789
time/epoch (s)                               26.5266
time/total (s)                             7360.1
Epoch                                       288
---------------------------------------  ----------------
2023-08-05 02:24:13.919979 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 289 finished
---------------------------------------  ----------------
epoch                                       289
replay_buffer/size                       580000
trainer/QF Loss                               3.96686e+11
trainer/Policy Loss                          -3.45057e+06
trainer/Raw Policy Loss                      -3.45057e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.81945e+06
trainer/Q Predictions Std                433263
trainer/Q Predictions Max                     5.28933e+06
trainer/Q Predictions Min                  2639.34
trainer/Q Targets Mean                        3.28175e+06
trainer/Q Targets Std                    182866
trainer/Q Targets Max                         4.86523e+06
trainer/Q Targets Min                         1.73571e+06
trainer/Bellman Errors Mean                   3.96686e+11
trainer/Bellman Errors Std                    6.67139e+11
trainer/Bellman Errors Max                    1.00413e+13
trainer/Bellman Errors Min               121278
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     580000
expl/num paths total                      14500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.542977
expl/Rewards Std                              0.66644
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            21.7191
expl/Returns Std                             19.7612
expl/Returns Max                             44.5687
expl/Returns Min                              0
expl/Actions Mean                             0.280966
expl/Actions Std                              0.80759
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.7191
expl/env_infos/final/reward_dist Mean         0.844841
expl/env_infos/final/reward_dist Std          0.779642
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00110641
expl/env_infos/initial/reward_dist Std        0.00375902
expl/env_infos/initial/reward_dist Max        0.0197113
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.542977
expl/env_infos/reward_dist Std                0.66644
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     116000
eval/num paths total                       2900
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.899722
eval/Rewards Std                              0.679455
eval/Rewards Max                              1.57071
eval/Rewards Min                              0
eval/Returns Mean                            35.9889
eval/Returns Std                             17.0197
eval/Returns Max                             45.3803
eval/Returns Min                              0.00959554
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.9889
eval/env_infos/final/reward_dist Mean         1.29074
eval/env_infos/final/reward_dist Std          0.562628
eval/env_infos/final/reward_dist Max          1.57071
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00210754
eval/env_infos/initial/reward_dist Std        0.00606065
eval/env_infos/initial/reward_dist Max        0.0202754
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.899722
eval/env_infos/reward_dist Std                0.679455
eval/env_infos/reward_dist Max                1.57071
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590127
time/evaluation sampling (s)                  3.46028
time/exploration sampling (s)                17.3602
time/logging (s)                              0.00538437
time/saving (s)                               0.000977996
time/training (s)                             4.60019
time/epoch (s)                               25.433
time/total (s)                             7385.54
Epoch                                       289
---------------------------------------  ----------------
2023-08-05 02:24:39.435436 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 290 finished
---------------------------------------  ----------------
epoch                                       290
replay_buffer/size                       582000
trainer/QF Loss                               3.97469e+11
trainer/Policy Loss                          -3.48276e+06
trainer/Raw Policy Loss                      -3.48276e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.84698e+06
trainer/Q Predictions Std                439119
trainer/Q Predictions Max                     5.59243e+06
trainer/Q Predictions Min                  1204.98
trainer/Q Targets Mean                        3.31559e+06
trainer/Q Targets Std                    182996
trainer/Q Targets Max                         5.9999e+06
trainer/Q Targets Min                         1.76306e+06
trainer/Bellman Errors Mean                   3.97469e+11
trainer/Bellman Errors Std                    6.84493e+11
trainer/Bellman Errors Max                    1.07756e+13
trainer/Bellman Errors Min               355812
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     582000
expl/num paths total                      14550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.393078
expl/Rewards Std                              0.621804
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            15.7231
expl/Returns Std                             19.9849
expl/Returns Max                             44.5439
expl/Returns Min                              0
expl/Actions Mean                             0.262952
expl/Actions Std                              0.794923
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.7231
expl/env_infos/final/reward_dist Mean         0.592654
expl/env_infos/final/reward_dist Std          0.757144
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       2.84817e-05
expl/env_infos/initial/reward_dist Std        0.000156534
expl/env_infos/initial/reward_dist Max        0.00106679
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.393078
expl/env_infos/reward_dist Std                0.621804
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     116400
eval/num paths total                       2910
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.557769
eval/Rewards Std                              0.694611
eval/Rewards Max                              1.56978
eval/Rewards Min                              0
eval/Returns Mean                            22.3108
eval/Returns Std                             22.2838
eval/Returns Max                             45.0999
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.3108
eval/env_infos/final/reward_dist Mean         0.783701
eval/env_infos/final/reward_dist Std          0.783702
eval/env_infos/final/reward_dist Max          1.56978
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00271036
eval/env_infos/initial/reward_dist Std        0.00545758
eval/env_infos/initial/reward_dist Max        0.0149677
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.557769
eval/env_infos/reward_dist Std                0.694611
eval/env_infos/reward_dist Max                1.56978
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00605047
time/evaluation sampling (s)                  3.41227
time/exploration sampling (s)                17.5769
time/logging (s)                              0.00539055
time/saving (s)                               0.000971916
time/training (s)                             4.51053
time/epoch (s)                               25.5121
time/total (s)                             7411.05
Epoch                                       290
---------------------------------------  ----------------
2023-08-05 02:25:05.030505 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 291 finished
---------------------------------------  ----------------
epoch                                       291
replay_buffer/size                       584000
trainer/QF Loss                               3.98851e+11
trainer/Policy Loss                          -3.52061e+06
trainer/Raw Policy Loss                      -3.52061e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.88459e+06
trainer/Q Predictions Std                441235
trainer/Q Predictions Max                     5.17895e+06
trainer/Q Predictions Min                  1212.88
trainer/Q Targets Mean                        3.34365e+06
trainer/Q Targets Std                    192500
trainer/Q Targets Max                         5.84867e+06
trainer/Q Targets Min                         1.7711e+06
trainer/Bellman Errors Mean                   3.98851e+11
trainer/Bellman Errors Std                    7.1716e+11
trainer/Bellman Errors Max                    1.0833e+13
trainer/Bellman Errors Min                22201
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     584000
expl/num paths total                      14600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.624927
expl/Rewards Std                              0.68052
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            24.9971
expl/Returns Std                             19.6036
expl/Returns Max                             44.5431
expl/Returns Min                              0
expl/Actions Mean                             0.248093
expl/Actions Std                              0.800821
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.9971
expl/env_infos/final/reward_dist Mean         0.906633
expl/env_infos/final/reward_dist Std          0.771948
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00128085
expl/env_infos/initial/reward_dist Std        0.00477918
expl/env_infos/initial/reward_dist Max        0.0280456
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.624927
expl/env_infos/reward_dist Std                0.68052
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     116800
eval/num paths total                       2920
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.54728
eval/Rewards Std                              0.690683
eval/Rewards Max                              1.57071
eval/Rewards Min                              0
eval/Returns Mean                            21.8912
eval/Returns Std                             21.8955
eval/Returns Max                             45.2519
eval/Returns Min                              0.0135899
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         21.8912
eval/env_infos/final/reward_dist Mean         0.78425
eval/env_infos/final/reward_dist Std          0.784253
eval/env_infos/final/reward_dist Max          1.57071
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000393156
eval/env_infos/initial/reward_dist Std        0.000643751
eval/env_infos/initial/reward_dist Max        0.00183071
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.54728
eval/env_infos/reward_dist Std                0.690683
eval/env_infos/reward_dist Max                1.57071
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594207
time/evaluation sampling (s)                  3.42798
time/exploration sampling (s)                17.6267
time/logging (s)                              0.00535396
time/saving (s)                               0.000995876
time/training (s)                             4.52459
time/epoch (s)                               25.5916
time/total (s)                             7436.65
Epoch                                       291
---------------------------------------  ----------------
2023-08-05 02:25:30.975115 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 292 finished
---------------------------------------  ----------------
epoch                                       292
replay_buffer/size                       586000
trainer/QF Loss                               4.27053e+11
trainer/Policy Loss                          -3.55314e+06
trainer/Raw Policy Loss                      -3.55314e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.89142e+06
trainer/Q Predictions Std                448070
trainer/Q Predictions Max                     4.4849e+06
trainer/Q Predictions Min                  1635.9
trainer/Q Targets Mean                        3.38029e+06
trainer/Q Targets Std                    189557
trainer/Q Targets Max                         5.05854e+06
trainer/Q Targets Min                         1.83324e+06
trainer/Bellman Errors Mean                   4.27053e+11
trainer/Bellman Errors Std                    7.1198e+11
trainer/Bellman Errors Max                    1.09591e+13
trainer/Bellman Errors Min                 1660.56
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     586000
expl/num paths total                      14650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.438082
expl/Rewards Std                              0.638751
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            17.5233
expl/Returns Std                             20.2149
expl/Returns Max                             44.8837
expl/Returns Min                              0
expl/Actions Mean                             0.260926
expl/Actions Std                              0.808086
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.5233
expl/env_infos/final/reward_dist Mean         0.654618
expl/env_infos/final/reward_dist Std          0.769695
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00186874
expl/env_infos/initial/reward_dist Std        0.00559307
expl/env_infos/initial/reward_dist Max        0.0276273
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.438082
expl/env_infos/reward_dist Std                0.638751
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     117200
eval/num paths total                       2930
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.00655
eval/Rewards Std                              0.648135
eval/Rewards Max                              1.57076
eval/Rewards Min                              0
eval/Returns Mean                            40.2619
eval/Returns Std                             13.4298
eval/Returns Max                             45.5974
eval/Returns Min                              0.00969931
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         40.2619
eval/env_infos/final/reward_dist Mean         1.41142
eval/env_infos/final/reward_dist Std          0.47048
eval/env_infos/final/reward_dist Max          1.57076
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00486411
eval/env_infos/initial/reward_dist Std        0.00767294
eval/env_infos/initial/reward_dist Max        0.0229377
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.00655
eval/env_infos/reward_dist Std                0.648135
eval/env_infos/reward_dist Max                1.57076
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585853
time/evaluation sampling (s)                  3.43722
time/exploration sampling (s)                18.0308
time/logging (s)                              0.00534956
time/saving (s)                               0.000994062
time/training (s)                             4.46097
time/epoch (s)                               25.9412
time/total (s)                             7462.59
Epoch                                       292
---------------------------------------  ----------------
2023-08-05 02:25:56.636870 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 293 finished
---------------------------------------  ----------------
epoch                                       293
replay_buffer/size                       588000
trainer/QF Loss                               4.22246e+11
trainer/Policy Loss                          -3.59039e+06
trainer/Raw Policy Loss                      -3.59039e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.93372e+06
trainer/Q Predictions Std                446878
trainer/Q Predictions Max                     4.53218e+06
trainer/Q Predictions Min                  1294.8
trainer/Q Targets Mean                        3.41685e+06
trainer/Q Targets Std                    183903
trainer/Q Targets Max                         5.39386e+06
trainer/Q Targets Min                         1.83397e+06
trainer/Bellman Errors Mean                   4.22246e+11
trainer/Bellman Errors Std                    6.89919e+11
trainer/Bellman Errors Max                    1.14617e+13
trainer/Bellman Errors Min                 2500
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     588000
expl/num paths total                      14700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.543839
expl/Rewards Std                              0.659814
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            21.7536
expl/Returns Std                             19.7335
expl/Returns Max                             44.8549
expl/Returns Min                              0
expl/Actions Mean                             0.254793
expl/Actions Std                              0.801516
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.7536
expl/env_infos/final/reward_dist Mean         0.782857
expl/env_infos/final/reward_dist Std          0.77006
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0021968
expl/env_infos/initial/reward_dist Std        0.00554505
expl/env_infos/initial/reward_dist Max        0.0217456
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.543839
expl/env_infos/reward_dist Std                0.659814
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     117600
eval/num paths total                       2940
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.432748
eval/Rewards Std                              0.651415
eval/Rewards Max                              1.57007
eval/Rewards Min                              0
eval/Returns Mean                            17.3099
eval/Returns Std                             21.2505
eval/Returns Max                             45.1089
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.3099
eval/env_infos/final/reward_dist Mean         0.62677
eval/env_infos/final/reward_dist Std          0.767633
eval/env_infos/final/reward_dist Max          1.56897
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000659252
eval/env_infos/initial/reward_dist Std        0.00197776
eval/env_infos/initial/reward_dist Max        0.00659252
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.432748
eval/env_infos/reward_dist Std                0.651415
eval/env_infos/reward_dist Max                1.57007
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00592267
time/evaluation sampling (s)                  3.48565
time/exploration sampling (s)                18.1276
time/logging (s)                              0.00535774
time/saving (s)                               0.000999191
time/training (s)                             4.03284
time/epoch (s)                               25.6583
time/total (s)                             7488.25
Epoch                                       293
---------------------------------------  ----------------
2023-08-05 02:26:22.131856 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 294 finished
---------------------------------------  ----------------
epoch                                       294
replay_buffer/size                       590000
trainer/QF Loss                               4.21641e+11
trainer/Policy Loss                          -3.62901e+06
trainer/Raw Policy Loss                      -3.62901e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    2.9666e+06
trainer/Q Predictions Std                454985
trainer/Q Predictions Max                     5.5166e+06
trainer/Q Predictions Min                  1236.74
trainer/Q Targets Mean                        3.44907e+06
trainer/Q Targets Std                    181435
trainer/Q Targets Max                         5.0136e+06
trainer/Q Targets Min                         1.8781e+06
trainer/Bellman Errors Mean                   4.21641e+11
trainer/Bellman Errors Std                    7.23856e+11
trainer/Bellman Errors Max                    1.1809e+13
trainer/Bellman Errors Min               592515
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     590000
expl/num paths total                      14750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.473995
expl/Rewards Std                              0.647912
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            18.9598
expl/Returns Std                             19.969
expl/Returns Max                             45.0867
expl/Returns Min                              0
expl/Actions Mean                             0.240639
expl/Actions Std                              0.805671
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.9598
expl/env_infos/final/reward_dist Mean         0.7207
expl/env_infos/final/reward_dist Std          0.779325
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00090193
expl/env_infos/initial/reward_dist Std        0.00299724
expl/env_infos/initial/reward_dist Max        0.0184685
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.473995
expl/env_infos/reward_dist Std                0.647912
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                     118000
eval/num paths total                       2950
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.511949
eval/Rewards Std                              0.669495
eval/Rewards Max                              1.57051
eval/Rewards Min                              0
eval/Returns Mean                            20.478
eval/Returns Std                             21.01
eval/Returns Max                             45.0174
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.478
eval/env_infos/final/reward_dist Mean         0.774825
eval/env_infos/final/reward_dist Std          0.775311
eval/env_infos/final/reward_dist Max          1.57051
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000171953
eval/env_infos/initial/reward_dist Std        0.000515859
eval/env_infos/initial/reward_dist Max        0.00171953
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.511949
eval/env_infos/reward_dist Std                0.669495
eval/env_infos/reward_dist Max                1.57051
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00599491
time/evaluation sampling (s)                  3.44047
time/exploration sampling (s)                17.9102
time/logging (s)                              0.00538701
time/saving (s)                               0.000971207
time/training (s)                             4.12849
time/epoch (s)                               25.4916
time/total (s)                             7513.74
Epoch                                       294
---------------------------------------  ----------------
2023-08-05 02:26:47.251719 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 295 finished
---------------------------------------  ----------------
epoch                                       295
replay_buffer/size                       592000
trainer/QF Loss                               4.50205e+11
trainer/Policy Loss                          -3.6633e+06
trainer/Raw Policy Loss                      -3.6633e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    3.00087e+06
trainer/Q Predictions Std                473008
trainer/Q Predictions Max                     4.71047e+06
trainer/Q Predictions Min                  1796.06
trainer/Q Targets Mean                        3.48346e+06
trainer/Q Targets Std                    198028
trainer/Q Targets Max                         5.2403e+06
trainer/Q Targets Min                         1.86679e+06
trainer/Bellman Errors Mean                   4.50205e+11
trainer/Bellman Errors Std                    8.28849e+11
trainer/Bellman Errors Max                    1.19085e+13
trainer/Bellman Errors Min                 9604
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     592000
expl/num paths total                      14800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.467087
expl/Rewards Std                              0.644859
expl/Rewards Max                              1.57071
expl/Rewards Min                              0
expl/Returns Mean                            18.6835
expl/Returns Std                             19.7473
expl/Returns Max                             44.3975
expl/Returns Min                              0
expl/Actions Mean                             0.252289
expl/Actions Std                              0.814597
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.6835
expl/env_infos/final/reward_dist Mean         0.735432
expl/env_infos/final/reward_dist Std          0.774774
expl/env_infos/final/reward_dist Max          1.57071
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00137852
expl/env_infos/initial/reward_dist Std        0.0054636
expl/env_infos/initial/reward_dist Max        0.0345481
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.467087
expl/env_infos/reward_dist Std                0.644859
expl/env_infos/reward_dist Max                1.57071
expl/env_infos/reward_dist Min                0
eval/num steps total                     118400
eval/num paths total                       2960
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.674599
eval/Rewards Std                              0.711984
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            26.984
eval/Returns Std                             22.0283
eval/Returns Max                             45.677
eval/Returns Min                              0.00433376
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.984
eval/env_infos/final/reward_dist Mean         0.941746
eval/env_infos/final/reward_dist Std          0.768933
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00346649
eval/env_infos/initial/reward_dist Std        0.00536707
eval/env_infos/initial/reward_dist Max        0.0143387
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.674599
eval/env_infos/reward_dist Std                0.711984
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593945
time/evaluation sampling (s)                  3.36747
time/exploration sampling (s)                17.4134
time/logging (s)                              0.00531686
time/saving (s)                               0.00096022
time/training (s)                             4.32334
time/epoch (s)                               25.1164
time/total (s)                             7538.86
Epoch                                       295
---------------------------------------  ----------------
2023-08-05 02:27:13.059313 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 296 finished
---------------------------------------  ----------------
epoch                                       296
replay_buffer/size                       594000
trainer/QF Loss                               4.31164e+11
trainer/Policy Loss                          -3.69119e+06
trainer/Raw Policy Loss                      -3.69119e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    3.03398e+06
trainer/Q Predictions Std                456753
trainer/Q Predictions Max                     4.58517e+06
trainer/Q Predictions Min                  1252.78
trainer/Q Targets Mean                        3.51539e+06
trainer/Q Targets Std                    187035
trainer/Q Targets Max                         5.23221e+06
trainer/Q Targets Min                         1.88256e+06
trainer/Bellman Errors Mean                   4.31164e+11
trainer/Bellman Errors Std                    7.41781e+11
trainer/Bellman Errors Max                    1.18806e+13
trainer/Bellman Errors Min                  324
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     594000
expl/num paths total                      14850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.461645
expl/Rewards Std                              0.642471
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            18.4658
expl/Returns Std                             19.796
expl/Returns Max                             44.7292
expl/Returns Min                              0
expl/Actions Mean                             0.251364
expl/Actions Std                              0.810226
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.4658
expl/env_infos/final/reward_dist Mean         0.689642
expl/env_infos/final/reward_dist Std          0.778007
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00140961
expl/env_infos/initial/reward_dist Std        0.00440568
expl/env_infos/initial/reward_dist Max        0.0249025
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.461645
expl/env_infos/reward_dist Std                0.642471
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     118800
eval/num paths total                       2970
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.513634
eval/Rewards Std                              0.672424
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            20.5453
eval/Returns Std                             20.9943
eval/Returns Max                             44.5018
eval/Returns Min                              0.00374097
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.5453
eval/env_infos/final/reward_dist Mean         0.776375
eval/env_infos/final/reward_dist Std          0.776704
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.513634
eval/env_infos/reward_dist Std                0.672424
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00618925
time/evaluation sampling (s)                  3.44336
time/exploration sampling (s)                18.0083
time/logging (s)                              0.00742892
time/saving (s)                               0.00110014
time/training (s)                             4.33979
time/epoch (s)                               25.8062
time/total (s)                             7564.67
Epoch                                       296
---------------------------------------  ----------------
2023-08-05 02:27:39.086143 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 297 finished
---------------------------------------  ----------------
epoch                                       297
replay_buffer/size                       596000
trainer/QF Loss                               4.30783e+11
trainer/Policy Loss                          -3.73674e+06
trainer/Raw Policy Loss                      -3.73674e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    3.06272e+06
trainer/Q Predictions Std                454710
trainer/Q Predictions Max                     5.80502e+06
trainer/Q Predictions Min                  6458.57
trainer/Q Targets Mean                        3.54996e+06
trainer/Q Targets Std                    196240
trainer/Q Targets Max                         5.88046e+06
trainer/Q Targets Min                         1.89805e+06
trainer/Bellman Errors Mean                   4.30783e+11
trainer/Bellman Errors Std                    6.93878e+11
trainer/Bellman Errors Max                    1.19141e+13
trainer/Bellman Errors Min                   49
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     596000
expl/num paths total                      14900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.452855
expl/Rewards Std                              0.629646
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            18.1142
expl/Returns Std                             19.3641
expl/Returns Max                             43.5446
expl/Returns Min                              0
expl/Actions Mean                             0.247664
expl/Actions Std                              0.796582
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.1142
expl/env_infos/final/reward_dist Mean         0.668483
expl/env_infos/final/reward_dist Std          0.764084
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00121687
expl/env_infos/initial/reward_dist Std        0.00363816
expl/env_infos/initial/reward_dist Max        0.0192751
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.452855
expl/env_infos/reward_dist Std                0.629646
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     119200
eval/num paths total                       2980
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.333674
eval/Rewards Std                              0.603832
eval/Rewards Max                              1.56874
eval/Rewards Min                              0
eval/Returns Mean                            13.347
eval/Returns Std                             20.377
eval/Returns Max                             44.9451
eval/Returns Min                              0
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         13.347
eval/env_infos/final/reward_dist Mean         0.470364
eval/env_infos/final/reward_dist Std          0.718493
eval/env_infos/final/reward_dist Max          1.56874
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.333674
eval/env_infos/reward_dist Std                0.603832
eval/env_infos/reward_dist Max                1.56874
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588639
time/evaluation sampling (s)                  3.37316
time/exploration sampling (s)                18.1385
time/logging (s)                              0.00536861
time/saving (s)                               0.00101442
time/training (s)                             4.49515
time/epoch (s)                               26.0191
time/total (s)                             7590.69
Epoch                                       297
---------------------------------------  ----------------
2023-08-05 02:28:04.797867 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 298 finished
---------------------------------------  ----------------
epoch                                       298
replay_buffer/size                       598000
trainer/QF Loss                               4.41026e+11
trainer/Policy Loss                          -3.7665e+06
trainer/Raw Policy Loss                      -3.7665e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    3.08972e+06
trainer/Q Predictions Std                454764
trainer/Q Predictions Max                     5.05317e+06
trainer/Q Predictions Min                 21616
trainer/Q Targets Mean                        3.58511e+06
trainer/Q Targets Std                    185904
trainer/Q Targets Max                         5.17671e+06
trainer/Q Targets Min                         1.95085e+06
trainer/Bellman Errors Mean                   4.41026e+11
trainer/Bellman Errors Std                    7.38997e+11
trainer/Bellman Errors Max                    1.30352e+13
trainer/Bellman Errors Min               169950
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     598000
expl/num paths total                      14950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.570831
expl/Rewards Std                              0.674175
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            22.8333
expl/Returns Std                             19.5671
expl/Returns Max                             43.68
expl/Returns Min                              0
expl/Actions Mean                             0.260223
expl/Actions Std                              0.808838
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.8333
expl/env_infos/final/reward_dist Mean         0.878169
expl/env_infos/final/reward_dist Std          0.778417
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000912286
expl/env_infos/initial/reward_dist Std        0.00357188
expl/env_infos/initial/reward_dist Max        0.0191659
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.570831
expl/env_infos/reward_dist Std                0.674175
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     119600
eval/num paths total                       2990
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.782735
eval/Rewards Std                              0.709974
eval/Rewards Max                              1.57051
eval/Rewards Min                              0
eval/Returns Mean                            31.3094
eval/Returns Std                             20.5022
eval/Returns Max                             45.7824
eval/Returns Min                              0.000107394
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.3094
eval/env_infos/final/reward_dist Mean         1.09782
eval/env_infos/final/reward_dist Std          0.71869
eval/env_infos/final/reward_dist Max          1.57051
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0028287
eval/env_infos/initial/reward_dist Std        0.00668824
eval/env_infos/initial/reward_dist Max        0.0221205
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.782735
eval/env_infos/reward_dist Std                0.709974
eval/env_infos/reward_dist Max                1.57051
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593414
time/evaluation sampling (s)                  3.40768
time/exploration sampling (s)                17.3851
time/logging (s)                              0.00539441
time/saving (s)                               0.0010255
time/training (s)                             4.90318
time/epoch (s)                               25.7083
time/total (s)                             7616.4
Epoch                                       298
---------------------------------------  ----------------
2023-08-05 02:28:29.979820 PDT | [Fanuc_pivoting_v2_ddpg_2023_08_05_00_21_08_0000--s-0] Epoch 299 finished
---------------------------------------  ----------------
epoch                                       299
replay_buffer/size                       600000
trainer/QF Loss                               4.57341e+11
trainer/Policy Loss                          -3.80844e+06
trainer/Raw Policy Loss                      -3.80844e+06
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                    3.11943e+06
trainer/Q Predictions Std                463758
trainer/Q Predictions Max                     4.91728e+06
trainer/Q Predictions Min                818364
trainer/Q Targets Mean                        3.62681e+06
trainer/Q Targets Std                    212184
trainer/Q Targets Max                         5.25976e+06
trainer/Q Targets Min                         1.93219e+06
trainer/Bellman Errors Mean                   4.57341e+11
trainer/Bellman Errors Std                    6.8021e+11
trainer/Bellman Errors Max                    9.29921e+12
trainer/Bellman Errors Min                 1482.25
trainer/Policy Action Mean                    0.333333
trainer/Policy Action Std                     0.942809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     600000
expl/num paths total                      15000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.510612
expl/Rewards Std                              0.653413
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            20.4245
expl/Returns Std                             19.3912
expl/Returns Max                             43.5973
expl/Returns Min                              0
expl/Actions Mean                             0.271901
expl/Actions Std                              0.801843
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.4245
expl/env_infos/final/reward_dist Mean         0.780833
expl/env_infos/final/reward_dist Std          0.780915
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00117331
expl/env_infos/initial/reward_dist Std        0.00298195
expl/env_infos/initial/reward_dist Max        0.0140825
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.510612
expl/env_infos/reward_dist Std                0.653413
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                     120000
eval/num paths total                       3000
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.197383
eval/Rewards Std                              0.475748
eval/Rewards Max                              1.5514
eval/Rewards Min                              0
eval/Returns Mean                             7.89532
eval/Returns Std                             15.9085
eval/Returns Max                             44.2632
eval/Returns Min                              0.00283368
eval/Actions Mean                             0.333333
eval/Actions Std                              0.942809
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          7.89532
eval/env_infos/final/reward_dist Mean         0.303069
eval/env_infos/final/reward_dist Std          0.606353
eval/env_infos/final/reward_dist Max          1.5514
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.197383
eval/env_infos/reward_dist Std                0.475748
eval/env_infos/reward_dist Max                1.5514
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00604924
time/evaluation sampling (s)                  3.42424
time/exploration sampling (s)                17.3971
time/logging (s)                              0.00748918
time/saving (s)                               0.00112112
time/training (s)                             4.34448
time/epoch (s)                               25.1804
time/total (s)                             7641.58
Epoch                                       299
---------------------------------------  ----------------
