2023-08-05 00:21:41.056203 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 0 finished
---------------------------------------  --------------
epoch                                       0
replay_buffer/size                       2000
trainer/QF1 Loss                            0.00125184
trainer/QF2 Loss                            0.0012533
trainer/Policy Loss                        -0.000154764
trainer/Q1 Predictions Mean                 4.72631e-05
trainer/Q1 Predictions Std                  5.05675e-05
trainer/Q1 Predictions Max                  0.000258521
trainer/Q1 Predictions Min                 -8.60264e-05
trainer/Q2 Predictions Mean                 1.29582e-06
trainer/Q2 Predictions Std                  5.07948e-05
trainer/Q2 Predictions Max                  0.00017721
trainer/Q2 Predictions Min                 -0.000174536
trainer/Q Targets Mean                      0.0109486
trainer/Q Targets Std                       0.0336621
trainer/Q Targets Max                       0.233487
trainer/Q Targets Min                      -0.000563596
trainer/Bellman Errors 1 Mean               0.00125184
trainer/Bellman Errors 1 Std                0.00499733
trainer/Bellman Errors 1 Max                0.054478
trainer/Bellman Errors 1 Min                3.44239e-16
trainer/Bellman Errors 2 Mean               0.0012533
trainer/Bellman Errors 2 Std                0.0050011
trainer/Bellman Errors 2 Max                0.0544896
trainer/Bellman Errors 2 Min                1.28356e-15
trainer/Policy Action Mean                  1.67207e-05
trainer/Policy Action Std                   3.15007e-05
trainer/Policy Action Max                   0.000105356
trainer/Policy Action Min                  -7.53312e-05
expl/num steps total                     2000
expl/num paths total                       50
expl/path length Mean                      40
expl/path length Std                        0
expl/path length Max                       40
expl/path length Min                       40
expl/Rewards Mean                           0.0109845
expl/Rewards Std                            0.0336101
expl/Rewards Max                            0.233524
expl/Rewards Min                            0
expl/Returns Mean                           0.43938
expl/Returns Std                            0.556957
expl/Returns Max                            2.06576
expl/Returns Min                            0
expl/Actions Mean                          -0.00125063
expl/Actions Std                            0.100151
expl/Actions Max                            0.343491
expl/Actions Min                           -0.373989
expl/Num Paths                             50
expl/Average Returns                        0.43938
expl/env_infos/final/reward_dist Mean       1.36815e-09
expl/env_infos/final/reward_dist Std        9.57702e-09
expl/env_infos/final/reward_dist Max        6.84073e-08
expl/env_infos/final/reward_dist Min        0
expl/env_infos/initial/reward_dist Mean     9.72184e-05
expl/env_infos/initial/reward_dist Std      0.000502968
expl/env_infos/initial/reward_dist Max      0.0033659
expl/env_infos/initial/reward_dist Min      0
expl/env_infos/reward_dist Mean             0.0109845
expl/env_infos/reward_dist Std              0.0336101
expl/env_infos/reward_dist Max              0.233524
expl/env_infos/reward_dist Min              0
eval/num steps total                      400
eval/num paths total                       10
eval/path length Mean                      40
eval/path length Std                        0
eval/path length Max                       40
eval/path length Min                       40
eval/Rewards Mean                           0.0106699
eval/Rewards Std                            0.0317303
eval/Rewards Max                            0.191619
eval/Rewards Min                            0
eval/Returns Mean                           0.426798
eval/Returns Std                            0.497185
eval/Returns Max                            1.57085
eval/Returns Min                            0.00190241
eval/Actions Mean                           1.70547e-05
eval/Actions Std                            3.16927e-05
eval/Actions Max                            9.61374e-05
eval/Actions Min                           -5.48785e-05
eval/Num Paths                             10
eval/Average Returns                        0.426798
eval/env_infos/final/reward_dist Mean       8.81676e-09
eval/env_infos/final/reward_dist Std        2.64503e-08
eval/env_infos/final/reward_dist Max        8.81676e-08
eval/env_infos/final/reward_dist Min        0
eval/env_infos/initial/reward_dist Mean     0
eval/env_infos/initial/reward_dist Std      0
eval/env_infos/initial/reward_dist Max      0
eval/env_infos/initial/reward_dist Min      0
eval/env_infos/reward_dist Mean             0.0106699
eval/env_infos/reward_dist Std              0.0317303
eval/env_infos/reward_dist Max              0.191619
eval/env_infos/reward_dist Min              0
time/data storing (s)                       0.0058092
time/evaluation sampling (s)                3.31447
time/exploration sampling (s)              18.2431
time/logging (s)                            0.00794157
time/saving (s)                             0.00340334
time/training (s)                           4.23026
time/epoch (s)                             25.805
time/total (s)                             29.0467
Epoch                                       0
---------------------------------------  --------------
2023-08-05 00:22:07.511983 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 1 finished
---------------------------------------  --------------
epoch                                       1
replay_buffer/size                       4000
trainer/QF1 Loss                            0.0306778
trainer/QF2 Loss                            0.0141549
trainer/Policy Loss                        -0.312688
trainer/Q1 Predictions Mean                 0.223288
trainer/Q1 Predictions Std                  0.144482
trainer/Q1 Predictions Max                  0.481558
trainer/Q1 Predictions Min                  0.053766
trainer/Q2 Predictions Mean                 0.183465
trainer/Q2 Predictions Std                  0.105108
trainer/Q2 Predictions Max                  0.387572
trainer/Q2 Predictions Min                  0.0559567
trainer/Q Targets Mean                      0.102273
trainer/Q Targets Std                       0.042938
trainer/Q Targets Max                       0.352449
trainer/Q Targets Min                       0.0347934
trainer/Bellman Errors 1 Mean               0.0306778
trainer/Bellman Errors 1 Std                0.0319996
trainer/Bellman Errors 1 Max                0.137944
trainer/Bellman Errors 1 Min                1.77466e-10
trainer/Bellman Errors 2 Mean               0.0141549
trainer/Bellman Errors 2 Std                0.0147955
trainer/Bellman Errors 2 Max                0.0721002
trainer/Bellman Errors 2 Min                2.20324e-13
trainer/Policy Action Mean                  0.314199
trainer/Policy Action Std                   0.911103
trainer/Policy Action Max                   0.998545
trainer/Policy Action Min                  -0.99811
expl/num steps total                     4000
expl/num paths total                      100
expl/path length Mean                      40
expl/path length Std                        0
expl/path length Max                       40
expl/path length Min                       40
expl/Rewards Mean                           0.00494206
expl/Rewards Std                            0.00770837
expl/Rewards Max                            0.0507916
expl/Rewards Min                            0
expl/Returns Mean                           0.197682
expl/Returns Std                            0.0952495
expl/Returns Max                            0.466638
expl/Returns Min                            0.0974786
expl/Actions Mean                           0.306015
expl/Actions Std                            0.888548
expl/Actions Max                            1
expl/Actions Min                           -1
expl/Num Paths                             50
expl/Average Returns                        0.197682
expl/env_infos/final/reward_dist Mean       0.022686
expl/env_infos/final/reward_dist Std        0.0123877
expl/env_infos/final/reward_dist Max        0.0507916
expl/env_infos/final/reward_dist Min        0
expl/env_infos/initial/reward_dist Mean     0.000341972
expl/env_infos/initial/reward_dist Std      0.000684885
expl/env_infos/initial/reward_dist Max      0.00256646
expl/env_infos/initial/reward_dist Min      0
expl/env_infos/reward_dist Mean             0.00494206
expl/env_infos/reward_dist Std              0.00770837
expl/env_infos/reward_dist Max              0.0507916
expl/env_infos/reward_dist Min              0
eval/num steps total                      800
eval/num paths total                       20
eval/path length Mean                      40
eval/path length Std                        0
eval/path length Max                       40
eval/path length Min                       40
eval/Rewards Mean                           0.00318185
eval/Rewards Std                            0.00472678
eval/Rewards Max                            0.0360805
eval/Rewards Min                            0
eval/Returns Mean                           0.127274
eval/Returns Std                            0.0649197
eval/Returns Max                            0.299277
eval/Returns Min                            0.0781583
eval/Actions Mean                           0.315061
eval/Actions Std                            0.913138
eval/Actions Max                            0.998323
eval/Actions Min                           -0.997834
eval/Num Paths                             10
eval/Average Returns                        0.127274
eval/env_infos/final/reward_dist Mean       0.0147735
eval/env_infos/final/reward_dist Std        0.00906404
eval/env_infos/final/reward_dist Max        0.0360805
eval/env_infos/final/reward_dist Min        0.00208913
eval/env_infos/initial/reward_dist Mean     0
eval/env_infos/initial/reward_dist Std      0
eval/env_infos/initial/reward_dist Max      0
eval/env_infos/initial/reward_dist Min      0
eval/env_infos/reward_dist Mean             0.00318185
eval/env_infos/reward_dist Std              0.00472678
eval/env_infos/reward_dist Max              0.0360805
eval/env_infos/reward_dist Min              0
time/data storing (s)                       0.00598223
time/evaluation sampling (s)                3.67431
time/exploration sampling (s)              18.937
time/logging (s)                            0.00402566
time/saving (s)                             0.0114204
time/training (s)                           3.81546
time/epoch (s)                             26.4482
time/total (s)                             55.498
Epoch                                       1
---------------------------------------  --------------
2023-08-05 00:22:30.542463 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 2 finished
---------------------------------------  --------------
epoch                                       2
replay_buffer/size                       6000
trainer/QF1 Loss                            0.0573615
trainer/QF2 Loss                            0.0422846
trainer/Policy Loss                        -0.865849
trainer/Q1 Predictions Mean                 0.634744
trainer/Q1 Predictions Std                  0.207776
trainer/Q1 Predictions Max                  1.04399
trainer/Q1 Predictions Min                  0.408405
trainer/Q2 Predictions Mean                 0.615108
trainer/Q2 Predictions Std                  0.179862
trainer/Q2 Predictions Max                  0.974843
trainer/Q2 Predictions Min                  0.416912
trainer/Q Targets Mean                      0.501498
trainer/Q Targets Std                       0.0697883
trainer/Q Targets Max                       0.809535
trainer/Q Targets Min                       0.339916
trainer/Bellman Errors 1 Mean               0.0573615
trainer/Bellman Errors 1 Std                0.0822543
trainer/Bellman Errors 1 Max                0.321583
trainer/Bellman Errors 1 Min                2.68287e-09
trainer/Bellman Errors 2 Mean               0.0422846
trainer/Bellman Errors 2 Std                0.0603218
trainer/Bellman Errors 2 Max                0.240679
trainer/Bellman Errors 2 Min                1.89324e-11
trainer/Policy Action Mean                  0.33288
trainer/Policy Action Std                   0.938987
trainer/Policy Action Max                   1
trainer/Policy Action Min                  -0.999993
expl/num steps total                     6000
expl/num paths total                      150
expl/path length Mean                      40
expl/path length Std                        0
expl/path length Max                       40
expl/path length Min                       40
expl/Rewards Mean                           0
expl/Rewards Std                            0
expl/Rewards Max                            0
expl/Rewards Min                            0
expl/Returns Mean                           0
expl/Returns Std                            0
expl/Returns Max                            0
expl/Returns Min                            0
expl/Actions Mean                           0.31909
expl/Actions Std                            0.904134
expl/Actions Max                            1
expl/Actions Min                           -1
expl/Num Paths                             50
expl/Average Returns                        0
expl/env_infos/final/reward_dist Mean       0
expl/env_infos/final/reward_dist Std        0
expl/env_infos/final/reward_dist Max        0
expl/env_infos/final/reward_dist Min        0
expl/env_infos/initial/reward_dist Mean     0
expl/env_infos/initial/reward_dist Std      0
expl/env_infos/initial/reward_dist Max      0
expl/env_infos/initial/reward_dist Min      0
expl/env_infos/reward_dist Mean             0
expl/env_infos/reward_dist Std              0
expl/env_infos/reward_dist Max              0
expl/env_infos/reward_dist Min              0
eval/num steps total                     1200
eval/num paths total                       30
eval/path length Mean                      40
eval/path length Std                        0
eval/path length Max                       40
eval/path length Min                       40
eval/Rewards Mean                           0
eval/Rewards Std                            0
eval/Rewards Max                            0
eval/Rewards Min                            0
eval/Returns Mean                           0
eval/Returns Std                            0
eval/Returns Max                            0
eval/Returns Min                            0
eval/Actions Mean                           0.332636
eval/Actions Std                            0.93647
eval/Actions Max                            0.999968
eval/Actions Min                           -0.999743
eval/Num Paths                             10
eval/Average Returns                        0
eval/env_infos/final/reward_dist Mean       0
eval/env_infos/final/reward_dist Std        0
eval/env_infos/final/reward_dist Max        0
eval/env_infos/final/reward_dist Min        0
eval/env_infos/initial/reward_dist Mean     0
eval/env_infos/initial/reward_dist Std      0
eval/env_infos/initial/reward_dist Max      0
eval/env_infos/initial/reward_dist Min      0
eval/env_infos/reward_dist Mean             0
eval/env_infos/reward_dist Std              0
eval/env_infos/reward_dist Max              0
eval/env_infos/reward_dist Min              0
time/data storing (s)                       0.0057314
time/evaluation sampling (s)                3.18205
time/exploration sampling (s)              16.1107
time/logging (s)                            0.00627961
time/saving (s)                             0.00238342
time/training (s)                           3.72343
time/epoch (s)                             23.0306
time/total (s)                             78.5304
Epoch                                       2
---------------------------------------  --------------
2023-08-05 00:22:53.909397 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 3 finished
---------------------------------------  --------------
epoch                                       3
replay_buffer/size                       8000
trainer/QF1 Loss                            0.00072708
trainer/QF2 Loss                            0.00070547
trainer/Policy Loss                        -0.441413
trainer/Q1 Predictions Mean                 0.437621
trainer/Q1 Predictions Std                  0.0310272
trainer/Q1 Predictions Max                  0.570959
trainer/Q1 Predictions Min                  0.380177
trainer/Q2 Predictions Mean                 0.437724
trainer/Q2 Predictions Std                  0.0306007
trainer/Q2 Predictions Max                  0.581156
trainer/Q2 Predictions Min                  0.384937
trainer/Q Targets Mean                      0.438014
trainer/Q Targets Std                       0.0405185
trainer/Q Targets Max                       0.694627
trainer/Q Targets Min                       0.33923
trainer/Bellman Errors 1 Mean               0.00072708
trainer/Bellman Errors 1 Std                0.00146978
trainer/Bellman Errors 1 Max                0.0251434
trainer/Bellman Errors 1 Min                2.40163e-12
trainer/Bellman Errors 2 Mean               0.00070547
trainer/Bellman Errors 2 Std                0.00143978
trainer/Bellman Errors 2 Max                0.0266972
trainer/Bellman Errors 2 Min                8.18545e-12
trainer/Policy Action Mean                  0.333412
trainer/Policy Action Std                   0.94128
trainer/Policy Action Max                   1
trainer/Policy Action Min                  -0.999998
expl/num steps total                     8000
expl/num paths total                      200
expl/path length Mean                      40
expl/path length Std                        0
expl/path length Max                       40
expl/path length Min                       40
expl/Rewards Mean                           0
expl/Rewards Std                            0
expl/Rewards Max                            0
expl/Rewards Min                            0
expl/Returns Mean                           0
expl/Returns Std                            0
expl/Returns Max                            0
expl/Returns Min                            0
expl/Actions Mean                           0.319591
expl/Actions Std                            0.906559
expl/Actions Max                            1
expl/Actions Min                           -1
expl/Num Paths                             50
expl/Average Returns                        0
expl/env_infos/final/reward_dist Mean       0
expl/env_infos/final/reward_dist Std        0
expl/env_infos/final/reward_dist Max        0
expl/env_infos/final/reward_dist Min        0
expl/env_infos/initial/reward_dist Mean     0
expl/env_infos/initial/reward_dist Std      0
expl/env_infos/initial/reward_dist Max      0
expl/env_infos/initial/reward_dist Min      0
expl/env_infos/reward_dist Mean             0
expl/env_infos/reward_dist Std              0
expl/env_infos/reward_dist Max              0
expl/env_infos/reward_dist Min              0
eval/num steps total                     1600
eval/num paths total                       40
eval/path length Mean                      40
eval/path length Std                        0
eval/path length Max                       40
eval/path length Min                       40
eval/Rewards Mean                           0
eval/Rewards Std                            0
eval/Rewards Max                            0
eval/Rewards Min                            0
eval/Returns Mean                           0
eval/Returns Std                            0
eval/Returns Max                            0
eval/Returns Min                            0
eval/Actions Mean                           0.333449
eval/Actions Std                            0.940416
eval/Actions Max                            0.999992
eval/Actions Min                           -0.999915
eval/Num Paths                             10
eval/Average Returns                        0
eval/env_infos/final/reward_dist Mean       0
eval/env_infos/final/reward_dist Std        0
eval/env_infos/final/reward_dist Max        0
eval/env_infos/final/reward_dist Min        0
eval/env_infos/initial/reward_dist Mean     0
eval/env_infos/initial/reward_dist Std      0
eval/env_infos/initial/reward_dist Max      0
eval/env_infos/initial/reward_dist Min      0
eval/env_infos/reward_dist Mean             0
eval/env_infos/reward_dist Std              0
eval/env_infos/reward_dist Max              0
eval/env_infos/reward_dist Min              0
time/data storing (s)                       0.00583219
time/evaluation sampling (s)                3.17215
time/exploration sampling (s)              16.3551
time/logging (s)                            0.00735383
time/saving (s)                             0.00272315
time/training (s)                           3.82272
time/epoch (s)                             23.3659
time/total (s)                            101.898
Epoch                                       3
---------------------------------------  --------------
2023-08-05 00:23:17.184195 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 4 finished
---------------------------------------  ---------------
epoch                                        4
replay_buffer/size                       10000
trainer/QF1 Loss                             0.000415578
trainer/QF2 Loss                             0.000402815
trainer/Policy Loss                         -0.432804
trainer/Q1 Predictions Mean                  0.428561
trainer/Q1 Predictions Std                   0.0275774
trainer/Q1 Predictions Max                   0.566449
trainer/Q1 Predictions Min                   0.375072
trainer/Q2 Predictions Mean                  0.428688
trainer/Q2 Predictions Std                   0.0275676
trainer/Q2 Predictions Max                   0.585177
trainer/Q2 Predictions Min                   0.375334
trainer/Q Targets Mean                       0.428777
trainer/Q Targets Std                        0.0338279
trainer/Q Targets Max                        0.680906
trainer/Q Targets Min                        0.338565
trainer/Bellman Errors 1 Mean                0.000415578
trainer/Bellman Errors 1 Std                 0.00105717
trainer/Bellman Errors 1 Max                 0.0215302
trainer/Bellman Errors 1 Min                 4.86366e-10
trainer/Bellman Errors 2 Mean                0.000402815
trainer/Bellman Errors 2 Std                 0.00101295
trainer/Bellman Errors 2 Max                 0.0221408
trainer/Bellman Errors 2 Min                 1.59481e-11
trainer/Policy Action Mean                   0.333394
trainer/Policy Action Std                    0.94212
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     10000
expl/num paths total                       250
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320012
expl/Actions Std                             0.905835
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      2000
eval/num paths total                        50
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333413
eval/Actions Std                             0.941878
eval/Actions Max                             0.999997
eval/Actions Min                            -0.999972
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00593729
time/evaluation sampling (s)                 3.23126
time/exploration sampling (s)               16.0892
time/logging (s)                             0.00524883
time/saving (s)                              0.00240306
time/training (s)                            3.9352
time/epoch (s)                              23.2693
time/total (s)                             125.17
Epoch                                        4
---------------------------------------  ---------------
2023-08-05 00:23:40.262578 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 5 finished
---------------------------------------  ---------------
epoch                                        5
replay_buffer/size                       12000
trainer/QF1 Loss                             0.000328294
trainer/QF2 Loss                             0.000316248
trainer/Policy Loss                         -0.426675
trainer/Q1 Predictions Mean                  0.424271
trainer/Q1 Predictions Std                   0.0257612
trainer/Q1 Predictions Max                   0.560609
trainer/Q1 Predictions Min                   0.370917
trainer/Q2 Predictions Mean                  0.424696
trainer/Q2 Predictions Std                   0.0259122
trainer/Q2 Predictions Max                   0.577504
trainer/Q2 Predictions Min                   0.372873
trainer/Q Targets Mean                       0.424311
trainer/Q Targets Std                        0.0316517
trainer/Q Targets Max                        0.676446
trainer/Q Targets Min                        0.341755
trainer/Bellman Errors 1 Mean                0.000328294
trainer/Bellman Errors 1 Std                 0.000887828
trainer/Bellman Errors 1 Max                 0.0184004
trainer/Bellman Errors 1 Min                 9.97957e-12
trainer/Bellman Errors 2 Mean                0.000316248
trainer/Bellman Errors 2 Std                 0.000849761
trainer/Bellman Errors 2 Max                 0.0184325
trainer/Bellman Errors 2 Min                 1.05524e-11
trainer/Policy Action Mean                   0.333353
trainer/Policy Action Std                    0.942542
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     12000
expl/num paths total                       300
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319732
expl/Actions Std                             0.906442
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      2400
eval/num paths total                        60
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333359
eval/Actions Std                             0.942461
eval/Actions Max                             0.999999
eval/Actions Min                            -0.999991
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00672973
time/evaluation sampling (s)                 3.14433
time/exploration sampling (s)               15.8493
time/logging (s)                             0.00526038
time/saving (s)                              0.00240911
time/training (s)                            4.06816
time/epoch (s)                              23.0762
time/total (s)                             148.248
Epoch                                        5
---------------------------------------  ---------------
2023-08-05 00:24:03.173161 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 6 finished
---------------------------------------  ---------------
epoch                                        6
replay_buffer/size                       14000
trainer/QF1 Loss                             0.000261656
trainer/QF2 Loss                             0.000244973
trainer/Policy Loss                         -0.420397
trainer/Q1 Predictions Mean                  0.419504
trainer/Q1 Predictions Std                   0.0231037
trainer/Q1 Predictions Max                   0.563955
trainer/Q1 Predictions Min                   0.367956
trainer/Q2 Predictions Mean                  0.419199
trainer/Q2 Predictions Std                   0.0231515
trainer/Q2 Predictions Max                   0.574394
trainer/Q2 Predictions Min                   0.36725
trainer/Q Targets Mean                       0.418888
trainer/Q Targets Std                        0.0281767
trainer/Q Targets Max                        0.651007
trainer/Q Targets Min                        0.343968
trainer/Bellman Errors 1 Mean                0.000261656
trainer/Bellman Errors 1 Std                 0.000738535
trainer/Bellman Errors 1 Max                 0.0194747
trainer/Bellman Errors 1 Min                 2.8777e-13
trainer/Bellman Errors 2 Mean                0.000244973
trainer/Bellman Errors 2 Std                 0.000681752
trainer/Bellman Errors 2 Max                 0.0206837
trainer/Bellman Errors 2 Min                 6.05036e-11
trainer/Policy Action Mean                   0.333342
trainer/Policy Action Std                    0.94267
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     14000
expl/num paths total                       350
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319704
expl/Actions Std                             0.907766
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      2800
eval/num paths total                        70
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333344
eval/Actions Std                             0.942623
eval/Actions Max                             0.999999
eval/Actions Min                            -0.999995
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.0058519
time/evaluation sampling (s)                 3.20046
time/exploration sampling (s)               15.7285
time/logging (s)                             0.00540494
time/saving (s)                              0.00232349
time/training (s)                            3.96595
time/epoch (s)                              22.9085
time/total (s)                             171.159
Epoch                                        6
---------------------------------------  ---------------
2023-08-05 00:24:26.276306 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 7 finished
---------------------------------------  ---------------
epoch                                        7
replay_buffer/size                       16000
trainer/QF1 Loss                             0.000211615
trainer/QF2 Loss                             0.000198625
trainer/Policy Loss                         -0.409254
trainer/Q1 Predictions Mean                  0.408876
trainer/Q1 Predictions Std                   0.0207974
trainer/Q1 Predictions Max                   0.567902
trainer/Q1 Predictions Min                   0.36379
trainer/Q2 Predictions Mean                  0.408989
trainer/Q2 Predictions Std                   0.0212915
trainer/Q2 Predictions Max                   0.603106
trainer/Q2 Predictions Min                   0.365663
trainer/Q Targets Mean                       0.409452
trainer/Q Targets Std                        0.0258949
trainer/Q Targets Max                        0.654648
trainer/Q Targets Min                        0.344855
trainer/Bellman Errors 1 Mean                0.000211615
trainer/Bellman Errors 1 Std                 0.000750621
trainer/Bellman Errors 1 Max                 0.0177194
trainer/Bellman Errors 1 Min                 5.55112e-11
trainer/Bellman Errors 2 Mean                0.000198625
trainer/Bellman Errors 2 Std                 0.000687081
trainer/Bellman Errors 2 Max                 0.0180961
trainer/Bellman Errors 2 Min                 3.20632e-11
trainer/Policy Action Mean                   0.333334
trainer/Policy Action Std                    0.942729
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     16000
expl/num paths total                       400
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319684
expl/Actions Std                             0.906915
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      3200
eval/num paths total                        80
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333334
eval/Actions Std                             0.942702
eval/Actions Max                             1
eval/Actions Min                            -0.999997
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00588879
time/evaluation sampling (s)                 3.27046
time/exploration sampling (s)               15.8604
time/logging (s)                             0.00544048
time/saving (s)                              0.00245094
time/training (s)                            3.95529
time/epoch (s)                              23.1
time/total (s)                             194.262
Epoch                                        7
---------------------------------------  ---------------
2023-08-05 00:24:49.608408 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 8 finished
---------------------------------------  ---------------
epoch                                        8
replay_buffer/size                       18000
trainer/QF1 Loss                             0.000153803
trainer/QF2 Loss                             0.000145681
trainer/Policy Loss                         -0.396879
trainer/Q1 Predictions Mean                  0.396279
trainer/Q1 Predictions Std                   0.0184272
trainer/Q1 Predictions Max                   0.528459
trainer/Q1 Predictions Min                   0.350905
trainer/Q2 Predictions Mean                  0.396211
trainer/Q2 Predictions Std                   0.0182865
trainer/Q2 Predictions Max                   0.522352
trainer/Q2 Predictions Min                   0.350688
trainer/Q Targets Mean                       0.396217
trainer/Q Targets Std                        0.0216007
trainer/Q Targets Max                        0.58231
trainer/Q Targets Min                        0.341626
trainer/Bellman Errors 1 Mean                0.000153803
trainer/Bellman Errors 1 Std                 0.000584382
trainer/Bellman Errors 1 Max                 0.0225508
trainer/Bellman Errors 1 Min                 5.11591e-13
trainer/Bellman Errors 2 Mean                0.000145681
trainer/Bellman Errors 2 Std                 0.000517221
trainer/Bellman Errors 2 Max                 0.0213066
trainer/Bellman Errors 2 Min                 5.55112e-13
trainer/Policy Action Mean                   0.333332
trainer/Policy Action Std                    0.942755
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     18000
expl/num paths total                       450
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320636
expl/Actions Std                             0.907048
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      3600
eval/num paths total                        90
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333331
eval/Actions Std                             0.94274
eval/Actions Max                             1
eval/Actions Min                            -0.999998
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00604385
time/evaluation sampling (s)                 3.29227
time/exploration sampling (s)               15.7551
time/logging (s)                             0.00544461
time/saving (s)                              0.00236504
time/training (s)                            4.2677
time/epoch (s)                              23.3289
time/total (s)                             217.593
Epoch                                        8
---------------------------------------  ---------------
2023-08-05 00:25:13.051764 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 9 finished
---------------------------------------  ---------------
epoch                                        9
replay_buffer/size                       20000
trainer/QF1 Loss                             0.000122727
trainer/QF2 Loss                             0.000109274
trainer/Policy Loss                         -0.377734
trainer/Q1 Predictions Mean                  0.379326
trainer/Q1 Predictions Std                   0.0173517
trainer/Q1 Predictions Max                   0.541434
trainer/Q1 Predictions Min                   0.339968
trainer/Q2 Predictions Mean                  0.379218
trainer/Q2 Predictions Std                   0.0173245
trainer/Q2 Predictions Max                   0.56725
trainer/Q2 Predictions Min                   0.339933
trainer/Q Targets Mean                       0.378723
trainer/Q Targets Std                        0.0206143
trainer/Q Targets Max                        0.638581
trainer/Q Targets Min                        0.329571
trainer/Bellman Errors 1 Mean                0.000122727
trainer/Bellman Errors 1 Std                 0.000524367
trainer/Bellman Errors 1 Max                 0.014792
trainer/Bellman Errors 1 Min                 1.45519e-11
trainer/Bellman Errors 2 Mean                0.000109274
trainer/Bellman Errors 2 Std                 0.000371395
trainer/Bellman Errors 2 Max                 0.0104272
trainer/Bellman Errors 2 Min                 1.43254e-11
trainer/Policy Action Mean                   0.333332
trainer/Policy Action Std                    0.942768
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     20000
expl/num paths total                       500
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319744
expl/Actions Std                             0.905887
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      4000
eval/num paths total                       100
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333332
eval/Actions Std                             0.942758
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00587864
time/evaluation sampling (s)                 3.40574
time/exploration sampling (s)               16.0264
time/logging (s)                             0.00527022
time/saving (s)                              0.00231663
time/training (s)                            3.99261
time/epoch (s)                              23.4383
time/total (s)                             241.036
Epoch                                        9
---------------------------------------  ---------------
2023-08-05 00:25:37.005122 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 10 finished
---------------------------------------  ---------------
epoch                                       10
replay_buffer/size                       22000
trainer/QF1 Loss                             9.14462e-05
trainer/QF2 Loss                             8.82696e-05
trainer/Policy Loss                         -0.359247
trainer/Q1 Predictions Mean                  0.359224
trainer/Q1 Predictions Std                   0.0156007
trainer/Q1 Predictions Max                   0.511034
trainer/Q1 Predictions Min                   0.326781
trainer/Q2 Predictions Mean                  0.358944
trainer/Q2 Predictions Std                   0.0158866
trainer/Q2 Predictions Max                   0.541173
trainer/Q2 Predictions Min                   0.326441
trainer/Q Targets Mean                       0.359403
trainer/Q Targets Std                        0.0185696
trainer/Q Targets Max                        0.600757
trainer/Q Targets Min                        0.322413
trainer/Bellman Errors 1 Mean                9.14462e-05
trainer/Bellman Errors 1 Std                 0.000440249
trainer/Bellman Errors 1 Max                 0.014317
trainer/Bellman Errors 1 Min                 1.35092e-12
trainer/Bellman Errors 2 Mean                8.82696e-05
trainer/Bellman Errors 2 Std                 0.000346276
trainer/Bellman Errors 2 Max                 0.0102485
trainer/Bellman Errors 2 Min                 2.53673e-11
trainer/Policy Action Mean                   0.333332
trainer/Policy Action Std                    0.942775
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     22000
expl/num paths total                       550
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319383
expl/Actions Std                             0.906682
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      4400
eval/num paths total                       110
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333332
eval/Actions Std                             0.942765
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00586847
time/evaluation sampling (s)                 3.56844
time/exploration sampling (s)               16.1032
time/logging (s)                             0.00736101
time/saving (s)                              0.0026879
time/training (s)                            4.26554
time/epoch (s)                              23.9531
time/total (s)                             264.991
Epoch                                       10
---------------------------------------  ---------------
2023-08-05 00:26:00.769503 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 11 finished
---------------------------------------  ---------------
epoch                                       11
replay_buffer/size                       24000
trainer/QF1 Loss                             7.01442e-05
trainer/QF2 Loss                             6.37136e-05
trainer/Policy Loss                         -0.337329
trainer/Q1 Predictions Mean                  0.338469
trainer/Q1 Predictions Std                   0.0149475
trainer/Q1 Predictions Max                   0.492438
trainer/Q1 Predictions Min                   0.310293
trainer/Q2 Predictions Mean                  0.338258
trainer/Q2 Predictions Std                   0.0152205
trainer/Q2 Predictions Max                   0.517831
trainer/Q2 Predictions Min                   0.309553
trainer/Q Targets Mean                       0.338036
trainer/Q Targets Std                        0.0172172
trainer/Q Targets Max                        0.519054
trainer/Q Targets Min                        0.307275
trainer/Bellman Errors 1 Mean                7.01442e-05
trainer/Bellman Errors 1 Std                 0.000302783
trainer/Bellman Errors 1 Max                 0.0123321
trainer/Bellman Errors 1 Min                 3.75255e-12
trainer/Bellman Errors 2 Mean                6.37136e-05
trainer/Bellman Errors 2 Std                 0.000237539
trainer/Bellman Errors 2 Max                 0.0106531
trainer/Bellman Errors 2 Min                 4.47731e-12
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.94278
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     24000
expl/num paths total                       600
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320012
expl/Actions Std                             0.907156
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      4800
eval/num paths total                       120
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942772
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00592086
time/evaluation sampling (s)                 3.36575
time/exploration sampling (s)               16.3887
time/logging (s)                             0.00532249
time/saving (s)                              0.00238961
time/training (s)                            3.99084
time/epoch (s)                              23.7589
time/total (s)                             288.753
Epoch                                       11
---------------------------------------  ---------------
2023-08-05 00:26:24.908759 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 12 finished
---------------------------------------  ---------------
epoch                                       12
replay_buffer/size                       26000
trainer/QF1 Loss                             5.36931e-05
trainer/QF2 Loss                             5.03314e-05
trainer/Policy Loss                         -0.314842
trainer/Q1 Predictions Mean                  0.315312
trainer/Q1 Predictions Std                   0.0121452
trainer/Q1 Predictions Max                   0.519809
trainer/Q1 Predictions Min                   0.290762
trainer/Q2 Predictions Mean                  0.315699
trainer/Q2 Predictions Std                   0.0127712
trainer/Q2 Predictions Max                   0.537997
trainer/Q2 Predictions Min                   0.293499
trainer/Q Targets Mean                       0.316138
trainer/Q Targets Std                        0.0146215
trainer/Q Targets Max                        0.548285
trainer/Q Targets Min                        0.288022
trainer/Bellman Errors 1 Mean                5.36931e-05
trainer/Bellman Errors 1 Std                 0.000254709
trainer/Bellman Errors 1 Max                 0.0106024
trainer/Bellman Errors 1 Min                 3.19744e-12
trainer/Bellman Errors 2 Mean                5.03314e-05
trainer/Bellman Errors 2 Std                 0.000181212
trainer/Bellman Errors 2 Max                 0.00762676
trainer/Bellman Errors 2 Min                 8.88178e-12
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942783
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     26000
expl/num paths total                       650
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320071
expl/Actions Std                             0.907078
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      5200
eval/num paths total                       130
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.94278
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00600327
time/evaluation sampling (s)                 3.21244
time/exploration sampling (s)               16.0011
time/logging (s)                             0.00757827
time/saving (s)                              0.00312848
time/training (s)                            4.90897
time/epoch (s)                              24.1393
time/total (s)                             312.894
Epoch                                       12
---------------------------------------  ---------------
2023-08-05 00:26:49.230400 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 13 finished
---------------------------------------  ---------------
epoch                                       13
replay_buffer/size                       28000
trainer/QF1 Loss                             4.64177e-05
trainer/QF2 Loss                             4.38591e-05
trainer/Policy Loss                         -0.293052
trainer/Q1 Predictions Mean                  0.29447
trainer/Q1 Predictions Std                   0.0110883
trainer/Q1 Predictions Max                   0.44904
trainer/Q1 Predictions Min                   0.275438
trainer/Q2 Predictions Mean                  0.294748
trainer/Q2 Predictions Std                   0.0110347
trainer/Q2 Predictions Max                   0.463336
trainer/Q2 Predictions Min                   0.271257
trainer/Q Targets Mean                       0.293953
trainer/Q Targets Std                        0.0125568
trainer/Q Targets Max                        0.477033
trainer/Q Targets Min                        0.269188
trainer/Bellman Errors 1 Mean                4.64177e-05
trainer/Bellman Errors 1 Std                 0.000274097
trainer/Bellman Errors 1 Max                 0.0133739
trainer/Bellman Errors 1 Min                 1.30038e-11
trainer/Bellman Errors 2 Mean                4.38591e-05
trainer/Bellman Errors 2 Std                 0.000200311
trainer/Bellman Errors 2 Max                 0.0101438
trainer/Bellman Errors 2 Min                 2.22045e-14
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942786
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     28000
expl/num paths total                       700
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.321054
expl/Actions Std                             0.9066
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      5600
eval/num paths total                       140
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942783
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00583546
time/evaluation sampling (s)                 3.20406
time/exploration sampling (s)               16.7401
time/logging (s)                             0.00533679
time/saving (s)                              0.00245157
time/training (s)                            4.358
time/epoch (s)                              24.3158
time/total (s)                             337.213
Epoch                                       13
---------------------------------------  ---------------
2023-08-05 00:27:14.221645 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 14 finished
---------------------------------------  ---------------
epoch                                       14
replay_buffer/size                       30000
trainer/QF1 Loss                             4.36253e-05
trainer/QF2 Loss                             3.76533e-05
trainer/Policy Loss                         -0.271704
trainer/Q1 Predictions Mean                  0.272623
trainer/Q1 Predictions Std                   0.0112851
trainer/Q1 Predictions Max                   0.442546
trainer/Q1 Predictions Min                   0.254892
trainer/Q2 Predictions Mean                  0.272665
trainer/Q2 Predictions Std                   0.0120171
trainer/Q2 Predictions Max                   0.449482
trainer/Q2 Predictions Min                   0.256954
trainer/Q Targets Mean                       0.272933
trainer/Q Targets Std                        0.0136895
trainer/Q Targets Max                        0.469565
trainer/Q Targets Min                        0.249469
trainer/Bellman Errors 1 Mean                4.36253e-05
trainer/Bellman Errors 1 Std                 0.000247841
trainer/Bellman Errors 1 Max                 0.00935774
trainer/Bellman Errors 1 Min                 3.41416e-12
trainer/Bellman Errors 2 Mean                3.76533e-05
trainer/Bellman Errors 2 Std                 0.000155154
trainer/Bellman Errors 2 Max                 0.00447865
trainer/Bellman Errors 2 Min                 8.88178e-14
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942788
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     30000
expl/num paths total                       750
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319226
expl/Actions Std                             0.907015
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      6000
eval/num paths total                       150
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942784
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00567301
time/evaluation sampling (s)                 3.24691
time/exploration sampling (s)               16.7055
time/logging (s)                             0.00782123
time/saving (s)                              0.00325897
time/training (s)                            5.02235
time/epoch (s)                              24.9915
time/total (s)                             362.206
Epoch                                       14
---------------------------------------  ---------------
2023-08-05 00:27:38.287669 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 15 finished
---------------------------------------  ---------------
epoch                                       15
replay_buffer/size                       32000
trainer/QF1 Loss                             3.82156e-05
trainer/QF2 Loss                             3.29244e-05
trainer/Policy Loss                         -0.252201
trainer/Q1 Predictions Mean                  0.253302
trainer/Q1 Predictions Std                   0.0119746
trainer/Q1 Predictions Max                   0.426508
trainer/Q1 Predictions Min                   0.235743
trainer/Q2 Predictions Mean                  0.253472
trainer/Q2 Predictions Std                   0.0117869
trainer/Q2 Predictions Max                   0.425995
trainer/Q2 Predictions Min                   0.239135
trainer/Q Targets Mean                       0.253231
trainer/Q Targets Std                        0.012777
trainer/Q Targets Max                        0.452027
trainer/Q Targets Min                        0.231253
trainer/Bellman Errors 1 Mean                3.82156e-05
trainer/Bellman Errors 1 Std                 0.000210172
trainer/Bellman Errors 1 Max                 0.00591313
trainer/Bellman Errors 1 Min                 5.26601e-12
trainer/Bellman Errors 2 Mean                3.29244e-05
trainer/Bellman Errors 2 Std                 0.000136585
trainer/Bellman Errors 2 Max                 0.00382524
trainer/Bellman Errors 2 Min                 9.97957e-12
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.94279
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     32000
expl/num paths total                       800
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.32048
expl/Actions Std                             0.907385
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      6400
eval/num paths total                       160
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942786
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.0057581
time/evaluation sampling (s)                 3.2142
time/exploration sampling (s)               16.5391
time/logging (s)                             0.00526867
time/saving (s)                              0.00237011
time/training (s)                            4.29315
time/epoch (s)                              24.0599
time/total (s)                             386.269
Epoch                                       15
---------------------------------------  ---------------
2023-08-05 00:28:02.407889 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 16 finished
---------------------------------------  ---------------
epoch                                       16
replay_buffer/size                       34000
trainer/QF1 Loss                             2.94464e-05
trainer/QF2 Loss                             2.76904e-05
trainer/Policy Loss                         -0.233783
trainer/Q1 Predictions Mean                  0.234591
trainer/Q1 Predictions Std                   0.00994486
trainer/Q1 Predictions Max                   0.430288
trainer/Q1 Predictions Min                   0.219957
trainer/Q2 Predictions Mean                  0.234559
trainer/Q2 Predictions Std                   0.00987686
trainer/Q2 Predictions Max                   0.421509
trainer/Q2 Predictions Min                   0.221111
trainer/Q Targets Mean                       0.234492
trainer/Q Targets Std                        0.0108851
trainer/Q Targets Max                        0.41038
trainer/Q Targets Min                        0.216783
trainer/Bellman Errors 1 Mean                2.94464e-05
trainer/Bellman Errors 1 Std                 0.000153893
trainer/Bellman Errors 1 Max                 0.00792377
trainer/Bellman Errors 1 Min                 2.27374e-13
trainer/Bellman Errors 2 Mean                2.76904e-05
trainer/Bellman Errors 2 Std                 0.000143738
trainer/Bellman Errors 2 Max                 0.00748479
trainer/Bellman Errors 2 Min                 3.14437e-12
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942792
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     34000
expl/num paths total                       850
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319338
expl/Actions Std                             0.907569
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      6800
eval/num paths total                       170
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942788
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00580287
time/evaluation sampling (s)                 3.15317
time/exploration sampling (s)               16.4875
time/logging (s)                             0.00405552
time/saving (s)                              0.0114393
time/training (s)                            4.45491
time/epoch (s)                              24.1169
time/total (s)                             410.388
Epoch                                       16
---------------------------------------  ---------------
2023-08-05 00:28:26.539796 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 17 finished
---------------------------------------  ---------------
epoch                                       17
replay_buffer/size                       36000
trainer/QF1 Loss                             2.12662e-05
trainer/QF2 Loss                             2.06244e-05
trainer/Policy Loss                         -0.215725
trainer/Q1 Predictions Mean                  0.216507
trainer/Q1 Predictions Std                   0.010163
trainer/Q1 Predictions Max                   0.441485
trainer/Q1 Predictions Min                   0.205143
trainer/Q2 Predictions Mean                  0.216829
trainer/Q2 Predictions Std                   0.0100071
trainer/Q2 Predictions Max                   0.432666
trainer/Q2 Predictions Min                   0.201458
trainer/Q Targets Mean                       0.216921
trainer/Q Targets Std                        0.0111622
trainer/Q Targets Max                        0.449883
trainer/Q Targets Min                        0.198421
trainer/Bellman Errors 1 Mean                2.12662e-05
trainer/Bellman Errors 1 Std                 9.25184e-05
trainer/Bellman Errors 1 Max                 0.00411101
trainer/Bellman Errors 1 Min                 1.83875e-12
trainer/Bellman Errors 2 Mean                2.06244e-05
trainer/Bellman Errors 2 Std                 7.6625e-05
trainer/Bellman Errors 2 Max                 0.00265664
trainer/Bellman Errors 2 Min                 2.26508e-12
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942793
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     36000
expl/num paths total                       900
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319493
expl/Actions Std                             0.907285
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      7200
eval/num paths total                       180
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942792
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00565918
time/evaluation sampling (s)                 3.17434
time/exploration sampling (s)               16.2855
time/logging (s)                             0.00741436
time/saving (s)                              0.00277802
time/training (s)                            4.65751
time/epoch (s)                              24.1332
time/total (s)                             434.523
Epoch                                       17
---------------------------------------  ---------------
2023-08-05 00:28:50.692485 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 18 finished
---------------------------------------  ---------------
epoch                                       18
replay_buffer/size                       38000
trainer/QF1 Loss                             2.12277e-05
trainer/QF2 Loss                             1.95849e-05
trainer/Policy Loss                         -0.200238
trainer/Q1 Predictions Mean                  0.200179
trainer/Q1 Predictions Std                   0.00785038
trainer/Q1 Predictions Max                   0.331549
trainer/Q1 Predictions Min                   0.189314
trainer/Q2 Predictions Mean                  0.200366
trainer/Q2 Predictions Std                   0.00766388
trainer/Q2 Predictions Max                   0.329968
trainer/Q2 Predictions Min                   0.1848
trainer/Q Targets Mean                       0.20066
trainer/Q Targets Std                        0.00923456
trainer/Q Targets Max                        0.352419
trainer/Q Targets Min                        0.181886
trainer/Bellman Errors 1 Mean                2.12277e-05
trainer/Bellman Errors 1 Std                 0.000120072
trainer/Bellman Errors 1 Max                 0.00574675
trainer/Bellman Errors 1 Min                 1.38778e-11
trainer/Bellman Errors 2 Mean                1.95849e-05
trainer/Bellman Errors 2 Std                 8.43881e-05
trainer/Bellman Errors 2 Max                 0.00347243
trainer/Bellman Errors 2 Min                 4.35207e-14
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942794
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     38000
expl/num paths total                       950
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319718
expl/Actions Std                             0.907636
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      7600
eval/num paths total                       190
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942791
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00577704
time/evaluation sampling (s)                 3.20962
time/exploration sampling (s)               16.6882
time/logging (s)                             0.00529225
time/saving (s)                              0.00241936
time/training (s)                            4.23571
time/epoch (s)                              24.147
time/total (s)                             458.673
Epoch                                       18
---------------------------------------  ---------------
2023-08-05 00:29:15.237497 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 19 finished
---------------------------------------  ---------------
epoch                                       19
replay_buffer/size                       40000
trainer/QF1 Loss                             1.78908e-05
trainer/QF2 Loss                             1.82519e-05
trainer/Policy Loss                         -0.184237
trainer/Q1 Predictions Mean                  0.184365
trainer/Q1 Predictions Std                   0.00619858
trainer/Q1 Predictions Max                   0.329878
trainer/Q1 Predictions Min                   0.175181
trainer/Q2 Predictions Mean                  0.184479
trainer/Q2 Predictions Std                   0.00646687
trainer/Q2 Predictions Max                   0.35218
trainer/Q2 Predictions Min                   0.171062
trainer/Q Targets Mean                       0.1849
trainer/Q Targets Std                        0.00716725
trainer/Q Targets Max                        0.329552
trainer/Q Targets Min                        0.169701
trainer/Bellman Errors 1 Mean                1.78908e-05
trainer/Bellman Errors 1 Std                 0.000155778
trainer/Bellman Errors 1 Max                 0.0094721
trainer/Bellman Errors 1 Min                 4.29878e-13
trainer/Bellman Errors 2 Mean                1.82519e-05
trainer/Bellman Errors 2 Std                 0.000168947
trainer/Bellman Errors 2 Max                 0.0102369
trainer/Bellman Errors 2 Min                 1.15108e-12
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942795
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     40000
expl/num paths total                      1000
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319992
expl/Actions Std                             0.907151
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      8000
eval/num paths total                       200
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942792
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00580588
time/evaluation sampling (s)                 3.22748
time/exploration sampling (s)               16.8828
time/logging (s)                             0.00529893
time/saving (s)                              0.00234508
time/training (s)                            4.41921
time/epoch (s)                              24.5429
time/total (s)                             483.217
Epoch                                       19
---------------------------------------  ---------------
2023-08-05 00:29:39.760949 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 20 finished
---------------------------------------  ---------------
epoch                                       20
replay_buffer/size                       42000
trainer/QF1 Loss                             1.26525e-05
trainer/QF2 Loss                             1.1788e-05
trainer/Policy Loss                         -0.170062
trainer/Q1 Predictions Mean                  0.170949
trainer/Q1 Predictions Std                   0.00735974
trainer/Q1 Predictions Max                   0.339288
trainer/Q1 Predictions Min                   0.15389
trainer/Q2 Predictions Mean                  0.170994
trainer/Q2 Predictions Std                   0.00770304
trainer/Q2 Predictions Max                   0.349407
trainer/Q2 Predictions Min                   0.158849
trainer/Q Targets Mean                       0.170751
trainer/Q Targets Std                        0.0086197
trainer/Q Targets Max                        0.369159
trainer/Q Targets Min                        0.156804
trainer/Bellman Errors 1 Mean                1.26525e-05
trainer/Bellman Errors 1 Std                 4.45717e-05
trainer/Bellman Errors 1 Max                 0.00150885
trainer/Bellman Errors 1 Min                 1.68066e-12
trainer/Bellman Errors 2 Mean                1.1788e-05
trainer/Bellman Errors 2 Std                 3.15084e-05
trainer/Bellman Errors 2 Max                 0.000828636
trainer/Bellman Errors 2 Min                 3.69504e-12
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942796
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     42000
expl/num paths total                      1050
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320611
expl/Actions Std                             0.90728
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      8400
eval/num paths total                       210
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942793
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00566989
time/evaluation sampling (s)                 3.23771
time/exploration sampling (s)               16.8521
time/logging (s)                             0.0053353
time/saving (s)                              0.00235431
time/training (s)                            4.41816
time/epoch (s)                              24.5213
time/total (s)                             507.74
Epoch                                       20
---------------------------------------  ---------------
2023-08-05 00:30:03.610700 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 21 finished
---------------------------------------  ---------------
epoch                                       21
replay_buffer/size                       44000
trainer/QF1 Loss                             1.22603e-05
trainer/QF2 Loss                             1.10062e-05
trainer/Policy Loss                         -0.156639
trainer/Q1 Predictions Mean                  0.157334
trainer/Q1 Predictions Std                   0.00791525
trainer/Q1 Predictions Max                   0.33027
trainer/Q1 Predictions Min                   0.149135
trainer/Q2 Predictions Mean                  0.157656
trainer/Q2 Predictions Std                   0.00778316
trainer/Q2 Predictions Max                   0.326124
trainer/Q2 Predictions Min                   0.146956
trainer/Q Targets Mean                       0.15739
trainer/Q Targets Std                        0.008555
trainer/Q Targets Max                        0.322523
trainer/Q Targets Min                        0.144743
trainer/Bellman Errors 1 Mean                1.22603e-05
trainer/Bellman Errors 1 Std                 7.16452e-05
trainer/Bellman Errors 1 Max                 0.00367488
trainer/Bellman Errors 1 Min                 3.19744e-14
trainer/Bellman Errors 2 Mean                1.10062e-05
trainer/Bellman Errors 2 Std                 3.91937e-05
trainer/Bellman Errors 2 Max                 0.0014337
trainer/Bellman Errors 2 Min                 2.27374e-13
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942796
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     44000
expl/num paths total                      1100
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320674
expl/Actions Std                             0.907255
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      8800
eval/num paths total                       220
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942794
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00589275
time/evaluation sampling (s)                 3.19479
time/exploration sampling (s)               16.3796
time/logging (s)                             0.0053268
time/saving (s)                              0.00232433
time/training (s)                            4.25969
time/epoch (s)                              23.8476
time/total (s)                             531.59
Epoch                                       21
---------------------------------------  ---------------
2023-08-05 00:30:28.622722 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 22 finished
---------------------------------------  ---------------
epoch                                       22
replay_buffer/size                       46000
trainer/QF1 Loss                             1.16132e-05
trainer/QF2 Loss                             1.02626e-05
trainer/Policy Loss                         -0.14401
trainer/Q1 Predictions Mean                  0.144831
trainer/Q1 Predictions Std                   0.00735664
trainer/Q1 Predictions Max                   0.308826
trainer/Q1 Predictions Min                   0.130841
trainer/Q2 Predictions Mean                  0.144813
trainer/Q2 Predictions Std                   0.00799606
trainer/Q2 Predictions Max                   0.325797
trainer/Q2 Predictions Min                   0.130097
trainer/Q Targets Mean                       0.1447
trainer/Q Targets Std                        0.00869463
trainer/Q Targets Max                        0.349105
trainer/Q Targets Min                        0.131926
trainer/Bellman Errors 1 Mean                1.16132e-05
trainer/Bellman Errors 1 Std                 5.63905e-05
trainer/Bellman Errors 1 Max                 0.00162244
trainer/Bellman Errors 1 Min                 1.42109e-14
trainer/Bellman Errors 2 Mean                1.02626e-05
trainer/Bellman Errors 2 Std                 3.79401e-05
trainer/Bellman Errors 2 Max                 0.00112474
trainer/Bellman Errors 2 Min                 1.9984e-13
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942797
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     46000
expl/num paths total                      1150
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319908
expl/Actions Std                             0.907343
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      9200
eval/num paths total                       230
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942795
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00579261
time/evaluation sampling (s)                 3.17553
time/exploration sampling (s)               17.3012
time/logging (s)                             0.00544647
time/saving (s)                              0.00248357
time/training (s)                            4.51955
time/epoch (s)                              25.01
time/total (s)                             556.601
Epoch                                       22
---------------------------------------  ---------------
2023-08-05 00:30:52.403140 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 23 finished
---------------------------------------  ---------------
epoch                                       23
replay_buffer/size                       48000
trainer/QF1 Loss                             8.83531e-06
trainer/QF2 Loss                             7.68511e-06
trainer/Policy Loss                         -0.132051
trainer/Q1 Predictions Mean                  0.132369
trainer/Q1 Predictions Std                   0.00566179
trainer/Q1 Predictions Max                   0.291526
trainer/Q1 Predictions Min                   0.118916
trainer/Q2 Predictions Mean                  0.132528
trainer/Q2 Predictions Std                   0.00573473
trainer/Q2 Predictions Max                   0.301681
trainer/Q2 Predictions Min                   0.124979
trainer/Q Targets Mean                       0.132547
trainer/Q Targets Std                        0.0062822
trainer/Q Targets Max                        0.291723
trainer/Q Targets Min                        0.12034
trainer/Bellman Errors 1 Mean                8.83531e-06
trainer/Bellman Errors 1 Std                 5.16931e-05
trainer/Bellman Errors 1 Max                 0.00259737
trainer/Bellman Errors 1 Min                 7.21423e-13
trainer/Bellman Errors 2 Mean                7.68511e-06
trainer/Bellman Errors 2 Std                 2.66962e-05
trainer/Bellman Errors 2 Max                 0.00105162
trainer/Bellman Errors 2 Min                 2.22045e-14
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942797
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     48000
expl/num paths total                      1200
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320237
expl/Actions Std                             0.906861
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                      9600
eval/num paths total                       240
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942797
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00585839
time/evaluation sampling (s)                 3.21988
time/exploration sampling (s)               16.3851
time/logging (s)                             0.00529814
time/saving (s)                              0.00239296
time/training (s)                            4.15957
time/epoch (s)                              23.7781
time/total (s)                             580.381
Epoch                                       23
---------------------------------------  ---------------
2023-08-05 00:31:16.351932 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 24 finished
---------------------------------------  ---------------
epoch                                       24
replay_buffer/size                       50000
trainer/QF1 Loss                             8.01423e-06
trainer/QF2 Loss                             6.82345e-06
trainer/Policy Loss                         -0.120852
trainer/Q1 Predictions Mean                  0.121385
trainer/Q1 Predictions Std                   0.00788041
trainer/Q1 Predictions Max                   0.270913
trainer/Q1 Predictions Min                   0.113327
trainer/Q2 Predictions Mean                  0.121653
trainer/Q2 Predictions Std                   0.00778438
trainer/Q2 Predictions Max                   0.267162
trainer/Q2 Predictions Min                   0.107487
trainer/Q Targets Mean                       0.121784
trainer/Q Targets Std                        0.00834361
trainer/Q Targets Max                        0.274206
trainer/Q Targets Min                        0.111347
trainer/Bellman Errors 1 Mean                8.01423e-06
trainer/Bellman Errors 1 Std                 3.36497e-05
trainer/Bellman Errors 1 Max                 0.00105064
trainer/Bellman Errors 1 Min                 1.0747e-13
trainer/Bellman Errors 2 Mean                6.82345e-06
trainer/Bellman Errors 2 Std                 2.63566e-05
trainer/Bellman Errors 2 Max                 0.000991478
trainer/Bellman Errors 2 Min                 1.55931e-13
trainer/Policy Action Mean                   0.333334
trainer/Policy Action Std                    0.942798
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     50000
expl/num paths total                      1250
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320098
expl/Actions Std                             0.90673
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                     10000
eval/num paths total                       250
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333334
eval/Actions Std                             0.942796
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00809537
time/evaluation sampling (s)                 3.20705
time/exploration sampling (s)               16.4596
time/logging (s)                             0.00527725
time/saving (s)                              0.00237743
time/training (s)                            4.26413
time/epoch (s)                              23.9465
time/total (s)                             604.329
Epoch                                       24
---------------------------------------  ---------------
2023-08-05 00:31:39.850906 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 25 finished
---------------------------------------  ---------------
epoch                                       25
replay_buffer/size                       52000
trainer/QF1 Loss                             6.32055e-06
trainer/QF2 Loss                             6.08808e-06
trainer/Policy Loss                         -0.110513
trainer/Q1 Predictions Mean                  0.11135
trainer/Q1 Predictions Std                   0.00882671
trainer/Q1 Predictions Max                   0.339965
trainer/Q1 Predictions Min                   0.0992968
trainer/Q2 Predictions Mean                  0.111394
trainer/Q2 Predictions Std                   0.00857162
trainer/Q2 Predictions Max                   0.341717
trainer/Q2 Predictions Min                   0.104317
trainer/Q Targets Mean                       0.111292
trainer/Q Targets Std                        0.00906567
trainer/Q Targets Max                        0.338281
trainer/Q Targets Min                        0.0987641
trainer/Bellman Errors 1 Mean                6.32055e-06
trainer/Bellman Errors 1 Std                 3.20866e-05
trainer/Bellman Errors 1 Max                 0.00104286
trainer/Bellman Errors 1 Min                 3.03979e-13
trainer/Bellman Errors 2 Mean                6.08808e-06
trainer/Bellman Errors 2 Std                 2.71493e-05
trainer/Bellman Errors 2 Max                 0.00081423
trainer/Bellman Errors 2 Min                 1.38778e-13
trainer/Policy Action Mean                   0.333334
trainer/Policy Action Std                    0.942799
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     52000
expl/num paths total                      1300
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319934
expl/Actions Std                             0.907211
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                     10400
eval/num paths total                       260
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333334
eval/Actions Std                             0.942798
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00810696
time/evaluation sampling (s)                 3.16072
time/exploration sampling (s)               15.848
time/logging (s)                             0.00531018
time/saving (s)                              0.00238773
time/training (s)                            4.47235
time/epoch (s)                              23.4968
time/total (s)                             627.828
Epoch                                       25
---------------------------------------  ---------------
2023-08-05 00:32:03.297617 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 26 finished
---------------------------------------  ---------------
epoch                                       26
replay_buffer/size                       54000
trainer/QF1 Loss                             6.09715e-06
trainer/QF2 Loss                             5.93008e-06
trainer/Policy Loss                         -0.101315
trainer/Q1 Predictions Mean                  0.101474
trainer/Q1 Predictions Std                   0.00626056
trainer/Q1 Predictions Max                   0.314899
trainer/Q1 Predictions Min                   0.0940394
trainer/Q2 Predictions Mean                  0.101531
trainer/Q2 Predictions Std                   0.00621773
trainer/Q2 Predictions Max                   0.324586
trainer/Q2 Predictions Min                   0.091918
trainer/Q Targets Mean                       0.101668
trainer/Q Targets Std                        0.00680039
trainer/Q Targets Max                        0.332394
trainer/Q Targets Min                        0.0911944
trainer/Bellman Errors 1 Mean                6.09715e-06
trainer/Bellman Errors 1 Std                 3.27016e-05
trainer/Bellman Errors 1 Max                 0.00110629
trainer/Bellman Errors 1 Min                 8.12739e-13
trainer/Bellman Errors 2 Mean                5.93008e-06
trainer/Bellman Errors 2 Std                 3.10241e-05
trainer/Bellman Errors 2 Max                 0.00112697
trainer/Bellman Errors 2 Min                 2.20324e-13
trainer/Policy Action Mean                   0.333335
trainer/Policy Action Std                    0.9428
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     54000
expl/num paths total                      1350
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320339
expl/Actions Std                             0.906447
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                     10800
eval/num paths total                       270
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333335
eval/Actions Std                             0.942798
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00583495
time/evaluation sampling (s)                 3.17943
time/exploration sampling (s)               15.9287
time/logging (s)                             0.00545882
time/saving (s)                              0.00238926
time/training (s)                            4.32273
time/epoch (s)                              23.4446
time/total (s)                             651.274
Epoch                                       26
---------------------------------------  ---------------
2023-08-05 00:32:27.095933 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 27 finished
---------------------------------------  ---------------
epoch                                       27
replay_buffer/size                       56000
trainer/QF1 Loss                             4.73007e-06
trainer/QF2 Loss                             4.74508e-06
trainer/Policy Loss                         -0.0922412
trainer/Q1 Predictions Mean                  0.0927042
trainer/Q1 Predictions Std                   0.00639888
trainer/Q1 Predictions Max                   0.311925
trainer/Q1 Predictions Min                   0.0856343
trainer/Q2 Predictions Mean                  0.0926832
trainer/Q2 Predictions Std                   0.00644626
trainer/Q2 Predictions Max                   0.309621
trainer/Q2 Predictions Min                   0.0810597
trainer/Q Targets Mean                       0.092876
trainer/Q Targets Std                        0.00691593
trainer/Q Targets Max                        0.311396
trainer/Q Targets Min                        0.0822435
trainer/Bellman Errors 1 Mean                4.73007e-06
trainer/Bellman Errors 1 Std                 2.51814e-05
trainer/Bellman Errors 1 Max                 0.000974582
trainer/Bellman Errors 1 Min                 1.38778e-15
trainer/Bellman Errors 2 Mean                4.74508e-06
trainer/Bellman Errors 2 Std                 2.5514e-05
trainer/Bellman Errors 2 Max                 0.00105326
trainer/Bellman Errors 2 Min                 9.38138e-15
trainer/Policy Action Mean                   0.333334
trainer/Policy Action Std                    0.9428
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     56000
expl/num paths total                      1400
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319875
expl/Actions Std                             0.907038
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                     11200
eval/num paths total                       280
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333335
eval/Actions Std                             0.942798
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00570101
time/evaluation sampling (s)                 3.24611
time/exploration sampling (s)               15.9474
time/logging (s)                             0.0054133
time/saving (s)                              0.00240163
time/training (s)                            4.58875
time/epoch (s)                              23.7958
time/total (s)                             675.072
Epoch                                       27
---------------------------------------  ---------------
2023-08-05 00:32:50.622816 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 28 finished
---------------------------------------  ---------------
epoch                                       28
replay_buffer/size                       58000
trainer/QF1 Loss                             4.05447e-06
trainer/QF2 Loss                             3.6819e-06
trainer/Policy Loss                         -0.0840353
trainer/Q1 Predictions Mean                  0.0844888
trainer/Q1 Predictions Std                   0.00792269
trainer/Q1 Predictions Max                   0.296608
trainer/Q1 Predictions Min                   0.076728
trainer/Q2 Predictions Mean                  0.0844798
trainer/Q2 Predictions Std                   0.0077691
trainer/Q2 Predictions Max                   0.298274
trainer/Q2 Predictions Min                   0.0772489
trainer/Q Targets Mean                       0.0846929
trainer/Q Targets Std                        0.00806306
trainer/Q Targets Max                        0.296087
trainer/Q Targets Min                        0.0741657
trainer/Bellman Errors 1 Mean                4.05447e-06
trainer/Bellman Errors 1 Std                 2.02717e-05
trainer/Bellman Errors 1 Max                 0.000537208
trainer/Bellman Errors 1 Min                 1.8674e-13
trainer/Bellman Errors 2 Mean                3.6819e-06
trainer/Bellman Errors 2 Std                 1.73725e-05
trainer/Bellman Errors 2 Max                 0.000740617
trainer/Bellman Errors 2 Min                 4.996e-14
trainer/Policy Action Mean                   0.333334
trainer/Policy Action Std                    0.942798
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     58000
expl/num paths total                      1450
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320331
expl/Actions Std                             0.908135
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                     11600
eval/num paths total                       290
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333334
eval/Actions Std                             0.942797
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.0059043
time/evaluation sampling (s)                 3.25005
time/exploration sampling (s)               15.8515
time/logging (s)                             0.00527844
time/saving (s)                              0.00233138
time/training (s)                            4.40906
time/epoch (s)                              23.5241
time/total (s)                             698.598
Epoch                                       28
---------------------------------------  ---------------
2023-08-05 00:33:15.336437 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 29 finished
---------------------------------------  ---------------
epoch                                       29
replay_buffer/size                       60000
trainer/QF1 Loss                             4.55257e-06
trainer/QF2 Loss                             4.27513e-06
trainer/Policy Loss                         -0.0764467
trainer/Q1 Predictions Mean                  0.0769198
trainer/Q1 Predictions Std                   0.00889741
trainer/Q1 Predictions Max                   0.295171
trainer/Q1 Predictions Min                   0.0648128
trainer/Q2 Predictions Mean                  0.0770017
trainer/Q2 Predictions Std                   0.00897604
trainer/Q2 Predictions Max                   0.293501
trainer/Q2 Predictions Min                   0.061339
trainer/Q Targets Mean                       0.0771834
trainer/Q Targets Std                        0.0091748
trainer/Q Targets Max                        0.305108
trainer/Q Targets Min                        0.0666408
trainer/Bellman Errors 1 Mean                4.55257e-06
trainer/Bellman Errors 1 Std                 3.25281e-05
trainer/Bellman Errors 1 Max                 0.00108409
trainer/Bellman Errors 1 Min                 6.04516e-14
trainer/Bellman Errors 2 Mean                4.27513e-06
trainer/Bellman Errors 2 Std                 2.70964e-05
trainer/Bellman Errors 2 Max                 0.00092617
trainer/Bellman Errors 2 Min                 1.52967e-12
trainer/Policy Action Mean                   0.333333
trainer/Policy Action Std                    0.942796
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     60000
expl/num paths total                      1500
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320091
expl/Actions Std                             0.907461
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                     12000
eval/num paths total                       300
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333333
eval/Actions Std                             0.942794
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00593001
time/evaluation sampling (s)                 4.46257
time/exploration sampling (s)               15.8763
time/logging (s)                             0.0053608
time/saving (s)                              0.00234993
time/training (s)                            4.35882
time/epoch (s)                              24.7113
time/total (s)                             723.312
Epoch                                       29
---------------------------------------  ---------------
2023-08-05 00:33:39.722129 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 30 finished
---------------------------------------  ---------------
epoch                                       30
replay_buffer/size                       62000
trainer/QF1 Loss                             4.12552e-06
trainer/QF2 Loss                             3.40578e-06
trainer/Policy Loss                         -0.0693688
trainer/Q1 Predictions Mean                  0.069895
trainer/Q1 Predictions Std                   0.00787033
trainer/Q1 Predictions Max                   0.287066
trainer/Q1 Predictions Min                   0.0618372
trainer/Q2 Predictions Mean                  0.0698979
trainer/Q2 Predictions Std                   0.00754357
trainer/Q2 Predictions Max                   0.285009
trainer/Q2 Predictions Min                   0.0605655
trainer/Q Targets Mean                       0.0699876
trainer/Q Targets Std                        0.00810615
trainer/Q Targets Max                        0.300207
trainer/Q Targets Min                        0.0594593
trainer/Bellman Errors 1 Mean                4.12552e-06
trainer/Bellman Errors 1 Std                 3.67824e-05
trainer/Bellman Errors 1 Max                 0.00164155
trainer/Bellman Errors 1 Min                 9.79217e-14
trainer/Bellman Errors 2 Mean                3.40578e-06
trainer/Bellman Errors 2 Std                 2.94451e-05
trainer/Bellman Errors 2 Max                 0.00165259
trainer/Bellman Errors 2 Min                 6.23723e-13
trainer/Policy Action Mean                   0.333332
trainer/Policy Action Std                    0.942789
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     62000
expl/num paths total                      1550
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.319763
expl/Actions Std                             0.906459
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                     12400
eval/num paths total                       310
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333332
eval/Actions Std                             0.942787
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.0059421
time/evaluation sampling (s)                 4.02575
time/exploration sampling (s)               16.6849
time/logging (s)                             0.0039731
time/saving (s)                              0.00200207
time/training (s)                            3.6595
time/epoch (s)                              24.382
time/total (s)                             747.695
Epoch                                       30
---------------------------------------  ---------------
2023-08-05 00:34:04.386263 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 31 finished
---------------------------------------  ---------------
epoch                                       31
replay_buffer/size                       64000
trainer/QF1 Loss                             2.94577e-06
trainer/QF2 Loss                             2.69953e-06
trainer/Policy Loss                         -0.0629032
trainer/Q1 Predictions Mean                  0.0632346
trainer/Q1 Predictions Std                   0.00539201
trainer/Q1 Predictions Max                   0.228455
trainer/Q1 Predictions Min                   0.0551669
trainer/Q2 Predictions Mean                  0.063294
trainer/Q2 Predictions Std                   0.00532635
trainer/Q2 Predictions Max                   0.226815
trainer/Q2 Predictions Min                   0.0559262
trainer/Q Targets Mean                       0.063234
trainer/Q Targets Std                        0.00566549
trainer/Q Targets Max                        0.230338
trainer/Q Targets Min                        0.0501502
trainer/Bellman Errors 1 Mean                2.94577e-06
trainer/Bellman Errors 1 Std                 1.87108e-05
trainer/Bellman Errors 1 Max                 0.00057472
trainer/Bellman Errors 1 Min                 8.88178e-16
trainer/Bellman Errors 2 Mean                2.69953e-06
trainer/Bellman Errors 2 Std                 1.63873e-05
trainer/Bellman Errors 2 Max                 0.00061328
trainer/Bellman Errors 2 Min                 2.44804e-14
trainer/Policy Action Mean                   0.33334
trainer/Policy Action Std                    0.942762
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     64000
expl/num paths total                      1600
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.320452
expl/Actions Std                             0.907569
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                     12800
eval/num paths total                       320
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.333341
eval/Actions Std                             0.942755
eval/Actions Max                             1
eval/Actions Min                            -0.999997
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00569976
time/evaluation sampling (s)                 3.23193
time/exploration sampling (s)               16.8367
time/logging (s)                             0.00530197
time/saving (s)                              0.00232623
time/training (s)                            4.58135
time/epoch (s)                              24.6633
time/total (s)                             772.36
Epoch                                       31
---------------------------------------  ---------------
2023-08-05 00:34:28.702462 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 32 finished
---------------------------------------  ---------------
epoch                                       32
replay_buffer/size                       66000
trainer/QF1 Loss                             3.40032e-06
trainer/QF2 Loss                             3.0317e-06
trainer/Policy Loss                         -0.0569461
trainer/Q1 Predictions Mean                  0.0571699
trainer/Q1 Predictions Std                   0.00687356
trainer/Q1 Predictions Max                   0.28437
trainer/Q1 Predictions Min                   0.0492406
trainer/Q2 Predictions Mean                  0.0570866
trainer/Q2 Predictions Std                   0.0066997
trainer/Q2 Predictions Max                   0.285725
trainer/Q2 Predictions Min                   0.0490373
trainer/Q Targets Mean                       0.057348
trainer/Q Targets Std                        0.00686267
trainer/Q Targets Max                        0.288771
trainer/Q Targets Min                        0.0457927
trainer/Bellman Errors 1 Mean                3.40032e-06
trainer/Bellman Errors 1 Std                 2.48116e-05
trainer/Bellman Errors 1 Max                 0.000967598
trainer/Bellman Errors 1 Min                 2.09957e-13
trainer/Bellman Errors 2 Mean                3.0317e-06
trainer/Bellman Errors 2 Std                 2.25887e-05
trainer/Bellman Errors 2 Max                 0.000960513
trainer/Bellman Errors 2 Min                 1.08802e-14
trainer/Policy Action Mean                   0.344475
trainer/Policy Action Std                    0.926657
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.999721
expl/num steps total                     66000
expl/num paths total                      1650
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0
expl/Rewards Std                             0
expl/Rewards Max                             0
expl/Rewards Min                             0
expl/Returns Mean                            0
expl/Returns Std                             0
expl/Returns Max                             0
expl/Returns Min                             0
expl/Actions Mean                            0.326683
expl/Actions Std                             0.896918
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                         0
expl/env_infos/final/reward_dist Mean        0
expl/env_infos/final/reward_dist Std         0
expl/env_infos/final/reward_dist Max         0
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0
expl/env_infos/initial/reward_dist Std       0
expl/env_infos/initial/reward_dist Max       0
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0
expl/env_infos/reward_dist Std               0
expl/env_infos/reward_dist Max               0
expl/env_infos/reward_dist Min               0
eval/num steps total                     13200
eval/num paths total                       330
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0
eval/Rewards Std                             0
eval/Rewards Max                             0
eval/Rewards Min                             0
eval/Returns Mean                            0
eval/Returns Std                             0
eval/Returns Max                             0
eval/Returns Min                             0
eval/Actions Mean                            0.345404
eval/Actions Std                             0.925267
eval/Actions Max                             0.999996
eval/Actions Min                            -0.995707
eval/Num Paths                              10
eval/Average Returns                         0
eval/env_infos/final/reward_dist Mean        0
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max         0
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0
eval/env_infos/reward_dist Std               0
eval/env_infos/reward_dist Max               0
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00586559
time/evaluation sampling (s)                 3.27399
time/exploration sampling (s)               16.8872
time/logging (s)                             0.00532292
time/saving (s)                              0.00241717
time/training (s)                            4.13907
time/epoch (s)                              24.3139
time/total (s)                             796.676
Epoch                                       32
---------------------------------------  ---------------
2023-08-05 00:34:54.730354 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 33 finished
---------------------------------------  ---------------
epoch                                       33
replay_buffer/size                       68000
trainer/QF1 Loss                             0.0352609
trainer/QF2 Loss                             0.0348107
trainer/Policy Loss                         -0.133742
trainer/Q1 Predictions Mean                  0.0854244
trainer/Q1 Predictions Std                   0.0237107
trainer/Q1 Predictions Max                   0.246927
trainer/Q1 Predictions Min                   0.0541847
trainer/Q2 Predictions Mean                  0.0850031
trainer/Q2 Predictions Std                   0.0240262
trainer/Q2 Predictions Max                   0.245456
trainer/Q2 Predictions Min                   0.0518884
trainer/Q Targets Mean                       0.113206
trainer/Q Targets Std                        0.190672
trainer/Q Targets Max                        1.66621
trainer/Q Targets Min                        0.0222966
trainer/Bellman Errors 1 Mean                0.0352609
trainer/Bellman Errors 1 Std                 0.270981
trainer/Bellman Errors 1 Max                 2.4221
trainer/Bellman Errors 1 Min                 9.79217e-14
trainer/Bellman Errors 2 Mean                0.0348107
trainer/Bellman Errors 2 Std                 0.267749
trainer/Bellman Errors 2 Max                 2.36703
trainer/Bellman Errors 2 Min                 2.88569e-12
trainer/Policy Action Mean                   0.642217
trainer/Policy Action Std                    0.619861
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.765091
expl/num steps total                     68000
expl/num paths total                      1700
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.858052
expl/Rewards Std                             0.620743
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           34.3221
expl/Returns Std                             0.943622
expl/Returns Max                            36.5136
expl/Returns Min                            32.5244
expl/Actions Mean                            0.617285
expl/Actions Std                             0.616414
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        34.3221
expl/env_infos/final/reward_dist Mean        1.56961
expl/env_infos/final/reward_dist Std         0.00177303
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         1.56349
expl/env_infos/initial/reward_dist Mean      0.000906671
expl/env_infos/initial/reward_dist Std       0.00271158
expl/env_infos/initial/reward_dist Max       0.0109548
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.858052
expl/env_infos/reward_dist Std               0.620743
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     13600
eval/num paths total                       340
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.869894
eval/Rewards Std                             0.620888
eval/Rewards Max                             1.57079
eval/Rewards Min                             0
eval/Returns Mean                           34.7958
eval/Returns Std                             0.94858
eval/Returns Max                            36.5266
eval/Returns Min                            33.3578
eval/Actions Mean                            0.642488
eval/Actions Std                             0.627941
eval/Actions Max                             1
eval/Actions Min                            -0.750722
eval/Num Paths                              10
eval/Average Returns                        34.7958
eval/env_infos/final/reward_dist Mean        1.56991
eval/env_infos/final/reward_dist Std         0.00201781
eval/env_infos/final/reward_dist Max         1.57079
eval/env_infos/final/reward_dist Min         1.56388
eval/env_infos/initial/reward_dist Mean      0.00115416
eval/env_infos/initial/reward_dist Std       0.00317633
eval/env_infos/initial/reward_dist Max       0.0106497
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.869894
eval/env_infos/reward_dist Std               0.620888
eval/env_infos/reward_dist Max               1.57079
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00576386
time/evaluation sampling (s)                 3.53951
time/exploration sampling (s)               18.0857
time/logging (s)                             0.00530586
time/saving (s)                              0.00232802
time/training (s)                            4.38704
time/epoch (s)                              26.0256
time/total (s)                             822.704
Epoch                                       33
---------------------------------------  ---------------
2023-08-05 00:35:20.427504 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 34 finished
---------------------------------------  ---------------
epoch                                       34
replay_buffer/size                       70000
trainer/QF1 Loss                             0.0145262
trainer/QF2 Loss                             0.0143631
trainer/Policy Loss                         -2.41622
trainer/Q1 Predictions Mean                  1.72513
trainer/Q1 Predictions Std                   1.11312
trainer/Q1 Predictions Max                   4.34527
trainer/Q1 Predictions Min                  -0.480919
trainer/Q2 Predictions Mean                  1.72667
trainer/Q2 Predictions Std                   1.10955
trainer/Q2 Predictions Max                   4.24034
trainer/Q2 Predictions Min                  -0.163594
trainer/Q Targets Mean                       1.71801
trainer/Q Targets Std                        1.11427
trainer/Q Targets Max                        4.36191
trainer/Q Targets Min                       -0.363055
trainer/Bellman Errors 1 Mean                0.0145262
trainer/Bellman Errors 1 Std                 0.0560823
trainer/Bellman Errors 1 Max                 2.15187
trainer/Bellman Errors 1 Min                 6.508e-10
trainer/Bellman Errors 2 Mean                0.0143631
trainer/Bellman Errors 2 Std                 0.051303
trainer/Bellman Errors 2 Max                 1.85128
trainer/Bellman Errors 2 Min                 8.88178e-16
trainer/Policy Action Mean                   0.743047
trainer/Policy Action Std                    0.568557
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.859457
expl/num steps total                     70000
expl/num paths total                      1750
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.837767
expl/Rewards Std                             0.667159
expl/Rewards Max                             1.5708
expl/Rewards Min                             0
expl/Returns Mean                           33.5107
expl/Returns Std                            13.8256
expl/Returns Max                            41.0418
expl/Returns Min                             0
expl/Actions Mean                            0.70521
expl/Actions Std                             0.568972
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        33.5107
expl/env_infos/final/reward_dist Mean        1.34781
expl/env_infos/final/reward_dist Std         0.543752
expl/env_infos/final/reward_dist Max         1.5708
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000798644
expl/env_infos/initial/reward_dist Std       0.00283614
expl/env_infos/initial/reward_dist Max       0.0133274
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.837767
expl/env_infos/reward_dist Std               0.667159
expl/env_infos/reward_dist Max               1.5708
expl/env_infos/reward_dist Min               0
eval/num steps total                     14000
eval/num paths total                       350
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.903126
eval/Rewards Std                             0.657327
eval/Rewards Max                             1.57075
eval/Rewards Min                             0
eval/Returns Mean                           36.125
eval/Returns Std                            12.052
eval/Returns Max                            41.4133
eval/Returns Min                             0.0418681
eval/Actions Mean                            0.736523
eval/Actions Std                             0.585664
eval/Actions Max                             1
eval/Actions Min                            -0.818491
eval/Num Paths                              10
eval/Average Returns                        36.125
eval/env_infos/final/reward_dist Mean        1.41228
eval/env_infos/final/reward_dist Std         0.470766
eval/env_infos/final/reward_dist Max         1.57075
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.000325508
eval/env_infos/initial/reward_dist Std       0.000659951
eval/env_infos/initial/reward_dist Max       0.00186955
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.903126
eval/env_infos/reward_dist Std               0.657327
eval/env_infos/reward_dist Max               1.57075
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00584512
time/evaluation sampling (s)                 3.47312
time/exploration sampling (s)               17.6591
time/logging (s)                             0.00529445
time/saving (s)                              0.00236663
time/training (s)                            4.54907
time/epoch (s)                              25.6948
time/total (s)                             848.4
Epoch                                       34
---------------------------------------  ---------------
2023-08-05 00:35:46.082193 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 35 finished
---------------------------------------  ---------------
epoch                                       35
replay_buffer/size                       72000
trainer/QF1 Loss                             0.0423554
trainer/QF2 Loss                             0.041671
trainer/Policy Loss                         -4.24936
trainer/Q1 Predictions Mean                  3.36892
trainer/Q1 Predictions Std                   2.22348
trainer/Q1 Predictions Max                   7.25955
trainer/Q1 Predictions Min                  -0.16235
trainer/Q2 Predictions Mean                  3.37227
trainer/Q2 Predictions Std                   2.22565
trainer/Q2 Predictions Max                   7.28478
trainer/Q2 Predictions Min                  -0.150428
trainer/Q Targets Mean                       3.38014
trainer/Q Targets Std                        2.23944
trainer/Q Targets Max                       10.2805
trainer/Q Targets Min                       -0.228199
trainer/Bellman Errors 1 Mean                0.0423554
trainer/Bellman Errors 1 Std                 1.23819
trainer/Bellman Errors 1 Max                79.1691
trainer/Bellman Errors 1 Min                 6.88397e-09
trainer/Bellman Errors 2 Mean                0.041671
trainer/Bellman Errors 2 Std                 1.20167
trainer/Bellman Errors 2 Max                76.8456
trainer/Bellman Errors 2 Min                 1.14619e-09
trainer/Policy Action Mean                   0.739205
trainer/Policy Action Std                    0.583052
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.781872
expl/num steps total                     72000
expl/num paths total                      1800
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.919044
expl/Rewards Std                             0.649202
expl/Rewards Max                             1.5708
expl/Rewards Min                             0
expl/Returns Mean                           36.7617
expl/Returns Std                            10.8584
expl/Returns Max                            41.3678
expl/Returns Min                             0.0259299
expl/Actions Mean                            0.707539
expl/Actions Std                             0.569998
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        36.7617
expl/env_infos/final/reward_dist Mean        1.4433
expl/env_infos/final/reward_dist Std         0.42561
expl/env_infos/final/reward_dist Max         1.5708
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.00145599
expl/env_infos/initial/reward_dist Std       0.00357395
expl/env_infos/initial/reward_dist Max       0.0169246
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.919044
expl/env_infos/reward_dist Std               0.649202
expl/env_infos/reward_dist Max               1.5708
expl/env_infos/reward_dist Min               0
eval/num steps total                     14400
eval/num paths total                       360
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.802042
eval/Rewards Std                             0.68224
eval/Rewards Max                             1.5704
eval/Rewards Min                             0
eval/Returns Mean                           32.0817
eval/Returns Std                            16.0326
eval/Returns Max                            41.415
eval/Returns Min                             0.0398466
eval/Actions Mean                            0.741592
eval/Actions Std                             0.579225
eval/Actions Max                             1
eval/Actions Min                            -0.981369
eval/Num Paths                              10
eval/Average Returns                        32.0817
eval/env_infos/final/reward_dist Mean        1.25425
eval/env_infos/final/reward_dist Std         0.627128
eval/env_infos/final/reward_dist Max         1.5704
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.000378184
eval/env_infos/initial/reward_dist Std       0.00113455
eval/env_infos/initial/reward_dist Max       0.00378184
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.802042
eval/env_infos/reward_dist Std               0.68224
eval/env_infos/reward_dist Max               1.5704
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00579055
time/evaluation sampling (s)                 3.41626
time/exploration sampling (s)               17.9644
time/logging (s)                             0.00743848
time/saving (s)                              0.00272395
time/training (s)                            4.25792
time/epoch (s)                              25.6545
time/total (s)                             874.057
Epoch                                       35
---------------------------------------  ---------------
2023-08-05 00:36:11.626835 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 36 finished
---------------------------------------  ---------------
epoch                                       36
replay_buffer/size                       74000
trainer/QF1 Loss                             0.0307878
trainer/QF2 Loss                             0.030501
trainer/Policy Loss                         -6.462
trainer/Q1 Predictions Mean                  5.45421
trainer/Q1 Predictions Std                   3.43345
trainer/Q1 Predictions Max                  11.4274
trainer/Q1 Predictions Min                  -0.228301
trainer/Q2 Predictions Mean                  5.45261
trainer/Q2 Predictions Std                   3.43368
trainer/Q2 Predictions Max                  11.5176
trainer/Q2 Predictions Min                  -0.228525
trainer/Q Targets Mean                       5.45903
trainer/Q Targets Std                        3.44315
trainer/Q Targets Max                       11.7771
trainer/Q Targets Min                        0.015496
trainer/Bellman Errors 1 Mean                0.0307878
trainer/Bellman Errors 1 Std                 0.0625156
trainer/Bellman Errors 1 Max                 1.12672
trainer/Bellman Errors 1 Min                 3.84261e-09
trainer/Bellman Errors 2 Mean                0.030501
trainer/Bellman Errors 2 Std                 0.0615106
trainer/Bellman Errors 2 Max                 1.18848
trainer/Bellman Errors 2 Min                 1.80103e-09
trainer/Policy Action Mean                   0.726483
trainer/Policy Action Std                    0.612343
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.980574
expl/num steps total                     74000
expl/num paths total                      1850
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.968711
expl/Rewards Std                             0.625599
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           38.7484
expl/Returns Std                             5.59277
expl/Returns Max                            40.939
expl/Returns Min                             0.0399593
expl/Actions Mean                            0.696217
expl/Actions Std                             0.592954
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        38.7484
expl/env_infos/final/reward_dist Mean        1.53718
expl/env_infos/final/reward_dist Std         0.219607
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.00166529
expl/env_infos/initial/reward_dist Std       0.00381198
expl/env_infos/initial/reward_dist Max       0.0157269
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.968711
expl/env_infos/reward_dist Std               0.625599
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     14800
eval/num paths total                       370
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.804042
eval/Rewards Std                             0.680848
eval/Rewards Max                             1.57078
eval/Rewards Min                             0
eval/Returns Mean                           32.1617
eval/Returns Std                            16.0895
eval/Returns Max                            41.2356
eval/Returns Min                             0
eval/Actions Mean                            0.726828
eval/Actions Std                             0.612584
eval/Actions Max                             1
eval/Actions Min                            -0.9999
eval/Num Paths                              10
eval/Average Returns                        32.1617
eval/env_infos/final/reward_dist Mean        1.25535
eval/env_infos/final/reward_dist Std         0.627679
eval/env_infos/final/reward_dist Max         1.57078
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.000909618
eval/env_infos/initial/reward_dist Std       0.00126982
eval/env_infos/initial/reward_dist Max       0.00291028
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.804042
eval/env_infos/reward_dist Std               0.680848
eval/env_infos/reward_dist Max               1.57078
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00572448
time/evaluation sampling (s)                 3.51795
time/exploration sampling (s)               17.8047
time/logging (s)                             0.00527012
time/saving (s)                              0.00232787
time/training (s)                            4.20282
time/epoch (s)                              25.5387
time/total (s)                             899.598
Epoch                                       36
---------------------------------------  ---------------
2023-08-05 00:36:37.293729 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 37 finished
---------------------------------------  ---------------
epoch                                       37
replay_buffer/size                       76000
trainer/QF1 Loss                             0.0440589
trainer/QF2 Loss                             0.043647
trainer/Policy Loss                         -8.65002
trainer/Q1 Predictions Mean                  7.59121
trainer/Q1 Predictions Std                   4.47793
trainer/Q1 Predictions Max                  15.6548
trainer/Q1 Predictions Min                  -0.378144
trainer/Q2 Predictions Mean                  7.594
trainer/Q2 Predictions Std                   4.48001
trainer/Q2 Predictions Max                  15.6136
trainer/Q2 Predictions Min                  -0.358282
trainer/Q Targets Mean                       7.59066
trainer/Q Targets Std                        4.47964
trainer/Q Targets Max                       16.0217
trainer/Q Targets Min                       -0.149606
trainer/Bellman Errors 1 Mean                0.0440589
trainer/Bellman Errors 1 Std                 0.108579
trainer/Bellman Errors 1 Max                 3.05294
trainer/Bellman Errors 1 Min                 3.84261e-09
trainer/Bellman Errors 2 Mean                0.043647
trainer/Bellman Errors 2 Std                 0.108549
trainer/Bellman Errors 2 Max                 2.95277
trainer/Bellman Errors 2 Min                 1.60435e-09
trainer/Policy Action Mean                   0.712086
trainer/Policy Action Std                    0.645862
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.999996
expl/num steps total                     76000
expl/num paths total                      1900
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.975255
expl/Rewards Std                             0.621269
expl/Rewards Max                             1.57077
expl/Rewards Min                             0
expl/Returns Mean                           39.0102
expl/Returns Std                             0.80712
expl/Returns Max                            40.4697
expl/Returns Min                            37.1977
expl/Actions Mean                            0.683966
expl/Actions Std                             0.624926
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        39.0102
expl/env_infos/final/reward_dist Mean        1.56912
expl/env_infos/final/reward_dist Std         0.0017074
expl/env_infos/final/reward_dist Max         1.57077
expl/env_infos/final/reward_dist Min         1.56393
expl/env_infos/initial/reward_dist Mean      0.00132252
expl/env_infos/initial/reward_dist Std       0.00315855
expl/env_infos/initial/reward_dist Max       0.0134424
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.975255
expl/env_infos/reward_dist Std               0.621269
expl/env_infos/reward_dist Max               1.57077
expl/env_infos/reward_dist Min               0
eval/num steps total                     15200
eval/num paths total                       380
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.990569
eval/Rewards Std                             0.618173
eval/Rewards Max                             1.57079
eval/Rewards Min                             0
eval/Returns Mean                           39.6228
eval/Returns Std                             0.538224
eval/Returns Max                            40.5059
eval/Returns Min                            38.9232
eval/Actions Mean                            0.716245
eval/Actions Std                             0.637406
eval/Actions Max                             1
eval/Actions Min                            -0.904704
eval/Num Paths                              10
eval/Average Returns                        39.6228
eval/env_infos/final/reward_dist Mean        1.56885
eval/env_infos/final/reward_dist Std         0.00262518
eval/env_infos/final/reward_dist Max         1.57079
eval/env_infos/final/reward_dist Min         1.56389
eval/env_infos/initial/reward_dist Mean      0.00113075
eval/env_infos/initial/reward_dist Std       0.00230339
eval/env_infos/initial/reward_dist Max       0.00663162
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.990569
eval/env_infos/reward_dist Std               0.618173
eval/env_infos/reward_dist Max               1.57079
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00587358
time/evaluation sampling (s)                 3.54478
time/exploration sampling (s)               17.7647
time/logging (s)                             0.00530621
time/saving (s)                              0.00233888
time/training (s)                            4.34153
time/epoch (s)                              25.6646
time/total (s)                             925.265
Epoch                                       37
---------------------------------------  ---------------
2023-08-05 00:37:03.320191 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 38 finished
---------------------------------------  ---------------
epoch                                       38
replay_buffer/size                       78000
trainer/QF1 Loss                             0.0463776
trainer/QF2 Loss                             0.0461257
trainer/Policy Loss                        -10.4067
trainer/Q1 Predictions Mean                  9.40011
trainer/Q1 Predictions Std                   5.22105
trainer/Q1 Predictions Max                  18.9158
trainer/Q1 Predictions Min                  -0.222926
trainer/Q2 Predictions Mean                  9.39761
trainer/Q2 Predictions Std                   5.22127
trainer/Q2 Predictions Max                  18.9299
trainer/Q2 Predictions Min                  -0.319012
trainer/Q Targets Mean                       9.40287
trainer/Q Targets Std                        5.2352
trainer/Q Targets Max                       19.3455
trainer/Q Targets Min                       -0.381461
trainer/Bellman Errors 1 Mean                0.0463776
trainer/Bellman Errors 1 Std                 0.102897
trainer/Bellman Errors 1 Max                 3.0295
trainer/Bellman Errors 1 Min                 1.92449e-09
trainer/Bellman Errors 2 Mean                0.0461257
trainer/Bellman Errors 2 Std                 0.105554
trainer/Bellman Errors 2 Max                 3.08439
trainer/Bellman Errors 2 Min                 2.27374e-11
trainer/Policy Action Mean                   0.717333
trainer/Policy Action Std                    0.633805
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.979992
expl/num steps total                     78000
expl/num paths total                      1950
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.977721
expl/Rewards Std                             0.622493
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           39.1089
expl/Returns Std                             0.78268
expl/Returns Max                            40.7334
expl/Returns Min                            37.6772
expl/Actions Mean                            0.688186
expl/Actions Std                             0.613995
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        39.1089
expl/env_infos/final/reward_dist Mean        1.56949
expl/env_infos/final/reward_dist Std         0.00175872
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         1.56397
expl/env_infos/initial/reward_dist Mean      0.00113666
expl/env_infos/initial/reward_dist Std       0.0029359
expl/env_infos/initial/reward_dist Max       0.0145318
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.977721
expl/env_infos/reward_dist Std               0.622493
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     15600
eval/num paths total                       390
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.890914
eval/Rewards Std                             0.658765
eval/Rewards Max                             1.57077
eval/Rewards Min                             0
eval/Returns Mean                           35.6366
eval/Returns Std                            11.8811
eval/Returns Max                            40.7273
eval/Returns Min                             0.0365494
eval/Actions Mean                            0.719711
eval/Actions Std                             0.632865
eval/Actions Max                             1
eval/Actions Min                            -0.999748
eval/Num Paths                              10
eval/Average Returns                        35.6366
eval/env_infos/final/reward_dist Mean        1.41183
eval/env_infos/final/reward_dist Std         0.470613
eval/env_infos/final/reward_dist Max         1.57077
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.000797983
eval/env_infos/initial/reward_dist Std       0.00187161
eval/env_infos/initial/reward_dist Max       0.00617604
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.890914
eval/env_infos/reward_dist Std               0.658765
eval/env_infos/reward_dist Max               1.57077
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00593065
time/evaluation sampling (s)                 3.43261
time/exploration sampling (s)               18.018
time/logging (s)                             0.00530164
time/saving (s)                              0.00235505
time/training (s)                            4.55985
time/epoch (s)                              26.0241
time/total (s)                             951.291
Epoch                                       38
---------------------------------------  ---------------
2023-08-05 00:37:29.208017 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 39 finished
---------------------------------------  ---------------
epoch                                       39
replay_buffer/size                       80000
trainer/QF1 Loss                             0.0648972
trainer/QF2 Loss                             0.0652447
trainer/Policy Loss                        -12.4172
trainer/Q1 Predictions Mean                 11.4547
trainer/Q1 Predictions Std                   5.90944
trainer/Q1 Predictions Max                  22.0942
trainer/Q1 Predictions Min                  -0.334562
trainer/Q2 Predictions Mean                 11.4531
trainer/Q2 Predictions Std                   5.91006
trainer/Q2 Predictions Max                  22.1273
trainer/Q2 Predictions Min                  -0.479069
trainer/Q Targets Mean                      11.4422
trainer/Q Targets Std                        5.91339
trainer/Q Targets Max                       22.5706
trainer/Q Targets Min                       -0.712292
trainer/Bellman Errors 1 Mean                0.0648972
trainer/Bellman Errors 1 Std                 0.193918
trainer/Bellman Errors 1 Max                 4.64873
trainer/Bellman Errors 1 Min                 8.03629e-09
trainer/Bellman Errors 2 Mean                0.0652447
trainer/Bellman Errors 2 Std                 0.193185
trainer/Bellman Errors 2 Max                 4.62987
trainer/Bellman Errors 2 Min                 2.04636e-12
trainer/Policy Action Mean                   0.7198
trainer/Policy Action Std                    0.628375
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.990239
expl/num steps total                     80000
expl/num paths total                      2000
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.901534
expl/Rewards Std                             0.654021
expl/Rewards Max                             1.57076
expl/Rewards Min                             0
expl/Returns Mean                           36.0614
expl/Returns Std                            10.6415
expl/Returns Max                            40.7848
expl/Returns Min                             0.0198455
expl/Actions Mean                            0.690691
expl/Actions Std                             0.614219
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        36.0614
expl/env_infos/final/reward_dist Mean        1.44339
expl/env_infos/final/reward_dist Std         0.425527
expl/env_infos/final/reward_dist Max         1.57076
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000627212
expl/env_infos/initial/reward_dist Std       0.00232212
expl/env_infos/initial/reward_dist Max       0.0142585
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.901534
expl/env_infos/reward_dist Std               0.654021
expl/env_infos/reward_dist Max               1.57076
expl/env_infos/reward_dist Min               0
eval/num steps total                     16000
eval/num paths total                       400
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.896876
eval/Rewards Std                             0.658801
eval/Rewards Max                             1.5708
eval/Rewards Min                             0
eval/Returns Mean                           35.875
eval/Returns Std                            11.966
eval/Returns Max                            41.0831
eval/Returns Min                             0.0291432
eval/Actions Mean                            0.720864
eval/Actions Std                             0.629692
eval/Actions Max                             1
eval/Actions Min                            -0.999875
eval/Num Paths                              10
eval/Average Returns                        35.875
eval/env_infos/final/reward_dist Mean        1.41191
eval/env_infos/final/reward_dist Std         0.470641
eval/env_infos/final/reward_dist Max         1.5708
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.000574128
eval/env_infos/initial/reward_dist Std       0.00153137
eval/env_infos/initial/reward_dist Max       0.00513627
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.896876
eval/env_infos/reward_dist Std               0.658801
eval/env_infos/reward_dist Max               1.5708
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00590426
time/evaluation sampling (s)                 3.4796
time/exploration sampling (s)               17.9192
time/logging (s)                             0.00530129
time/saving (s)                              0.00238389
time/training (s)                            4.47316
time/epoch (s)                              25.8855
time/total (s)                             977.178
Epoch                                       39
---------------------------------------  ---------------
2023-08-05 00:37:55.288851 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 40 finished
---------------------------------------  ---------------
epoch                                       40
replay_buffer/size                       82000
trainer/QF1 Loss                             0.0727555
trainer/QF2 Loss                             0.0726209
trainer/Policy Loss                        -14.0533
trainer/Q1 Predictions Mean                 13.1107
trainer/Q1 Predictions Std                   6.52543
trainer/Q1 Predictions Max                  24.8719
trainer/Q1 Predictions Min                  -0.668914
trainer/Q2 Predictions Mean                 13.1114
trainer/Q2 Predictions Std                   6.52388
trainer/Q2 Predictions Max                  24.826
trainer/Q2 Predictions Min                  -0.749929
trainer/Q Targets Mean                      13.1235
trainer/Q Targets Std                        6.53477
trainer/Q Targets Max                       25.2102
trainer/Q Targets Min                       -0.663528
trainer/Bellman Errors 1 Mean                0.0727555
trainer/Bellman Errors 1 Std                 0.167568
trainer/Bellman Errors 1 Max                 3.04196
trainer/Bellman Errors 1 Min                 2.32831e-10
trainer/Bellman Errors 2 Mean                0.0726209
trainer/Bellman Errors 2 Std                 0.166186
trainer/Bellman Errors 2 Max                 2.97924
trainer/Bellman Errors 2 Min                 8.3819e-09
trainer/Policy Action Mean                   0.712365
trainer/Policy Action Std                    0.645575
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.999999
expl/num steps total                     82000
expl/num paths total                      2050
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.981128
expl/Rewards Std                             0.620327
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           39.2451
expl/Returns Std                             0.834689
expl/Returns Max                            40.8101
expl/Returns Min                            37.7137
expl/Actions Mean                            0.686662
expl/Actions Std                             0.622897
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        39.2451
expl/env_infos/final/reward_dist Mean        1.56919
expl/env_infos/final/reward_dist Std         0.00201024
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         1.56385
expl/env_infos/initial/reward_dist Mean      0.00123446
expl/env_infos/initial/reward_dist Std       0.00267055
expl/env_infos/initial/reward_dist Max       0.0117822
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.981128
expl/env_infos/reward_dist Std               0.620327
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     16400
eval/num paths total                       410
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.996826
eval/Rewards Std                             0.618691
eval/Rewards Max                             1.57076
eval/Rewards Min                             0
eval/Returns Mean                           39.873
eval/Returns Std                             0.852977
eval/Returns Max                            41.0394
eval/Returns Min                            38.7089
eval/Actions Mean                            0.719852
eval/Actions Std                             0.632808
eval/Actions Max                             1
eval/Actions Min                            -0.899061
eval/Num Paths                              10
eval/Average Returns                        39.873
eval/env_infos/final/reward_dist Mean        1.56902
eval/env_infos/final/reward_dist Std         0.00228161
eval/env_infos/final/reward_dist Max         1.57076
eval/env_infos/final/reward_dist Min         1.56468
eval/env_infos/initial/reward_dist Mean      0.00264108
eval/env_infos/initial/reward_dist Std       0.00487084
eval/env_infos/initial/reward_dist Max       0.0149461
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.996826
eval/env_infos/reward_dist Std               0.618691
eval/env_infos/reward_dist Max               1.57076
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00590235
time/evaluation sampling (s)                 3.6039
time/exploration sampling (s)               18.0006
time/logging (s)                             0.00530403
time/saving (s)                              0.00229576
time/training (s)                            4.46052
time/epoch (s)                              26.0785
time/total (s)                            1003.26
Epoch                                       40
---------------------------------------  ---------------
2023-08-05 00:38:21.285713 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 41 finished
---------------------------------------  ---------------
epoch                                       41
replay_buffer/size                       84000
trainer/QF1 Loss                             0.0924108
trainer/QF2 Loss                             0.093507
trainer/Policy Loss                        -15.4953
trainer/Q1 Predictions Mean                 14.5784
trainer/Q1 Predictions Std                   6.99269
trainer/Q1 Predictions Max                  27.2785
trainer/Q1 Predictions Min                  -0.720532
trainer/Q2 Predictions Mean                 14.575
trainer/Q2 Predictions Std                   6.99317
trainer/Q2 Predictions Max                  27.2973
trainer/Q2 Predictions Min                  -0.888391
trainer/Q Targets Mean                      14.5753
trainer/Q Targets Std                        7.00226
trainer/Q Targets Max                       27.5315
trainer/Q Targets Min                       -0.717622
trainer/Bellman Errors 1 Mean                0.0924108
trainer/Bellman Errors 1 Std                 0.255387
trainer/Bellman Errors 1 Max                 5.21268
trainer/Bellman Errors 1 Min                 2.45927e-09
trainer/Bellman Errors 2 Mean                0.093507
trainer/Bellman Errors 2 Std                 0.259974
trainer/Bellman Errors 2 Max                 5.14564
trainer/Bellman Errors 2 Min                 8.20819e-11
trainer/Policy Action Mean                   0.711753
trainer/Policy Action Std                    0.646914
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.999995
expl/num steps total                     84000
expl/num paths total                      2100
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.980017
expl/Rewards Std                             0.621666
expl/Rewards Max                             1.57078
expl/Rewards Min                             0
expl/Returns Mean                           39.2007
expl/Returns Std                             0.773066
expl/Returns Max                            40.7292
expl/Returns Min                            37.5797
expl/Actions Mean                            0.68744
expl/Actions Std                             0.618249
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        39.2007
expl/env_infos/final/reward_dist Mean        1.56884
expl/env_infos/final/reward_dist Std         0.00213487
expl/env_infos/final/reward_dist Max         1.57078
expl/env_infos/final/reward_dist Min         1.5636
expl/env_infos/initial/reward_dist Mean      0.000835472
expl/env_infos/initial/reward_dist Std       0.00255894
expl/env_infos/initial/reward_dist Max       0.0129187
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.980017
expl/env_infos/reward_dist Std               0.621666
expl/env_infos/reward_dist Max               1.57078
expl/env_infos/reward_dist Min               0
eval/num steps total                     16800
eval/num paths total                       420
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.997655
eval/Rewards Std                             0.618247
eval/Rewards Max                             1.57078
eval/Rewards Min                             0
eval/Returns Mean                           39.9062
eval/Returns Std                             0.793709
eval/Returns Max                            41.2778
eval/Returns Min                            38.5296
eval/Actions Mean                            0.720272
eval/Actions Std                             0.631747
eval/Actions Max                             1
eval/Actions Min                            -0.89802
eval/Num Paths                              10
eval/Average Returns                        39.9062
eval/env_infos/final/reward_dist Mean        1.56941
eval/env_infos/final/reward_dist Std         0.00152705
eval/env_infos/final/reward_dist Max         1.57078
eval/env_infos/final/reward_dist Min         1.56634
eval/env_infos/initial/reward_dist Mean      0.00221685
eval/env_infos/initial/reward_dist Std       0.00447928
eval/env_infos/initial/reward_dist Max       0.0125094
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.997655
eval/env_infos/reward_dist Std               0.618247
eval/env_infos/reward_dist Max               1.57078
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00584135
time/evaluation sampling (s)                 3.92374
time/exploration sampling (s)               17.4772
time/logging (s)                             0.00534775
time/saving (s)                              0.00232027
time/training (s)                            4.57997
time/epoch (s)                              25.9944
time/total (s)                            1029.25
Epoch                                       41
---------------------------------------  ---------------
2023-08-05 00:38:46.986264 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 42 finished
---------------------------------------  ---------------
epoch                                       42
replay_buffer/size                       86000
trainer/QF1 Loss                             0.0966001
trainer/QF2 Loss                             0.0983451
trainer/Policy Loss                        -16.7727
trainer/Q1 Predictions Mean                 15.9014
trainer/Q1 Predictions Std                   7.22489
trainer/Q1 Predictions Max                  29.5304
trainer/Q1 Predictions Min                  -0.837733
trainer/Q2 Predictions Mean                 15.9002
trainer/Q2 Predictions Std                   7.22574
trainer/Q2 Predictions Max                  29.6594
trainer/Q2 Predictions Min                  -1.10525
trainer/Q Targets Mean                      15.9076
trainer/Q Targets Std                        7.24118
trainer/Q Targets Max                       29.7397
trainer/Q Targets Min                       -1.07338
trainer/Bellman Errors 1 Mean                0.0966001
trainer/Bellman Errors 1 Std                 0.353264
trainer/Bellman Errors 1 Max                17.0674
trainer/Bellman Errors 1 Min                 1.08881e-07
trainer/Bellman Errors 2 Mean                0.0983451
trainer/Bellman Errors 2 Std                 0.356251
trainer/Bellman Errors 2 Max                17.1219
trainer/Bellman Errors 2 Min                 2.45927e-09
trainer/Policy Action Mean                   0.718266
trainer/Policy Action Std                    0.632621
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.999992
expl/num steps total                     86000
expl/num paths total                      2150
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.962139
expl/Rewards Std                             0.632389
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           38.4856
expl/Returns Std                             5.53387
expl/Returns Max                            40.6159
expl/Returns Min                             0.0382025
expl/Actions Mean                            0.695148
expl/Actions Std                             0.604395
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        38.4856
expl/env_infos/final/reward_dist Mean        1.53793
expl/env_infos/final/reward_dist Std         0.219713
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000629006
expl/env_infos/initial/reward_dist Std       0.00200612
expl/env_infos/initial/reward_dist Max       0.0100432
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.962139
expl/env_infos/reward_dist Std               0.632389
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     17200
eval/num paths total                       430
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            1.00301
eval/Rewards Std                             0.61847
eval/Rewards Max                             1.57079
eval/Rewards Min                             0
eval/Returns Mean                           40.1205
eval/Returns Std                             0.803167
eval/Returns Max                            41.2797
eval/Returns Min                            39.0814
eval/Actions Mean                            0.728179
eval/Actions Std                             0.615617
eval/Actions Max                             1
eval/Actions Min                            -0.86804
eval/Num Paths                              10
eval/Average Returns                        40.1205
eval/env_infos/final/reward_dist Mean        1.5695
eval/env_infos/final/reward_dist Std         0.00123943
eval/env_infos/final/reward_dist Max         1.57079
eval/env_infos/final/reward_dist Min         1.56767
eval/env_infos/initial/reward_dist Mean      0.00340345
eval/env_infos/initial/reward_dist Std       0.00431659
eval/env_infos/initial/reward_dist Max       0.0106097
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              1.00301
eval/env_infos/reward_dist Std               0.61847
eval/env_infos/reward_dist Max               1.57079
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00579759
time/evaluation sampling (s)                 4.00286
time/exploration sampling (s)               17.3463
time/logging (s)                             0.00526388
time/saving (s)                              0.00234409
time/training (s)                            4.33555
time/epoch (s)                              25.6981
time/total (s)                            1054.95
Epoch                                       42
---------------------------------------  ---------------
2023-08-05 00:39:12.622458 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 43 finished
---------------------------------------  ---------------
epoch                                       43
replay_buffer/size                       88000
trainer/QF1 Loss                             0.110676
trainer/QF2 Loss                             0.112339
trainer/Policy Loss                        -17.9799
trainer/Q1 Predictions Mean                 17.1129
trainer/Q1 Predictions Std                   7.39448
trainer/Q1 Predictions Max                  31.0113
trainer/Q1 Predictions Min                  -0.715462
trainer/Q2 Predictions Mean                 17.1122
trainer/Q2 Predictions Std                   7.39452
trainer/Q2 Predictions Max                  31.0567
trainer/Q2 Predictions Min                  -0.857284
trainer/Q Targets Mean                      17.1105
trainer/Q Targets Std                        7.39801
trainer/Q Targets Max                       31.2263
trainer/Q Targets Min                       -0.576878
trainer/Bellman Errors 1 Mean                0.110676
trainer/Bellman Errors 1 Std                 0.298598
trainer/Bellman Errors 1 Max                 6.25941
trainer/Bellman Errors 1 Min                 9.31323e-10
trainer/Bellman Errors 2 Mean                0.112339
trainer/Bellman Errors 2 Std                 0.311199
trainer/Bellman Errors 2 Max                 7.76624
trainer/Bellman Errors 2 Min                 4.85315e-08
trainer/Policy Action Mean                   0.728141
trainer/Policy Action Std                    0.610334
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -0.999493
expl/num steps total                     88000
expl/num paths total                      2200
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.912331
expl/Rewards Std                             0.652327
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           36.4932
expl/Returns Std                            10.7734
expl/Returns Max                            40.8928
expl/Returns Min                             0.0083955
expl/Actions Mean                            0.697114
expl/Actions Std                             0.602117
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        36.4932
expl/env_infos/final/reward_dist Mean        1.44301
expl/env_infos/final/reward_dist Std         0.42553
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000750385
expl/env_infos/initial/reward_dist Std       0.00216406
expl/env_infos/initial/reward_dist Max       0.0101192
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.912331
expl/env_infos/reward_dist Std               0.652327
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     17600
eval/num paths total                       440
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            1.01666
eval/Rewards Std                             0.611414
eval/Rewards Max                             1.57077
eval/Rewards Min                             0
eval/Returns Mean                           40.6664
eval/Returns Std                             0.608071
eval/Returns Max                            41.4682
eval/Returns Min                            39.2914
eval/Actions Mean                            0.73171
eval/Actions Std                             0.60739
eval/Actions Max                             1
eval/Actions Min                            -0.809469
eval/Num Paths                              10
eval/Average Returns                        40.6664
eval/env_infos/final/reward_dist Mean        1.56956
eval/env_infos/final/reward_dist Std         0.00094069
eval/env_infos/final/reward_dist Max         1.57077
eval/env_infos/final/reward_dist Min         1.56813
eval/env_infos/initial/reward_dist Mean      0.00253467
eval/env_infos/initial/reward_dist Std       0.00457973
eval/env_infos/initial/reward_dist Max       0.0138048
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              1.01666
eval/env_infos/reward_dist Std               0.611414
eval/env_infos/reward_dist Max               1.57077
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00574036
time/evaluation sampling (s)                 4.04752
time/exploration sampling (s)               17.3682
time/logging (s)                             0.00532683
time/saving (s)                              0.0023134
time/training (s)                            4.20471
time/epoch (s)                              25.6338
time/total (s)                            1080.59
Epoch                                       43
---------------------------------------  ---------------
2023-08-05 00:39:38.299248 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 44 finished
---------------------------------------  ---------------
epoch                                       44
replay_buffer/size                       90000
trainer/QF1 Loss                             0.123632
trainer/QF2 Loss                             0.126551
trainer/Policy Loss                        -19.2262
trainer/Q1 Predictions Mean                 18.387
trainer/Q1 Predictions Std                   7.76275
trainer/Q1 Predictions Max                  33.3775
trainer/Q1 Predictions Min                  -1.22544
trainer/Q2 Predictions Mean                 18.3847
trainer/Q2 Predictions Std                   7.76294
trainer/Q2 Predictions Max                  33.4316
trainer/Q2 Predictions Min                  -1.35356
trainer/Q Targets Mean                      18.3571
trainer/Q Targets Std                        7.7669
trainer/Q Targets Max                       33.4552
trainer/Q Targets Min                       -1.04463
trainer/Bellman Errors 1 Mean                0.123632
trainer/Bellman Errors 1 Std                 0.358741
trainer/Bellman Errors 1 Max                 7.4835
trainer/Bellman Errors 1 Min                 4.45652e-09
trainer/Bellman Errors 2 Mean                0.126551
trainer/Bellman Errors 2 Std                 0.360535
trainer/Bellman Errors 2 Max                 5.75405
trainer/Bellman Errors 2 Min                 4.71482e-09
trainer/Policy Action Mean                   0.736017
trainer/Policy Action Std                    0.593734
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     90000
expl/num paths total                      2250
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.873938
expl/Rewards Std                             0.663803
expl/Rewards Max                             1.57078
expl/Rewards Min                             0
expl/Returns Mean                           34.9575
expl/Returns Std                            13.018
expl/Returns Max                            41.2913
expl/Returns Min                             0
expl/Actions Mean                            0.696295
expl/Actions Std                             0.602275
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        34.9575
expl/env_infos/final/reward_dist Mean        1.37953
expl/env_infos/final/reward_dist Std         0.509532
expl/env_infos/final/reward_dist Max         1.57078
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.00106215
expl/env_infos/initial/reward_dist Std       0.00290982
expl/env_infos/initial/reward_dist Max       0.0137097
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.873938
expl/env_infos/reward_dist Std               0.663803
expl/env_infos/reward_dist Max               1.57078
expl/env_infos/reward_dist Min               0
eval/num steps total                     18000
eval/num paths total                       450
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            1.01697
eval/Rewards Std                             0.613974
eval/Rewards Max                             1.5706
eval/Rewards Min                             0
eval/Returns Mean                           40.6787
eval/Returns Std                             0.739764
eval/Returns Max                            41.8138
eval/Returns Min                            39.4664
eval/Actions Mean                            0.73393
eval/Actions Std                             0.604343
eval/Actions Max                             1
eval/Actions Min                            -0.833947
eval/Num Paths                              10
eval/Average Returns                        40.6787
eval/env_infos/final/reward_dist Mean        1.56902
eval/env_infos/final/reward_dist Std         0.00164934
eval/env_infos/final/reward_dist Max         1.5706
eval/env_infos/final/reward_dist Min         1.56522
eval/env_infos/initial/reward_dist Mean      0.00307244
eval/env_infos/initial/reward_dist Std       0.00616142
eval/env_infos/initial/reward_dist Max       0.0163712
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              1.01697
eval/env_infos/reward_dist Std               0.613974
eval/env_infos/reward_dist Max               1.5706
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00578832
time/evaluation sampling (s)                 3.71923
time/exploration sampling (s)               17.2134
time/logging (s)                             0.00531058
time/saving (s)                              0.00244008
time/training (s)                            4.7283
time/epoch (s)                              25.6744
time/total (s)                            1106.27
Epoch                                       44
---------------------------------------  ---------------
2023-08-05 00:40:03.451647 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 45 finished
---------------------------------------  ---------------
epoch                                       45
replay_buffer/size                       92000
trainer/QF1 Loss                             0.14236
trainer/QF2 Loss                             0.145922
trainer/Policy Loss                        -20.2307
trainer/Q1 Predictions Mean                 19.366
trainer/Q1 Predictions Std                   8.11667
trainer/Q1 Predictions Max                  34.9958
trainer/Q1 Predictions Min                  -0.828234
trainer/Q2 Predictions Mean                 19.3665
trainer/Q2 Predictions Std                   8.11518
trainer/Q2 Predictions Max                  35.0271
trainer/Q2 Predictions Min                  -1.10134
trainer/Q Targets Mean                      19.3655
trainer/Q Targets Std                        8.12557
trainer/Q Targets Max                       35.2703
trainer/Q Targets Min                       -1.14876
trainer/Bellman Errors 1 Mean                0.14236
trainer/Bellman Errors 1 Std                 0.535512
trainer/Bellman Errors 1 Max                14.0464
trainer/Bellman Errors 1 Min                 5.37048e-08
trainer/Bellman Errors 2 Mean                0.145922
trainer/Bellman Errors 2 Std                 0.544245
trainer/Bellman Errors 2 Max                15.2285
trainer/Bellman Errors 2 Min                 4.45652e-11
trainer/Policy Action Mean                   0.733203
trainer/Policy Action Std                    0.600982
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     92000
expl/num paths total                      2300
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.742524
expl/Rewards Std                             0.684789
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           29.701
expl/Returns Std                            17.0875
expl/Returns Max                            40.9256
expl/Returns Min                             0
expl/Actions Mean                            0.691306
expl/Actions Std                             0.613743
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        29.701
expl/env_infos/final/reward_dist Mean        1.18602
expl/env_infos/final/reward_dist Std         0.667827
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.000729119
expl/env_infos/initial/reward_dist Std       0.00210995
expl/env_infos/initial/reward_dist Max       0.00991572
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.742524
expl/env_infos/reward_dist Std               0.684789
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     18400
eval/num paths total                       460
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            1.00446
eval/Rewards Std                             0.619509
eval/Rewards Max                             1.57073
eval/Rewards Min                             0
eval/Returns Mean                           40.1786
eval/Returns Std                             0.58671
eval/Returns Max                            41.5489
eval/Returns Min                            39.4882
eval/Actions Mean                            0.734772
eval/Actions Std                             0.603286
eval/Actions Max                             1
eval/Actions Min                            -0.835082
eval/Num Paths                              10
eval/Average Returns                        40.1786
eval/env_infos/final/reward_dist Mean        1.56884
eval/env_infos/final/reward_dist Std         0.00189687
eval/env_infos/final/reward_dist Max         1.57073
eval/env_infos/final/reward_dist Min         1.56548
eval/env_infos/initial/reward_dist Mean      0.000907769
eval/env_infos/initial/reward_dist Std       0.00272331
eval/env_infos/initial/reward_dist Max       0.00907769
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              1.00446
eval/env_infos/reward_dist Std               0.619509
eval/env_infos/reward_dist Max               1.57073
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00582157
time/evaluation sampling (s)                 3.55715
time/exploration sampling (s)               17.2943
time/logging (s)                             0.00528442
time/saving (s)                              0.00233485
time/training (s)                            4.28516
time/epoch (s)                              25.1501
time/total (s)                            1131.42
Epoch                                       45
---------------------------------------  ---------------
2023-08-05 00:40:29.013409 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 46 finished
---------------------------------------  ---------------
epoch                                       46
replay_buffer/size                       94000
trainer/QF1 Loss                             0.162229
trainer/QF2 Loss                             0.170854
trainer/Policy Loss                        -20.8879
trainer/Q1 Predictions Mean                 20.0907
trainer/Q1 Predictions Std                   8.1626
trainer/Q1 Predictions Max                  36.3277
trainer/Q1 Predictions Min                  -1.2272
trainer/Q2 Predictions Mean                 20.0954
trainer/Q2 Predictions Std                   8.16045
trainer/Q2 Predictions Max                  36.3265
trainer/Q2 Predictions Min                  -1.91528
trainer/Q Targets Mean                      20.0682
trainer/Q Targets Std                        8.18133
trainer/Q Targets Max                       36.1905
trainer/Q Targets Min                       -1.14075
trainer/Bellman Errors 1 Mean                0.162229
trainer/Bellman Errors 1 Std                 0.68542
trainer/Bellman Errors 1 Max                22.0146
trainer/Bellman Errors 1 Min                 1.45519e-11
trainer/Bellman Errors 2 Mean                0.170854
trainer/Bellman Errors 2 Std                 0.752753
trainer/Bellman Errors 2 Max                18.5119
trainer/Bellman Errors 2 Min                 3.63798e-12
trainer/Policy Action Mean                   0.727316
trainer/Policy Action Std                    0.614242
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     94000
expl/num paths total                      2350
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.758711
expl/Rewards Std                             0.68178
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           30.3484
expl/Returns Std                            16.5021
expl/Returns Max                            40.7173
expl/Returns Min                             0
expl/Actions Mean                            0.684142
expl/Actions Std                             0.629383
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        30.3484
expl/env_infos/final/reward_dist Mean        1.219
expl/env_infos/final/reward_dist Std         0.648358
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.00044283
expl/env_infos/initial/reward_dist Std       0.00138072
expl/env_infos/initial/reward_dist Max       0.00717788
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.758711
expl/env_infos/reward_dist Std               0.68178
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     18800
eval/num paths total                       470
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            1.00176
eval/Rewards Std                             0.619181
eval/Rewards Max                             1.57063
eval/Rewards Min                             0
eval/Returns Mean                           40.0704
eval/Returns Std                             0.519582
eval/Returns Max                            40.8676
eval/Returns Min                            39.189
eval/Actions Mean                            0.725497
eval/Actions Std                             0.623509
eval/Actions Max                             1
eval/Actions Min                            -0.859127
eval/Num Paths                              10
eval/Average Returns                        40.0704
eval/env_infos/final/reward_dist Mean        1.56897
eval/env_infos/final/reward_dist Std         0.00159313
eval/env_infos/final/reward_dist Max         1.57063
eval/env_infos/final/reward_dist Min         1.56491
eval/env_infos/initial/reward_dist Mean      0.000166225
eval/env_infos/initial/reward_dist Std       0.000498675
eval/env_infos/initial/reward_dist Max       0.00166225
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              1.00176
eval/env_infos/reward_dist Std               0.619181
eval/env_infos/reward_dist Max               1.57063
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00569207
time/evaluation sampling (s)                 3.74449
time/exploration sampling (s)               17.4204
time/logging (s)                             0.0052897
time/saving (s)                              0.00234915
time/training (s)                            4.38118
time/epoch (s)                              25.5594
time/total (s)                            1156.98
Epoch                                       46
---------------------------------------  ---------------
2023-08-05 00:40:54.652612 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 47 finished
---------------------------------------  ---------------
epoch                                       47
replay_buffer/size                       96000
trainer/QF1 Loss                             0.173447
trainer/QF2 Loss                             0.181326
trainer/Policy Loss                        -21.6275
trainer/Q1 Predictions Mean                 20.7828
trainer/Q1 Predictions Std                   8.48109
trainer/Q1 Predictions Max                  37.1915
trainer/Q1 Predictions Min                  -1.14631
trainer/Q2 Predictions Mean                 20.7684
trainer/Q2 Predictions Std                   8.47985
trainer/Q2 Predictions Max                  37.1962
trainer/Q2 Predictions Min                  -1.21634
trainer/Q Targets Mean                      20.7843
trainer/Q Targets Std                        8.49003
trainer/Q Targets Max                       37.7562
trainer/Q Targets Min                       -1.42392
trainer/Bellman Errors 1 Mean                0.173447
trainer/Bellman Errors 1 Std                 0.754001
trainer/Bellman Errors 1 Max                19.9511
trainer/Bellman Errors 1 Min                 1.6822e-08
trainer/Bellman Errors 2 Mean                0.181326
trainer/Bellman Errors 2 Std                 0.790368
trainer/Bellman Errors 2 Max                17.3705
trainer/Bellman Errors 2 Min                 1.45519e-11
trainer/Policy Action Mean                   0.720519
trainer/Policy Action Std                    0.629472
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     96000
expl/num paths total                      2400
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.924819
expl/Rewards Std                             0.638567
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           36.9928
expl/Returns Std                             8.00865
expl/Returns Max                            40.3399
expl/Returns Min                             0.0190306
expl/Actions Mean                            0.677277
expl/Actions Std                             0.644817
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        36.9928
expl/env_infos/final/reward_dist Mean        1.50457
expl/env_infos/final/reward_dist Std         0.307392
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.0019624
expl/env_infos/initial/reward_dist Std       0.00394903
expl/env_infos/initial/reward_dist Max       0.0162985
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.924819
expl/env_infos/reward_dist Std               0.638567
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     19200
eval/num paths total                       480
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.805636
eval/Rewards Std                             0.662339
eval/Rewards Max                             1.57074
eval/Rewards Min                             0
eval/Returns Mean                           32.2254
eval/Returns Std                            14.1575
eval/Returns Max                            40.0901
eval/Returns Min                             0.0230574
eval/Actions Mean                            0.704344
eval/Actions Std                             0.669386
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        32.2254
eval/env_infos/final/reward_dist Mean        1.3225
eval/env_infos/final/reward_dist Std         0.515418
eval/env_infos/final/reward_dist Max         1.57074
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0
eval/env_infos/initial/reward_dist Std       0
eval/env_infos/initial/reward_dist Max       0
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.805636
eval/env_infos/reward_dist Std               0.662339
eval/env_infos/reward_dist Max               1.57074
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00603221
time/evaluation sampling (s)                 3.60048
time/exploration sampling (s)               17.5494
time/logging (s)                             0.00742934
time/saving (s)                              0.00270117
time/training (s)                            4.4729
time/epoch (s)                              25.639
time/total (s)                            1182.62
Epoch                                       47
---------------------------------------  ---------------
2023-08-05 00:41:20.273742 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 48 finished
---------------------------------------  ---------------
epoch                                       48
replay_buffer/size                       98000
trainer/QF1 Loss                             0.156943
trainer/QF2 Loss                             0.167797
trainer/Policy Loss                        -21.6346
trainer/Q1 Predictions Mean                 20.833
trainer/Q1 Predictions Std                   8.73036
trainer/Q1 Predictions Max                  38.2722
trainer/Q1 Predictions Min                  -1.10524
trainer/Q2 Predictions Mean                 20.8339
trainer/Q2 Predictions Std                   8.72864
trainer/Q2 Predictions Max                  38.2767
trainer/Q2 Predictions Min                  -1.17227
trainer/Q Targets Mean                      20.8101
trainer/Q Targets Std                        8.73738
trainer/Q Targets Max                       38.8151
trainer/Q Targets Min                       -1.5774
trainer/Bellman Errors 1 Mean                0.156943
trainer/Bellman Errors 1 Std                 0.550568
trainer/Bellman Errors 1 Max                13.0805
trainer/Bellman Errors 1 Min                 3.27418e-09
trainer/Bellman Errors 2 Mean                0.167797
trainer/Bellman Errors 2 Std                 0.634682
trainer/Bellman Errors 2 Max                14.8088
trainer/Bellman Errors 2 Min                 4.45652e-09
trainer/Policy Action Mean                   0.684229
trainer/Policy Action Std                    0.615683
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     98000
expl/num paths total                      2450
expl/path length Mean                       40
expl/path length Std                         0
expl/path length Max                        40
expl/path length Min                        40
expl/Rewards Mean                            0.604244
expl/Rewards Std                             0.669715
expl/Rewards Max                             1.57079
expl/Rewards Min                             0
expl/Returns Mean                           24.1697
expl/Returns Std                            18.1186
expl/Returns Max                            39.5234
expl/Returns Min                             0
expl/Actions Mean                            0.65117
expl/Actions Std                             0.648919
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              50
expl/Average Returns                        24.1697
expl/env_infos/final/reward_dist Mean        1.00864
expl/env_infos/final/reward_dist Std         0.742527
expl/env_infos/final/reward_dist Max         1.57079
expl/env_infos/final/reward_dist Min         0
expl/env_infos/initial/reward_dist Mean      0.00030049
expl/env_infos/initial/reward_dist Std       0.00129824
expl/env_infos/initial/reward_dist Max       0.00758089
expl/env_infos/initial/reward_dist Min       0
expl/env_infos/reward_dist Mean              0.604244
expl/env_infos/reward_dist Std               0.669715
expl/env_infos/reward_dist Max               1.57079
expl/env_infos/reward_dist Min               0
eval/num steps total                     19600
eval/num paths total                       490
eval/path length Mean                       40
eval/path length Std                         0
eval/path length Max                        40
eval/path length Min                        40
eval/Rewards Mean                            0.780788
eval/Rewards Std                             0.675633
eval/Rewards Max                             1.57079
eval/Rewards Min                             0
eval/Returns Mean                           31.2315
eval/Returns Std                            15.6188
eval/Returns Max                            39.9001
eval/Returns Min                             0.00297972
eval/Actions Mean                            0.680978
eval/Actions Std                             0.648117
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                              10
eval/Average Returns                        31.2315
eval/env_infos/final/reward_dist Mean        1.25543
eval/env_infos/final/reward_dist Std         0.627718
eval/env_infos/final/reward_dist Max         1.57079
eval/env_infos/final/reward_dist Min         0
eval/env_infos/initial/reward_dist Mean      0.000684224
eval/env_infos/initial/reward_dist Std       0.00192848
eval/env_infos/initial/reward_dist Max       0.00645952
eval/env_infos/initial/reward_dist Min       0
eval/env_infos/reward_dist Mean              0.780788
eval/env_infos/reward_dist Std               0.675633
eval/env_infos/reward_dist Max               1.57079
eval/env_infos/reward_dist Min               0
time/data storing (s)                        0.00582266
time/evaluation sampling (s)                 4.20166
time/exploration sampling (s)               17.4473
time/logging (s)                             0.00527949
time/saving (s)                              0.0023509
time/training (s)                            3.95272
time/epoch (s)                              25.6151
time/total (s)                            1208.24
Epoch                                       48
---------------------------------------  ---------------
2023-08-05 00:41:46.141402 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 49 finished
---------------------------------------  ----------------
epoch                                        49
replay_buffer/size                       100000
trainer/QF1 Loss                              0.164203
trainer/QF2 Loss                              0.175638
trainer/Policy Loss                         -22.1323
trainer/Q1 Predictions Mean                  21.3415
trainer/Q1 Predictions Std                    8.88837
trainer/Q1 Predictions Max                   39.3839
trainer/Q1 Predictions Min                   -1.18908
trainer/Q2 Predictions Mean                  21.3363
trainer/Q2 Predictions Std                    8.88457
trainer/Q2 Predictions Max                   39.3767
trainer/Q2 Predictions Min                   -1.16436
trainer/Q Targets Mean                       21.3497
trainer/Q Targets Std                         8.88813
trainer/Q Targets Max                        39.4277
trainer/Q Targets Min                        -1.48983
trainer/Bellman Errors 1 Mean                 0.164203
trainer/Bellman Errors 1 Std                  0.535288
trainer/Bellman Errors 1 Max                  9.12875
trainer/Bellman Errors 1 Min                  2.94676e-10
trainer/Bellman Errors 2 Mean                 0.175638
trainer/Bellman Errors 2 Std                  0.620808
trainer/Bellman Errors 2 Max                 10.4038
trainer/Bellman Errors 2 Min                  2.32831e-10
trainer/Policy Action Mean                    0.673316
trainer/Policy Action Std                     0.648531
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     100000
expl/num paths total                       2500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.744471
expl/Rewards Std                              0.665879
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            29.7788
expl/Returns Std                             15.1389
expl/Returns Max                             39.3074
expl/Returns Min                              0
expl/Actions Mean                             0.647391
expl/Actions Std                              0.658647
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.7788
expl/env_infos/final/reward_dist Mean         1.25347
expl/env_infos/final/reward_dist Std          0.626761
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00112723
expl/env_infos/initial/reward_dist Std        0.00227368
expl/env_infos/initial/reward_dist Max        0.00797969
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.744471
expl/env_infos/reward_dist Std                0.665879
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      20000
eval/num paths total                        500
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.93322
eval/Rewards Std                              0.613906
eval/Rewards Max                              1.57071
eval/Rewards Min                              0
eval/Returns Mean                            37.3288
eval/Returns Std                              3.33923
eval/Returns Max                             39.6772
eval/Returns Min                             27.5396
eval/Actions Mean                             0.675422
eval/Actions Std                              0.667617
eval/Actions Max                              1
eval/Actions Min                             -0.9999
eval/Num Paths                               10
eval/Average Returns                         37.3288
eval/env_infos/final/reward_dist Mean         1.56126
eval/env_infos/final/reward_dist Std          0.0241697
eval/env_infos/final/reward_dist Max          1.57071
eval/env_infos/final/reward_dist Min          1.4888
eval/env_infos/initial/reward_dist Mean       0.00185416
eval/env_infos/initial/reward_dist Std        0.00415615
eval/env_infos/initial/reward_dist Max        0.0134672
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.93322
eval/env_infos/reward_dist Std                0.613906
eval/env_infos/reward_dist Max                1.57071
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00582851
time/evaluation sampling (s)                  4.22196
time/exploration sampling (s)                17.2543
time/logging (s)                              0.00529654
time/saving (s)                               0.00236093
time/training (s)                             4.37537
time/epoch (s)                               25.8651
time/total (s)                             1234.11
Epoch                                        49
---------------------------------------  ----------------
2023-08-05 00:42:12.090272 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 50 finished
---------------------------------------  ----------------
epoch                                        50
replay_buffer/size                       102000
trainer/QF1 Loss                              0.185591
trainer/QF2 Loss                              0.199871
trainer/Policy Loss                         -22.5712
trainer/Q1 Predictions Mean                  21.796
trainer/Q1 Predictions Std                    8.93156
trainer/Q1 Predictions Max                   39.7295
trainer/Q1 Predictions Min                   -1.23192
trainer/Q2 Predictions Mean                  21.7948
trainer/Q2 Predictions Std                    8.93218
trainer/Q2 Predictions Max                   39.7053
trainer/Q2 Predictions Min                   -1.41225
trainer/Q Targets Mean                       21.8035
trainer/Q Targets Std                         8.942
trainer/Q Targets Max                        40.2834
trainer/Q Targets Min                        -1.85249
trainer/Bellman Errors 1 Mean                 0.185591
trainer/Bellman Errors 1 Std                  0.551572
trainer/Bellman Errors 1 Max                 14.7924
trainer/Bellman Errors 1 Min                  3.63798e-12
trainer/Bellman Errors 2 Mean                 0.199871
trainer/Bellman Errors 2 Std                  0.654127
trainer/Bellman Errors 2 Max                 15.9178
trainer/Bellman Errors 2 Min                  7.69796e-09
trainer/Policy Action Mean                    0.661911
trainer/Policy Action Std                     0.649278
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     102000
expl/num paths total                       2550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.856769
expl/Rewards Std                              0.651351
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            34.2708
expl/Returns Std                             11.5038
expl/Returns Max                             39.802
expl/Returns Min                              0.0165721
expl/Actions Mean                             0.607068
expl/Actions Std                              0.647842
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         34.2708
expl/env_infos/final/reward_dist Mean         1.4108
expl/env_infos/final/reward_dist Std          0.47038
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00151255
expl/env_infos/initial/reward_dist Std        0.00371047
expl/env_infos/initial/reward_dist Max        0.0149123
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.856769
expl/env_infos/reward_dist Std                0.651351
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      20400
eval/num paths total                        510
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.758819
eval/Rewards Std                              0.669087
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            30.3527
eval/Returns Std                             15.2189
eval/Returns Max                             39.6261
eval/Returns Min                              0.0330275
eval/Actions Mean                             0.63348
eval/Actions Std                              0.672214
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.3527
eval/env_infos/final/reward_dist Mean         1.25388
eval/env_infos/final/reward_dist Std          0.626944
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00235618
eval/env_infos/initial/reward_dist Std        0.0056501
eval/env_infos/initial/reward_dist Max        0.0187513
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.758819
eval/env_infos/reward_dist Std                0.669087
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595464
time/evaluation sampling (s)                  4.24836
time/exploration sampling (s)                17.1325
time/logging (s)                              0.00546146
time/saving (s)                               0.00232832
time/training (s)                             4.5521
time/epoch (s)                               25.9467
time/total (s)                             1260.05
Epoch                                        50
---------------------------------------  ----------------
2023-08-05 00:42:37.501491 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 51 finished
---------------------------------------  ----------------
epoch                                        51
replay_buffer/size                       104000
trainer/QF1 Loss                              0.189441
trainer/QF2 Loss                              0.20444
trainer/Policy Loss                         -22.3053
trainer/Q1 Predictions Mean                  21.5092
trainer/Q1 Predictions Std                    9.09321
trainer/Q1 Predictions Max                   40.2554
trainer/Q1 Predictions Min                   -1.4002
trainer/Q2 Predictions Mean                  21.4967
trainer/Q2 Predictions Std                    9.0868
trainer/Q2 Predictions Max                   40.181
trainer/Q2 Predictions Min                   -1.62418
trainer/Q Targets Mean                       21.5061
trainer/Q Targets Std                         9.11211
trainer/Q Targets Max                        40.1872
trainer/Q Targets Min                        -1.76419
trainer/Bellman Errors 1 Mean                 0.189441
trainer/Bellman Errors 1 Std                  0.596668
trainer/Bellman Errors 1 Max                 17.0411
trainer/Bellman Errors 1 Min                  1.53705e-08
trainer/Bellman Errors 2 Mean                 0.20444
trainer/Bellman Errors 2 Std                  0.717892
trainer/Bellman Errors 2 Max                 17.5059
trainer/Bellman Errors 2 Min                  1.84173e-09
trainer/Policy Action Mean                    0.663481
trainer/Policy Action Std                     0.659402
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     104000
expl/num paths total                       2600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.776352
expl/Rewards Std                              0.663893
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            31.0541
expl/Returns Std                             14.5642
expl/Returns Max                             39.4646
expl/Returns Min                              0
expl/Actions Mean                             0.614942
expl/Actions Std                              0.657316
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.0541
expl/env_infos/final/reward_dist Mean         1.28694
expl/env_infos/final/reward_dist Std          0.602959
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00185613
expl/env_infos/initial/reward_dist Std        0.00387485
expl/env_infos/initial/reward_dist Max        0.0144425
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.776352
expl/env_infos/reward_dist Std                0.663893
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      20800
eval/num paths total                        520
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.955238
eval/Rewards Std                              0.614328
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            38.2095
eval/Returns Std                              0.630444
eval/Returns Max                             39.3645
eval/Returns Min                             37.2699
eval/Actions Mean                             0.63408
eval/Actions Std                              0.658702
eval/Actions Max                              1
eval/Actions Min                             -0.978859
eval/Num Paths                               10
eval/Average Returns                         38.2095
eval/env_infos/final/reward_dist Mean         1.56843
eval/env_infos/final/reward_dist Std          0.00314766
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          1.56179
eval/env_infos/initial/reward_dist Mean       0.00053439
eval/env_infos/initial/reward_dist Std        0.00160317
eval/env_infos/initial/reward_dist Max        0.0053439
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.955238
eval/env_infos/reward_dist Std                0.614328
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00581736
time/evaluation sampling (s)                  3.65589
time/exploration sampling (s)                17.1788
time/logging (s)                              0.00557157
time/saving (s)                               0.00241969
time/training (s)                             4.56019
time/epoch (s)                               25.4087
time/total (s)                             1285.46
Epoch                                        51
---------------------------------------  ----------------
2023-08-05 00:43:02.791101 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 52 finished
---------------------------------------  ----------------
epoch                                        52
replay_buffer/size                       106000
trainer/QF1 Loss                              0.225289
trainer/QF2 Loss                              0.235439
trainer/Policy Loss                         -22.7354
trainer/Q1 Predictions Mean                  21.9642
trainer/Q1 Predictions Std                    9.17843
trainer/Q1 Predictions Max                   40.4638
trainer/Q1 Predictions Min                   -1.76968
trainer/Q2 Predictions Mean                  21.9613
trainer/Q2 Predictions Std                    9.17417
trainer/Q2 Predictions Max                   40.281
trainer/Q2 Predictions Min                   -1.98778
trainer/Q Targets Mean                       21.9701
trainer/Q Targets Std                         9.20319
trainer/Q Targets Max                        40.9362
trainer/Q Targets Min                        -1.64398
trainer/Bellman Errors 1 Mean                 0.225289
trainer/Bellman Errors 1 Std                  1.22297
trainer/Bellman Errors 1 Max                 63.4213
trainer/Bellman Errors 1 Min                  9.47688e-09
trainer/Bellman Errors 2 Mean                 0.235439
trainer/Bellman Errors 2 Std                  1.24877
trainer/Bellman Errors 2 Max                 62.0745
trainer/Bellman Errors 2 Min                  1.57394e-07
trainer/Policy Action Mean                    0.658501
trainer/Policy Action Std                     0.657377
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     106000
expl/num paths total                       2650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.846108
expl/Rewards Std                              0.645225
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            33.8443
expl/Returns Std                             10.9005
expl/Returns Max                             38.9009
expl/Returns Min                              0
expl/Actions Mean                             0.613254
expl/Actions Std                              0.640918
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         33.8443
expl/env_infos/final/reward_dist Mean         1.42343
expl/env_infos/final/reward_dist Std          0.442744
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000211212
expl/env_infos/initial/reward_dist Std        0.000782548
expl/env_infos/initial/reward_dist Max        0.00411864
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.846108
expl/env_infos/reward_dist Std                0.645225
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      21200
eval/num paths total                        530
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.964841
eval/Rewards Std                              0.609007
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            38.5937
eval/Returns Std                              0.787894
eval/Returns Max                             39.6423
eval/Returns Min                             36.9663
eval/Actions Mean                             0.634612
eval/Actions Std                              0.645875
eval/Actions Max                              1
eval/Actions Min                             -0.979534
eval/Num Paths                               10
eval/Average Returns                         38.5937
eval/env_infos/final/reward_dist Mean         1.56908
eval/env_infos/final/reward_dist Std          0.00195606
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          1.56556
eval/env_infos/initial/reward_dist Mean       0.00282856
eval/env_infos/initial/reward_dist Std        0.0044724
eval/env_infos/initial/reward_dist Max        0.013664
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.964841
eval/env_infos/reward_dist Std                0.609007
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591207
time/evaluation sampling (s)                  3.59982
time/exploration sampling (s)                17.0575
time/logging (s)                              0.00539806
time/saving (s)                               0.00232378
time/training (s)                             4.61329
time/epoch (s)                               25.2842
time/total (s)                             1310.75
Epoch                                        52
---------------------------------------  ----------------
2023-08-05 00:43:28.810101 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 53 finished
---------------------------------------  ----------------
epoch                                        53
replay_buffer/size                       108000
trainer/QF1 Loss                              0.186146
trainer/QF2 Loss                              0.197548
trainer/Policy Loss                         -22.763
trainer/Q1 Predictions Mean                  21.9346
trainer/Q1 Predictions Std                    9.22143
trainer/Q1 Predictions Max                   40.5516
trainer/Q1 Predictions Min                   -1.78652
trainer/Q2 Predictions Mean                  21.9338
trainer/Q2 Predictions Std                    9.21666
trainer/Q2 Predictions Max                   40.5163
trainer/Q2 Predictions Min                   -1.93434
trainer/Q Targets Mean                       21.9365
trainer/Q Targets Std                         9.23055
trainer/Q Targets Max                        40.7265
trainer/Q Targets Min                        -1.62144
trainer/Bellman Errors 1 Mean                 0.186146
trainer/Bellman Errors 1 Std                  0.48449
trainer/Bellman Errors 1 Max                 12.5781
trainer/Bellman Errors 1 Min                  2.32831e-10
trainer/Bellman Errors 2 Mean                 0.197548
trainer/Bellman Errors 2 Std                  0.549509
trainer/Bellman Errors 2 Max                 12.3762
trainer/Bellman Errors 2 Min                  1.6822e-08
trainer/Policy Action Mean                    0.650398
trainer/Policy Action Std                     0.660183
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     108000
expl/num paths total                       2700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.916662
expl/Rewards Std                              0.623929
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            36.6665
expl/Returns Std                              5.30588
expl/Returns Max                             39.0173
expl/Returns Min                              0.0154435
expl/Actions Mean                             0.59991
expl/Actions Std                              0.623496
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         36.6665
expl/env_infos/final/reward_dist Mean         1.53786
expl/env_infos/final/reward_dist Std          0.219706
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000767948
expl/env_infos/initial/reward_dist Std        0.00213569
expl/env_infos/initial/reward_dist Max        0.0106909
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.916662
expl/env_infos/reward_dist Std                0.623929
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      21600
eval/num paths total                        540
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.757527
eval/Rewards Std                              0.667034
eval/Rewards Max                              1.57007
eval/Rewards Min                              0
eval/Returns Mean                            30.3011
eval/Returns Std                             15.1598
eval/Returns Max                             39.6513
eval/Returns Min                              0.0273861
eval/Actions Mean                             0.631242
eval/Actions Std                              0.653687
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.3011
eval/env_infos/final/reward_dist Mean         1.25416
eval/env_infos/final/reward_dist Std          0.627083
eval/env_infos/final/reward_dist Max          1.57007
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000689408
eval/env_infos/initial/reward_dist Std        0.00206823
eval/env_infos/initial/reward_dist Max        0.00689408
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.757527
eval/env_infos/reward_dist Std                0.667034
eval/env_infos/reward_dist Max                1.57007
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00597835
time/evaluation sampling (s)                  4.45493
time/exploration sampling (s)                17.2699
time/logging (s)                              0.00536071
time/saving (s)                               0.0023172
time/training (s)                             4.27781
time/epoch (s)                               26.0163
time/total (s)                             1336.77
Epoch                                        53
---------------------------------------  ----------------
2023-08-05 00:43:54.545706 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 54 finished
---------------------------------------  ----------------
epoch                                        54
replay_buffer/size                       110000
trainer/QF1 Loss                              0.206961
trainer/QF2 Loss                              0.235105
trainer/Policy Loss                         -22.539
trainer/Q1 Predictions Mean                  21.7256
trainer/Q1 Predictions Std                    9.23986
trainer/Q1 Predictions Max                   40.8236
trainer/Q1 Predictions Min                   -1.76228
trainer/Q2 Predictions Mean                  21.7148
trainer/Q2 Predictions Std                    9.23966
trainer/Q2 Predictions Max                   40.7784
trainer/Q2 Predictions Min                   -1.61459
trainer/Q Targets Mean                       21.7689
trainer/Q Targets Std                         9.25202
trainer/Q Targets Max                        40.7381
trainer/Q Targets Min                        -1.79844
trainer/Bellman Errors 1 Mean                 0.206961
trainer/Bellman Errors 1 Std                  0.598327
trainer/Bellman Errors 1 Max                 17.3645
trainer/Bellman Errors 1 Min                  1.78261e-10
trainer/Bellman Errors 2 Mean                 0.235105
trainer/Bellman Errors 2 Std                  0.78052
trainer/Bellman Errors 2 Max                 20.662
trainer/Bellman Errors 2 Min                  1.05138e-09
trainer/Policy Action Mean                    0.64189
trainer/Policy Action Std                     0.648575
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     110000
expl/num paths total                       2750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.845068
expl/Rewards Std                              0.648155
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            33.8027
expl/Returns Std                             11.2778
expl/Returns Max                             39.0789
expl/Returns Min                              0.000143297
expl/Actions Mean                             0.589678
expl/Actions Std                              0.615328
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         33.8027
expl/env_infos/final/reward_dist Mean         1.41263
expl/env_infos/final/reward_dist Std          0.470728
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000796312
expl/env_infos/initial/reward_dist Std        0.00252826
expl/env_infos/initial/reward_dist Max        0.013523
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.845068
expl/env_infos/reward_dist Std                0.648155
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      22000
eval/num paths total                        550
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.945696
eval/Rewards Std                              0.616302
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            37.8278
eval/Returns Std                              0.841676
eval/Returns Max                             39.1065
eval/Returns Min                             36.4862
eval/Actions Mean                             0.602054
eval/Actions Std                              0.61556
eval/Actions Max                              1
eval/Actions Min                             -0.987028
eval/Num Paths                               10
eval/Average Returns                         37.8278
eval/env_infos/final/reward_dist Mean         1.56809
eval/env_infos/final/reward_dist Std          0.00512897
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          1.5529
eval/env_infos/initial/reward_dist Mean       0.00201314
eval/env_infos/initial/reward_dist Std        0.00436147
eval/env_infos/initial/reward_dist Max        0.014367
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.945696
eval/env_infos/reward_dist Std                0.616302
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00571971
time/evaluation sampling (s)                  4.02516
time/exploration sampling (s)                17.2475
time/logging (s)                              0.00546017
time/saving (s)                               0.00235834
time/training (s)                             4.44696
time/epoch (s)                               25.7332
time/total (s)                             1362.51
Epoch                                        54
---------------------------------------  ----------------
2023-08-05 00:44:19.596985 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 55 finished
---------------------------------------  ----------------
epoch                                        55
replay_buffer/size                       112000
trainer/QF1 Loss                              0.232286
trainer/QF2 Loss                              0.250257
trainer/Policy Loss                         -22.3015
trainer/Q1 Predictions Mean                  21.5733
trainer/Q1 Predictions Std                    9.23765
trainer/Q1 Predictions Max                   41.2197
trainer/Q1 Predictions Min                   -1.91238
trainer/Q2 Predictions Mean                  21.5615
trainer/Q2 Predictions Std                    9.23504
trainer/Q2 Predictions Max                   41.148
trainer/Q2 Predictions Min                   -1.78688
trainer/Q Targets Mean                       21.5393
trainer/Q Targets Std                         9.25405
trainer/Q Targets Max                        41.6486
trainer/Q Targets Min                        -2.14091
trainer/Bellman Errors 1 Mean                 0.232286
trainer/Bellman Errors 1 Std                  0.877323
trainer/Bellman Errors 1 Max                 37.8468
trainer/Bellman Errors 1 Min                  3.93484e-08
trainer/Bellman Errors 2 Mean                 0.250257
trainer/Bellman Errors 2 Std                  0.806461
trainer/Bellman Errors 2 Max                 17.2721
trainer/Bellman Errors 2 Min                  3.66731e-09
trainer/Policy Action Mean                    0.639849
trainer/Policy Action Std                     0.642564
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     112000
expl/num paths total                       2800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.942366
expl/Rewards Std                              0.614203
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            37.6947
expl/Returns Std                              0.875638
expl/Returns Max                             39.675
expl/Returns Min                             36.0641
expl/Actions Mean                             0.575324
expl/Actions Std                              0.601961
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         37.6947
expl/env_infos/final/reward_dist Mean         1.56877
expl/env_infos/final/reward_dist Std          0.00298783
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          1.55132
expl/env_infos/initial/reward_dist Mean       0.0017041
expl/env_infos/initial/reward_dist Std        0.00400539
expl/env_infos/initial/reward_dist Max        0.0141513
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.942366
expl/env_infos/reward_dist Std                0.614203
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      22400
eval/num paths total                        560
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.851255
eval/Rewards Std                              0.651433
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            34.0502
eval/Returns Std                             11.3584
eval/Returns Max                             39.4104
eval/Returns Min                              0.0279601
eval/Actions Mean                             0.600449
eval/Actions Std                              0.62438
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         34.0502
eval/env_infos/final/reward_dist Mean         1.41142
eval/env_infos/final/reward_dist Std          0.470474
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00102222
eval/env_infos/initial/reward_dist Std        0.00306665
eval/env_infos/initial/reward_dist Max        0.0102222
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.851255
eval/env_infos/reward_dist Std                0.651433
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0057753
time/evaluation sampling (s)                  3.51074
time/exploration sampling (s)                17.0821
time/logging (s)                              0.00542959
time/saving (s)                               0.00234511
time/training (s)                             4.44212
time/epoch (s)                               25.0485
time/total (s)                             1387.56
Epoch                                        55
---------------------------------------  ----------------
2023-08-05 00:44:45.138959 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 56 finished
---------------------------------------  ----------------
epoch                                        56
replay_buffer/size                       114000
trainer/QF1 Loss                              0.297869
trainer/QF2 Loss                              0.31114
trainer/Policy Loss                         -22.4041
trainer/Q1 Predictions Mean                  21.5434
trainer/Q1 Predictions Std                    9.4167
trainer/Q1 Predictions Max                   41.6579
trainer/Q1 Predictions Min                   -1.98968
trainer/Q2 Predictions Mean                  21.5326
trainer/Q2 Predictions Std                    9.41209
trainer/Q2 Predictions Max                   41.5933
trainer/Q2 Predictions Min                   -1.73416
trainer/Q Targets Mean                       21.5429
trainer/Q Targets Std                         9.43713
trainer/Q Targets Max                        41.9975
trainer/Q Targets Min                        -1.85778
trainer/Bellman Errors 1 Mean                 0.297869
trainer/Bellman Errors 1 Std                  1.26723
trainer/Bellman Errors 1 Max                 51.1053
trainer/Bellman Errors 1 Min                  9.31323e-10
trainer/Bellman Errors 2 Mean                 0.31114
trainer/Bellman Errors 2 Std                  1.26564
trainer/Bellman Errors 2 Max                 46.1741
trainer/Bellman Errors 2 Min                  6.92817e-08
trainer/Policy Action Mean                    0.621409
trainer/Policy Action Std                     0.655494
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     114000
expl/num paths total                       2850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.101726
expl/Rewards Std                              0.247263
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                             4.06904
expl/Returns Std                              6.12218
expl/Returns Max                             27.551
expl/Returns Min                              0
expl/Actions Mean                             0.628481
expl/Actions Std                              0.693672
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          4.06904
expl/env_infos/final/reward_dist Mean         0.132239
expl/env_infos/final/reward_dist Std          0.419318
expl/env_infos/final/reward_dist Max          1.55692
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000856679
expl/env_infos/initial/reward_dist Std        0.00266785
expl/env_infos/initial/reward_dist Max        0.0125298
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.101726
expl/env_infos/reward_dist Std                0.247263
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      22800
eval/num paths total                        570
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.104789
eval/Rewards Std                              0.195953
eval/Rewards Max                              1.13734
eval/Rewards Min                              0
eval/Returns Mean                             4.19154
eval/Returns Std                              3.87543
eval/Returns Max                             13.4956
eval/Returns Min                              0
eval/Actions Mean                             0.659446
eval/Actions Std                              0.71521
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          4.19154
eval/env_infos/final/reward_dist Mean         0.194325
eval/env_infos/final/reward_dist Std          0.395652
eval/env_infos/final/reward_dist Max          1.13734
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00118354
eval/env_infos/initial/reward_dist Std        0.00355061
eval/env_infos/initial/reward_dist Max        0.0118354
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.104789
eval/env_infos/reward_dist Std                0.195953
eval/env_infos/reward_dist Max                1.13734
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00600786
time/evaluation sampling (s)                  3.66541
time/exploration sampling (s)                17.3715
time/logging (s)                              0.00543493
time/saving (s)                               0.0023072
time/training (s)                             4.48861
time/epoch (s)                               25.5392
time/total (s)                             1413.1
Epoch                                        56
---------------------------------------  ----------------
2023-08-05 00:45:10.375660 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 57 finished
---------------------------------------  ----------------
epoch                                        57
replay_buffer/size                       116000
trainer/QF1 Loss                              0.317401
trainer/QF2 Loss                              0.318318
trainer/Policy Loss                         -22.5739
trainer/Q1 Predictions Mean                  21.4097
trainer/Q1 Predictions Std                    9.8124
trainer/Q1 Predictions Max                   41.7278
trainer/Q1 Predictions Min                   -3.04373
trainer/Q2 Predictions Mean                  21.4167
trainer/Q2 Predictions Std                    9.81043
trainer/Q2 Predictions Max                   41.7601
trainer/Q2 Predictions Min                   -2.16521
trainer/Q Targets Mean                       21.4189
trainer/Q Targets Std                         9.85662
trainer/Q Targets Max                        42.034
trainer/Q Targets Min                        -1.88388
trainer/Bellman Errors 1 Mean                 0.317401
trainer/Bellman Errors 1 Std                  1.05622
trainer/Bellman Errors 1 Max                 32.7572
trainer/Bellman Errors 1 Min                  3.63798e-10
trainer/Bellman Errors 2 Mean                 0.318318
trainer/Bellman Errors 2 Std                  1.00862
trainer/Bellman Errors 2 Max                 24.8228
trainer/Bellman Errors 2 Min                  2.94676e-10
trainer/Policy Action Mean                    0.61017
trainer/Policy Action Std                     0.665437
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     116000
expl/num paths total                       2900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.0733962
expl/Rewards Std                              0.202412
expl/Rewards Max                              1.57008
expl/Rewards Min                              0
expl/Returns Mean                             2.93585
expl/Returns Std                              5.29029
expl/Returns Max                             23.8642
expl/Returns Min                              0
expl/Actions Mean                             0.630019
expl/Actions Std                              0.708078
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          2.93585
expl/env_infos/final/reward_dist Mean         0.130131
expl/env_infos/final/reward_dist Std          0.384085
expl/env_infos/final/reward_dist Max          1.56018
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00124296
expl/env_infos/initial/reward_dist Std        0.00324895
expl/env_infos/initial/reward_dist Max        0.013777
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.0733962
expl/env_infos/reward_dist Std                0.202412
expl/env_infos/reward_dist Max                1.57008
expl/env_infos/reward_dist Min                0
eval/num steps total                      23200
eval/num paths total                        580
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.0364564
eval/Rewards Std                              0.103035
eval/Rewards Max                              0.730727
eval/Rewards Min                              0
eval/Returns Mean                             1.45826
eval/Returns Std                              2.30572
eval/Returns Max                              8.10496
eval/Returns Min                              0
eval/Actions Mean                             0.656362
eval/Actions Std                              0.723584
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          1.45826
eval/env_infos/final/reward_dist Mean         0.073099
eval/env_infos/final/reward_dist Std          0.219209
eval/env_infos/final/reward_dist Max          0.730727
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00114747
eval/env_infos/initial/reward_dist Std        0.00215721
eval/env_infos/initial/reward_dist Max        0.00698787
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.0364564
eval/env_infos/reward_dist Std                0.103035
eval/env_infos/reward_dist Max                0.730727
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585985
time/evaluation sampling (s)                  3.33549
time/exploration sampling (s)                16.6842
time/logging (s)                              0.0074486
time/saving (s)                               0.003385
time/training (s)                             5.1998
time/epoch (s)                               25.2362
time/total (s)                             1438.34
Epoch                                        57
---------------------------------------  ----------------
2023-08-05 00:45:35.378250 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 58 finished
---------------------------------------  ----------------
epoch                                        58
replay_buffer/size                       118000
trainer/QF1 Loss                              0.39772
trainer/QF2 Loss                              0.397706
trainer/Policy Loss                         -22.0139
trainer/Q1 Predictions Mean                  21.0704
trainer/Q1 Predictions Std                   10.2852
trainer/Q1 Predictions Max                   43.6066
trainer/Q1 Predictions Min                   -2.19113
trainer/Q2 Predictions Mean                  21.0625
trainer/Q2 Predictions Std                   10.2888
trainer/Q2 Predictions Max                   43.4649
trainer/Q2 Predictions Min                   -2.01262
trainer/Q Targets Mean                       21.05
trainer/Q Targets Std                        10.3159
trainer/Q Targets Max                        44.4654
trainer/Q Targets Min                        -1.75392
trainer/Bellman Errors 1 Mean                 0.39772
trainer/Bellman Errors 1 Std                  1.76049
trainer/Bellman Errors 1 Max                 82.9754
trainer/Bellman Errors 1 Min                  2.94676e-10
trainer/Bellman Errors 2 Mean                 0.397707
trainer/Bellman Errors 2 Std                  1.74222
trainer/Bellman Errors 2 Max                 79.277
trainer/Bellman Errors 2 Min                  1.6822e-08
trainer/Policy Action Mean                    0.623989
trainer/Policy Action Std                     0.641519
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     118000
expl/num paths total                       2950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.0827822
expl/Rewards Std                              0.222466
expl/Rewards Max                              1.53155
expl/Rewards Min                              0
expl/Returns Mean                             3.31129
expl/Returns Std                              5.72037
expl/Returns Max                             32.1594
expl/Returns Min                              0
expl/Actions Mean                             0.631806
expl/Actions Std                              0.692055
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          3.31129
expl/env_infos/final/reward_dist Mean         0.0607
expl/env_infos/final/reward_dist Std          0.296565
expl/env_infos/final/reward_dist Max          1.53155
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000823695
expl/env_infos/initial/reward_dist Std        0.00297706
expl/env_infos/initial/reward_dist Max        0.0188209
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.0827822
expl/env_infos/reward_dist Std                0.222466
expl/env_infos/reward_dist Max                1.53155
expl/env_infos/reward_dist Min                0
eval/num steps total                      23600
eval/num paths total                        590
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.0444268
eval/Rewards Std                              0.145704
eval/Rewards Max                              1.02549
eval/Rewards Min                              0
eval/Returns Mean                             1.77707
eval/Returns Std                              3.08716
eval/Returns Max                             10.4279
eval/Returns Min                              0
eval/Actions Mean                             0.658929
eval/Actions Std                              0.722291
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          1.77707
eval/env_infos/final/reward_dist Mean         8.13887e-09
eval/env_infos/final/reward_dist Std          2.44166e-08
eval/env_infos/final/reward_dist Max          8.13887e-08
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.0444268
eval/env_infos/reward_dist Std                0.145704
eval/env_infos/reward_dist Max                1.02549
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594917
time/evaluation sampling (s)                  3.63046
time/exploration sampling (s)                16.8376
time/logging (s)                              0.00540148
time/saving (s)                               0.00234452
time/training (s)                             4.51437
time/epoch (s)                               24.9961
time/total (s)                             1463.34
Epoch                                        58
---------------------------------------  ----------------
2023-08-05 00:46:00.586497 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 59 finished
---------------------------------------  ----------------
epoch                                        59
replay_buffer/size                       120000
trainer/QF1 Loss                              0.400579
trainer/QF2 Loss                              0.378573
trainer/Policy Loss                         -21.9335
trainer/Q1 Predictions Mean                  20.9691
trainer/Q1 Predictions Std                   10.6766
trainer/Q1 Predictions Max                   44.3999
trainer/Q1 Predictions Min                   -2.52812
trainer/Q2 Predictions Mean                  20.9558
trainer/Q2 Predictions Std                   10.6958
trainer/Q2 Predictions Max                   44.372
trainer/Q2 Predictions Min                   -2.44326
trainer/Q Targets Mean                       20.9558
trainer/Q Targets Std                        10.726
trainer/Q Targets Max                        45.3227
trainer/Q Targets Min                        -2.22292
trainer/Bellman Errors 1 Mean                 0.400579
trainer/Bellman Errors 1 Std                  1.43356
trainer/Bellman Errors 1 Max                 33.0109
trainer/Bellman Errors 1 Min                  5.13012e-10
trainer/Bellman Errors 2 Mean                 0.378573
trainer/Bellman Errors 2 Std                  1.24836
trainer/Bellman Errors 2 Max                 32.2425
trainer/Bellman Errors 2 Min                  9.99464e-08
trainer/Policy Action Mean                    0.641938
trainer/Policy Action Std                     0.626726
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     120000
expl/num paths total                       3000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.115943
expl/Rewards Std                              0.262884
expl/Rewards Max                              1.57015
expl/Rewards Min                              0
expl/Returns Mean                             4.63772
expl/Returns Std                              6.51112
expl/Returns Max                             32.9324
expl/Returns Min                              0
expl/Actions Mean                             0.632182
expl/Actions Std                              0.673433
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          4.63772
expl/env_infos/final/reward_dist Mean         0.1452
expl/env_infos/final/reward_dist Std          0.415054
expl/env_infos/final/reward_dist Max          1.56892
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00104088
expl/env_infos/initial/reward_dist Std        0.00371981
expl/env_infos/initial/reward_dist Max        0.0182445
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.115943
expl/env_infos/reward_dist Std                0.262884
expl/env_infos/reward_dist Max                1.57015
expl/env_infos/reward_dist Min                0
eval/num steps total                      24000
eval/num paths total                        600
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.0835167
eval/Rewards Std                              0.222481
eval/Rewards Max                              1.5053
eval/Rewards Min                              0
eval/Returns Mean                             3.34067
eval/Returns Std                              5.22767
eval/Returns Max                             17.3497
eval/Returns Min                              0
eval/Actions Mean                             0.664439
eval/Actions Std                              0.713017
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          3.34067
eval/env_infos/final/reward_dist Mean         0.151017
eval/env_infos/final/reward_dist Std          0.451429
eval/env_infos/final/reward_dist Max          1.5053
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.0835167
eval/env_infos/reward_dist Std                0.222481
eval/env_infos/reward_dist Max                1.5053
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584473
time/evaluation sampling (s)                  3.61774
time/exploration sampling (s)                17.1625
time/logging (s)                              0.00539735
time/saving (s)                               0.00233043
time/training (s)                             4.41179
time/epoch (s)                               25.2056
time/total (s)                             1488.54
Epoch                                        59
---------------------------------------  ----------------
2023-08-05 00:46:25.275749 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 60 finished
---------------------------------------  ----------------
epoch                                        60
replay_buffer/size                       122000
trainer/QF1 Loss                              0.469672
trainer/QF2 Loss                              0.468836
trainer/Policy Loss                         -21.5962
trainer/Q1 Predictions Mean                  20.6067
trainer/Q1 Predictions Std                   11.2145
trainer/Q1 Predictions Max                   46.2922
trainer/Q1 Predictions Min                   -2.8579
trainer/Q2 Predictions Mean                  20.6053
trainer/Q2 Predictions Std                   11.2232
trainer/Q2 Predictions Max                   46.2435
trainer/Q2 Predictions Min                   -2.68735
trainer/Q Targets Mean                       20.6171
trainer/Q Targets Std                        11.2549
trainer/Q Targets Max                        46.994
trainer/Q Targets Min                        -2.56759
trainer/Bellman Errors 1 Mean                 0.469672
trainer/Bellman Errors 1 Std                  2.38531
trainer/Bellman Errors 1 Max                105.367
trainer/Bellman Errors 1 Min                  1.60435e-09
trainer/Bellman Errors 2 Mean                 0.468836
trainer/Bellman Errors 2 Std                  2.49075
trainer/Bellman Errors 2 Max                116.492
trainer/Bellman Errors 2 Min                  3.08068e-07
trainer/Policy Action Mean                    0.630416
trainer/Policy Action Std                     0.628636
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     122000
expl/num paths total                       3050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.112201
expl/Rewards Std                              0.26058
expl/Rewards Max                              1.5707
expl/Rewards Min                              0
expl/Returns Mean                             4.48804
expl/Returns Std                              6.41555
expl/Returns Max                             31.8916
expl/Returns Min                              0
expl/Actions Mean                             0.626226
expl/Actions Std                              0.66759
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          4.48804
expl/env_infos/final/reward_dist Mean         0.0928415
expl/env_infos/final/reward_dist Std          0.36615
expl/env_infos/final/reward_dist Max          1.56719
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000884598
expl/env_infos/initial/reward_dist Std        0.00300975
expl/env_infos/initial/reward_dist Max        0.0165394
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.112201
expl/env_infos/reward_dist Std                0.26058
expl/env_infos/reward_dist Max                1.5707
expl/env_infos/reward_dist Min                0
eval/num steps total                      24400
eval/num paths total                        610
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.12395
eval/Rewards Std                              0.288337
eval/Rewards Max                              1.57018
eval/Rewards Min                              0
eval/Returns Mean                             4.95802
eval/Returns Std                              7.04812
eval/Returns Max                             24.9218
eval/Returns Min                              0.00210756
eval/Actions Mean                             0.657367
eval/Actions Std                              0.689447
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          4.95802
eval/env_infos/final/reward_dist Mean         0.156852
eval/env_infos/final/reward_dist Std          0.469763
eval/env_infos/final/reward_dist Max          1.56614
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.12395
eval/env_infos/reward_dist Std                0.288337
eval/env_infos/reward_dist Max                1.57018
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596263
time/evaluation sampling (s)                  3.50385
time/exploration sampling (s)                16.7872
time/logging (s)                              0.00541382
time/saving (s)                               0.00238833
time/training (s)                             4.38181
time/epoch (s)                               24.6866
time/total (s)                             1513.23
Epoch                                        60
---------------------------------------  ----------------
2023-08-05 00:46:50.828043 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 61 finished
---------------------------------------  ----------------
epoch                                        61
replay_buffer/size                       124000
trainer/QF1 Loss                              0.522629
trainer/QF2 Loss                              0.512879
trainer/Policy Loss                         -21.0115
trainer/Q1 Predictions Mean                  20.1074
trainer/Q1 Predictions Std                   11.5416
trainer/Q1 Predictions Max                   47.1906
trainer/Q1 Predictions Min                   -2.91317
trainer/Q2 Predictions Mean                  20.1126
trainer/Q2 Predictions Std                   11.5402
trainer/Q2 Predictions Max                   47.0413
trainer/Q2 Predictions Min                   -2.74311
trainer/Q Targets Mean                       20.0661
trainer/Q Targets Std                        11.5769
trainer/Q Targets Max                        46.6673
trainer/Q Targets Min                        -2.43899
trainer/Bellman Errors 1 Mean                 0.522629
trainer/Bellman Errors 1 Std                  2.02295
trainer/Bellman Errors 1 Max                 88.2405
trainer/Bellman Errors 1 Min                  6.24314e-08
trainer/Bellman Errors 2 Mean                 0.512879
trainer/Bellman Errors 2 Std                  2.04296
trainer/Bellman Errors 2 Max                 92.2569
trainer/Bellman Errors 2 Min                  3.28328e-10
trainer/Policy Action Mean                    0.623424
trainer/Policy Action Std                     0.639045
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     124000
expl/num paths total                       3100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.107569
expl/Rewards Std                              0.234603
expl/Rewards Max                              1.56911
expl/Rewards Min                              0
expl/Returns Mean                             4.30274
expl/Returns Std                              4.94667
expl/Returns Max                             21.744
expl/Returns Min                              0
expl/Actions Mean                             0.633772
expl/Actions Std                              0.665232
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          4.30274
expl/env_infos/final/reward_dist Mean         0.108308
expl/env_infos/final/reward_dist Std          0.370137
expl/env_infos/final/reward_dist Max          1.56831
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00108866
expl/env_infos/initial/reward_dist Std        0.00409862
expl/env_infos/initial/reward_dist Max        0.025134
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.107569
expl/env_infos/reward_dist Std                0.234603
expl/env_infos/reward_dist Max                1.56911
expl/env_infos/reward_dist Min                0
eval/num steps total                      24800
eval/num paths total                        620
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.0896138
eval/Rewards Std                              0.169396
eval/Rewards Max                              0.681813
eval/Rewards Min                              0
eval/Returns Mean                             3.58455
eval/Returns Std                              1.90908
eval/Returns Max                              5.69197
eval/Returns Min                              0.0012485
eval/Actions Mean                             0.654212
eval/Actions Std                              0.684842
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          3.58455
eval/env_infos/final/reward_dist Mean         0.0421303
eval/env_infos/final/reward_dist Std          0.126182
eval/env_infos/final/reward_dist Max          0.420677
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       1.09364e-05
eval/env_infos/initial/reward_dist Std        3.28093e-05
eval/env_infos/initial/reward_dist Max        0.000109364
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.0896138
eval/env_infos/reward_dist Std                0.169396
eval/env_infos/reward_dist Max                0.681813
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00597232
time/evaluation sampling (s)                  3.49727
time/exploration sampling (s)                17.041
time/logging (s)                              0.00539129
time/saving (s)                               0.00234385
time/training (s)                             4.9976
time/epoch (s)                               25.5496
time/total (s)                             1538.78
Epoch                                        61
---------------------------------------  ----------------
2023-08-05 00:47:16.833221 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 62 finished
---------------------------------------  ----------------
epoch                                        62
replay_buffer/size                       126000
trainer/QF1 Loss                              0.527416
trainer/QF2 Loss                              0.486801
trainer/Policy Loss                         -21.4337
trainer/Q1 Predictions Mean                  19.8906
trainer/Q1 Predictions Std                   11.4789
trainer/Q1 Predictions Max                   47.9355
trainer/Q1 Predictions Min                   -1.21854
trainer/Q2 Predictions Mean                  19.8819
trainer/Q2 Predictions Std                   11.4851
trainer/Q2 Predictions Max                   47.9242
trainer/Q2 Predictions Min                   -1.17943
trainer/Q Targets Mean                       19.8273
trainer/Q Targets Std                        11.4796
trainer/Q Targets Max                        48.054
trainer/Q Targets Min                        -1.93462
trainer/Bellman Errors 1 Mean                 0.527416
trainer/Bellman Errors 1 Std                  1.55772
trainer/Bellman Errors 1 Max                 30.9704
trainer/Bellman Errors 1 Min                  1.3411e-07
trainer/Bellman Errors 2 Mean                 0.486801
trainer/Bellman Errors 2 Std                  1.3123
trainer/Bellman Errors 2 Max                 28.4484
trainer/Bellman Errors 2 Min                  5.32636e-08
trainer/Policy Action Mean                    0.323387
trainer/Policy Action Std                     0.730947
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     126000
expl/num paths total                       3150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.160661
expl/Rewards Std                              0.200266
expl/Rewards Max                              0.744595
expl/Rewards Min                              0
expl/Returns Mean                             6.42643
expl/Returns Std                              0.870039
expl/Returns Max                              8.65887
expl/Returns Min                              4.65293
expl/Actions Mean                             0.337327
expl/Actions Std                              0.720429
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          6.42643
expl/env_infos/final/reward_dist Mean         1.69019e-08
expl/env_infos/final/reward_dist Std          2.87687e-08
expl/env_infos/final/reward_dist Max          8.75918e-08
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000348071
expl/env_infos/initial/reward_dist Std        0.000760262
expl/env_infos/initial/reward_dist Max        0.00270752
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.160661
expl/env_infos/reward_dist Std                0.200266
expl/env_infos/reward_dist Max                0.744595
expl/env_infos/reward_dist Min                0
eval/num steps total                      25200
eval/num paths total                        630
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.163698
eval/Rewards Std                              0.199885
eval/Rewards Max                              0.663914
eval/Rewards Min                              0
eval/Returns Mean                             6.54791
eval/Returns Std                              0.565131
eval/Returns Max                              7.1096
eval/Returns Min                              5.28978
eval/Actions Mean                             0.343319
eval/Actions Std                              0.732189
eval/Actions Max                              1
eval/Actions Min                             -0.986811
eval/Num Paths                               10
eval/Average Returns                          6.54791
eval/env_infos/final/reward_dist Mean         5.57568e-09
eval/env_infos/final/reward_dist Std          1.6727e-08
eval/env_infos/final/reward_dist Max          5.57568e-08
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.163698
eval/env_infos/reward_dist Std                0.199885
eval/env_infos/reward_dist Max                0.663914
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00578325
time/evaluation sampling (s)                  3.82013
time/exploration sampling (s)                17.5484
time/logging (s)                              0.00548661
time/saving (s)                               0.00243876
time/training (s)                             4.62019
time/epoch (s)                               26.0024
time/total (s)                             1564.79
Epoch                                        62
---------------------------------------  ----------------
2023-08-05 00:47:42.775167 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 63 finished
---------------------------------------  ----------------
epoch                                        63
replay_buffer/size                       128000
trainer/QF1 Loss                              0.554837
trainer/QF2 Loss                              0.535868
trainer/Policy Loss                         -19.108
trainer/Q1 Predictions Mean                  18.4385
trainer/Q1 Predictions Std                   10.9857
trainer/Q1 Predictions Max                   47.0212
trainer/Q1 Predictions Min                   -0.64234
trainer/Q2 Predictions Mean                  18.434
trainer/Q2 Predictions Std                   10.9759
trainer/Q2 Predictions Max                   47.113
trainer/Q2 Predictions Min                   -0.644046
trainer/Q Targets Mean                       18.4534
trainer/Q Targets Std                        10.984
trainer/Q Targets Max                        47.342
trainer/Q Targets Min                        -0.468933
trainer/Bellman Errors 1 Mean                 0.554837
trainer/Bellman Errors 1 Std                  2.25625
trainer/Bellman Errors 1 Max                100.75
trainer/Bellman Errors 1 Min                  3.02919e-08
trainer/Bellman Errors 2 Mean                 0.535868
trainer/Bellman Errors 2 Std                  1.90685
trainer/Bellman Errors 2 Max                 66.5823
trainer/Bellman Errors 2 Min                  3.27418e-11
trainer/Policy Action Mean                    0.430667
trainer/Policy Action Std                     0.709952
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     128000
expl/num paths total                       3200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.103078
expl/Rewards Std                              0.188834
expl/Rewards Max                              0.745356
expl/Rewards Min                              0
expl/Returns Mean                             4.12311
expl/Returns Std                              2.65819
expl/Returns Max                              7.44883
expl/Returns Min                              0
expl/Actions Mean                             0.348337
expl/Actions Std                              0.74554
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          4.12311
expl/env_infos/final/reward_dist Mean         7.47348e-09
expl/env_infos/final/reward_dist Std          2.21049e-08
expl/env_infos/final/reward_dist Max          8.77656e-08
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       5.63568e-05
expl/env_infos/initial/reward_dist Std        0.000392504
expl/env_infos/initial/reward_dist Max        0.00280385
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.103078
expl/env_infos/reward_dist Std                0.188834
expl/env_infos/reward_dist Max                0.745356
expl/env_infos/reward_dist Min                0
eval/num steps total                      25600
eval/num paths total                        640
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.0636887
eval/Rewards Std                              0.158865
eval/Rewards Max                              0.722298
eval/Rewards Min                              0
eval/Returns Mean                             2.54755
eval/Returns Std                              3.13779
eval/Returns Max                              7.40868
eval/Returns Min                              0
eval/Actions Mean                             0.310003
eval/Actions Std                              0.783488
eval/Actions Max                              1
eval/Actions Min                             -0.995564
eval/Num Paths                               10
eval/Average Returns                          2.54755
eval/env_infos/final/reward_dist Mean         1.45912e-08
eval/env_infos/final/reward_dist Std          2.92453e-08
eval/env_infos/final/reward_dist Max          7.72462e-08
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.0636887
eval/env_infos/reward_dist Std                0.158865
eval/env_infos/reward_dist Max                0.722298
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00597117
time/evaluation sampling (s)                  4.17576
time/exploration sampling (s)                17.2663
time/logging (s)                              0.00543354
time/saving (s)                               0.00235169
time/training (s)                             4.48329
time/epoch (s)                               25.9391
time/total (s)                             1590.73
Epoch                                        63
---------------------------------------  ----------------
2023-08-05 00:48:08.108788 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 64 finished
---------------------------------------  ----------------
epoch                                        64
replay_buffer/size                       130000
trainer/QF1 Loss                              0.571815
trainer/QF2 Loss                              0.562084
trainer/Policy Loss                         -19.2832
trainer/Q1 Predictions Mean                  18.0669
trainer/Q1 Predictions Std                   10.9948
trainer/Q1 Predictions Max                   46.2517
trainer/Q1 Predictions Min                   -0.190178
trainer/Q2 Predictions Mean                  18.0589
trainer/Q2 Predictions Std                   10.9951
trainer/Q2 Predictions Max                   46.1487
trainer/Q2 Predictions Min                   -0.194406
trainer/Q Targets Mean                       18.0611
trainer/Q Targets Std                        11.023
trainer/Q Targets Max                        46.3395
trainer/Q Targets Min                        -0.921349
trainer/Bellman Errors 1 Mean                 0.571815
trainer/Bellman Errors 1 Std                  2.07749
trainer/Bellman Errors 1 Max                 66.5165
trainer/Bellman Errors 1 Min                  5.0141e-09
trainer/Bellman Errors 2 Mean                 0.562084
trainer/Bellman Errors 2 Std                  2.02408
trainer/Bellman Errors 2 Max                 56.3139
trainer/Bellman Errors 2 Min                  2.75359e-08
trainer/Policy Action Mean                    0.526015
trainer/Policy Action Std                     0.714028
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     130000
expl/num paths total                       3250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.210942
expl/Rewards Std                              0.379202
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                             8.43766
expl/Returns Std                              8.61041
expl/Returns Max                             37.2986
expl/Returns Min                              0
expl/Actions Mean                             0.50957
expl/Actions Std                              0.696707
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.43766
expl/env_infos/final/reward_dist Mean         0.0945476
expl/env_infos/final/reward_dist Std          0.372832
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00125692
expl/env_infos/initial/reward_dist Std        0.00344827
expl/env_infos/initial/reward_dist Max        0.0140766
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.210942
expl/env_infos/reward_dist Std                0.379202
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      26000
eval/num paths total                        650
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.220374
eval/Rewards Std                              0.386324
eval/Rewards Max                              1.37116
eval/Rewards Min                              0
eval/Returns Mean                             8.81498
eval/Returns Std                              9.12337
eval/Returns Max                             30.8661
eval/Returns Min                              0
eval/Actions Mean                             0.546468
eval/Actions Std                              0.696199
eval/Actions Max                              1
eval/Actions Min                             -0.999991
eval/Num Paths                               10
eval/Average Returns                          8.81498
eval/env_infos/final/reward_dist Mean         0.137415
eval/env_infos/final/reward_dist Std          0.411249
eval/env_infos/final/reward_dist Max          1.37116
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00204319
eval/env_infos/initial/reward_dist Std        0.00458783
eval/env_infos/initial/reward_dist Max        0.0148795
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.220374
eval/env_infos/reward_dist Std                0.386324
eval/env_infos/reward_dist Max                1.37116
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.005841
time/evaluation sampling (s)                  3.56555
time/exploration sampling (s)                17.3609
time/logging (s)                              0.00542081
time/saving (s)                               0.00236758
time/training (s)                             4.38995
time/epoch (s)                               25.33
time/total (s)                             1616.06
Epoch                                        64
---------------------------------------  ----------------
2023-08-05 00:48:33.817726 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 65 finished
---------------------------------------  ----------------
epoch                                        65
replay_buffer/size                       132000
trainer/QF1 Loss                              0.554029
trainer/QF2 Loss                              0.543604
trainer/Policy Loss                         -18.4815
trainer/Q1 Predictions Mean                  17.3521
trainer/Q1 Predictions Std                   11.058
trainer/Q1 Predictions Max                   47.1437
trainer/Q1 Predictions Min                    0.00466638
trainer/Q2 Predictions Mean                  17.3459
trainer/Q2 Predictions Std                   11.0601
trainer/Q2 Predictions Max                   47.0333
trainer/Q2 Predictions Min                    0.0942307
trainer/Q Targets Mean                       17.3733
trainer/Q Targets Std                        11.1016
trainer/Q Targets Max                        47.4253
trainer/Q Targets Min                        -0.0276975
trainer/Bellman Errors 1 Mean                 0.554029
trainer/Bellman Errors 1 Std                  1.55325
trainer/Bellman Errors 1 Max                 39.0887
trainer/Bellman Errors 1 Min                  7.64885e-10
trainer/Bellman Errors 2 Mean                 0.543604
trainer/Bellman Errors 2 Std                  1.50472
trainer/Bellman Errors 2 Max                 42.0144
trainer/Bellman Errors 2 Min                  3.49392e-08
trainer/Policy Action Mean                    0.53777
trainer/Policy Action Std                     0.723001
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     132000
expl/num paths total                       3300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.423736
expl/Rewards Std                              0.55903
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            16.9494
expl/Returns Std                             14.4054
expl/Returns Max                             40.1754
expl/Returns Min                              0
expl/Actions Mean                             0.559472
expl/Actions Std                              0.68308
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.9494
expl/env_infos/final/reward_dist Mean         0.528668
expl/env_infos/final/reward_dist Std          0.7368
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00107255
expl/env_infos/initial/reward_dist Std        0.00305785
expl/env_infos/initial/reward_dist Max        0.0145289
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.423736
expl/env_infos/reward_dist Std                0.55903
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      26400
eval/num paths total                        660
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.292027
eval/Rewards Std                              0.452655
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            11.6811
eval/Returns Std                             10.56
eval/Returns Max                             37.9818
eval/Returns Min                              0.000365174
eval/Actions Mean                             0.574371
eval/Actions Std                              0.707271
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.6811
eval/env_infos/final/reward_dist Mean         0.157195
eval/env_infos/final/reward_dist Std          0.471191
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000434856
eval/env_infos/initial/reward_dist Std        0.00130457
eval/env_infos/initial/reward_dist Max        0.00434856
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.292027
eval/env_infos/reward_dist Std                0.452655
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00580927
time/evaluation sampling (s)                  3.56472
time/exploration sampling (s)                17.5407
time/logging (s)                              0.00544401
time/saving (s)                               0.00240536
time/training (s)                             4.58713
time/epoch (s)                               25.7062
time/total (s)                             1641.77
Epoch                                        65
---------------------------------------  ----------------
2023-08-05 00:48:59.114953 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 66 finished
---------------------------------------  ----------------
epoch                                        66
replay_buffer/size                       134000
trainer/QF1 Loss                              0.630251
trainer/QF2 Loss                              0.640928
trainer/Policy Loss                         -17.9033
trainer/Q1 Predictions Mean                  16.8262
trainer/Q1 Predictions Std                   10.9679
trainer/Q1 Predictions Max                   47.5074
trainer/Q1 Predictions Min                   -0.22024
trainer/Q2 Predictions Mean                  16.8139
trainer/Q2 Predictions Std                   10.9744
trainer/Q2 Predictions Max                   47.3054
trainer/Q2 Predictions Min                   -0.521694
trainer/Q Targets Mean                       16.7829
trainer/Q Targets Std                        10.9888
trainer/Q Targets Max                        47.3632
trainer/Q Targets Min                         0.0506231
trainer/Bellman Errors 1 Mean                 0.630251
trainer/Bellman Errors 1 Std                  2.44644
trainer/Bellman Errors 1 Max                 88.2606
trainer/Bellman Errors 1 Min                  3.63798e-08
trainer/Bellman Errors 2 Mean                 0.640928
trainer/Bellman Errors 2 Std                  2.8319
trainer/Bellman Errors 2 Max                124.397
trainer/Bellman Errors 2 Min                  3.11252e-09
trainer/Policy Action Mean                    0.53291
trainer/Policy Action Std                     0.726656
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     134000
expl/num paths total                       3350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.806111
expl/Rewards Std                              0.627305
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            32.2444
expl/Returns Std                             11.2703
expl/Returns Max                             39.1087
expl/Returns Min                              0
expl/Actions Mean                             0.578309
expl/Actions Std                              0.658541
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.2444
expl/env_infos/final/reward_dist Mean         1.26554
expl/env_infos/final/reward_dist Std          0.596107
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000790323
expl/env_infos/initial/reward_dist Std        0.00229938
expl/env_infos/initial/reward_dist Max        0.011468
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.806111
expl/env_infos/reward_dist Std                0.627305
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      26800
eval/num paths total                        670
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.932174
eval/Rewards Std                              0.599781
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            37.2869
eval/Returns Std                              1.22114
eval/Returns Max                             39.1045
eval/Returns Min                             34.7252
eval/Actions Mean                             0.608113
eval/Actions Std                              0.657552
eval/Actions Max                              1
eval/Actions Min                             -0.998874
eval/Num Paths                               10
eval/Average Returns                         37.2869
eval/env_infos/final/reward_dist Mean         1.54783
eval/env_infos/final/reward_dist Std          0.0640227
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          1.35582
eval/env_infos/initial/reward_dist Mean       0.000366961
eval/env_infos/initial/reward_dist Std        0.00110088
eval/env_infos/initial/reward_dist Max        0.00366961
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.932174
eval/env_infos/reward_dist Std                0.599781
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00586409
time/evaluation sampling (s)                  3.52806
time/exploration sampling (s)                17.1946
time/logging (s)                              0.00464734
time/saving (s)                               0.0115889
time/training (s)                             4.54793
time/epoch (s)                               25.2927
time/total (s)                             1667.07
Epoch                                        66
---------------------------------------  ----------------
2023-08-05 00:49:24.757541 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 67 finished
---------------------------------------  ----------------
epoch                                        67
replay_buffer/size                       136000
trainer/QF1 Loss                              0.680151
trainer/QF2 Loss                              0.670607
trainer/Policy Loss                         -17.6013
trainer/Q1 Predictions Mean                  16.448
trainer/Q1 Predictions Std                   10.7961
trainer/Q1 Predictions Max                   46.9754
trainer/Q1 Predictions Min                    1.16188
trainer/Q2 Predictions Mean                  16.4628
trainer/Q2 Predictions Std                   10.8154
trainer/Q2 Predictions Max                   47.2321
trainer/Q2 Predictions Min                    0.762599
trainer/Q Targets Mean                       16.4862
trainer/Q Targets Std                        10.851
trainer/Q Targets Max                        47.0992
trainer/Q Targets Min                         1.0556
trainer/Bellman Errors 1 Mean                 0.680151
trainer/Bellman Errors 1 Std                  2.26383
trainer/Bellman Errors 1 Max                 62.8445
trainer/Bellman Errors 1 Min                  1.53705e-08
trainer/Bellman Errors 2 Mean                 0.670607
trainer/Bellman Errors 2 Std                  2.24353
trainer/Bellman Errors 2 Max                 57.0618
trainer/Bellman Errors 2 Min                  6.41739e-09
trainer/Policy Action Mean                    0.519252
trainer/Policy Action Std                     0.735115
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     136000
expl/num paths total                       3400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.537766
expl/Rewards Std                              0.61875
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            21.5106
expl/Returns Std                             16.1257
expl/Returns Max                             41.0529
expl/Returns Min                              0
expl/Actions Mean                             0.540147
expl/Actions Std                              0.701001
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.5106
expl/env_infos/final/reward_dist Mean         0.793917
expl/env_infos/final/reward_dist Std          0.764928
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000830795
expl/env_infos/initial/reward_dist Std        0.00307785
expl/env_infos/initial/reward_dist Max        0.0197174
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.537766
expl/env_infos/reward_dist Std                0.61875
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      27200
eval/num paths total                        680
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.698968
eval/Rewards Std                              0.647604
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            27.9587
eval/Returns Std                             15.4967
eval/Returns Max                             39.5723
eval/Returns Min                              0
eval/Actions Mean                             0.607258
eval/Actions Std                              0.674345
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         27.9587
eval/env_infos/final/reward_dist Mean         1.07799
eval/env_infos/final/reward_dist Std          0.707988
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00112881
eval/env_infos/initial/reward_dist Std        0.00226643
eval/env_infos/initial/reward_dist Max        0.00609052
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.698968
eval/env_infos/reward_dist Std                0.647604
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00819594
time/evaluation sampling (s)                  3.59049
time/exploration sampling (s)                17.3714
time/logging (s)                              0.00531588
time/saving (s)                               0.00235055
time/training (s)                             4.66276
time/epoch (s)                               25.6405
time/total (s)                             1692.71
Epoch                                        67
---------------------------------------  ----------------
2023-08-05 00:49:50.276556 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 68 finished
---------------------------------------  ----------------
epoch                                        68
replay_buffer/size                       138000
trainer/QF1 Loss                              0.662866
trainer/QF2 Loss                              0.677238
trainer/Policy Loss                         -17.4104
trainer/Q1 Predictions Mean                  16.269
trainer/Q1 Predictions Std                   10.5511
trainer/Q1 Predictions Max                   48.0023
trainer/Q1 Predictions Min                    1.00996
trainer/Q2 Predictions Mean                  16.262
trainer/Q2 Predictions Std                   10.5444
trainer/Q2 Predictions Max                   47.457
trainer/Q2 Predictions Min                    0.587297
trainer/Q Targets Mean                       16.2735
trainer/Q Targets Std                        10.5892
trainer/Q Targets Max                        48.4337
trainer/Q Targets Min                         0.869827
trainer/Bellman Errors 1 Mean                 0.662866
trainer/Bellman Errors 1 Std                  3.76646
trainer/Bellman Errors 1 Max                213.075
trainer/Bellman Errors 1 Min                  3.33532e-08
trainer/Bellman Errors 2 Mean                 0.677238
trainer/Bellman Errors 2 Std                  3.81042
trainer/Bellman Errors 2 Max                214.697
trainer/Bellman Errors 2 Min                  3.60978e-09
trainer/Policy Action Mean                    0.524164
trainer/Policy Action Std                     0.743808
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     138000
expl/num paths total                       3450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.747755
expl/Rewards Std                              0.644969
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            29.9102
expl/Returns Std                             14.1743
expl/Returns Max                             39.7935
expl/Returns Min                              0
expl/Actions Mean                             0.56216
expl/Actions Std                              0.687827
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.9102
expl/env_infos/final/reward_dist Mean         1.17692
expl/env_infos/final/reward_dist Std          0.663465
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00132187
expl/env_infos/initial/reward_dist Std        0.00269646
expl/env_infos/initial/reward_dist Max        0.0112387
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.747755
expl/env_infos/reward_dist Std                0.644969
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      27600
eval/num paths total                        690
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.929689
eval/Rewards Std                              0.597697
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            37.1875
eval/Returns Std                              1.6366
eval/Returns Max                             39.0771
eval/Returns Min                             34.1063
eval/Actions Mean                             0.61355
eval/Actions Std                              0.664512
eval/Actions Max                              1
eval/Actions Min                             -0.999997
eval/Num Paths                               10
eval/Average Returns                         37.1875
eval/env_infos/final/reward_dist Mean         1.52575
eval/env_infos/final/reward_dist Std          0.0869812
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          1.33255
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.929689
eval/env_infos/reward_dist Std                0.597697
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00815187
time/evaluation sampling (s)                  3.3869
time/exploration sampling (s)                17.5592
time/logging (s)                              0.00531406
time/saving (s)                               0.0023643
time/training (s)                             4.5546
time/epoch (s)                               25.5166
time/total (s)                             1718.23
Epoch                                        68
---------------------------------------  ----------------
2023-08-05 00:50:15.615414 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 69 finished
---------------------------------------  ----------------
epoch                                        69
replay_buffer/size                       140000
trainer/QF1 Loss                              0.63947
trainer/QF2 Loss                              0.626605
trainer/Policy Loss                         -16.8782
trainer/Q1 Predictions Mean                  15.7724
trainer/Q1 Predictions Std                   10.1727
trainer/Q1 Predictions Max                   45.7509
trainer/Q1 Predictions Min                    0.144775
trainer/Q2 Predictions Mean                  15.7993
trainer/Q2 Predictions Std                   10.1777
trainer/Q2 Predictions Max                   45.8822
trainer/Q2 Predictions Min                   -0.222017
trainer/Q Targets Mean                       15.8492
trainer/Q Targets Std                        10.2315
trainer/Q Targets Max                        45.978
trainer/Q Targets Min                         0.113652
trainer/Bellman Errors 1 Mean                 0.63947
trainer/Bellman Errors 1 Std                  1.76826
trainer/Bellman Errors 1 Max                 48.0959
trainer/Bellman Errors 1 Min                  1.45519e-09
trainer/Bellman Errors 2 Mean                 0.626605
trainer/Bellman Errors 2 Std                  1.79056
trainer/Bellman Errors 2 Max                 48.7765
trainer/Bellman Errors 2 Min                  9.54751e-08
trainer/Policy Action Mean                    0.523143
trainer/Policy Action Std                     0.745147
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     140000
expl/num paths total                       3500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.870051
expl/Rewards Std                              0.633661
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            34.802
expl/Returns Std                             10.8793
expl/Returns Max                             42.6083
expl/Returns Min                              0
expl/Actions Mean                             0.588894
expl/Actions Std                              0.656543
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         34.802
expl/env_infos/final/reward_dist Mean         1.36733
expl/env_infos/final/reward_dist Std          0.507572
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00132104
expl/env_infos/initial/reward_dist Std        0.00282973
expl/env_infos/initial/reward_dist Max        0.0105543
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.870051
expl/env_infos/reward_dist Std                0.633661
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      28000
eval/num paths total                        700
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.724069
eval/Rewards Std                              0.629828
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            28.9628
eval/Returns Std                             14.2836
eval/Returns Max                             40.8796
eval/Returns Min                              0
eval/Actions Mean                             0.633966
eval/Actions Std                              0.646386
eval/Actions Max                              1
eval/Actions Min                             -0.999999
eval/Num Paths                               10
eval/Average Returns                         28.9628
eval/env_infos/final/reward_dist Mean         1.04979
eval/env_infos/final/reward_dist Std          0.693522
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00175372
eval/env_infos/initial/reward_dist Std        0.00330301
eval/env_infos/initial/reward_dist Max        0.0107637
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.724069
eval/env_infos/reward_dist Std                0.629828
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584166
time/evaluation sampling (s)                  3.43636
time/exploration sampling (s)                17.1996
time/logging (s)                              0.00541936
time/saving (s)                               0.00240289
time/training (s)                             4.68687
time/epoch (s)                               25.3365
time/total (s)                             1743.57
Epoch                                        69
---------------------------------------  ----------------
2023-08-05 00:50:41.576821 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 70 finished
---------------------------------------  ----------------
epoch                                        70
replay_buffer/size                       142000
trainer/QF1 Loss                              0.618664
trainer/QF2 Loss                              0.620153
trainer/Policy Loss                         -16.2055
trainer/Q1 Predictions Mean                  15.2428
trainer/Q1 Predictions Std                    9.54796
trainer/Q1 Predictions Max                   45.4284
trainer/Q1 Predictions Min                   -0.30953
trainer/Q2 Predictions Mean                  15.2466
trainer/Q2 Predictions Std                    9.54528
trainer/Q2 Predictions Max                   45.5019
trainer/Q2 Predictions Min                   -0.46068
trainer/Q Targets Mean                       15.273
trainer/Q Targets Std                         9.58318
trainer/Q Targets Max                        46.4125
trainer/Q Targets Min                        -0.215943
trainer/Bellman Errors 1 Mean                 0.618664
trainer/Bellman Errors 1 Std                  1.83586
trainer/Bellman Errors 1 Max                 52.5504
trainer/Bellman Errors 1 Min                  2.41221e-09
trainer/Bellman Errors 2 Mean                 0.620153
trainer/Bellman Errors 2 Std                  1.86127
trainer/Bellman Errors 2 Max                 54.8337
trainer/Bellman Errors 2 Min                  9.64883e-09
trainer/Policy Action Mean                    0.526189
trainer/Policy Action Std                     0.741959
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     142000
expl/num paths total                       3550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.604824
expl/Rewards Std                              0.638351
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            24.193
expl/Returns Std                             16.3358
expl/Returns Max                             42.5629
expl/Returns Min                              0
expl/Actions Mean                             0.582628
expl/Actions Std                              0.664776
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.193
expl/env_infos/final/reward_dist Mean         0.867629
expl/env_infos/final/reward_dist Std          0.770425
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00181299
expl/env_infos/initial/reward_dist Std        0.0037881
expl/env_infos/initial/reward_dist Max        0.014773
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.604824
expl/env_infos/reward_dist Std                0.638351
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      28400
eval/num paths total                        710
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.579
eval/Rewards Std                              0.65195
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            23.16
eval/Returns Std                             18.1473
eval/Returns Max                             43.7647
eval/Returns Min                              0
eval/Actions Mean                             0.497397
eval/Actions Std                              0.769628
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         23.16
eval/env_infos/final/reward_dist Mean         0.783491
eval/env_infos/final/reward_dist Std          0.783502
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00139902
eval/env_infos/initial/reward_dist Std        0.00371417
eval/env_infos/initial/reward_dist Max        0.0124568
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.579
eval/env_infos/reward_dist Std                0.65195
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593407
time/evaluation sampling (s)                  3.50585
time/exploration sampling (s)                17.7233
time/logging (s)                              0.00534769
time/saving (s)                               0.00242706
time/training (s)                             4.71602
time/epoch (s)                               25.9589
time/total (s)                             1769.53
Epoch                                        70
---------------------------------------  ----------------
2023-08-05 00:51:07.181026 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 71 finished
---------------------------------------  ----------------
epoch                                        71
replay_buffer/size                       144000
trainer/QF1 Loss                              0.614263
trainer/QF2 Loss                              0.62003
trainer/Policy Loss                         -16.4284
trainer/Q1 Predictions Mean                  15.5403
trainer/Q1 Predictions Std                    9.61131
trainer/Q1 Predictions Max                   45.472
trainer/Q1 Predictions Min                   -0.562096
trainer/Q2 Predictions Mean                  15.5363
trainer/Q2 Predictions Std                    9.60826
trainer/Q2 Predictions Max                   45.2058
trainer/Q2 Predictions Min                   -0.583639
trainer/Q Targets Mean                       15.4983
trainer/Q Targets Std                         9.61681
trainer/Q Targets Max                        44.6097
trainer/Q Targets Min                        -0.694407
trainer/Bellman Errors 1 Mean                 0.614263
trainer/Bellman Errors 1 Std                  1.94175
trainer/Bellman Errors 1 Max                 54.4729
trainer/Bellman Errors 1 Min                  1.46248e-07
trainer/Bellman Errors 2 Mean                 0.62003
trainer/Bellman Errors 2 Std                  1.97788
trainer/Bellman Errors 2 Max                 62.0091
trainer/Bellman Errors 2 Min                  9.09495e-09
trainer/Policy Action Mean                    0.530417
trainer/Policy Action Std                     0.73176
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     144000
expl/num paths total                       3600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.639075
expl/Rewards Std                              0.645637
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            25.563
expl/Returns Std                             16.5818
expl/Returns Max                             42.0803
expl/Returns Min                              0
expl/Actions Mean                             0.595732
expl/Actions Std                              0.643058
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.563
expl/env_infos/final/reward_dist Mean         0.901566
expl/env_infos/final/reward_dist Std          0.76814
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00110014
expl/env_infos/initial/reward_dist Std        0.0030915
expl/env_infos/initial/reward_dist Max        0.0133373
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.639075
expl/env_infos/reward_dist Std                0.645637
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      28800
eval/num paths total                        720
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.637249
eval/Rewards Std                              0.633557
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            25.49
eval/Returns Std                             15.2658
eval/Returns Max                             40.5868
eval/Returns Min                              0.00715452
eval/Actions Mean                             0.624307
eval/Actions Std                              0.649426
eval/Actions Max                              1
eval/Actions Min                             -0.999952
eval/Num Paths                               10
eval/Average Returns                         25.49
eval/env_infos/final/reward_dist Mean         0.783804
eval/env_infos/final/reward_dist Std          0.783807
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       1.15032e-05
eval/env_infos/initial/reward_dist Std        3.45096e-05
eval/env_infos/initial/reward_dist Max        0.000115032
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.637249
eval/env_infos/reward_dist Std                0.633557
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0063195
time/evaluation sampling (s)                  3.3911
time/exploration sampling (s)                17.4528
time/logging (s)                              0.00531898
time/saving (s)                               0.00240774
time/training (s)                             4.74378
time/epoch (s)                               25.6017
time/total (s)                             1795.13
Epoch                                        71
---------------------------------------  ----------------
2023-08-05 00:51:33.012180 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 72 finished
---------------------------------------  ----------------
epoch                                        72
replay_buffer/size                       146000
trainer/QF1 Loss                              0.579401
trainer/QF2 Loss                              0.591796
trainer/Policy Loss                         -16.1632
trainer/Q1 Predictions Mean                  15.3199
trainer/Q1 Predictions Std                    9.3568
trainer/Q1 Predictions Max                   44.1403
trainer/Q1 Predictions Min                   -0.866119
trainer/Q2 Predictions Mean                  15.3379
trainer/Q2 Predictions Std                    9.35191
trainer/Q2 Predictions Max                   43.9087
trainer/Q2 Predictions Min                   -1.38907
trainer/Q Targets Mean                       15.3657
trainer/Q Targets Std                         9.39548
trainer/Q Targets Max                        43.9657
trainer/Q Targets Min                        -1.0315
trainer/Bellman Errors 1 Mean                 0.579401
trainer/Bellman Errors 1 Std                  1.85973
trainer/Bellman Errors 1 Max                 48.738
trainer/Bellman Errors 1 Min                  3.90196e-09
trainer/Bellman Errors 2 Mean                 0.591796
trainer/Bellman Errors 2 Std                  1.86783
trainer/Bellman Errors 2 Max                 49.1833
trainer/Bellman Errors 2 Min                  4.8467e-09
trainer/Policy Action Mean                    0.522635
trainer/Policy Action Std                     0.734511
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     146000
expl/num paths total                       3650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.558263
expl/Rewards Std                              0.636253
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            22.3305
expl/Returns Std                             17.2209
expl/Returns Max                             40.407
expl/Returns Min                              0
expl/Actions Mean                             0.560705
expl/Actions Std                              0.687659
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.3305
expl/env_infos/final/reward_dist Mean         0.798972
expl/env_infos/final/reward_dist Std          0.769526
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000556319
expl/env_infos/initial/reward_dist Std        0.00242756
expl/env_infos/initial/reward_dist Max        0.0129461
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.558263
expl/env_infos/reward_dist Std                0.636253
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      29200
eval/num paths total                        730
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.482058
eval/Rewards Std                              0.603702
eval/Rewards Max                              1.57068
eval/Rewards Min                              0
eval/Returns Mean                            19.2823
eval/Returns Std                             16.9514
eval/Returns Max                             40.6087
eval/Returns Min                              0.00570974
eval/Actions Mean                             0.560645
eval/Actions Std                              0.727487
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         19.2823
eval/env_infos/final/reward_dist Mean         0.603913
eval/env_infos/final/reward_dist Std          0.742572
eval/env_infos/final/reward_dist Max          1.57068
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000907593
eval/env_infos/initial/reward_dist Std        0.00272278
eval/env_infos/initial/reward_dist Max        0.00907593
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.482058
eval/env_infos/reward_dist Std                0.603702
eval/env_infos/reward_dist Max                1.57068
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0062051
time/evaluation sampling (s)                  3.4899
time/exploration sampling (s)                17.7123
time/logging (s)                              0.00745192
time/saving (s)                               0.00269602
time/training (s)                             4.61221
time/epoch (s)                               25.8308
time/total (s)                             1820.96
Epoch                                        72
---------------------------------------  ----------------
2023-08-05 00:51:58.598945 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 73 finished
---------------------------------------  ----------------
epoch                                        73
replay_buffer/size                       148000
trainer/QF1 Loss                              0.457466
trainer/QF2 Loss                              0.457221
trainer/Policy Loss                         -15.7786
trainer/Q1 Predictions Mean                  15.0359
trainer/Q1 Predictions Std                    8.89319
trainer/Q1 Predictions Max                   44.0702
trainer/Q1 Predictions Min                   -1.55134
trainer/Q2 Predictions Mean                  15.0255
trainer/Q2 Predictions Std                    8.89715
trainer/Q2 Predictions Max                   43.8868
trainer/Q2 Predictions Min                   -1.7446
trainer/Q Targets Mean                       15.0372
trainer/Q Targets Std                         8.93523
trainer/Q Targets Max                        44.4337
trainer/Q Targets Min                        -2.11007
trainer/Bellman Errors 1 Mean                 0.457466
trainer/Bellman Errors 1 Std                  1.21737
trainer/Bellman Errors 1 Max                 22.2939
trainer/Bellman Errors 1 Min                  1.37597e-08
trainer/Bellman Errors 2 Mean                 0.457221
trainer/Bellman Errors 2 Std                  1.27693
trainer/Bellman Errors 2 Max                 25.3745
trainer/Bellman Errors 2 Min                  4.64533e-08
trainer/Policy Action Mean                    0.523239
trainer/Policy Action Std                     0.725419
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     148000
expl/num paths total                       3700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.694299
expl/Rewards Std                              0.661434
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            27.772
expl/Returns Std                             16.9139
expl/Returns Max                             41.0765
expl/Returns Min                              0.000667689
expl/Actions Mean                             0.589693
expl/Actions Std                              0.639102
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         27.772
expl/env_infos/final/reward_dist Mean         1.05334
expl/env_infos/final/reward_dist Std          0.724336
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00101344
expl/env_infos/initial/reward_dist Std        0.00283736
expl/env_infos/initial/reward_dist Max        0.0125472
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.694299
expl/env_infos/reward_dist Std                0.661434
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      29600
eval/num paths total                        740
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.646317
eval/Rewards Std                              0.620969
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            25.8527
eval/Returns Std                             14.4518
eval/Returns Max                             41.1787
eval/Returns Min                             11.057
eval/Actions Mean                             0.629136
eval/Actions Std                              0.610705
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.8527
eval/env_infos/final/reward_dist Mean         0.785209
eval/env_infos/final/reward_dist Std          0.785209
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00279842
eval/env_infos/initial/reward_dist Std        0.00543784
eval/env_infos/initial/reward_dist Max        0.0183725
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.646317
eval/env_infos/reward_dist Std                0.620969
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00582347
time/evaluation sampling (s)                  3.40767
time/exploration sampling (s)                17.9306
time/logging (s)                              0.00532799
time/saving (s)                               0.00238783
time/training (s)                             4.22885
time/epoch (s)                               25.5806
time/total (s)                             1846.55
Epoch                                        73
---------------------------------------  ----------------
2023-08-05 00:52:24.168857 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 74 finished
---------------------------------------  ----------------
epoch                                        74
replay_buffer/size                       150000
trainer/QF1 Loss                              0.494357
trainer/QF2 Loss                              0.485675
trainer/Policy Loss                         -15.7097
trainer/Q1 Predictions Mean                  15.0621
trainer/Q1 Predictions Std                    8.81272
trainer/Q1 Predictions Max                   43.2523
trainer/Q1 Predictions Min                   -1.03738
trainer/Q2 Predictions Mean                  15.0492
trainer/Q2 Predictions Std                    8.79984
trainer/Q2 Predictions Max                   42.7597
trainer/Q2 Predictions Min                   -1.34607
trainer/Q Targets Mean                       15.0625
trainer/Q Targets Std                         8.83046
trainer/Q Targets Max                        43.4933
trainer/Q Targets Min                        -1.57635
trainer/Bellman Errors 1 Mean                 0.494357
trainer/Bellman Errors 1 Std                  1.80323
trainer/Bellman Errors 1 Max                 55.8889
trainer/Bellman Errors 1 Min                  3.27418e-07
trainer/Bellman Errors 2 Mean                 0.485675
trainer/Bellman Errors 2 Std                  1.69785
trainer/Bellman Errors 2 Max                 55.3515
trainer/Bellman Errors 2 Min                  2.5062e-08
trainer/Policy Action Mean                    0.520204
trainer/Policy Action Std                     0.727009
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     150000
expl/num paths total                       3750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.646378
expl/Rewards Std                              0.659234
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            25.8551
expl/Returns Std                             17.1711
expl/Returns Max                             42.2288
expl/Returns Min                              0
expl/Actions Mean                             0.569253
expl/Actions Std                              0.649205
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.8551
expl/env_infos/final/reward_dist Mean         0.936658
expl/env_infos/final/reward_dist Std          0.765535
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000270307
expl/env_infos/initial/reward_dist Std        0.00131209
expl/env_infos/initial/reward_dist Max        0.00828554
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.646378
expl/env_infos/reward_dist Std                0.659234
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      30000
eval/num paths total                        750
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.759168
eval/Rewards Std                              0.65811
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            30.3667
eval/Returns Std                             15.1227
eval/Returns Max                             41.4323
eval/Returns Min                              0.00666013
eval/Actions Mean                             0.631057
eval/Actions Std                              0.615108
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.3667
eval/env_infos/final/reward_dist Mean         1.09891
eval/env_infos/final/reward_dist Std          0.719408
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00181487
eval/env_infos/initial/reward_dist Std        0.00368937
eval/env_infos/initial/reward_dist Max        0.0105514
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.759168
eval/env_infos/reward_dist Std                0.65811
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590531
time/evaluation sampling (s)                  3.40108
time/exploration sampling (s)                17.72
time/logging (s)                              0.00532918
time/saving (s)                               0.00240762
time/training (s)                             4.43277
time/epoch (s)                               25.5674
time/total (s)                             1872.12
Epoch                                        74
---------------------------------------  ----------------
2023-08-05 00:52:50.004758 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 75 finished
---------------------------------------  ----------------
epoch                                        75
replay_buffer/size                       152000
trainer/QF1 Loss                              0.429222
trainer/QF2 Loss                              0.421803
trainer/Policy Loss                         -15.4222
trainer/Q1 Predictions Mean                  14.8558
trainer/Q1 Predictions Std                    8.68415
trainer/Q1 Predictions Max                   42.2573
trainer/Q1 Predictions Min                   -2.16836
trainer/Q2 Predictions Mean                  14.8584
trainer/Q2 Predictions Std                    8.68496
trainer/Q2 Predictions Max                   42.1869
trainer/Q2 Predictions Min                   -2.30669
trainer/Q Targets Mean                       14.8583
trainer/Q Targets Std                         8.72026
trainer/Q Targets Max                        42.4507
trainer/Q Targets Min                        -2.00702
trainer/Bellman Errors 1 Mean                 0.429222
trainer/Bellman Errors 1 Std                  1.32564
trainer/Bellman Errors 1 Max                 30.2116
trainer/Bellman Errors 1 Min                  1.44391e-08
trainer/Bellman Errors 2 Mean                 0.421803
trainer/Bellman Errors 2 Std                  1.27763
trainer/Bellman Errors 2 Max                 27.924
trainer/Bellman Errors 2 Min                  4.2055e-09
trainer/Policy Action Mean                    0.522326
trainer/Policy Action Std                     0.725159
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     152000
expl/num paths total                       3800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.89375
expl/Rewards Std                              0.643742
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            35.75
expl/Returns Std                             11.3699
expl/Returns Max                             41.4119
expl/Returns Min                              0
expl/Actions Mean                             0.636477
expl/Actions Std                              0.565189
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         35.75
expl/env_infos/final/reward_dist Mean         1.37662
expl/env_infos/final/reward_dist Std          0.509101
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00144507
expl/env_infos/initial/reward_dist Std        0.00345122
expl/env_infos/initial/reward_dist Max        0.0133354
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.89375
expl/env_infos/reward_dist Std                0.643742
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      30400
eval/num paths total                        760
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.872148
eval/Rewards Std                              0.639873
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            34.8859
eval/Returns Std                             11.956
eval/Returns Max                             42.2382
eval/Returns Min                             10.9811
eval/Actions Mean                             0.660909
eval/Actions Std                              0.566209
eval/Actions Max                              1
eval/Actions Min                             -0.999997
eval/Num Paths                               10
eval/Average Returns                         34.8859
eval/env_infos/final/reward_dist Mean         1.25601
eval/env_infos/final/reward_dist Std          0.628004
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00556988
eval/env_infos/initial/reward_dist Std        0.00719994
eval/env_infos/initial/reward_dist Max        0.0186311
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.872148
eval/env_infos/reward_dist Std                0.639873
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00579488
time/evaluation sampling (s)                  3.40206
time/exploration sampling (s)                17.7873
time/logging (s)                              0.00532194
time/saving (s)                               0.00235579
time/training (s)                             4.63027
time/epoch (s)                               25.8331
time/total (s)                             1897.95
Epoch                                        75
---------------------------------------  ----------------
2023-08-05 00:53:16.766850 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 76 finished
---------------------------------------  ----------------
epoch                                        76
replay_buffer/size                       154000
trainer/QF1 Loss                              0.452125
trainer/QF2 Loss                              0.446634
trainer/Policy Loss                         -14.8301
trainer/Q1 Predictions Mean                  14.2846
trainer/Q1 Predictions Std                    8.41831
trainer/Q1 Predictions Max                   41.6444
trainer/Q1 Predictions Min                   -2.14987
trainer/Q2 Predictions Mean                  14.2953
trainer/Q2 Predictions Std                    8.4317
trainer/Q2 Predictions Max                   41.7585
trainer/Q2 Predictions Min                   -2.29758
trainer/Q Targets Mean                       14.297
trainer/Q Targets Std                         8.45151
trainer/Q Targets Max                        41.9243
trainer/Q Targets Min                        -2.07613
trainer/Bellman Errors 1 Mean                 0.452125
trainer/Bellman Errors 1 Std                  1.6254
trainer/Bellman Errors 1 Max                 57.3743
trainer/Bellman Errors 1 Min                  5.53337e-09
trainer/Bellman Errors 2 Mean                 0.446634
trainer/Bellman Errors 2 Std                  1.70779
trainer/Bellman Errors 2 Max                 65.8811
trainer/Bellman Errors 2 Min                  1.50178e-08
trainer/Policy Action Mean                    0.515963
trainer/Policy Action Std                     0.732646
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     154000
expl/num paths total                       3850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.659577
expl/Rewards Std                              0.650485
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            26.3831
expl/Returns Std                             16.3835
expl/Returns Max                             42.8433
expl/Returns Min                              0
expl/Actions Mean                             0.592648
expl/Actions Std                              0.625166
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.3831
expl/env_infos/final/reward_dist Mean         0.932845
expl/env_infos/final/reward_dist Std          0.762612
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00149103
expl/env_infos/initial/reward_dist Std        0.00380678
expl/env_infos/initial/reward_dist Max        0.0177854
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.659577
expl/env_infos/reward_dist Std                0.650485
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      30800
eval/num paths total                        770
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.763004
eval/Rewards Std                              0.662071
eval/Rewards Max                              1.57042
eval/Rewards Min                              0
eval/Returns Mean                            30.5202
eval/Returns Std                             15.0414
eval/Returns Max                             41.8627
eval/Returns Min                              0.00103086
eval/Actions Mean                             0.656109
eval/Actions Std                              0.583155
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.5202
eval/env_infos/final/reward_dist Mean         1.09841
eval/env_infos/final/reward_dist Std          0.719077
eval/env_infos/final/reward_dist Max          1.57042
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000179045
eval/env_infos/initial/reward_dist Std        0.000537134
eval/env_infos/initial/reward_dist Max        0.00179045
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.763004
eval/env_infos/reward_dist Std                0.662071
eval/env_infos/reward_dist Max                1.57042
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00599305
time/evaluation sampling (s)                  3.42403
time/exploration sampling (s)                18.7515
time/logging (s)                              0.00532665
time/saving (s)                               0.00234888
time/training (s)                             4.57035
time/epoch (s)                               26.7595
time/total (s)                             1924.71
Epoch                                        76
---------------------------------------  ----------------
2023-08-05 00:53:42.488142 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 77 finished
---------------------------------------  ----------------
epoch                                        77
replay_buffer/size                       156000
trainer/QF1 Loss                              0.359633
trainer/QF2 Loss                              0.358722
trainer/Policy Loss                         -14.592
trainer/Q1 Predictions Mean                  14.0314
trainer/Q1 Predictions Std                    8.2704
trainer/Q1 Predictions Max                   41.9153
trainer/Q1 Predictions Min                   -2.77608
trainer/Q2 Predictions Mean                  14.0354
trainer/Q2 Predictions Std                    8.26121
trainer/Q2 Predictions Max                   41.8523
trainer/Q2 Predictions Min                   -2.74614
trainer/Q Targets Mean                       14.0514
trainer/Q Targets Std                         8.29022
trainer/Q Targets Max                        42.6777
trainer/Q Targets Min                        -2.50214
trainer/Bellman Errors 1 Mean                 0.359633
trainer/Bellman Errors 1 Std                  1.46153
trainer/Bellman Errors 1 Max                 60.8561
trainer/Bellman Errors 1 Min                  2.65945e-08
trainer/Bellman Errors 2 Mean                 0.358722
trainer/Bellman Errors 2 Std                  1.46001
trainer/Bellman Errors 2 Max                 55.6024
trainer/Bellman Errors 2 Min                  1.30967e-10
trainer/Policy Action Mean                    0.503704
trainer/Policy Action Std                     0.731235
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     156000
expl/num paths total                       3900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.927221
expl/Rewards Std                              0.633431
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            37.0888
expl/Returns Std                              9.43182
expl/Returns Max                             42.8853
expl/Returns Min                              0.0397062
expl/Actions Mean                             0.632097
expl/Actions Std                              0.568683
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         37.0888
expl/env_infos/final/reward_dist Mean         1.41163
expl/env_infos/final/reward_dist Std          0.470554
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00100956
expl/env_infos/initial/reward_dist Std        0.00276808
expl/env_infos/initial/reward_dist Max        0.0147535
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.927221
expl/env_infos/reward_dist Std                0.633431
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      31200
eval/num paths total                        780
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.751742
eval/Rewards Std                              0.657089
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            30.0697
eval/Returns Std                             15.1619
eval/Returns Max                             41.0505
eval/Returns Min                              0.00685171
eval/Actions Mean                             0.601171
eval/Actions Std                              0.653062
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.0697
eval/env_infos/final/reward_dist Mean         1.09916
eval/env_infos/final/reward_dist Std          0.719554
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.751742
eval/env_infos/reward_dist Std                0.657089
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00582706
time/evaluation sampling (s)                  3.4289
time/exploration sampling (s)                17.8821
time/logging (s)                              0.00486553
time/saving (s)                               0.010987
time/training (s)                             4.38573
time/epoch (s)                               25.7184
time/total (s)                             1950.43
Epoch                                        77
---------------------------------------  ----------------
2023-08-05 00:54:08.672744 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 78 finished
---------------------------------------  ----------------
epoch                                        78
replay_buffer/size                       158000
trainer/QF1 Loss                              0.421102
trainer/QF2 Loss                              0.41699
trainer/Policy Loss                         -14.7189
trainer/Q1 Predictions Mean                  14.1546
trainer/Q1 Predictions Std                    8.32002
trainer/Q1 Predictions Max                   41.5623
trainer/Q1 Predictions Min                   -2.80434
trainer/Q2 Predictions Mean                  14.1542
trainer/Q2 Predictions Std                    8.32511
trainer/Q2 Predictions Max                   41.5
trainer/Q2 Predictions Min                   -2.88504
trainer/Q Targets Mean                       14.2112
trainer/Q Targets Std                         8.36561
trainer/Q Targets Max                        41.8968
trainer/Q Targets Min                        -2.72308
trainer/Bellman Errors 1 Mean                 0.421101
trainer/Bellman Errors 1 Std                  1.44896
trainer/Bellman Errors 1 Max                 42.127
trainer/Bellman Errors 1 Min                  4.2055e-09
trainer/Bellman Errors 2 Mean                 0.41699
trainer/Bellman Errors 2 Std                  1.49199
trainer/Bellman Errors 2 Max                 48.1101
trainer/Bellman Errors 2 Min                  1.05138e-07
trainer/Policy Action Mean                    0.519508
trainer/Policy Action Std                     0.709718
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     158000
expl/num paths total                       3950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.766223
expl/Rewards Std                              0.658532
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            30.6489
expl/Returns Std                             15.4671
expl/Returns Max                             43.3865
expl/Returns Min                              0
expl/Actions Mean                             0.595354
expl/Actions Std                              0.625513
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.6489
expl/env_infos/final/reward_dist Mean         1.14386
expl/env_infos/final/reward_dist Std          0.680501
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000627395
expl/env_infos/initial/reward_dist Std        0.00230845
expl/env_infos/initial/reward_dist Max        0.0137326
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.766223
expl/env_infos/reward_dist Std                0.658532
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      31600
eval/num paths total                        790
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.950737
eval/Rewards Std                              0.629259
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            38.0295
eval/Returns Std                              8.99861
eval/Returns Max                             42.364
eval/Returns Min                             11.1425
eval/Actions Mean                             0.660626
eval/Actions Std                              0.566468
eval/Actions Max                              1
eval/Actions Min                             -0.999973
eval/Num Paths                               10
eval/Average Returns                         38.0295
eval/env_infos/final/reward_dist Mean         1.4123
eval/env_infos/final/reward_dist Std          0.470773
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00217812
eval/env_infos/initial/reward_dist Std        0.0033844
eval/env_infos/initial/reward_dist Max        0.00816802
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.950737
eval/env_infos/reward_dist Std                0.629259
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00567438
time/evaluation sampling (s)                  3.48197
time/exploration sampling (s)                17.4798
time/logging (s)                              0.00534138
time/saving (s)                               0.0023406
time/training (s)                             5.20759
time/epoch (s)                               26.1827
time/total (s)                             1976.62
Epoch                                        78
---------------------------------------  ----------------
2023-08-05 00:54:34.709825 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 79 finished
---------------------------------------  ----------------
epoch                                        79
replay_buffer/size                       160000
trainer/QF1 Loss                              0.478142
trainer/QF2 Loss                              0.480316
trainer/Policy Loss                         -14.888
trainer/Q1 Predictions Mean                  14.3191
trainer/Q1 Predictions Std                    8.42262
trainer/Q1 Predictions Max                   40.9424
trainer/Q1 Predictions Min                   -2.73429
trainer/Q2 Predictions Mean                  14.3081
trainer/Q2 Predictions Std                    8.41491
trainer/Q2 Predictions Max                   40.8773
trainer/Q2 Predictions Min                   -2.75189
trainer/Q Targets Mean                       14.3368
trainer/Q Targets Std                         8.44446
trainer/Q Targets Max                        40.989
trainer/Q Targets Min                        -2.75737
trainer/Bellman Errors 1 Mean                 0.478142
trainer/Bellman Errors 1 Std                  2.03889
trainer/Bellman Errors 1 Max                 51.0086
trainer/Bellman Errors 1 Min                  4.60432e-10
trainer/Bellman Errors 2 Mean                 0.480316
trainer/Bellman Errors 2 Std                  2.04294
trainer/Bellman Errors 2 Max                 49.7154
trainer/Bellman Errors 2 Min                  1.45519e-09
trainer/Policy Action Mean                    0.52587
trainer/Policy Action Std                     0.697419
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     160000
expl/num paths total                       4000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.736479
expl/Rewards Std                              0.665843
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            29.4592
expl/Returns Std                             16.1782
expl/Returns Max                             43.055
expl/Returns Min                              0.0094431
expl/Actions Mean                             0.597806
expl/Actions Std                              0.622372
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.4592
expl/env_infos/final/reward_dist Mean         1.06724
expl/env_infos/final/reward_dist Std          0.731743
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00139751
expl/env_infos/initial/reward_dist Std        0.00383915
expl/env_infos/initial/reward_dist Max        0.0177777
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.736479
expl/env_infos/reward_dist Std                0.665843
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      32000
eval/num paths total                        800
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.879849
eval/Rewards Std                              0.643623
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            35.194
eval/Returns Std                             12.0668
eval/Returns Max                             42.1167
eval/Returns Min                             11.0152
eval/Actions Mean                             0.653934
eval/Actions Std                              0.575954
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.194
eval/env_infos/final/reward_dist Mean         1.25461
eval/env_infos/final/reward_dist Std          0.627313
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00208376
eval/env_infos/initial/reward_dist Std        0.00277428
eval/env_infos/initial/reward_dist Max        0.00764717
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.879849
eval/env_infos/reward_dist Std                0.643623
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00580848
time/evaluation sampling (s)                  3.42831
time/exploration sampling (s)                17.8286
time/logging (s)                              0.00789288
time/saving (s)                               0.00333476
time/training (s)                             4.76305
time/epoch (s)                               26.037
time/total (s)                             2002.66
Epoch                                        79
---------------------------------------  ----------------
2023-08-05 00:55:00.767708 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 80 finished
---------------------------------------  ----------------
epoch                                        80
replay_buffer/size                       162000
trainer/QF1 Loss                              0.438707
trainer/QF2 Loss                              0.429439
trainer/Policy Loss                         -14.4065
trainer/Q1 Predictions Mean                  13.836
trainer/Q1 Predictions Std                    7.997
trainer/Q1 Predictions Max                   40.4067
trainer/Q1 Predictions Min                   -2.57646
trainer/Q2 Predictions Mean                  13.8347
trainer/Q2 Predictions Std                    8.00728
trainer/Q2 Predictions Max                   40.2422
trainer/Q2 Predictions Min                   -2.60591
trainer/Q Targets Mean                       13.8298
trainer/Q Targets Std                         8.02508
trainer/Q Targets Max                        40.7531
trainer/Q Targets Min                        -2.58195
trainer/Bellman Errors 1 Mean                 0.438707
trainer/Bellman Errors 1 Std                  1.39219
trainer/Bellman Errors 1 Max                 24.5897
trainer/Bellman Errors 1 Min                  5.25324e-09
trainer/Bellman Errors 2 Mean                 0.429439
trainer/Bellman Errors 2 Std                  1.38178
trainer/Bellman Errors 2 Max                 23.1568
trainer/Bellman Errors 2 Min                  1.46692e-08
trainer/Policy Action Mean                    0.526975
trainer/Policy Action Std                     0.69466
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     162000
expl/num paths total                       4050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.648993
expl/Rewards Std                              0.658803
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            25.9597
expl/Returns Std                             17.2763
expl/Returns Max                             42.2831
expl/Returns Min                              0
expl/Actions Mean                             0.592152
expl/Actions Std                              0.63557
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.9597
expl/env_infos/final/reward_dist Mean         0.915437
expl/env_infos/final/reward_dist Std          0.761881
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00118243
expl/env_infos/initial/reward_dist Std        0.00337429
expl/env_infos/initial/reward_dist Max        0.0136439
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.648993
expl/env_infos/reward_dist Std                0.658803
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      32400
eval/num paths total                        810
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.7579
eval/Rewards Std                              0.680651
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            30.316
eval/Returns Std                             17.6936
eval/Returns Max                             43.2571
eval/Returns Min                              0
eval/Actions Mean                             0.633842
eval/Actions Std                              0.629785
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.316
eval/env_infos/final/reward_dist Mean         1.0988
eval/env_infos/final/reward_dist Std          0.719164
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00212264
eval/env_infos/initial/reward_dist Std        0.0041268
eval/env_infos/initial/reward_dist Max        0.0113421
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.7579
eval/env_infos/reward_dist Std                0.680651
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590446
time/evaluation sampling (s)                  3.48013
time/exploration sampling (s)                17.988
time/logging (s)                              0.00532653
time/saving (s)                               0.00240542
time/training (s)                             4.56934
time/epoch (s)                               26.0511
time/total (s)                             2028.71
Epoch                                        80
---------------------------------------  ----------------
2023-08-05 00:55:26.679835 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 81 finished
---------------------------------------  ----------------
epoch                                        81
replay_buffer/size                       164000
trainer/QF1 Loss                              0.46328
trainer/QF2 Loss                              0.464158
trainer/Policy Loss                         -14.5528
trainer/Q1 Predictions Mean                  13.9267
trainer/Q1 Predictions Std                    8.05042
trainer/Q1 Predictions Max                   39.8291
trainer/Q1 Predictions Min                   -2.4463
trainer/Q2 Predictions Mean                  13.9319
trainer/Q2 Predictions Std                    8.056
trainer/Q2 Predictions Max                   39.62
trainer/Q2 Predictions Min                   -2.52012
trainer/Q Targets Mean                       13.9616
trainer/Q Targets Std                         8.08087
trainer/Q Targets Max                        40.3494
trainer/Q Targets Min                        -2.57202
trainer/Bellman Errors 1 Mean                 0.46328
trainer/Bellman Errors 1 Std                  1.67311
trainer/Bellman Errors 1 Max                 58.1205
trainer/Bellman Errors 1 Min                  1.53705e-08
trainer/Bellman Errors 2 Mean                 0.464158
trainer/Bellman Errors 2 Std                  1.86309
trainer/Bellman Errors 2 Max                 76.4502
trainer/Bellman Errors 2 Min                  5.04408e-08
trainer/Policy Action Mean                    0.521848
trainer/Policy Action Std                     0.700152
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     164000
expl/num paths total                       4100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.928017
expl/Rewards Std                              0.635023
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            37.1207
expl/Returns Std                             10.2166
expl/Returns Max                             42.238
expl/Returns Min                              0.0364125
expl/Actions Mean                             0.619605
expl/Actions Std                              0.595696
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         37.1207
expl/env_infos/final/reward_dist Mean         1.43325
expl/env_infos/final/reward_dist Std          0.424458
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00122432
expl/env_infos/initial/reward_dist Std        0.00339685
expl/env_infos/initial/reward_dist Max        0.0131191
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.928017
expl/env_infos/reward_dist Std                0.635023
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      32800
eval/num paths total                        820
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.960883
eval/Rewards Std                              0.625088
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            38.4353
eval/Returns Std                              7.34994
eval/Returns Max                             41.9668
eval/Returns Min                             16.4712
eval/Actions Mean                             0.651865
eval/Actions Std                              0.591374
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         38.4353
eval/env_infos/final/reward_dist Mean         1.41252
eval/env_infos/final/reward_dist Std          0.470841
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00107699
eval/env_infos/initial/reward_dist Std        0.00323096
eval/env_infos/initial/reward_dist Max        0.0107699
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.960883
eval/env_infos/reward_dist Std                0.625088
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00592527
time/evaluation sampling (s)                  3.3939
time/exploration sampling (s)                18.0523
time/logging (s)                              0.00529676
time/saving (s)                               0.00236777
time/training (s)                             4.44982
time/epoch (s)                               25.9096
time/total (s)                             2054.62
Epoch                                        81
---------------------------------------  ----------------
2023-08-05 00:55:52.574752 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 82 finished
---------------------------------------  ----------------
epoch                                        82
replay_buffer/size                       166000
trainer/QF1 Loss                              0.478861
trainer/QF2 Loss                              0.468888
trainer/Policy Loss                         -14.5812
trainer/Q1 Predictions Mean                  13.9239
trainer/Q1 Predictions Std                    8.00418
trainer/Q1 Predictions Max                   39.3583
trainer/Q1 Predictions Min                   -1.89509
trainer/Q2 Predictions Mean                  13.9415
trainer/Q2 Predictions Std                    8.00428
trainer/Q2 Predictions Max                   39.184
trainer/Q2 Predictions Min                   -1.89584
trainer/Q Targets Mean                       13.9094
trainer/Q Targets Std                         8.04491
trainer/Q Targets Max                        39.756
trainer/Q Targets Min                        -2.23543
trainer/Bellman Errors 1 Mean                 0.478861
trainer/Bellman Errors 1 Std                  1.56687
trainer/Bellman Errors 1 Max                 35.5852
trainer/Bellman Errors 1 Min                  5.82077e-09
trainer/Bellman Errors 2 Mean                 0.468888
trainer/Bellman Errors 2 Std                  1.54856
trainer/Bellman Errors 2 Max                 35.4204
trainer/Bellman Errors 2 Min                  3.63798e-10
trainer/Policy Action Mean                    0.515843
trainer/Policy Action Std                     0.706576
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     166000
expl/num paths total                       4150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.95071
expl/Rewards Std                              0.625021
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            38.0284
expl/Returns Std                              7.86528
expl/Returns Max                             41.8923
expl/Returns Min                             10.9164
expl/Actions Mean                             0.627522
expl/Actions Std                              0.575985
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         38.0284
expl/env_infos/final/reward_dist Mean         1.44394
expl/env_infos/final/reward_dist Std          0.425797
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00123483
expl/env_infos/initial/reward_dist Std        0.00355127
expl/env_infos/initial/reward_dist Max        0.0145423
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.95071
expl/env_infos/reward_dist Std                0.625021
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      33200
eval/num paths total                        830
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.01484
eval/Rewards Std                              0.602724
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            40.5936
eval/Returns Std                              0.964086
eval/Returns Max                             41.7226
eval/Returns Min                             39.0022
eval/Actions Mean                             0.649193
eval/Actions Std                              0.589512
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         40.5936
eval/env_infos/final/reward_dist Mean         1.56884
eval/env_infos/final/reward_dist Std          0.00226282
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          1.56333
eval/env_infos/initial/reward_dist Mean       0.000352032
eval/env_infos/initial/reward_dist Std        0.0010561
eval/env_infos/initial/reward_dist Max        0.00352032
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.01484
eval/env_infos/reward_dist Std                0.602724
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00582175
time/evaluation sampling (s)                  3.41775
time/exploration sampling (s)                17.8983
time/logging (s)                              0.00741216
time/saving (s)                               0.00269988
time/training (s)                             4.56261
time/epoch (s)                               25.8946
time/total (s)                             2080.52
Epoch                                        82
---------------------------------------  ----------------
2023-08-05 00:56:18.963694 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 83 finished
---------------------------------------  ----------------
epoch                                        83
replay_buffer/size                       168000
trainer/QF1 Loss                              0.460926
trainer/QF2 Loss                              0.450696
trainer/Policy Loss                         -14.4994
trainer/Q1 Predictions Mean                  13.8319
trainer/Q1 Predictions Std                    7.99754
trainer/Q1 Predictions Max                   40.3769
trainer/Q1 Predictions Min                   -2.12702
trainer/Q2 Predictions Mean                  13.832
trainer/Q2 Predictions Std                    7.99829
trainer/Q2 Predictions Max                   40.1502
trainer/Q2 Predictions Min                   -2.2318
trainer/Q Targets Mean                       13.8905
trainer/Q Targets Std                         8.04058
trainer/Q Targets Max                        40.626
trainer/Q Targets Min                        -2.4522
trainer/Bellman Errors 1 Mean                 0.460926
trainer/Bellman Errors 1 Std                  1.40553
trainer/Bellman Errors 1 Max                 30.9274
trainer/Bellman Errors 1 Min                  3.56558e-08
trainer/Bellman Errors 2 Mean                 0.450696
trainer/Bellman Errors 2 Std                  1.40061
trainer/Bellman Errors 2 Max                 31.5211
trainer/Bellman Errors 2 Min                  4.58476e-09
trainer/Policy Action Mean                    0.51028
trainer/Policy Action Std                     0.708596
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     168000
expl/num paths total                       4200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.871586
expl/Rewards Std                              0.647962
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            34.8634
expl/Returns Std                             12.5615
expl/Returns Max                             41.528
expl/Returns Min                              0
expl/Actions Mean                             0.592052
expl/Actions Std                              0.625357
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         34.8634
expl/env_infos/final/reward_dist Mean         1.34537
expl/env_infos/final/reward_dist Std          0.543255
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00051317
expl/env_infos/initial/reward_dist Std        0.00170539
expl/env_infos/initial/reward_dist Max        0.0107425
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.871586
expl/env_infos/reward_dist Std                0.647962
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      33600
eval/num paths total                        840
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.01497
eval/Rewards Std                              0.603571
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            40.5987
eval/Returns Std                              0.693756
eval/Returns Max                             41.302
eval/Returns Min                             39.2867
eval/Actions Mean                             0.645541
eval/Actions Std                              0.58792
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         40.5987
eval/env_infos/final/reward_dist Mean         1.56793
eval/env_infos/final/reward_dist Std          0.00258011
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          1.5631
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.01497
eval/env_infos/reward_dist Std                0.603571
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00565346
time/evaluation sampling (s)                  3.56122
time/exploration sampling (s)                18.221
time/logging (s)                              0.00532286
time/saving (s)                               0.00242372
time/training (s)                             4.5871
time/epoch (s)                               26.3827
time/total (s)                             2106.9
Epoch                                        83
---------------------------------------  ----------------
2023-08-05 00:56:45.246758 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 84 finished
---------------------------------------  ----------------
epoch                                        84
replay_buffer/size                       170000
trainer/QF1 Loss                              0.489812
trainer/QF2 Loss                              0.482239
trainer/Policy Loss                         -14.6104
trainer/Q1 Predictions Mean                  14.0032
trainer/Q1 Predictions Std                    7.97561
trainer/Q1 Predictions Max                   40.2919
trainer/Q1 Predictions Min                   -2.49614
trainer/Q2 Predictions Mean                  13.9963
trainer/Q2 Predictions Std                    7.97585
trainer/Q2 Predictions Max                   40.0113
trainer/Q2 Predictions Min                   -2.84232
trainer/Q Targets Mean                       13.9696
trainer/Q Targets Std                         7.99735
trainer/Q Targets Max                        40.5529
trainer/Q Targets Min                        -3.04026
trainer/Bellman Errors 1 Mean                 0.489812
trainer/Bellman Errors 1 Std                  1.8611
trainer/Bellman Errors 1 Max                 41.9408
trainer/Bellman Errors 1 Min                  7.25834e-08
trainer/Bellman Errors 2 Mean                 0.482239
trainer/Bellman Errors 2 Std                  1.84905
trainer/Bellman Errors 2 Max                 40.147
trainer/Bellman Errors 2 Min                  4.93756e-08
trainer/Policy Action Mean                    0.51038
trainer/Policy Action Std                     0.702664
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     170000
expl/num paths total                       4250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.67894
expl/Rewards Std                              0.647432
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            27.1576
expl/Returns Std                             16.4455
expl/Returns Max                             40.8585
expl/Returns Min                              0
expl/Actions Mean                             0.547394
expl/Actions Std                              0.671758
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         27.1576
expl/env_infos/final/reward_dist Mean         0.995568
expl/env_infos/final/reward_dist Std          0.738321
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000485257
expl/env_infos/initial/reward_dist Std        0.0015363
expl/env_infos/initial/reward_dist Max        0.00818648
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.67894
expl/env_infos/reward_dist Std                0.647432
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      34000
eval/num paths total                        850
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.600054
eval/Rewards Std                              0.627437
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            24.0022
eval/Returns Std                             16.6343
eval/Returns Max                             41.1673
eval/Returns Min                              0.000221147
eval/Actions Mean                             0.626113
eval/Actions Std                              0.637561
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.0022
eval/env_infos/final/reward_dist Mean         0.765672
eval/env_infos/final/reward_dist Std          0.766805
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00216545
eval/env_infos/initial/reward_dist Std        0.00433314
eval/env_infos/initial/reward_dist Max        0.0111384
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.600054
eval/env_infos/reward_dist Std                0.627437
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00576929
time/evaluation sampling (s)                  3.49988
time/exploration sampling (s)                18.2301
time/logging (s)                              0.00532969
time/saving (s)                               0.00230029
time/training (s)                             4.53727
time/epoch (s)                               26.2806
time/total (s)                             2133.19
Epoch                                        84
---------------------------------------  ----------------
2023-08-05 00:57:11.607388 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 85 finished
---------------------------------------  ----------------
epoch                                        85
replay_buffer/size                       172000
trainer/QF1 Loss                              0.535719
trainer/QF2 Loss                              0.535369
trainer/Policy Loss                         -14.5139
trainer/Q1 Predictions Mean                  13.869
trainer/Q1 Predictions Std                    7.96492
trainer/Q1 Predictions Max                   39.3503
trainer/Q1 Predictions Min                   -2.45636
trainer/Q2 Predictions Mean                  13.8607
trainer/Q2 Predictions Std                    7.96186
trainer/Q2 Predictions Max                   39.218
trainer/Q2 Predictions Min                   -2.29166
trainer/Q Targets Mean                       13.8558
trainer/Q Targets Std                         8.03258
trainer/Q Targets Max                        40.4688
trainer/Q Targets Min                        -2.70318
trainer/Bellman Errors 1 Mean                 0.535719
trainer/Bellman Errors 1 Std                  2.00345
trainer/Bellman Errors 1 Max                 56.8518
trainer/Bellman Errors 1 Min                  1.78966e-09
trainer/Bellman Errors 2 Mean                 0.535369
trainer/Bellman Errors 2 Std                  2.09444
trainer/Bellman Errors 2 Max                 67.8923
trainer/Bellman Errors 2 Min                  1.78261e-10
trainer/Policy Action Mean                    0.500273
trainer/Policy Action Std                     0.704621
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     172000
expl/num paths total                       4300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.638516
expl/Rewards Std                              0.631
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            25.5406
expl/Returns Std                             15.8918
expl/Returns Max                             41.6503
expl/Returns Min                              0
expl/Actions Mean                             0.538641
expl/Actions Std                              0.666644
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.5406
expl/env_infos/final/reward_dist Mean         0.870449
expl/env_infos/final/reward_dist Std          0.772511
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00103687
expl/env_infos/initial/reward_dist Std        0.00291807
expl/env_infos/initial/reward_dist Max        0.0171545
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.638516
expl/env_infos/reward_dist Std                0.631
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      34400
eval/num paths total                        860
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.474945
eval/Rewards Std                              0.579628
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            18.9978
eval/Returns Std                             14.6256
eval/Returns Max                             40.519
eval/Returns Min                              0.00499036
eval/Actions Mean                             0.56983
eval/Actions Std                              0.684743
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         18.9978
eval/env_infos/final/reward_dist Mean         0.470678
eval/env_infos/final/reward_dist Std          0.718956
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00149736
eval/env_infos/initial/reward_dist Std        0.00356632
eval/env_infos/initial/reward_dist Max        0.0120383
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.474945
eval/env_infos/reward_dist Std                0.579628
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587134
time/evaluation sampling (s)                  3.45933
time/exploration sampling (s)                18.3456
time/logging (s)                              0.00530218
time/saving (s)                               0.0023906
time/training (s)                             4.53959
time/epoch (s)                               26.3581
time/total (s)                             2159.55
Epoch                                        85
---------------------------------------  ----------------
2023-08-05 00:57:37.985841 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 86 finished
---------------------------------------  ----------------
epoch                                        86
replay_buffer/size                       174000
trainer/QF1 Loss                              0.52682
trainer/QF2 Loss                              0.51759
trainer/Policy Loss                         -14.6083
trainer/Q1 Predictions Mean                  13.8738
trainer/Q1 Predictions Std                    7.86326
trainer/Q1 Predictions Max                   39.3147
trainer/Q1 Predictions Min                   -1.31455
trainer/Q2 Predictions Mean                  13.8707
trainer/Q2 Predictions Std                    7.86231
trainer/Q2 Predictions Max                   39.2632
trainer/Q2 Predictions Min                   -1.28144
trainer/Q Targets Mean                       13.8817
trainer/Q Targets Std                         7.89402
trainer/Q Targets Max                        40.2073
trainer/Q Targets Min                        -1.31134
trainer/Bellman Errors 1 Mean                 0.52682
trainer/Bellman Errors 1 Std                  2.09501
trainer/Bellman Errors 1 Max                 60.9008
trainer/Bellman Errors 1 Min                  1.47344e-07
trainer/Bellman Errors 2 Mean                 0.51759
trainer/Bellman Errors 2 Std                  2.02306
trainer/Bellman Errors 2 Max                 59.9045
trainer/Bellman Errors 2 Min                  3.67887e-07
trainer/Policy Action Mean                    0.500162
trainer/Policy Action Std                     0.69983
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     174000
expl/num paths total                       4350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.361651
expl/Rewards Std                              0.524573
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            14.466
expl/Returns Std                             14.137
expl/Returns Max                             43.1122
expl/Returns Min                              0
expl/Actions Mean                             0.535458
expl/Actions Std                              0.694913
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.466
expl/env_infos/final/reward_dist Mean         0.370803
expl/env_infos/final/reward_dist Std          0.644432
expl/env_infos/final/reward_dist Max          1.57071
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00046253
expl/env_infos/initial/reward_dist Std        0.00145344
expl/env_infos/initial/reward_dist Max        0.00633359
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.361651
expl/env_infos/reward_dist Std                0.524573
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      34800
eval/num paths total                        870
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.506614
eval/Rewards Std                              0.614208
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            20.2646
eval/Returns Std                             18.1027
eval/Returns Max                             40.5082
eval/Returns Min                              0
eval/Actions Mean                             0.615079
eval/Actions Std                              0.68838
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.2646
eval/env_infos/final/reward_dist Mean         0.735503
eval/env_infos/final/reward_dist Std          0.739887
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000860978
eval/env_infos/initial/reward_dist Std        0.00258293
eval/env_infos/initial/reward_dist Max        0.00860978
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.506614
eval/env_infos/reward_dist Std                0.614208
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00582102
time/evaluation sampling (s)                  3.5921
time/exploration sampling (s)                18.1206
time/logging (s)                              0.00530056
time/saving (s)                               0.00240751
time/training (s)                             4.64968
time/epoch (s)                               26.3759
time/total (s)                             2185.92
Epoch                                        86
---------------------------------------  ----------------
2023-08-05 00:58:04.121687 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 87 finished
---------------------------------------  ----------------
epoch                                        87
replay_buffer/size                       176000
trainer/QF1 Loss                              0.5763
trainer/QF2 Loss                              0.559134
trainer/Policy Loss                         -14.4707
trainer/Q1 Predictions Mean                  13.6715
trainer/Q1 Predictions Std                    7.79165
trainer/Q1 Predictions Max                   40.2951
trainer/Q1 Predictions Min                   -0.556109
trainer/Q2 Predictions Mean                  13.6877
trainer/Q2 Predictions Std                    7.7954
trainer/Q2 Predictions Max                   40.1249
trainer/Q2 Predictions Min                   -0.269175
trainer/Q Targets Mean                       13.6932
trainer/Q Targets Std                         7.86369
trainer/Q Targets Max                        41.08
trainer/Q Targets Min                        -0.735599
trainer/Bellman Errors 1 Mean                 0.5763
trainer/Bellman Errors 1 Std                  2.13795
trainer/Bellman Errors 1 Max                 43.3703
trainer/Bellman Errors 1 Min                  3.84261e-09
trainer/Bellman Errors 2 Mean                 0.559134
trainer/Bellman Errors 2 Std                  2.12455
trainer/Bellman Errors 2 Max                 50.0506
trainer/Bellman Errors 2 Min                  3.27418e-11
trainer/Policy Action Mean                    0.490136
trainer/Policy Action Std                     0.706181
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     176000
expl/num paths total                       4400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.329861
expl/Rewards Std                              0.499542
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            13.1944
expl/Returns Std                             13.2692
expl/Returns Max                             42.0017
expl/Returns Min                              0
expl/Actions Mean                             0.496112
expl/Actions Std                              0.725286
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.1944
expl/env_infos/final/reward_dist Mean         0.270136
expl/env_infos/final/reward_dist Std          0.5773
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000686188
expl/env_infos/initial/reward_dist Std        0.00215753
expl/env_infos/initial/reward_dist Max        0.00927298
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.329861
expl/env_infos/reward_dist Std                0.499542
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      35200
eval/num paths total                        880
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.442361
eval/Rewards Std                              0.537217
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            17.6945
eval/Returns Std                             13.8907
eval/Returns Max                             41.23
eval/Returns Min                              0
eval/Actions Mean                             0.572853
eval/Actions Std                              0.675725
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.6945
eval/env_infos/final/reward_dist Mean         0.423532
eval/env_infos/final/reward_dist Std          0.649706
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00230375
eval/env_infos/initial/reward_dist Std        0.0042063
eval/env_infos/initial/reward_dist Max        0.0129733
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.442361
eval/env_infos/reward_dist Std                0.537217
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00569878
time/evaluation sampling (s)                  3.40095
time/exploration sampling (s)                18.0293
time/logging (s)                              0.00533498
time/saving (s)                               0.0025083
time/training (s)                             4.68966
time/epoch (s)                               26.1334
time/total (s)                             2212.06
Epoch                                        87
---------------------------------------  ----------------
2023-08-05 00:58:29.784249 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 88 finished
---------------------------------------  ----------------
epoch                                        88
replay_buffer/size                       178000
trainer/QF1 Loss                              0.614677
trainer/QF2 Loss                              0.605059
trainer/Policy Loss                         -14.3392
trainer/Q1 Predictions Mean                  13.6736
trainer/Q1 Predictions Std                    7.92652
trainer/Q1 Predictions Max                   39.6358
trainer/Q1 Predictions Min                   -0.196782
trainer/Q2 Predictions Mean                  13.6828
trainer/Q2 Predictions Std                    7.92816
trainer/Q2 Predictions Max                   39.4948
trainer/Q2 Predictions Min                   -0.163201
trainer/Q Targets Mean                       13.663
trainer/Q Targets Std                         7.96615
trainer/Q Targets Max                        39.9946
trainer/Q Targets Min                        -0.611371
trainer/Bellman Errors 1 Mean                 0.614677
trainer/Bellman Errors 1 Std                  2.42986
trainer/Bellman Errors 1 Max                 61.6237
trainer/Bellman Errors 1 Min                  4.24334e-08
trainer/Bellman Errors 2 Mean                 0.605059
trainer/Bellman Errors 2 Std                  2.44012
trainer/Bellman Errors 2 Max                 68.6004
trainer/Bellman Errors 2 Min                  2.90333e-09
trainer/Policy Action Mean                    0.491537
trainer/Policy Action Std                     0.711384
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     178000
expl/num paths total                       4450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.243016
expl/Rewards Std                              0.434709
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                             9.72065
expl/Returns Std                             11.2825
expl/Returns Max                             40.1916
expl/Returns Min                              0
expl/Actions Mean                             0.458481
expl/Actions Std                              0.760192
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          9.72065
expl/env_infos/final/reward_dist Mean         0.148352
expl/env_infos/final/reward_dist Std          0.445757
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000197457
expl/env_infos/initial/reward_dist Std        0.000715287
expl/env_infos/initial/reward_dist Max        0.00360558
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.243016
expl/env_infos/reward_dist Std                0.434709
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      35600
eval/num paths total                        890
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.462973
eval/Rewards Std                              0.573339
eval/Rewards Max                              1.56939
eval/Rewards Min                              0
eval/Returns Mean                            18.5189
eval/Returns Std                             14.8486
eval/Returns Max                             40.1277
eval/Returns Min                              0
eval/Actions Mean                             0.607802
eval/Actions Std                              0.650309
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         18.5189
eval/env_infos/final/reward_dist Mean         0.470257
eval/env_infos/final/reward_dist Std          0.71833
eval/env_infos/final/reward_dist Max          1.56939
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00102557
eval/env_infos/initial/reward_dist Std        0.00307671
eval/env_infos/initial/reward_dist Max        0.0102557
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.462973
eval/env_infos/reward_dist Std                0.573339
eval/env_infos/reward_dist Max                1.56939
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585096
time/evaluation sampling (s)                  3.47833
time/exploration sampling (s)                17.9288
time/logging (s)                              0.00534726
time/saving (s)                               0.00232984
time/training (s)                             4.23946
time/epoch (s)                               25.6601
time/total (s)                             2237.72
Epoch                                        88
---------------------------------------  ----------------
2023-08-05 00:58:56.014073 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 89 finished
---------------------------------------  ----------------
epoch                                        89
replay_buffer/size                       180000
trainer/QF1 Loss                              0.559691
trainer/QF2 Loss                              0.549676
trainer/Policy Loss                         -14.4052
trainer/Q1 Predictions Mean                  13.6667
trainer/Q1 Predictions Std                    8.15995
trainer/Q1 Predictions Max                   39.9185
trainer/Q1 Predictions Min                   -0.363221
trainer/Q2 Predictions Mean                  13.6714
trainer/Q2 Predictions Std                    8.16512
trainer/Q2 Predictions Max                   39.9444
trainer/Q2 Predictions Min                   -0.433882
trainer/Q Targets Mean                       13.6559
trainer/Q Targets Std                         8.19537
trainer/Q Targets Max                        41.3584
trainer/Q Targets Min                        -0.535165
trainer/Bellman Errors 1 Mean                 0.559691
trainer/Bellman Errors 1 Std                  2.28418
trainer/Bellman Errors 1 Max                 55.1891
trainer/Bellman Errors 1 Min                  4.45652e-11
trainer/Bellman Errors 2 Mean                 0.549676
trainer/Bellman Errors 2 Std                  2.20207
trainer/Bellman Errors 2 Max                 50.8572
trainer/Bellman Errors 2 Min                  1.2451e-09
trainer/Policy Action Mean                    0.489897
trainer/Policy Action Std                     0.71639
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     180000
expl/num paths total                       4500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.364798
expl/Rewards Std                              0.542651
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            14.5919
expl/Returns Std                             15.4997
expl/Returns Max                             42.9455
expl/Returns Min                              0
expl/Actions Mean                             0.537817
expl/Actions Std                              0.700307
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.5919
expl/env_infos/final/reward_dist Mean         0.448384
expl/env_infos/final/reward_dist Std          0.686506
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000361466
expl/env_infos/initial/reward_dist Std        0.0019305
expl/env_infos/initial/reward_dist Max        0.0131912
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.364798
expl/env_infos/reward_dist Std                0.542651
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      36000
eval/num paths total                        900
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.26267
eval/Rewards Std                              0.439218
eval/Rewards Max                              1.56743
eval/Rewards Min                              0
eval/Returns Mean                            10.5068
eval/Returns Std                             11.2269
eval/Returns Max                             38.5983
eval/Returns Min                              0
eval/Actions Mean                             0.509523
eval/Actions Std                              0.762598
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         10.5068
eval/env_infos/final/reward_dist Mean         0.158144
eval/env_infos/final/reward_dist Std          0.469767
eval/env_infos/final/reward_dist Max          1.56743
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00113347
eval/env_infos/initial/reward_dist Std        0.00261996
eval/env_infos/initial/reward_dist Max        0.00883744
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.26267
eval/env_infos/reward_dist Std                0.439218
eval/env_infos/reward_dist Max                1.56743
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00583029
time/evaluation sampling (s)                  3.46772
time/exploration sampling (s)                18.2207
time/logging (s)                              0.00531693
time/saving (s)                               0.0023651
time/training (s)                             4.52531
time/epoch (s)                               26.2273
time/total (s)                             2263.95
Epoch                                        89
---------------------------------------  ----------------
2023-08-05 00:59:22.728214 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 90 finished
---------------------------------------  ----------------
epoch                                        90
replay_buffer/size                       182000
trainer/QF1 Loss                              0.577468
trainer/QF2 Loss                              0.585323
trainer/Policy Loss                         -14.0733
trainer/Q1 Predictions Mean                  13.4129
trainer/Q1 Predictions Std                    8.10025
trainer/Q1 Predictions Max                   40.0307
trainer/Q1 Predictions Min                   -0.59942
trainer/Q2 Predictions Mean                  13.4208
trainer/Q2 Predictions Std                    8.10257
trainer/Q2 Predictions Max                   40.0672
trainer/Q2 Predictions Min                   -0.437804
trainer/Q Targets Mean                       13.3888
trainer/Q Targets Std                         8.12726
trainer/Q Targets Max                        40.7175
trainer/Q Targets Min                        -0.788096
trainer/Bellman Errors 1 Mean                 0.577468
trainer/Bellman Errors 1 Std                  2.42403
trainer/Bellman Errors 1 Max                 55.1522
trainer/Bellman Errors 1 Min                  1.12059e-08
trainer/Bellman Errors 2 Mean                 0.585323
trainer/Bellman Errors 2 Std                  2.50391
trainer/Bellman Errors 2 Max                 63.4312
trainer/Bellman Errors 2 Min                  1.02191e-08
trainer/Policy Action Mean                    0.489195
trainer/Policy Action Std                     0.725169
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     182000
expl/num paths total                       4550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.380041
expl/Rewards Std                              0.529958
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            15.2016
expl/Returns Std                             13.5598
expl/Returns Max                             40.3004
expl/Returns Min                              0
expl/Actions Mean                             0.522306
expl/Actions Std                              0.700133
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.2016
expl/env_infos/final/reward_dist Mean         0.372939
expl/env_infos/final/reward_dist Std          0.663522
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00073868
expl/env_infos/initial/reward_dist Std        0.00242621
expl/env_infos/initial/reward_dist Max        0.0121029
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.380041
expl/env_infos/reward_dist Std                0.529958
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      36400
eval/num paths total                        910
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.32607
eval/Rewards Std                              0.517863
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            13.0428
eval/Returns Std                             14.6368
eval/Returns Max                             41.2834
eval/Returns Min                              0.0136962
eval/Actions Mean                             0.452459
eval/Actions Std                              0.796901
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         13.0428
eval/env_infos/final/reward_dist Mean         0.314631
eval/env_infos/final/reward_dist Std          0.628064
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000622854
eval/env_infos/initial/reward_dist Std        0.00186856
eval/env_infos/initial/reward_dist Max        0.00622854
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.32607
eval/env_infos/reward_dist Std                0.517863
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595688
time/evaluation sampling (s)                  3.42976
time/exploration sampling (s)                18.7495
time/logging (s)                              0.00537255
time/saving (s)                               0.0024202
time/training (s)                             4.51865
time/epoch (s)                               26.7116
time/total (s)                             2290.66
Epoch                                        90
---------------------------------------  ----------------
2023-08-05 00:59:50.034725 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 91 finished
---------------------------------------  ----------------
epoch                                        91
replay_buffer/size                       184000
trainer/QF1 Loss                              0.609637
trainer/QF2 Loss                              0.604834
trainer/Policy Loss                         -14.0128
trainer/Q1 Predictions Mean                  13.3458
trainer/Q1 Predictions Std                    7.94832
trainer/Q1 Predictions Max                   40.2409
trainer/Q1 Predictions Min                   -0.786629
trainer/Q2 Predictions Mean                  13.3345
trainer/Q2 Predictions Std                    7.9488
trainer/Q2 Predictions Max                   40.2924
trainer/Q2 Predictions Min                   -0.67345
trainer/Q Targets Mean                       13.3316
trainer/Q Targets Std                         7.99911
trainer/Q Targets Max                        40.9995
trainer/Q Targets Min                        -1.3132
trainer/Bellman Errors 1 Mean                 0.609637
trainer/Bellman Errors 1 Std                  2.6891
trainer/Bellman Errors 1 Max                 48.8397
trainer/Bellman Errors 1 Min                  1.00272e-08
trainer/Bellman Errors 2 Mean                 0.604834
trainer/Bellman Errors 2 Std                  2.6161
trainer/Bellman Errors 2 Max                 47.3762
trainer/Bellman Errors 2 Min                  6.72662e-09
trainer/Policy Action Mean                    0.496602
trainer/Policy Action Std                     0.7203
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     184000
expl/num paths total                       4600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.368394
expl/Rewards Std                              0.526986
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            14.7358
expl/Returns Std                             14.1373
expl/Returns Max                             42.0807
expl/Returns Min                              0
expl/Actions Mean                             0.535761
expl/Actions Std                              0.694226
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.7358
expl/env_infos/final/reward_dist Mean         0.389354
expl/env_infos/final/reward_dist Std          0.658991
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000774906
expl/env_infos/initial/reward_dist Std        0.00283271
expl/env_infos/initial/reward_dist Max        0.0149793
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.368394
expl/env_infos/reward_dist Std                0.526986
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      36800
eval/num paths total                        920
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.217185
eval/Rewards Std                              0.427404
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                             8.68741
eval/Returns Std                             11.8733
eval/Returns Max                             40.1358
eval/Returns Min                              0
eval/Actions Mean                             0.532175
eval/Actions Std                              0.75986
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          8.68741
eval/env_infos/final/reward_dist Mean         0.273472
eval/env_infos/final/reward_dist Std          0.554123
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000262671
eval/env_infos/initial/reward_dist Std        0.000788013
eval/env_infos/initial/reward_dist Max        0.00262671
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.217185
eval/env_infos/reward_dist Std                0.427404
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591959
time/evaluation sampling (s)                  3.5245
time/exploration sampling (s)                18.7771
time/logging (s)                              0.00795877
time/saving (s)                               0.00333281
time/training (s)                             4.98781
time/epoch (s)                               27.3066
time/total (s)                             2317.97
Epoch                                        91
---------------------------------------  ----------------
2023-08-05 01:00:15.834356 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 92 finished
---------------------------------------  ----------------
epoch                                        92
replay_buffer/size                       186000
trainer/QF1 Loss                              0.604269
trainer/QF2 Loss                              0.601734
trainer/Policy Loss                         -14.0878
trainer/Q1 Predictions Mean                  13.3799
trainer/Q1 Predictions Std                    8.16405
trainer/Q1 Predictions Max                   40.9396
trainer/Q1 Predictions Min                   -0.825091
trainer/Q2 Predictions Mean                  13.3867
trainer/Q2 Predictions Std                    8.16434
trainer/Q2 Predictions Max                   41.0284
trainer/Q2 Predictions Min                   -0.646751
trainer/Q Targets Mean                       13.3467
trainer/Q Targets Std                         8.21367
trainer/Q Targets Max                        42.3935
trainer/Q Targets Min                        -1.41216
trainer/Bellman Errors 1 Mean                 0.604269
trainer/Bellman Errors 1 Std                  2.47729
trainer/Bellman Errors 1 Max                 53.6645
trainer/Bellman Errors 1 Min                  8.18545e-10
trainer/Bellman Errors 2 Mean                 0.601734
trainer/Bellman Errors 2 Std                  2.47327
trainer/Bellman Errors 2 Max                 54.0355
trainer/Bellman Errors 2 Min                  5.06552e-08
trainer/Policy Action Mean                    0.488374
trainer/Policy Action Std                     0.725869
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     186000
expl/num paths total                       4650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.333084
expl/Rewards Std                              0.502901
expl/Rewards Max                              1.57047
expl/Rewards Min                              0
expl/Returns Mean                            13.3234
expl/Returns Std                             13.299
expl/Returns Max                             42.7148
expl/Returns Min                              0
expl/Actions Mean                             0.519556
expl/Actions Std                              0.701086
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.3234
expl/env_infos/final/reward_dist Mean         0.278445
expl/env_infos/final/reward_dist Std          0.594127
expl/env_infos/final/reward_dist Max          1.57047
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00111018
expl/env_infos/initial/reward_dist Std        0.0033927
expl/env_infos/initial/reward_dist Max        0.0187725
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.333084
expl/env_infos/reward_dist Std                0.502901
expl/env_infos/reward_dist Max                1.57047
expl/env_infos/reward_dist Min                0
eval/num steps total                      37200
eval/num paths total                        930
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.258037
eval/Rewards Std                              0.393998
eval/Rewards Max                              1.30179
eval/Rewards Min                              0
eval/Returns Mean                            10.3215
eval/Returns Std                              5.23455
eval/Returns Max                             14.5548
eval/Returns Min                              0.00897736
eval/Actions Mean                             0.510536
eval/Actions Std                              0.727123
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         10.3215
eval/env_infos/final/reward_dist Mean         6.79503e-09
eval/env_infos/final/reward_dist Std          2.03851e-08
eval/env_infos/final/reward_dist Max          6.79503e-08
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00296331
eval/env_infos/initial/reward_dist Std        0.00480753
eval/env_infos/initial/reward_dist Max        0.0140143
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.258037
eval/env_infos/reward_dist Std                0.393998
eval/env_infos/reward_dist Max                1.30179
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00569896
time/evaluation sampling (s)                  3.46768
time/exploration sampling (s)                17.7153
time/logging (s)                              0.00533872
time/saving (s)                               0.00237371
time/training (s)                             4.59625
time/epoch (s)                               25.7927
time/total (s)                             2343.77
Epoch                                        92
---------------------------------------  ----------------
2023-08-05 01:00:41.693346 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 93 finished
---------------------------------------  ----------------
epoch                                        93
replay_buffer/size                       188000
trainer/QF1 Loss                              0.652081
trainer/QF2 Loss                              0.6337
trainer/Policy Loss                         -13.4686
trainer/Q1 Predictions Mean                  12.8224
trainer/Q1 Predictions Std                    8.08795
trainer/Q1 Predictions Max                   40.2459
trainer/Q1 Predictions Min                   -1.19225
trainer/Q2 Predictions Mean                  12.8221
trainer/Q2 Predictions Std                    8.08921
trainer/Q2 Predictions Max                   40.253
trainer/Q2 Predictions Min                   -1.39786
trainer/Q Targets Mean                       12.8152
trainer/Q Targets Std                         8.12348
trainer/Q Targets Max                        41.3174
trainer/Q Targets Min                        -1.77718
trainer/Bellman Errors 1 Mean                 0.652081
trainer/Bellman Errors 1 Std                  2.87103
trainer/Bellman Errors 1 Max                 58.7318
trainer/Bellman Errors 1 Min                  4.45652e-09
trainer/Bellman Errors 2 Mean                 0.6337
trainer/Bellman Errors 2 Std                  2.81913
trainer/Bellman Errors 2 Max                 57.356
trainer/Bellman Errors 2 Min                  3.61074e-08
trainer/Policy Action Mean                    0.485842
trainer/Policy Action Std                     0.731602
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     188000
expl/num paths total                       4700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.245928
expl/Rewards Std                              0.431951
expl/Rewards Max                              1.57074
expl/Rewards Min                              0
expl/Returns Mean                             9.83713
expl/Returns Std                             11.0843
expl/Returns Max                             40.0346
expl/Returns Min                              0
expl/Actions Mean                             0.476998
expl/Actions Std                              0.740749
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          9.83713
expl/env_infos/final/reward_dist Mean         0.147842
expl/env_infos/final/reward_dist Std          0.443018
expl/env_infos/final/reward_dist Max          1.57074
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000467516
expl/env_infos/initial/reward_dist Std        0.00182963
expl/env_infos/initial/reward_dist Max        0.0117264
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.245928
expl/env_infos/reward_dist Std                0.431951
expl/env_infos/reward_dist Max                1.57074
expl/env_infos/reward_dist Min                0
eval/num steps total                      37600
eval/num paths total                        940
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.164332
eval/Rewards Std                              0.338257
eval/Rewards Max                              1.2956
eval/Rewards Min                              0
eval/Returns Mean                             6.5733
eval/Returns Std                              6.57883
eval/Returns Max                             14.572
eval/Returns Min                              0
eval/Actions Mean                             0.511737
eval/Actions Std                              0.764654
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          6.5733
eval/env_infos/final/reward_dist Mean         0
eval/env_infos/final/reward_dist Std          0
eval/env_infos/final/reward_dist Max          0
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00121434
eval/env_infos/initial/reward_dist Std        0.00322575
eval/env_infos/initial/reward_dist Max        0.0108188
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.164332
eval/env_infos/reward_dist Std                0.338257
eval/env_infos/reward_dist Max                1.2956
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00578571
time/evaluation sampling (s)                  3.49005
time/exploration sampling (s)                17.7885
time/logging (s)                              0.00532341
time/saving (s)                               0.00237175
time/training (s)                             4.56434
time/epoch (s)                               25.8564
time/total (s)                             2369.63
Epoch                                        93
---------------------------------------  ----------------
2023-08-05 01:01:07.372915 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 94 finished
---------------------------------------  ----------------
epoch                                        94
replay_buffer/size                       190000
trainer/QF1 Loss                              0.613448
trainer/QF2 Loss                              0.592534
trainer/Policy Loss                         -13.5516
trainer/Q1 Predictions Mean                  12.7991
trainer/Q1 Predictions Std                    8.17684
trainer/Q1 Predictions Max                   39.998
trainer/Q1 Predictions Min                   -1.64472
trainer/Q2 Predictions Mean                  12.7751
trainer/Q2 Predictions Std                    8.17268
trainer/Q2 Predictions Max                   40.2147
trainer/Q2 Predictions Min                   -1.17617
trainer/Q Targets Mean                       12.7327
trainer/Q Targets Std                         8.20332
trainer/Q Targets Max                        41.3782
trainer/Q Targets Min                        -2.22006
trainer/Bellman Errors 1 Mean                 0.613448
trainer/Bellman Errors 1 Std                  2.50361
trainer/Bellman Errors 1 Max                 49.2119
trainer/Bellman Errors 1 Min                  2.5517e-10
trainer/Bellman Errors 2 Mean                 0.592534
trainer/Bellman Errors 2 Std                  2.4036
trainer/Bellman Errors 2 Max                 46.8158
trainer/Bellman Errors 2 Min                  9.69572e-09
trainer/Policy Action Mean                    0.486549
trainer/Policy Action Std                     0.731957
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     190000
expl/num paths total                       4750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.283468
expl/Rewards Std                              0.468226
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            11.3387
expl/Returns Std                             12.1399
expl/Returns Max                             40.5392
expl/Returns Min                              0
expl/Actions Mean                             0.47657
expl/Actions Std                              0.742613
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         11.3387
expl/env_infos/final/reward_dist Mean         0.188875
expl/env_infos/final/reward_dist Std          0.509246
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00139307
expl/env_infos/initial/reward_dist Std        0.00314645
expl/env_infos/initial/reward_dist Max        0.0126945
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.283468
expl/env_infos/reward_dist Std                0.468226
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      38000
eval/num paths total                        950
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.222101
eval/Rewards Std                              0.373428
eval/Rewards Max                              1.29198
eval/Rewards Min                              0
eval/Returns Mean                             8.88405
eval/Returns Std                              5.81506
eval/Returns Max                             13.5633
eval/Returns Min                              0.00224928
eval/Actions Mean                             0.432147
eval/Actions Std                              0.791293
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          8.88405
eval/env_infos/final/reward_dist Mean         0.000169911
eval/env_infos/final/reward_dist Std          0.000439058
eval/env_infos/final/reward_dist Max          0.00147932
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00137703
eval/env_infos/initial/reward_dist Std        0.00275829
eval/env_infos/initial/reward_dist Max        0.00722669
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.222101
eval/env_infos/reward_dist Std                0.373428
eval/env_infos/reward_dist Max                1.29198
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584167
time/evaluation sampling (s)                  3.415
time/exploration sampling (s)                17.6448
time/logging (s)                              0.00532737
time/saving (s)                               0.00239139
time/training (s)                             4.60361
time/epoch (s)                               25.677
time/total (s)                             2395.3
Epoch                                        94
---------------------------------------  ----------------
2023-08-05 01:01:33.429011 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 95 finished
---------------------------------------  ----------------
epoch                                        95
replay_buffer/size                       192000
trainer/QF1 Loss                              0.727305
trainer/QF2 Loss                              0.702692
trainer/Policy Loss                         -13.0984
trainer/Q1 Predictions Mean                  12.3568
trainer/Q1 Predictions Std                    7.95845
trainer/Q1 Predictions Max                   39.9182
trainer/Q1 Predictions Min                   -2.53258
trainer/Q2 Predictions Mean                  12.3478
trainer/Q2 Predictions Std                    7.96068
trainer/Q2 Predictions Max                   39.9998
trainer/Q2 Predictions Min                   -2.78943
trainer/Q Targets Mean                       12.3886
trainer/Q Targets Std                         8.01847
trainer/Q Targets Max                        40.2114
trainer/Q Targets Min                        -2.34182
trainer/Bellman Errors 1 Mean                 0.727305
trainer/Bellman Errors 1 Std                  3.29296
trainer/Bellman Errors 1 Max                 77.6269
trainer/Bellman Errors 1 Min                  3.16595e-09
trainer/Bellman Errors 2 Mean                 0.702692
trainer/Bellman Errors 2 Std                  3.17002
trainer/Bellman Errors 2 Max                 77.0786
trainer/Bellman Errors 2 Min                  4.58476e-09
trainer/Policy Action Mean                    0.483077
trainer/Policy Action Std                     0.737684
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     192000
expl/num paths total                       4800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.251419
expl/Rewards Std                              0.432803
expl/Rewards Max                              1.5707
expl/Rewards Min                              0
expl/Returns Mean                            10.0568
expl/Returns Std                             10.6622
expl/Returns Max                             41.1434
expl/Returns Min                              0
expl/Actions Mean                             0.482814
expl/Actions Std                              0.734964
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         10.0568
expl/env_infos/final/reward_dist Mean         0.122335
expl/env_infos/final/reward_dist Std          0.413703
expl/env_infos/final/reward_dist Max          1.57038
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000756574
expl/env_infos/initial/reward_dist Std        0.00226249
expl/env_infos/initial/reward_dist Max        0.0129752
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.251419
expl/env_infos/reward_dist Std                0.432803
expl/env_infos/reward_dist Max                1.5707
expl/env_infos/reward_dist Min                0
eval/num steps total                      38400
eval/num paths total                        960
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.325504
eval/Rewards Std                              0.516384
eval/Rewards Max                              1.56973
eval/Rewards Min                              0
eval/Returns Mean                            13.0201
eval/Returns Std                             14.5508
eval/Returns Max                             41.4932
eval/Returns Min                              0.00680895
eval/Actions Mean                             0.466552
eval/Actions Std                              0.780651
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         13.0201
eval/env_infos/final/reward_dist Mean         0.313982
eval/env_infos/final/reward_dist Std          0.62766
eval/env_infos/final/reward_dist Max          1.56973
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00215948
eval/env_infos/initial/reward_dist Std        0.00345754
eval/env_infos/initial/reward_dist Max        0.00925379
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.325504
eval/env_infos/reward_dist Std                0.516384
eval/env_infos/reward_dist Max                1.56973
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00580541
time/evaluation sampling (s)                  3.50006
time/exploration sampling (s)                18.1212
time/logging (s)                              0.00537751
time/saving (s)                               0.0023341
time/training (s)                             4.4189
time/epoch (s)                               26.0536
time/total (s)                             2421.36
Epoch                                        95
---------------------------------------  ----------------
2023-08-05 01:01:59.658523 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 96 finished
---------------------------------------  ----------------
epoch                                        96
replay_buffer/size                       194000
trainer/QF1 Loss                              0.689828
trainer/QF2 Loss                              0.67092
trainer/Policy Loss                         -13.1015
trainer/Q1 Predictions Mean                  12.4227
trainer/Q1 Predictions Std                    7.86581
trainer/Q1 Predictions Max                   39.832
trainer/Q1 Predictions Min                   -1.70442
trainer/Q2 Predictions Mean                  12.4229
trainer/Q2 Predictions Std                    7.86603
trainer/Q2 Predictions Max                   39.7681
trainer/Q2 Predictions Min                   -1.73861
trainer/Q Targets Mean                       12.4144
trainer/Q Targets Std                         7.92161
trainer/Q Targets Max                        40.2373
trainer/Q Targets Min                        -1.47208
trainer/Bellman Errors 1 Mean                 0.689828
trainer/Bellman Errors 1 Std                  3.11131
trainer/Bellman Errors 1 Max                 76.5086
trainer/Bellman Errors 1 Min                  2.07805e-07
trainer/Bellman Errors 2 Mean                 0.67092
trainer/Bellman Errors 2 Std                  3.0766
trainer/Bellman Errors 2 Max                 75.3969
trainer/Bellman Errors 2 Min                  2.98093e-09
trainer/Policy Action Mean                    0.488865
trainer/Policy Action Std                     0.728476
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     194000
expl/num paths total                       4850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.322054
expl/Rewards Std                              0.472543
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            12.8822
expl/Returns Std                             10.9076
expl/Returns Max                             40.4664
expl/Returns Min                              0
expl/Actions Mean                             0.499735
expl/Actions Std                              0.704782
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.8822
expl/env_infos/final/reward_dist Mean         0.215724
expl/env_infos/final/reward_dist Std          0.534725
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00194911
expl/env_infos/initial/reward_dist Std        0.00435772
expl/env_infos/initial/reward_dist Max        0.0191283
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.322054
expl/env_infos/reward_dist Std                0.472543
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      38800
eval/num paths total                        970
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.355147
eval/Rewards Std                              0.506028
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            14.2059
eval/Returns Std                             13.3015
eval/Returns Max                             40.1909
eval/Returns Min                              0
eval/Actions Mean                             0.453038
eval/Actions Std                              0.783216
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         14.2059
eval/env_infos/final/reward_dist Mean         0.292847
eval/env_infos/final/reward_dist Std          0.587297
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00160613
eval/env_infos/initial/reward_dist Std        0.00349124
eval/env_infos/initial/reward_dist Max        0.0110885
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.355147
eval/env_infos/reward_dist Std                0.506028
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00572241
time/evaluation sampling (s)                  3.39596
time/exploration sampling (s)                17.8813
time/logging (s)                              0.00784402
time/saving (s)                               0.00326225
time/training (s)                             4.9351
time/epoch (s)                               26.2292
time/total (s)                             2447.59
Epoch                                        96
---------------------------------------  ----------------
2023-08-05 01:02:26.206762 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 97 finished
---------------------------------------  ----------------
epoch                                        97
replay_buffer/size                       196000
trainer/QF1 Loss                              0.6521
trainer/QF2 Loss                              0.643435
trainer/Policy Loss                         -12.7959
trainer/Q1 Predictions Mean                  12.0799
trainer/Q1 Predictions Std                    7.92627
trainer/Q1 Predictions Max                   39.9009
trainer/Q1 Predictions Min                   -5.62664
trainer/Q2 Predictions Mean                  12.0579
trainer/Q2 Predictions Std                    7.91393
trainer/Q2 Predictions Max                   39.8823
trainer/Q2 Predictions Min                   -5.49692
trainer/Q Targets Mean                       12.0387
trainer/Q Targets Std                         7.96863
trainer/Q Targets Max                        41.2506
trainer/Q Targets Min                        -4.5862
trainer/Bellman Errors 1 Mean                 0.6521
trainer/Bellman Errors 1 Std                  3.1949
trainer/Bellman Errors 1 Max                 82.364
trainer/Bellman Errors 1 Min                  1.16239e-07
trainer/Bellman Errors 2 Mean                 0.643435
trainer/Bellman Errors 2 Std                  3.17948
trainer/Bellman Errors 2 Max                 87.0121
trainer/Bellman Errors 2 Min                  7.23267e-08
trainer/Policy Action Mean                    0.483175
trainer/Policy Action Std                     0.738214
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     196000
expl/num paths total                       4900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.201593
expl/Rewards Std                              0.393948
expl/Rewards Max                              1.5707
expl/Rewards Min                              0
expl/Returns Mean                             8.06371
expl/Returns Std                             10.0866
expl/Returns Max                             42.2731
expl/Returns Min                              0
expl/Actions Mean                             0.431842
expl/Actions Std                              0.778752
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.06371
expl/env_infos/final/reward_dist Mean         0.0898764
expl/env_infos/final/reward_dist Std          0.355163
expl/env_infos/final/reward_dist Max          1.5707
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00075152
expl/env_infos/initial/reward_dist Std        0.00250646
expl/env_infos/initial/reward_dist Max        0.0128179
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.201593
expl/env_infos/reward_dist Std                0.393948
expl/env_infos/reward_dist Max                1.5707
expl/env_infos/reward_dist Min                0
eval/num steps total                      39200
eval/num paths total                        980
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.279801
eval/Rewards Std                              0.433576
eval/Rewards Max                              1.37304
eval/Rewards Min                              0
eval/Returns Mean                            11.192
eval/Returns Std                              9.8485
eval/Returns Max                             35.274
eval/Returns Min                              0
eval/Actions Mean                             0.469384
eval/Actions Std                              0.765813
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.192
eval/env_infos/final/reward_dist Mean         0.137405
eval/env_infos/final/reward_dist Std          0.411877
eval/env_infos/final/reward_dist Max          1.37304
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00336546
eval/env_infos/initial/reward_dist Std        0.00673707
eval/env_infos/initial/reward_dist Max        0.0174709
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.279801
eval/env_infos/reward_dist Std                0.433576
eval/env_infos/reward_dist Max                1.37304
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00592043
time/evaluation sampling (s)                  3.51901
time/exploration sampling (s)                18.154
time/logging (s)                              0.00530582
time/saving (s)                               0.00235947
time/training (s)                             4.85477
time/epoch (s)                               26.5414
time/total (s)                             2474.14
Epoch                                        97
---------------------------------------  ----------------
2023-08-05 01:02:52.614135 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 98 finished
---------------------------------------  ----------------
epoch                                        98
replay_buffer/size                       198000
trainer/QF1 Loss                              0.762826
trainer/QF2 Loss                              0.757615
trainer/Policy Loss                         -13.0526
trainer/Q1 Predictions Mean                  12.2694
trainer/Q1 Predictions Std                    8.10733
trainer/Q1 Predictions Max                   39.5893
trainer/Q1 Predictions Min                   -7.04873
trainer/Q2 Predictions Mean                  12.2602
trainer/Q2 Predictions Std                    8.10932
trainer/Q2 Predictions Max                   39.8108
trainer/Q2 Predictions Min                   -6.86121
trainer/Q Targets Mean                       12.2495
trainer/Q Targets Std                         8.15331
trainer/Q Targets Max                        40.1746
trainer/Q Targets Min                        -5.94516
trainer/Bellman Errors 1 Mean                 0.762826
trainer/Bellman Errors 1 Std                  3.92833
trainer/Bellman Errors 1 Max                 65.6395
trainer/Bellman Errors 1 Min                  2.14297e-08
trainer/Bellman Errors 2 Mean                 0.757615
trainer/Bellman Errors 2 Std                  4.01611
trainer/Bellman Errors 2 Max                 67.1154
trainer/Bellman Errors 2 Min                  8.77941e-09
trainer/Policy Action Mean                    0.487703
trainer/Policy Action Std                     0.736663
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     198000
expl/num paths total                       4950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.224369
expl/Rewards Std                              0.401163
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                             8.97476
expl/Returns Std                              9.45657
expl/Returns Max                             39.4194
expl/Returns Min                              0
expl/Actions Mean                             0.473251
expl/Actions Std                              0.747717
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.97476
expl/env_infos/final/reward_dist Mean         0.0908873
expl/env_infos/final/reward_dist Std          0.357553
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000471391
expl/env_infos/initial/reward_dist Std        0.00195514
expl/env_infos/initial/reward_dist Max        0.0114019
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.224369
expl/env_infos/reward_dist Std                0.401163
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      39600
eval/num paths total                        990
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.218121
eval/Rewards Std                              0.406762
eval/Rewards Max                              1.32813
eval/Rewards Min                              0
eval/Returns Mean                             8.72483
eval/Returns Std                             10.9956
eval/Returns Max                             36.4098
eval/Returns Min                              0
eval/Actions Mean                             0.538556
eval/Actions Std                              0.741549
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          8.72483
eval/env_infos/final/reward_dist Mean         0.133136
eval/env_infos/final/reward_dist Std          0.39833
eval/env_infos/final/reward_dist Max          1.32813
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.218121
eval/env_infos/reward_dist Std                0.406762
eval/env_infos/reward_dist Max                1.32813
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00579871
time/evaluation sampling (s)                  3.48812
time/exploration sampling (s)                18.2428
time/logging (s)                              0.00745204
time/saving (s)                               0.00274195
time/training (s)                             4.65998
time/epoch (s)                               26.4069
time/total (s)                             2500.54
Epoch                                        98
---------------------------------------  ----------------
2023-08-05 01:03:18.638914 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 99 finished
---------------------------------------  ----------------
epoch                                        99
replay_buffer/size                       200000
trainer/QF1 Loss                              0.766311
trainer/QF2 Loss                              0.752169
trainer/Policy Loss                         -12.8163
trainer/Q1 Predictions Mean                  12.0988
trainer/Q1 Predictions Std                    7.97243
trainer/Q1 Predictions Max                   38.5887
trainer/Q1 Predictions Min                   -2.83422
trainer/Q2 Predictions Mean                  12.0948
trainer/Q2 Predictions Std                    7.96557
trainer/Q2 Predictions Max                   38.9344
trainer/Q2 Predictions Min                   -2.71599
trainer/Q Targets Mean                       11.9969
trainer/Q Targets Std                         8.00188
trainer/Q Targets Max                        39.457
trainer/Q Targets Min                        -2.72538
trainer/Bellman Errors 1 Mean                 0.766311
trainer/Bellman Errors 1 Std                  3.95707
trainer/Bellman Errors 1 Max                 80.8278
trainer/Bellman Errors 1 Min                  5.25324e-09
trainer/Bellman Errors 2 Mean                 0.752169
trainer/Bellman Errors 2 Std                  3.9244
trainer/Bellman Errors 2 Max                 80.5739
trainer/Bellman Errors 2 Min                  1.30967e-08
trainer/Policy Action Mean                    0.493701
trainer/Policy Action Std                     0.735627
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     200000
expl/num paths total                       5000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.262933
expl/Rewards Std                              0.418861
expl/Rewards Max                              1.56748
expl/Rewards Min                              0
expl/Returns Mean                            10.5173
expl/Returns Std                              9.01746
expl/Returns Max                             41.0046
expl/Returns Min                              0
expl/Actions Mean                             0.509878
expl/Actions Std                              0.710424
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         10.5173
expl/env_infos/final/reward_dist Mean         0.0893385
expl/env_infos/final/reward_dist Std          0.353949
expl/env_infos/final/reward_dist Max          1.56748
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000260552
expl/env_infos/initial/reward_dist Std        0.00159601
expl/env_infos/initial/reward_dist Max        0.0113043
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.262933
expl/env_infos/reward_dist Std                0.418861
expl/env_infos/reward_dist Max                1.56748
expl/env_infos/reward_dist Min                0
eval/num steps total                      40000
eval/num paths total                       1000
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.193131
eval/Rewards Std                              0.415396
eval/Rewards Max                              1.5706
eval/Rewards Min                              0
eval/Returns Mean                             7.72522
eval/Returns Std                             12.1595
eval/Returns Max                             40.2681
eval/Returns Min                              0
eval/Actions Mean                             0.530368
eval/Actions Std                              0.757151
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          7.72522
eval/env_infos/final/reward_dist Mean         0.15731
eval/env_infos/final/reward_dist Std          0.471098
eval/env_infos/final/reward_dist Max          1.5706
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000887415
eval/env_infos/initial/reward_dist Std        0.00168347
eval/env_infos/initial/reward_dist Max        0.00532477
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.193131
eval/env_infos/reward_dist Std                0.415396
eval/env_infos/reward_dist Max                1.5706
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588937
time/evaluation sampling (s)                  3.86352
time/exploration sampling (s)                17.7268
time/logging (s)                              0.0053132
time/saving (s)                               0.00233031
time/training (s)                             4.41449
time/epoch (s)                               26.0184
time/total (s)                             2526.57
Epoch                                        99
---------------------------------------  ----------------
2023-08-05 01:03:45.068396 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 100 finished
---------------------------------------  ----------------
epoch                                       100
replay_buffer/size                       202000
trainer/QF1 Loss                              0.629016
trainer/QF2 Loss                              0.608886
trainer/Policy Loss                         -12.3903
trainer/Q1 Predictions Mean                  11.672
trainer/Q1 Predictions Std                    7.85036
trainer/Q1 Predictions Max                   38.7376
trainer/Q1 Predictions Min                   -4.862
trainer/Q2 Predictions Mean                  11.6732
trainer/Q2 Predictions Std                    7.86075
trainer/Q2 Predictions Max                   38.9987
trainer/Q2 Predictions Min                   -5.01974
trainer/Q Targets Mean                       11.6581
trainer/Q Targets Std                         7.89863
trainer/Q Targets Max                        39.3766
trainer/Q Targets Min                        -4.39561
trainer/Bellman Errors 1 Mean                 0.629016
trainer/Bellman Errors 1 Std                  3.20304
trainer/Bellman Errors 1 Max                 81.8995
trainer/Bellman Errors 1 Min                  6.11544e-09
trainer/Bellman Errors 2 Mean                 0.608886
trainer/Bellman Errors 2 Std                  3.17148
trainer/Bellman Errors 2 Max                 82.7284
trainer/Bellman Errors 2 Min                  2.26465e-07
trainer/Policy Action Mean                    0.494807
trainer/Policy Action Std                     0.733462
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     202000
expl/num paths total                       5050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.181016
expl/Rewards Std                              0.35109
expl/Rewards Max                              1.56914
expl/Rewards Min                              0
expl/Returns Mean                             7.24065
expl/Returns Std                              6.86145
expl/Returns Max                             29.6409
expl/Returns Min                              0
expl/Actions Mean                             0.461732
expl/Actions Std                              0.76121
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          7.24065
expl/env_infos/final/reward_dist Mean         0.0543429
expl/env_infos/final/reward_dist Std          0.26832
expl/env_infos/final/reward_dist Max          1.56914
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000694478
expl/env_infos/initial/reward_dist Std        0.00286436
expl/env_infos/initial/reward_dist Max        0.0144355
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.181016
expl/env_infos/reward_dist Std                0.35109
expl/env_infos/reward_dist Max                1.56914
expl/env_infos/reward_dist Min                0
eval/num steps total                      40400
eval/num paths total                       1010
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.212216
eval/Rewards Std                              0.361041
eval/Rewards Max                              1.22708
eval/Rewards Min                              0
eval/Returns Mean                             8.48863
eval/Returns Std                              5.54579
eval/Returns Max                             13.0774
eval/Returns Min                              0
eval/Actions Mean                             0.522081
eval/Actions Std                              0.738821
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          8.48863
eval/env_infos/final/reward_dist Mean         3.00386e-05
eval/env_infos/final/reward_dist Std          9.00948e-05
eval/env_infos/final/reward_dist Max          0.000300323
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000976335
eval/env_infos/initial/reward_dist Std        0.00197278
eval/env_infos/initial/reward_dist Max        0.00550986
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.212216
eval/env_infos/reward_dist Std                0.361041
eval/env_infos/reward_dist Max                1.22708
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00586425
time/evaluation sampling (s)                  4.04912
time/exploration sampling (s)                17.6828
time/logging (s)                              0.00546408
time/saving (s)                               0.00233769
time/training (s)                             4.68156
time/epoch (s)                               26.4271
time/total (s)                             2552.99
Epoch                                       100
---------------------------------------  ----------------
2023-08-05 01:04:10.860637 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 101 finished
---------------------------------------  ----------------
epoch                                       101
replay_buffer/size                       204000
trainer/QF1 Loss                              0.72972
trainer/QF2 Loss                              0.713803
trainer/Policy Loss                         -12.2331
trainer/Q1 Predictions Mean                  11.503
trainer/Q1 Predictions Std                    7.79787
trainer/Q1 Predictions Max                   37.5852
trainer/Q1 Predictions Min                   -9.36899
trainer/Q2 Predictions Mean                  11.508
trainer/Q2 Predictions Std                    7.80585
trainer/Q2 Predictions Max                   37.8832
trainer/Q2 Predictions Min                   -9.26661
trainer/Q Targets Mean                       11.4924
trainer/Q Targets Std                         7.84677
trainer/Q Targets Max                        38.1831
trainer/Q Targets Min                        -8.662
trainer/Bellman Errors 1 Mean                 0.72972
trainer/Bellman Errors 1 Std                  3.86796
trainer/Bellman Errors 1 Max                 97.0162
trainer/Bellman Errors 1 Min                  4.06837e-08
trainer/Bellman Errors 2 Mean                 0.713803
trainer/Bellman Errors 2 Std                  3.9513
trainer/Bellman Errors 2 Max                101.974
trainer/Bellman Errors 2 Min                  8.28123e-08
trainer/Policy Action Mean                    0.49713
trainer/Policy Action Std                     0.740534
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     204000
expl/num paths total                       5100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.176942
expl/Rewards Std                              0.360374
expl/Rewards Max                              1.56564
expl/Rewards Min                              0
expl/Returns Mean                             7.07767
expl/Returns Std                              8.70329
expl/Returns Max                             39.1435
expl/Returns Min                              0
expl/Actions Mean                             0.448974
expl/Actions Std                              0.776336
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          7.07767
expl/env_infos/final/reward_dist Mean         0.0591717
expl/env_infos/final/reward_dist Std          0.288136
expl/env_infos/final/reward_dist Max          1.56564
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000345845
expl/env_infos/initial/reward_dist Std        0.00188044
expl/env_infos/initial/reward_dist Max        0.0133064
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.176942
expl/env_infos/reward_dist Std                0.360374
expl/env_infos/reward_dist Max                1.56564
expl/env_infos/reward_dist Min                0
eval/num steps total                      40800
eval/num paths total                       1020
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.151224
eval/Rewards Std                              0.318588
eval/Rewards Max                              1.22765
eval/Rewards Min                              0
eval/Returns Mean                             6.04895
eval/Returns Std                              6.05377
eval/Returns Max                             13.1964
eval/Returns Min                              0.000786663
eval/Actions Mean                             0.450003
eval/Actions Std                              0.813522
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          6.04895
eval/env_infos/final/reward_dist Mean         0.00017993
eval/env_infos/final/reward_dist Std          0.000336149
eval/env_infos/final/reward_dist Max          0.00108014
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000638338
eval/env_infos/initial/reward_dist Std        0.00191501
eval/env_infos/initial/reward_dist Max        0.00638338
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.151224
eval/env_infos/reward_dist Std                0.318588
eval/env_infos/reward_dist Max                1.22765
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00570931
time/evaluation sampling (s)                  3.74624
time/exploration sampling (s)                17.4601
time/logging (s)                              0.00549869
time/saving (s)                               0.0024041
time/training (s)                             4.56961
time/epoch (s)                               25.7896
time/total (s)                             2578.79
Epoch                                       101
---------------------------------------  ----------------
2023-08-05 01:04:36.848583 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 102 finished
---------------------------------------  ----------------
epoch                                       102
replay_buffer/size                       206000
trainer/QF1 Loss                              0.819487
trainer/QF2 Loss                              0.801957
trainer/Policy Loss                         -12.2264
trainer/Q1 Predictions Mean                  11.3674
trainer/Q1 Predictions Std                    7.88973
trainer/Q1 Predictions Max                   37.0528
trainer/Q1 Predictions Min                   -5.68018
trainer/Q2 Predictions Mean                  11.375
trainer/Q2 Predictions Std                    7.89174
trainer/Q2 Predictions Max                   37.3247
trainer/Q2 Predictions Min                   -5.7337
trainer/Q Targets Mean                       11.4166
trainer/Q Targets Std                         7.96781
trainer/Q Targets Max                        37.8224
trainer/Q Targets Min                        -5.56473
trainer/Bellman Errors 1 Mean                 0.819487
trainer/Bellman Errors 1 Std                  4.58158
trainer/Bellman Errors 1 Max                 84.1042
trainer/Bellman Errors 1 Min                  3.15495e-08
trainer/Bellman Errors 2 Mean                 0.801957
trainer/Bellman Errors 2 Std                  4.68379
trainer/Bellman Errors 2 Max                 87.7985
trainer/Bellman Errors 2 Min                  3.28328e-10
trainer/Policy Action Mean                    0.490809
trainer/Policy Action Std                     0.741205
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     206000
expl/num paths total                       5150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.198593
expl/Rewards Std                              0.370695
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                             7.94372
expl/Returns Std                              8.26958
expl/Returns Max                             37.968
expl/Returns Min                              0
expl/Actions Mean                             0.512866
expl/Actions Std                              0.722407
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          7.94372
expl/env_infos/final/reward_dist Mean         0.0582742
expl/env_infos/final/reward_dist Std          0.284584
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000714669
expl/env_infos/initial/reward_dist Std        0.00268488
expl/env_infos/initial/reward_dist Max        0.0140813
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.198593
expl/env_infos/reward_dist Std                0.370695
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      41200
eval/num paths total                       1030
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.242298
eval/Rewards Std                              0.434202
eval/Rewards Max                              1.5708
eval/Rewards Min                              0
eval/Returns Mean                             9.69194
eval/Returns Std                             11.4251
eval/Returns Max                             39.9274
eval/Returns Min                              0.000223787
eval/Actions Mean                             0.521545
eval/Actions Std                              0.759066
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          9.69194
eval/env_infos/final/reward_dist Mean         0.15708
eval/env_infos/final/reward_dist Std          0.471239
eval/env_infos/final/reward_dist Max          1.5708
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00061386
eval/env_infos/initial/reward_dist Std        0.00184158
eval/env_infos/initial/reward_dist Max        0.0061386
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.242298
eval/env_infos/reward_dist Std                0.434202
eval/env_infos/reward_dist Max                1.5708
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0058888
time/evaluation sampling (s)                  4.14292
time/exploration sampling (s)                17.1943
time/logging (s)                              0.00546565
time/saving (s)                               0.00242586
time/training (s)                             4.63403
time/epoch (s)                               25.9851
time/total (s)                             2604.77
Epoch                                       102
---------------------------------------  ----------------
2023-08-05 01:05:02.363488 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 103 finished
---------------------------------------  ----------------
epoch                                       103
replay_buffer/size                       208000
trainer/QF1 Loss                              0.729929
trainer/QF2 Loss                              0.723836
trainer/Policy Loss                         -11.9093
trainer/Q1 Predictions Mean                  11.0512
trainer/Q1 Predictions Std                    7.67993
trainer/Q1 Predictions Max                   37.1374
trainer/Q1 Predictions Min                   -5.05359
trainer/Q2 Predictions Mean                  11.049
trainer/Q2 Predictions Std                    7.68309
trainer/Q2 Predictions Max                   37.0048
trainer/Q2 Predictions Min                   -5.06775
trainer/Q Targets Mean                       11.1534
trainer/Q Targets Std                         7.74916
trainer/Q Targets Max                        38.5221
trainer/Q Targets Min                        -4.72645
trainer/Bellman Errors 1 Mean                 0.729929
trainer/Bellman Errors 1 Std                  3.9611
trainer/Bellman Errors 1 Max                 80.4859
trainer/Bellman Errors 1 Min                  3.28328e-10
trainer/Bellman Errors 2 Mean                 0.723836
trainer/Bellman Errors 2 Std                  4.03925
trainer/Bellman Errors 2 Max                 85.2049
trainer/Bellman Errors 2 Min                  3.28784e-09
trainer/Policy Action Mean                    0.487195
trainer/Policy Action Std                     0.742561
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     208000
expl/num paths total                       5200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.165918
expl/Rewards Std                              0.325806
expl/Rewards Max                              1.30051
expl/Rewards Min                              0
expl/Returns Mean                             6.63672
expl/Returns Std                              5.91542
expl/Returns Max                             15.3251
expl/Returns Min                              0
expl/Actions Mean                             0.452274
expl/Actions Std                              0.76925
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          6.63672
expl/env_infos/final/reward_dist Mean         0.000511714
expl/env_infos/final/reward_dist Std          0.00148163
expl/env_infos/final/reward_dist Max          0.00853821
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00147998
expl/env_infos/initial/reward_dist Std        0.00442829
expl/env_infos/initial/reward_dist Max        0.0209095
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.165918
expl/env_infos/reward_dist Std                0.325806
expl/env_infos/reward_dist Max                1.30051
expl/env_infos/reward_dist Min                0
eval/num steps total                      41600
eval/num paths total                       1040
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.139531
eval/Rewards Std                              0.30195
eval/Rewards Max                              1.13645
eval/Rewards Min                              0
eval/Returns Mean                             5.58126
eval/Returns Std                              5.54313
eval/Returns Max                             11.7525
eval/Returns Min                              0.000377768
eval/Actions Mean                             0.43011
eval/Actions Std                              0.813237
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          5.58126
eval/env_infos/final/reward_dist Mean         0
eval/env_infos/final/reward_dist Std          0
eval/env_infos/final/reward_dist Max          0
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.139531
eval/env_infos/reward_dist Std                0.30195
eval/env_infos/reward_dist Max                1.13645
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585422
time/evaluation sampling (s)                  3.84408
time/exploration sampling (s)                17.3197
time/logging (s)                              0.00549379
time/saving (s)                               0.00231559
time/training (s)                             4.33456
time/epoch (s)                               25.512
time/total (s)                             2630.29
Epoch                                       103
---------------------------------------  ----------------
2023-08-05 01:05:27.866181 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 104 finished
---------------------------------------  ----------------
epoch                                       104
replay_buffer/size                       210000
trainer/QF1 Loss                              0.826406
trainer/QF2 Loss                              0.813265
trainer/Policy Loss                         -11.896
trainer/Q1 Predictions Mean                  11.1077
trainer/Q1 Predictions Std                    7.6559
trainer/Q1 Predictions Max                   36.2625
trainer/Q1 Predictions Min                   -5.46206
trainer/Q2 Predictions Mean                  11.1155
trainer/Q2 Predictions Std                    7.66287
trainer/Q2 Predictions Max                   36.4235
trainer/Q2 Predictions Min                   -5.86261
trainer/Q Targets Mean                       11.1264
trainer/Q Targets Std                         7.70715
trainer/Q Targets Max                        37.0763
trainer/Q Targets Min                        -5.51736
trainer/Bellman Errors 1 Mean                 0.826406
trainer/Bellman Errors 1 Std                  4.70483
trainer/Bellman Errors 1 Max                 80.2905
trainer/Bellman Errors 1 Min                  1.06378e-07
trainer/Bellman Errors 2 Mean                 0.813265
trainer/Bellman Errors 2 Std                  4.76323
trainer/Bellman Errors 2 Max                 81.5663
trainer/Bellman Errors 2 Min                  3.72529e-09
trainer/Policy Action Mean                    0.483675
trainer/Policy Action Std                     0.744909
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     210000
expl/num paths total                       5250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.149892
expl/Rewards Std                              0.309958
expl/Rewards Max                              1.24073
expl/Rewards Min                              0
expl/Returns Mean                             5.99568
expl/Returns Std                              5.74973
expl/Returns Max                             13.702
expl/Returns Min                              0
expl/Actions Mean                             0.482938
expl/Actions Std                              0.750716
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          5.99568
expl/env_infos/final/reward_dist Mean         0.00088868
expl/env_infos/final/reward_dist Std          0.00192499
expl/env_infos/final/reward_dist Max          0.00831542
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000754373
expl/env_infos/initial/reward_dist Std        0.00268119
expl/env_infos/initial/reward_dist Max        0.0155498
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.149892
expl/env_infos/reward_dist Std                0.309958
expl/env_infos/reward_dist Max                1.24073
expl/env_infos/reward_dist Min                0
eval/num steps total                      42000
eval/num paths total                       1050
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.163569
eval/Rewards Std                              0.318834
eval/Rewards Max                              1.13104
eval/Rewards Min                              0
eval/Returns Mean                             6.54276
eval/Returns Std                              5.33863
eval/Returns Max                             11.5809
eval/Returns Min                              0
eval/Actions Mean                             0.473368
eval/Actions Std                              0.790275
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          6.54276
eval/env_infos/final/reward_dist Mean         0.000210854
eval/env_infos/final/reward_dist Std          0.000440335
eval/env_infos/final/reward_dist Max          0.00147793
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000903013
eval/env_infos/initial/reward_dist Std        0.00270904
eval/env_infos/initial/reward_dist Max        0.00903013
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.163569
eval/env_infos/reward_dist Std                0.318834
eval/env_infos/reward_dist Max                1.13104
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00573316
time/evaluation sampling (s)                  3.47146
time/exploration sampling (s)                17.4032
time/logging (s)                              0.0054155
time/saving (s)                               0.00235138
time/training (s)                             4.61158
time/epoch (s)                               25.4997
time/total (s)                             2655.79
Epoch                                       104
---------------------------------------  ----------------
2023-08-05 01:05:54.041765 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 105 finished
---------------------------------------  ----------------
epoch                                       105
replay_buffer/size                       212000
trainer/QF1 Loss                              0.900499
trainer/QF2 Loss                              0.89687
trainer/Policy Loss                         -11.567
trainer/Q1 Predictions Mean                  10.7393
trainer/Q1 Predictions Std                    7.57971
trainer/Q1 Predictions Max                   35.8201
trainer/Q1 Predictions Min                   -4.78546
trainer/Q2 Predictions Mean                  10.7305
trainer/Q2 Predictions Std                    7.57303
trainer/Q2 Predictions Max                   35.8922
trainer/Q2 Predictions Min                   -4.79509
trainer/Q Targets Mean                       10.715
trainer/Q Targets Std                         7.63527
trainer/Q Targets Max                        36.4424
trainer/Q Targets Min                        -5.2013
trainer/Bellman Errors 1 Mean                 0.900498
trainer/Bellman Errors 1 Std                  5.19372
trainer/Bellman Errors 1 Max                 91.5902
trainer/Bellman Errors 1 Min                  1.91613e-07
trainer/Bellman Errors 2 Mean                 0.89687
trainer/Bellman Errors 2 Std                  5.23664
trainer/Bellman Errors 2 Max                 92.7616
trainer/Bellman Errors 2 Min                  1.73204e-08
trainer/Policy Action Mean                    0.485032
trainer/Policy Action Std                     0.74934
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     212000
expl/num paths total                       5300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.151083
expl/Rewards Std                              0.309036
expl/Rewards Max                              1.25999
expl/Rewards Min                              0
expl/Returns Mean                             6.04331
expl/Returns Std                              5.59807
expl/Returns Max                             13.6387
expl/Returns Min                              0
expl/Actions Mean                             0.424041
expl/Actions Std                              0.789083
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          6.04331
expl/env_infos/final/reward_dist Mean         0.000171747
expl/env_infos/final/reward_dist Std          0.000792715
expl/env_infos/final/reward_dist Max          0.00552635
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000437837
expl/env_infos/initial/reward_dist Std        0.00156013
expl/env_infos/initial/reward_dist Max        0.00859565
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.151083
expl/env_infos/reward_dist Std                0.309036
expl/env_infos/reward_dist Max                1.25999
expl/env_infos/reward_dist Min                0
eval/num steps total                      42400
eval/num paths total                       1060
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.250345
eval/Rewards Std                              0.36495
eval/Rewards Max                              1.15206
eval/Rewards Min                              0
eval/Returns Mean                            10.0138
eval/Returns Std                              3.40206
eval/Returns Max                             11.9207
eval/Returns Min                              0.00863544
eval/Actions Mean                             0.539011
eval/Actions Std                              0.706623
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         10.0138
eval/env_infos/final/reward_dist Mean         1.03391e-08
eval/env_infos/final/reward_dist Std          2.39262e-08
eval/env_infos/final/reward_dist Max          7.86095e-08
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00305017
eval/env_infos/initial/reward_dist Std        0.00446384
eval/env_infos/initial/reward_dist Max        0.0120299
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.250345
eval/env_infos/reward_dist Std                0.36495
eval/env_infos/reward_dist Max                1.15206
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00566795
time/evaluation sampling (s)                  4.07049
time/exploration sampling (s)                17.5216
time/logging (s)                              0.00573345
time/saving (s)                               0.00243477
time/training (s)                             4.56721
time/epoch (s)                               26.1732
time/total (s)                             2681.96
Epoch                                       105
---------------------------------------  ----------------
2023-08-05 01:06:19.943571 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 106 finished
---------------------------------------  ----------------
epoch                                       106
replay_buffer/size                       214000
trainer/QF1 Loss                              0.868522
trainer/QF2 Loss                              0.862211
trainer/Policy Loss                         -11.2815
trainer/Q1 Predictions Mean                  10.4833
trainer/Q1 Predictions Std                    7.61219
trainer/Q1 Predictions Max                   34.6106
trainer/Q1 Predictions Min                   -4.61926
trainer/Q2 Predictions Mean                  10.478
trainer/Q2 Predictions Std                    7.61343
trainer/Q2 Predictions Max                   34.6433
trainer/Q2 Predictions Min                   -5.21654
trainer/Q Targets Mean                       10.4484
trainer/Q Targets Std                         7.6707
trainer/Q Targets Max                        34.9076
trainer/Q Targets Min                        -4.60677
trainer/Bellman Errors 1 Mean                 0.868522
trainer/Bellman Errors 1 Std                  5.10667
trainer/Bellman Errors 1 Max                106.764
trainer/Bellman Errors 1 Min                  2.9345e-08
trainer/Bellman Errors 2 Mean                 0.862211
trainer/Bellman Errors 2 Std                  5.20013
trainer/Bellman Errors 2 Max                110.087
trainer/Bellman Errors 2 Min                  6.66419e-07
trainer/Policy Action Mean                    0.472666
trainer/Policy Action Std                     0.758899
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     214000
expl/num paths total                       5350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.144315
expl/Rewards Std                              0.298832
expl/Rewards Max                              1.19561
expl/Rewards Min                              0
expl/Returns Mean                             5.77259
expl/Returns Std                              5.41677
expl/Returns Max                             12.9133
expl/Returns Min                              0
expl/Actions Mean                             0.44175
expl/Actions Std                              0.778261
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          5.77259
expl/env_infos/final/reward_dist Mean         0.0151682
expl/env_infos/final/reward_dist Std          0.102635
expl/env_infos/final/reward_dist Max          0.733575
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00039709
expl/env_infos/initial/reward_dist Std        0.00202269
expl/env_infos/initial/reward_dist Max        0.0137282
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.144315
expl/env_infos/reward_dist Std                0.298832
expl/env_infos/reward_dist Max                1.19561
expl/env_infos/reward_dist Min                0
eval/num steps total                      42800
eval/num paths total                       1070
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.0817743
eval/Rewards Std                              0.234082
eval/Rewards Max                              1.09173
eval/Rewards Min                              0
eval/Returns Mean                             3.27097
eval/Returns Std                              4.92452
eval/Returns Max                             11.196
eval/Returns Min                              0
eval/Actions Mean                             0.447902
eval/Actions Std                              0.842814
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          3.27097
eval/env_infos/final/reward_dist Mean         0.000399921
eval/env_infos/final/reward_dist Std          0.00104102
eval/env_infos/final/reward_dist Max          0.00349222
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000554444
eval/env_infos/initial/reward_dist Std        0.00166333
eval/env_infos/initial/reward_dist Max        0.00554444
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.0817743
eval/env_infos/reward_dist Std                0.234082
eval/env_infos/reward_dist Max                1.09173
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00658743
time/evaluation sampling (s)                  3.61037
time/exploration sampling (s)                17.6746
time/logging (s)                              0.00745475
time/saving (s)                               0.00272041
time/training (s)                             4.59884
time/epoch (s)                               25.9006
time/total (s)                             2707.87
Epoch                                       106
---------------------------------------  ----------------
2023-08-05 01:06:45.850388 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 107 finished
---------------------------------------  ----------------
epoch                                       107
replay_buffer/size                       216000
trainer/QF1 Loss                              0.837321
trainer/QF2 Loss                              0.823729
trainer/Policy Loss                         -11.059
trainer/Q1 Predictions Mean                  10.2585
trainer/Q1 Predictions Std                    7.34757
trainer/Q1 Predictions Max                   33.0551
trainer/Q1 Predictions Min                   -4.77534
trainer/Q2 Predictions Mean                  10.2497
trainer/Q2 Predictions Std                    7.34577
trainer/Q2 Predictions Max                   33.0403
trainer/Q2 Predictions Min                   -5.16453
trainer/Q Targets Mean                       10.1836
trainer/Q Targets Std                         7.39567
trainer/Q Targets Max                        33.7346
trainer/Q Targets Min                        -5.1278
trainer/Bellman Errors 1 Mean                 0.837321
trainer/Bellman Errors 1 Std                  5.24524
trainer/Bellman Errors 1 Max                110.422
trainer/Bellman Errors 1 Min                  1.6822e-08
trainer/Bellman Errors 2 Mean                 0.823729
trainer/Bellman Errors 2 Std                  5.38675
trainer/Bellman Errors 2 Max                110.392
trainer/Bellman Errors 2 Min                  3.4961e-09
trainer/Policy Action Mean                    0.468636
trainer/Policy Action Std                     0.75064
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     216000
expl/num paths total                       5400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.143465
expl/Rewards Std                              0.293208
expl/Rewards Max                              1.17095
expl/Rewards Min                              0
expl/Returns Mean                             5.73859
expl/Returns Std                              5.12176
expl/Returns Max                             12.6573
expl/Returns Min                              0
expl/Actions Mean                             0.491513
expl/Actions Std                              0.741699
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          5.73859
expl/env_infos/final/reward_dist Mean         0.000326445
expl/env_infos/final/reward_dist Std          0.0010187
expl/env_infos/final/reward_dist Max          0.0065192
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000711912
expl/env_infos/initial/reward_dist Std        0.00254282
expl/env_infos/initial/reward_dist Max        0.0136939
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.143465
expl/env_infos/reward_dist Std                0.293208
expl/env_infos/reward_dist Max                1.17095
expl/env_infos/reward_dist Min                0
eval/num steps total                      43200
eval/num paths total                       1080
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.123225
eval/Rewards Std                              0.274416
eval/Rewards Max                              1.09895
eval/Rewards Min                              0
eval/Returns Mean                             4.92899
eval/Returns Std                              4.92544
eval/Returns Max                             11.3029
eval/Returns Min                              0
eval/Actions Mean                             0.431915
eval/Actions Std                              0.823196
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          4.92899
eval/env_infos/final/reward_dist Mean         0.000406787
eval/env_infos/final/reward_dist Std          0.000668207
eval/env_infos/final/reward_dist Max          0.00174155
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000315647
eval/env_infos/initial/reward_dist Std        0.000946942
eval/env_infos/initial/reward_dist Max        0.00315647
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.123225
eval/env_infos/reward_dist Std                0.274416
eval/env_infos/reward_dist Max                1.09895
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591887
time/evaluation sampling (s)                  3.483
time/exploration sampling (s)                17.7955
time/logging (s)                              0.00534764
time/saving (s)                               0.00238923
time/training (s)                             4.60814
time/epoch (s)                               25.9003
time/total (s)                             2733.77
Epoch                                       107
---------------------------------------  ----------------
2023-08-05 01:07:11.361649 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 108 finished
---------------------------------------  ----------------
epoch                                       108
replay_buffer/size                       218000
trainer/QF1 Loss                              0.756118
trainer/QF2 Loss                              0.749048
trainer/Policy Loss                         -10.8245
trainer/Q1 Predictions Mean                   9.88771
trainer/Q1 Predictions Std                    7.07812
trainer/Q1 Predictions Max                   31.5344
trainer/Q1 Predictions Min                   -4.80878
trainer/Q2 Predictions Mean                   9.88735
trainer/Q2 Predictions Std                    7.07542
trainer/Q2 Predictions Max                   31.5404
trainer/Q2 Predictions Min                   -4.37953
trainer/Q Targets Mean                        9.87958
trainer/Q Targets Std                         7.1475
trainer/Q Targets Max                        31.626
trainer/Q Targets Min                        -4.06081
trainer/Bellman Errors 1 Mean                 0.756118
trainer/Bellman Errors 1 Std                  4.67295
trainer/Bellman Errors 1 Max                 97.8518
trainer/Bellman Errors 1 Min                  2.27374e-09
trainer/Bellman Errors 2 Mean                 0.749048
trainer/Bellman Errors 2 Std                  4.72485
trainer/Bellman Errors 2 Max                 98.3758
trainer/Bellman Errors 2 Min                  1.3661e-07
trainer/Policy Action Mean                    0.46256
trainer/Policy Action Std                     0.739875
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     218000
expl/num paths total                       5450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.158524
expl/Rewards Std                              0.322121
expl/Rewards Max                              1.3485
expl/Rewards Min                              0
expl/Returns Mean                             6.34098
expl/Returns Std                              6.72128
expl/Returns Max                             34.1198
expl/Returns Min                              0
expl/Actions Mean                             0.455192
expl/Actions Std                              0.756016
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          6.34098
expl/env_infos/final/reward_dist Mean         0.0272656
expl/env_infos/final/reward_dist Std          0.188752
expl/env_infos/final/reward_dist Max          1.3485
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00113834
expl/env_infos/initial/reward_dist Std        0.00349761
expl/env_infos/initial/reward_dist Max        0.0203735
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.158524
expl/env_infos/reward_dist Std                0.322121
expl/env_infos/reward_dist Max                1.3485
expl/env_infos/reward_dist Min                0
eval/num steps total                      43600
eval/num paths total                       1090
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.1567
eval/Rewards Std                              0.308316
eval/Rewards Max                              1.12067
eval/Rewards Min                              0
eval/Returns Mean                             6.26798
eval/Returns Std                              5.12314
eval/Returns Max                             11.2965
eval/Returns Min                              0.0041251
eval/Actions Mean                             0.485633
eval/Actions Std                              0.770781
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          6.26798
eval/env_infos/final/reward_dist Mean         0
eval/env_infos/final/reward_dist Std          0
eval/env_infos/final/reward_dist Max          0
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000175756
eval/env_infos/initial/reward_dist Std        0.000527268
eval/env_infos/initial/reward_dist Max        0.00175756
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.1567
eval/env_infos/reward_dist Std                0.308316
eval/env_infos/reward_dist Max                1.12067
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00814237
time/evaluation sampling (s)                  3.4952
time/exploration sampling (s)                17.4406
time/logging (s)                              0.0053696
time/saving (s)                               0.00244688
time/training (s)                             4.55684
time/epoch (s)                               25.5086
time/total (s)                             2759.28
Epoch                                       108
---------------------------------------  ----------------
2023-08-05 01:07:36.788324 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 109 finished
---------------------------------------  ----------------
epoch                                       109
replay_buffer/size                       220000
trainer/QF1 Loss                              0.774502
trainer/QF2 Loss                              0.764464
trainer/Policy Loss                         -10.7672
trainer/Q1 Predictions Mean                   9.81028
trainer/Q1 Predictions Std                    6.94015
trainer/Q1 Predictions Max                   30.8164
trainer/Q1 Predictions Min                   -3.82854
trainer/Q2 Predictions Mean                   9.8094
trainer/Q2 Predictions Std                    6.93273
trainer/Q2 Predictions Max                   30.5787
trainer/Q2 Predictions Min                   -3.31999
trainer/Q Targets Mean                        9.73884
trainer/Q Targets Std                         6.97242
trainer/Q Targets Max                        31.6136
trainer/Q Targets Min                        -3.72101
trainer/Bellman Errors 1 Mean                 0.774502
trainer/Bellman Errors 1 Std                  5.00634
trainer/Bellman Errors 1 Max                106.934
trainer/Bellman Errors 1 Min                  5.91399e-10
trainer/Bellman Errors 2 Mean                 0.764464
trainer/Bellman Errors 2 Std                  5.06068
trainer/Bellman Errors 2 Max                109.944
trainer/Bellman Errors 2 Min                  2.45927e-09
trainer/Policy Action Mean                    0.452633
trainer/Policy Action Std                     0.741845
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     220000
expl/num paths total                       5500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.219834
expl/Rewards Std                              0.415489
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                             8.79336
expl/Returns Std                             10.3893
expl/Returns Max                             39.9402
expl/Returns Min                              0
expl/Actions Mean                             0.44615
expl/Actions Std                              0.766651
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.79336
expl/env_infos/final/reward_dist Mean         0.145446
expl/env_infos/final/reward_dist Std          0.437848
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0013181
expl/env_infos/initial/reward_dist Std        0.00376653
expl/env_infos/initial/reward_dist Max        0.0169979
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.219834
expl/env_infos/reward_dist Std                0.415489
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      44000
eval/num paths total                       1100
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.378349
eval/Rewards Std                              0.481772
eval/Rewards Max                              1.5708
eval/Rewards Min                              0
eval/Returns Mean                            15.134
eval/Returns Std                              8.60682
eval/Returns Max                             40.8792
eval/Returns Min                             11.2506
eval/Actions Mean                             0.573742
eval/Actions Std                              0.667975
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         15.134
eval/env_infos/final/reward_dist Mean         0.15708
eval/env_infos/final/reward_dist Std          0.471239
eval/env_infos/final/reward_dist Max          1.5708
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00355778
eval/env_infos/initial/reward_dist Std        0.00496244
eval/env_infos/initial/reward_dist Max        0.0131298
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.378349
eval/env_infos/reward_dist Std                0.481772
eval/env_infos/reward_dist Max                1.5708
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00817407
time/evaluation sampling (s)                  3.35719
time/exploration sampling (s)                17.4711
time/logging (s)                              0.00534502
time/saving (s)                               0.0023439
time/training (s)                             4.57999
time/epoch (s)                               25.4241
time/total (s)                             2784.71
Epoch                                       109
---------------------------------------  ----------------
2023-08-05 01:08:02.054649 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 110 finished
---------------------------------------  ----------------
epoch                                       110
replay_buffer/size                       222000
trainer/QF1 Loss                              0.788574
trainer/QF2 Loss                              0.789811
trainer/Policy Loss                         -10.5781
trainer/Q1 Predictions Mean                   9.58156
trainer/Q1 Predictions Std                    6.85157
trainer/Q1 Predictions Max                   29.546
trainer/Q1 Predictions Min                   -4.8944
trainer/Q2 Predictions Mean                   9.57963
trainer/Q2 Predictions Std                    6.86309
trainer/Q2 Predictions Max                   29.5415
trainer/Q2 Predictions Min                   -5.92422
trainer/Q Targets Mean                        9.55909
trainer/Q Targets Std                         6.93526
trainer/Q Targets Max                        30.8358
trainer/Q Targets Min                        -5.93445
trainer/Bellman Errors 1 Mean                 0.788574
trainer/Bellman Errors 1 Std                  5.13289
trainer/Bellman Errors 1 Max                102.754
trainer/Bellman Errors 1 Min                  8.3819e-09
trainer/Bellman Errors 2 Mean                 0.789811
trainer/Bellman Errors 2 Std                  5.32457
trainer/Bellman Errors 2 Max                110.635
trainer/Bellman Errors 2 Min                  1.04128e-08
trainer/Policy Action Mean                    0.437698
trainer/Policy Action Std                     0.740821
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     222000
expl/num paths total                       5550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.291459
expl/Rewards Std                              0.45318
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            11.6584
expl/Returns Std                             10.3559
expl/Returns Max                             41.0384
expl/Returns Min                              0
expl/Actions Mean                             0.474062
expl/Actions Std                              0.730553
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         11.6584
expl/env_infos/final/reward_dist Mean         0.148773
expl/env_infos/final/reward_dist Std          0.447313
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00184071
expl/env_infos/initial/reward_dist Std        0.00424486
expl/env_infos/initial/reward_dist Max        0.0173855
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.291459
expl/env_infos/reward_dist Std                0.45318
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      44400
eval/num paths total                       1110
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.237893
eval/Rewards Std                              0.436091
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                             9.51571
eval/Returns Std                             10.3838
eval/Returns Max                             35.7871
eval/Returns Min                              0.00616348
eval/Actions Mean                             0.457554
eval/Actions Std                              0.784807
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          9.51571
eval/env_infos/final/reward_dist Mean         0.157176
eval/env_infos/final/reward_dist Std          0.471204
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000675342
eval/env_infos/initial/reward_dist Std        0.00202603
eval/env_infos/initial/reward_dist Max        0.00675342
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.237893
eval/env_infos/reward_dist Std                0.436091
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0059561
time/evaluation sampling (s)                  3.45105
time/exploration sampling (s)                17.1967
time/logging (s)                              0.00531871
time/saving (s)                               0.0023843
time/training (s)                             4.60222
time/epoch (s)                               25.2636
time/total (s)                             2809.97
Epoch                                       110
---------------------------------------  ----------------
2023-08-05 01:08:27.514479 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 111 finished
---------------------------------------  ----------------
epoch                                       111
replay_buffer/size                       224000
trainer/QF1 Loss                              0.912419
trainer/QF2 Loss                              0.896853
trainer/Policy Loss                         -10.8002
trainer/Q1 Predictions Mean                   9.57059
trainer/Q1 Predictions Std                    6.67506
trainer/Q1 Predictions Max                   28.6665
trainer/Q1 Predictions Min                   -4.15971
trainer/Q2 Predictions Mean                   9.5589
trainer/Q2 Predictions Std                    6.67521
trainer/Q2 Predictions Max                   28.7891
trainer/Q2 Predictions Min                   -4.18125
trainer/Q Targets Mean                        9.5628
trainer/Q Targets Std                         6.76992
trainer/Q Targets Max                        29.4153
trainer/Q Targets Min                        -3.73559
trainer/Bellman Errors 1 Mean                 0.912419
trainer/Bellman Errors 1 Std                  5.57769
trainer/Bellman Errors 1 Max                103.417
trainer/Bellman Errors 1 Min                  4.89526e-08
trainer/Bellman Errors 2 Mean                 0.896853
trainer/Bellman Errors 2 Std                  5.65623
trainer/Bellman Errors 2 Max                109.13
trainer/Bellman Errors 2 Min                  1.32609e-08
trainer/Policy Action Mean                    0.383941
trainer/Policy Action Std                     0.736733
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     224000
expl/num paths total                       5600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.122672
expl/Rewards Std                              0.3111
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                             4.90688
expl/Returns Std                              7.54015
expl/Returns Max                             39.7301
expl/Returns Min                              0
expl/Actions Mean                             0.273724
expl/Actions Std                              0.814095
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          4.90688
expl/env_infos/final/reward_dist Mean         0.0345575
expl/env_infos/final/reward_dist Std          0.220357
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000928372
expl/env_infos/initial/reward_dist Std        0.00320312
expl/env_infos/initial/reward_dist Max        0.0184292
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.122672
expl/env_infos/reward_dist Std                0.3111
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      44800
eval/num paths total                       1120
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.183656
eval/Rewards Std                              0.408101
eval/Rewards Max                              1.57062
eval/Rewards Min                              0
eval/Returns Mean                             7.34623
eval/Returns Std                             11.6103
eval/Returns Max                             38.5359
eval/Returns Min                              0
eval/Actions Mean                             0.283288
eval/Actions Std                              0.862679
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          7.34623
eval/env_infos/final/reward_dist Mean         0.158202
eval/env_infos/final/reward_dist Std          0.470818
eval/env_infos/final/reward_dist Max          1.57062
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.183656
eval/env_infos/reward_dist Std                0.408101
eval/env_infos/reward_dist Max                1.57062
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00597169
time/evaluation sampling (s)                  3.45898
time/exploration sampling (s)                17.2523
time/logging (s)                              0.00531848
time/saving (s)                               0.00231933
time/training (s)                             4.73235
time/epoch (s)                               25.4572
time/total (s)                             2835.43
Epoch                                       111
---------------------------------------  ----------------
2023-08-05 01:08:52.434193 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 112 finished
---------------------------------------  ----------------
epoch                                       112
replay_buffer/size                       226000
trainer/QF1 Loss                              0.734716
trainer/QF2 Loss                              0.728645
trainer/Policy Loss                         -10.5182
trainer/Q1 Predictions Mean                   9.26213
trainer/Q1 Predictions Std                    6.65124
trainer/Q1 Predictions Max                   29.0633
trainer/Q1 Predictions Min                   -5.1917
trainer/Q2 Predictions Mean                   9.25207
trainer/Q2 Predictions Std                    6.65488
trainer/Q2 Predictions Max                   29.1364
trainer/Q2 Predictions Min                   -5.11637
trainer/Q Targets Mean                        9.23051
trainer/Q Targets Std                         6.70534
trainer/Q Targets Max                        29.2445
trainer/Q Targets Min                        -5.6834
trainer/Bellman Errors 1 Mean                 0.734716
trainer/Bellman Errors 1 Std                  4.35727
trainer/Bellman Errors 1 Max                 91.65
trainer/Bellman Errors 1 Min                  6.72662e-09
trainer/Bellman Errors 2 Mean                 0.728645
trainer/Bellman Errors 2 Std                  4.43207
trainer/Bellman Errors 2 Max                 92.8609
trainer/Bellman Errors 2 Min                  7.4902e-09
trainer/Policy Action Mean                    0.408906
trainer/Policy Action Std                     0.713735
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     226000
expl/num paths total                       5650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.141693
expl/Rewards Std                              0.349799
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                             5.66772
expl/Returns Std                              9.42579
expl/Returns Max                             37.5113
expl/Returns Min                              0
expl/Actions Mean                             0.263782
expl/Actions Std                              0.824752
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          5.66772
expl/env_infos/final/reward_dist Mean         0.0943832
expl/env_infos/final/reward_dist Std          0.372676
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000291543
expl/env_infos/initial/reward_dist Std        0.00130792
expl/env_infos/initial/reward_dist Max        0.00830686
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.141693
expl/env_infos/reward_dist Std                0.349799
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      45200
eval/num paths total                       1130
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.0324185
eval/Rewards Std                              0.161123
eval/Rewards Max                              1.23318
eval/Rewards Min                              0
eval/Returns Mean                             1.29674
eval/Returns Std                              3.87762
eval/Returns Max                             12.9296
eval/Returns Min                              0
eval/Actions Mean                             0.168603
eval/Actions Std                              0.905906
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          1.29674
eval/env_infos/final/reward_dist Mean         0.000493788
eval/env_infos/final/reward_dist Std          0.00148136
eval/env_infos/final/reward_dist Max          0.00493788
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.0324185
eval/env_infos/reward_dist Std                0.161123
eval/env_infos/reward_dist Max                1.23318
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00602434
time/evaluation sampling (s)                  3.33488
time/exploration sampling (s)                16.6636
time/logging (s)                              0.00791085
time/saving (s)                               0.00333498
time/training (s)                             4.90384
time/epoch (s)                               24.9196
time/total (s)                             2860.35
Epoch                                       112
---------------------------------------  ----------------
2023-08-05 01:09:17.730305 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 113 finished
---------------------------------------  ----------------
epoch                                       113
replay_buffer/size                       228000
trainer/QF1 Loss                              0.707079
trainer/QF2 Loss                              0.695809
trainer/Policy Loss                         -10.039
trainer/Q1 Predictions Mean                   8.87572
trainer/Q1 Predictions Std                    6.65725
trainer/Q1 Predictions Max                   29.3969
trainer/Q1 Predictions Min                   -4.86475
trainer/Q2 Predictions Mean                   8.87645
trainer/Q2 Predictions Std                    6.67156
trainer/Q2 Predictions Max                   29.3539
trainer/Q2 Predictions Min                   -4.82535
trainer/Q Targets Mean                        8.89446
trainer/Q Targets Std                         6.72242
trainer/Q Targets Max                        29.8767
trainer/Q Targets Min                        -5.25113
trainer/Bellman Errors 1 Mean                 0.707079
trainer/Bellman Errors 1 Std                  4.51072
trainer/Bellman Errors 1 Max                110.392
trainer/Bellman Errors 1 Min                  7.09229e-08
trainer/Bellman Errors 2 Mean                 0.695809
trainer/Bellman Errors 2 Std                  4.71425
trainer/Bellman Errors 2 Max                121.226
trainer/Bellman Errors 2 Min                  5.98563e-09
trainer/Policy Action Mean                    0.411754
trainer/Policy Action Std                     0.720182
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     228000
expl/num paths total                       5700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.145606
expl/Rewards Std                              0.310654
expl/Rewards Max                              1.30363
expl/Rewards Min                              0
expl/Returns Mean                             5.82424
expl/Returns Std                              6.32091
expl/Returns Max                             15.6049
expl/Returns Min                              0
expl/Actions Mean                             0.281199
expl/Actions Std                              0.803662
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          5.82424
expl/env_infos/final/reward_dist Mean         0.000404878
expl/env_infos/final/reward_dist Std          0.00126946
expl/env_infos/final/reward_dist Max          0.00752475
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000856488
expl/env_infos/initial/reward_dist Std        0.00251401
expl/env_infos/initial/reward_dist Max        0.0148461
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.145606
expl/env_infos/reward_dist Std                0.310654
expl/env_infos/reward_dist Max                1.30363
expl/env_infos/reward_dist Min                0
eval/num steps total                      45600
eval/num paths total                       1140
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.226355
eval/Rewards Std                              0.394169
eval/Rewards Max                              1.32192
eval/Rewards Min                              0
eval/Returns Mean                             9.05419
eval/Returns Std                              9.86635
eval/Returns Max                             33.9313
eval/Returns Min                              0
eval/Actions Mean                             0.284977
eval/Actions Std                              0.8083
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          9.05419
eval/env_infos/final/reward_dist Mean         0.132247
eval/env_infos/final/reward_dist Std          0.396558
eval/env_infos/final/reward_dist Max          1.32192
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000186255
eval/env_infos/initial/reward_dist Std        0.000399038
eval/env_infos/initial/reward_dist Max        0.00125118
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.226355
eval/env_infos/reward_dist Std                0.394169
eval/env_infos/reward_dist Max                1.32192
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00816405
time/evaluation sampling (s)                  3.42827
time/exploration sampling (s)                17.2272
time/logging (s)                              0.00745426
time/saving (s)                               0.00269195
time/training (s)                             4.61724
time/epoch (s)                               25.291
time/total (s)                             2885.65
Epoch                                       113
---------------------------------------  ----------------
2023-08-05 01:09:43.363778 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 114 finished
---------------------------------------  ----------------
epoch                                       114
replay_buffer/size                       230000
trainer/QF1 Loss                              0.910215
trainer/QF2 Loss                              0.904222
trainer/Policy Loss                          -9.68004
trainer/Q1 Predictions Mean                   8.57089
trainer/Q1 Predictions Std                    6.81281
trainer/Q1 Predictions Max                   28.7441
trainer/Q1 Predictions Min                   -5.98328
trainer/Q2 Predictions Mean                   8.5695
trainer/Q2 Predictions Std                    6.80859
trainer/Q2 Predictions Max                   28.6983
trainer/Q2 Predictions Min                   -6.11797
trainer/Q Targets Mean                        8.54265
trainer/Q Targets Std                         6.86068
trainer/Q Targets Max                        29.1533
trainer/Q Targets Min                        -6.39807
trainer/Bellman Errors 1 Mean                 0.910215
trainer/Bellman Errors 1 Std                  5.61002
trainer/Bellman Errors 1 Max                104.943
trainer/Bellman Errors 1 Min                  2.21725e-09
trainer/Bellman Errors 2 Mean                 0.904222
trainer/Bellman Errors 2 Std                  5.81302
trainer/Bellman Errors 2 Max                108.053
trainer/Bellman Errors 2 Min                  4.40195e-10
trainer/Policy Action Mean                    0.417557
trainer/Policy Action Std                     0.728581
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     230000
expl/num paths total                       5750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.20047
expl/Rewards Std                              0.369712
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                             8.01879
expl/Returns Std                              8.06745
expl/Returns Max                             36.9385
expl/Returns Min                              0
expl/Actions Mean                             0.331634
expl/Actions Std                              0.776237
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.01879
expl/env_infos/final/reward_dist Mean         0.0894424
expl/env_infos/final/reward_dist Std          0.354507
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000819364
expl/env_infos/initial/reward_dist Std        0.00269715
expl/env_infos/initial/reward_dist Max        0.0149478
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.20047
expl/env_infos/reward_dist Std                0.369712
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      46000
eval/num paths total                       1150
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.180131
eval/Rewards Std                              0.333359
eval/Rewards Max                              1.20582
eval/Rewards Min                              0
eval/Returns Mean                             7.20523
eval/Returns Std                              5.88923
eval/Returns Max                             12.8307
eval/Returns Min                              0
eval/Actions Mean                             0.358975
eval/Actions Std                              0.775304
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          7.20523
eval/env_infos/final/reward_dist Mean         6.70228e-09
eval/env_infos/final/reward_dist Std          2.01068e-08
eval/env_infos/final/reward_dist Max          6.70228e-08
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000269379
eval/env_infos/initial/reward_dist Std        0.000808138
eval/env_infos/initial/reward_dist Max        0.00269379
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.180131
eval/env_infos/reward_dist Std                0.333359
eval/env_infos/reward_dist Max                1.20582
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00813389
time/evaluation sampling (s)                  3.47652
time/exploration sampling (s)                17.3881
time/logging (s)                              0.0079371
time/saving (s)                               0.00339906
time/training (s)                             4.74547
time/epoch (s)                               25.6296
time/total (s)                             2911.28
Epoch                                       114
---------------------------------------  ----------------
2023-08-05 01:10:09.688752 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 115 finished
---------------------------------------  ----------------
epoch                                       115
replay_buffer/size                       232000
trainer/QF1 Loss                              0.961338
trainer/QF2 Loss                              0.947241
trainer/Policy Loss                          -9.86526
trainer/Q1 Predictions Mean                   8.7123
trainer/Q1 Predictions Std                    6.65566
trainer/Q1 Predictions Max                   28.0394
trainer/Q1 Predictions Min                   -7.40875
trainer/Q2 Predictions Mean                   8.70292
trainer/Q2 Predictions Std                    6.64113
trainer/Q2 Predictions Max                   28.1231
trainer/Q2 Predictions Min                   -6.90168
trainer/Q Targets Mean                        8.66721
trainer/Q Targets Std                         6.73241
trainer/Q Targets Max                        28.4898
trainer/Q Targets Min                        -7.96611
trainer/Bellman Errors 1 Mean                 0.961338
trainer/Bellman Errors 1 Std                  5.92509
trainer/Bellman Errors 1 Max                108.272
trainer/Bellman Errors 1 Min                  1.22382e-08
trainer/Bellman Errors 2 Mean                 0.947241
trainer/Bellman Errors 2 Std                  6.07723
trainer/Bellman Errors 2 Max                107.689
trainer/Bellman Errors 2 Min                  6.14818e-10
trainer/Policy Action Mean                    0.43555
trainer/Policy Action Std                     0.712826
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     232000
expl/num paths total                       5800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.249639
expl/Rewards Std                              0.380247
expl/Rewards Max                              1.56735
expl/Rewards Min                              0
expl/Returns Mean                             9.98557
expl/Returns Std                              5.98943
expl/Returns Max                             33.3752
expl/Returns Min                              0
expl/Actions Mean                             0.383167
expl/Actions Std                              0.739485
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          9.98557
expl/env_infos/final/reward_dist Mean         0.0874429
expl/env_infos/final/reward_dist Std          0.347603
expl/env_infos/final/reward_dist Max          1.56735
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000759862
expl/env_infos/initial/reward_dist Std        0.00276001
expl/env_infos/initial/reward_dist Max        0.0141279
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.249639
expl/env_infos/reward_dist Std                0.380247
expl/env_infos/reward_dist Max                1.56735
expl/env_infos/reward_dist Min                0
eval/num steps total                      46400
eval/num paths total                       1160
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.117284
eval/Rewards Std                              0.276303
eval/Rewards Max                              1.18105
eval/Rewards Min                              0
eval/Returns Mean                             4.69135
eval/Returns Std                              5.71289
eval/Returns Max                             12.4252
eval/Returns Min                              0
eval/Actions Mean                             0.261785
eval/Actions Std                              0.824481
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          4.69135
eval/env_infos/final/reward_dist Mean         0.00145463
eval/env_infos/final/reward_dist Std          0.00269721
eval/env_infos/final/reward_dist Max          0.00831611
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00263742
eval/env_infos/initial/reward_dist Std        0.00625519
eval/env_infos/initial/reward_dist Max        0.0207049
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.117284
eval/env_infos/reward_dist Std                0.276303
eval/env_infos/reward_dist Max                1.18105
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00809817
time/evaluation sampling (s)                  3.49522
time/exploration sampling (s)                17.5289
time/logging (s)                              0.00791416
time/saving (s)                               0.0032968
time/training (s)                             5.27699
time/epoch (s)                               26.3204
time/total (s)                             2937.6
Epoch                                       115
---------------------------------------  ----------------
2023-08-05 01:10:34.888037 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 116 finished
---------------------------------------  ----------------
epoch                                       116
replay_buffer/size                       234000
trainer/QF1 Loss                              0.926146
trainer/QF2 Loss                              0.938598
trainer/Policy Loss                          -9.49607
trainer/Q1 Predictions Mean                   8.33524
trainer/Q1 Predictions Std                    6.63324
trainer/Q1 Predictions Max                   27.3749
trainer/Q1 Predictions Min                   -7.545
trainer/Q2 Predictions Mean                   8.32901
trainer/Q2 Predictions Std                    6.63031
trainer/Q2 Predictions Max                   27.361
trainer/Q2 Predictions Min                   -7.14657
trainer/Q Targets Mean                        8.26177
trainer/Q Targets Std                         6.69791
trainer/Q Targets Max                        27.9717
trainer/Q Targets Min                        -7.47623
trainer/Bellman Errors 1 Mean                 0.926146
trainer/Bellman Errors 1 Std                  5.95982
trainer/Bellman Errors 1 Max                105.604
trainer/Bellman Errors 1 Min                  2.04636e-10
trainer/Bellman Errors 2 Mean                 0.938598
trainer/Bellman Errors 2 Std                  6.18745
trainer/Bellman Errors 2 Max                112.845
trainer/Bellman Errors 2 Min                  1.9782e-07
trainer/Policy Action Mean                    0.438563
trainer/Policy Action Std                     0.713455
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     234000
expl/num paths total                       5850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.176836
expl/Rewards Std                              0.339064
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                             7.07346
expl/Returns Std                              6.80154
expl/Returns Max                             33.8398
expl/Returns Min                              0
expl/Actions Mean                             0.366938
expl/Actions Std                              0.759124
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          7.07346
expl/env_infos/final/reward_dist Mean         0.0825632
expl/env_infos/final/reward_dist Std          0.332065
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00065223
expl/env_infos/initial/reward_dist Std        0.0028508
expl/env_infos/initial/reward_dist Max        0.0158106
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.176836
expl/env_infos/reward_dist Std                0.339064
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      46800
eval/num paths total                       1170
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.167678
eval/Rewards Std                              0.320246
eval/Rewards Max                              1.18544
eval/Rewards Min                              0
eval/Returns Mean                             6.70711
eval/Returns Std                              5.42957
eval/Returns Max                             11.4553
eval/Returns Min                              0.000601647
eval/Actions Mean                             0.480413
eval/Actions Std                              0.735678
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          6.70711
eval/env_infos/final/reward_dist Mean         0.000866303
eval/env_infos/final/reward_dist Std          0.00259889
eval/env_infos/final/reward_dist Max          0.00866296
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00172818
eval/env_infos/initial/reward_dist Std        0.00518455
eval/env_infos/initial/reward_dist Max        0.0172818
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.167678
eval/env_infos/reward_dist Std                0.320246
eval/env_infos/reward_dist Max                1.18544
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00636514
time/evaluation sampling (s)                  3.44573
time/exploration sampling (s)                17.1258
time/logging (s)                              0.00531987
time/saving (s)                               0.00238121
time/training (s)                             4.6066
time/epoch (s)                               25.1922
time/total (s)                             2962.8
Epoch                                       116
---------------------------------------  ----------------
2023-08-05 01:11:01.146306 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 117 finished
---------------------------------------  ----------------
epoch                                       117
replay_buffer/size                       236000
trainer/QF1 Loss                              0.996853
trainer/QF2 Loss                              0.991768
trainer/Policy Loss                          -9.18418
trainer/Q1 Predictions Mean                   7.99002
trainer/Q1 Predictions Std                    6.43174
trainer/Q1 Predictions Max                   26.5165
trainer/Q1 Predictions Min                   -9.3521
trainer/Q2 Predictions Mean                   7.97242
trainer/Q2 Predictions Std                    6.42874
trainer/Q2 Predictions Max                   26.4487
trainer/Q2 Predictions Min                   -9.29063
trainer/Q Targets Mean                        7.98851
trainer/Q Targets Std                         6.50416
trainer/Q Targets Max                        27.0226
trainer/Q Targets Min                        -9.30447
trainer/Bellman Errors 1 Mean                 0.996853
trainer/Bellman Errors 1 Std                  6.43243
trainer/Bellman Errors 1 Max                112.885
trainer/Bellman Errors 1 Min                  7.44899e-09
trainer/Bellman Errors 2 Mean                 0.991768
trainer/Bellman Errors 2 Std                  6.6987
trainer/Bellman Errors 2 Max                121.208
trainer/Bellman Errors 2 Min                  3.44064e-08
trainer/Policy Action Mean                    0.446875
trainer/Policy Action Std                     0.705883
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     236000
expl/num paths total                       5900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.168859
expl/Rewards Std                              0.323716
expl/Rewards Max                              1.26719
expl/Rewards Min                              0
expl/Returns Mean                             6.75436
expl/Returns Std                              5.76475
expl/Returns Max                             13.7122
expl/Returns Min                              0
expl/Actions Mean                             0.328258
expl/Actions Std                              0.768243
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          6.75436
expl/env_infos/final/reward_dist Mean         0.000128724
expl/env_infos/final/reward_dist Std          0.000472372
expl/env_infos/final/reward_dist Max          0.00257614
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00131136
expl/env_infos/initial/reward_dist Std        0.0036757
expl/env_infos/initial/reward_dist Max        0.0179901
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.168859
expl/env_infos/reward_dist Std                0.323716
expl/env_infos/reward_dist Max                1.26719
expl/env_infos/reward_dist Min                0
eval/num steps total                      47200
eval/num paths total                       1180
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.188207
eval/Rewards Std                              0.382332
eval/Rewards Max                              1.56402
eval/Rewards Min                              0
eval/Returns Mean                             7.52828
eval/Returns Std                              9.25747
eval/Returns Max                             30.4357
eval/Returns Min                              0
eval/Actions Mean                             0.311805
eval/Actions Std                              0.796306
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          7.52828
eval/env_infos/final/reward_dist Mean         0.156982
eval/env_infos/final/reward_dist Std          0.469016
eval/env_infos/final/reward_dist Max          1.56402
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00126121
eval/env_infos/initial/reward_dist Std        0.00378362
eval/env_infos/initial/reward_dist Max        0.0126121
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.188207
eval/env_infos/reward_dist Std                0.382332
eval/env_infos/reward_dist Max                1.56402
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00810571
time/evaluation sampling (s)                  3.46061
time/exploration sampling (s)                17.7581
time/logging (s)                              0.00746733
time/saving (s)                               0.00270004
time/training (s)                             5.02081
time/epoch (s)                               26.2578
time/total (s)                             2989.06
Epoch                                       117
---------------------------------------  ----------------
2023-08-05 01:11:26.484626 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 118 finished
---------------------------------------  ----------------
epoch                                       118
replay_buffer/size                       238000
trainer/QF1 Loss                              1.01542
trainer/QF2 Loss                              1.02324
trainer/Policy Loss                          -9.08676
trainer/Q1 Predictions Mean                   7.88136
trainer/Q1 Predictions Std                    6.54413
trainer/Q1 Predictions Max                   26.3202
trainer/Q1 Predictions Min                  -11.7816
trainer/Q2 Predictions Mean                   7.88416
trainer/Q2 Predictions Std                    6.54466
trainer/Q2 Predictions Max                   26.2997
trainer/Q2 Predictions Min                   -9.21629
trainer/Q Targets Mean                        7.84992
trainer/Q Targets Std                         6.61086
trainer/Q Targets Max                        26.4641
trainer/Q Targets Min                       -10.1205
trainer/Bellman Errors 1 Mean                 1.01542
trainer/Bellman Errors 1 Std                  6.5951
trainer/Bellman Errors 1 Max                111.34
trainer/Bellman Errors 1 Min                  3.96176e-09
trainer/Bellman Errors 2 Mean                 1.02324
trainer/Bellman Errors 2 Std                  6.88326
trainer/Bellman Errors 2 Max                118.703
trainer/Bellman Errors 2 Min                  4.45652e-09
trainer/Policy Action Mean                    0.45115
trainer/Policy Action Std                     0.707092
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     238000
expl/num paths total                       5950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.205938
expl/Rewards Std                              0.344461
expl/Rewards Max                              1.25894
expl/Rewards Min                              0
expl/Returns Mean                             8.23751
expl/Returns Std                              5.16471
expl/Returns Max                             13.5276
expl/Returns Min                              0
expl/Actions Mean                             0.420942
expl/Actions Std                              0.718278
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.23751
expl/env_infos/final/reward_dist Mean         0.000413895
expl/env_infos/final/reward_dist Std          0.00149286
expl/env_infos/final/reward_dist Max          0.00839397
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0011051
expl/env_infos/initial/reward_dist Std        0.00317425
expl/env_infos/initial/reward_dist Max        0.0122188
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.205938
expl/env_infos/reward_dist Std                0.344461
expl/env_infos/reward_dist Max                1.25894
expl/env_infos/reward_dist Min                0
eval/num steps total                      47600
eval/num paths total                       1190
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.218771
eval/Rewards Std                              0.347907
eval/Rewards Max                              1.17152
eval/Rewards Min                              0
eval/Returns Mean                             8.75084
eval/Returns Std                              4.3767
eval/Returns Max                             11.3655
eval/Returns Min                              0.0124299
eval/Actions Mean                             0.427772
eval/Actions Std                              0.727931
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          8.75084
eval/env_infos/final/reward_dist Mean         2.92402e-05
eval/env_infos/final/reward_dist Std          8.7694e-05
eval/env_infos/final/reward_dist Max          0.000292322
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.218771
eval/env_infos/reward_dist Std                0.347907
eval/env_infos/reward_dist Max                1.17152
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00578798
time/evaluation sampling (s)                  3.4029
time/exploration sampling (s)                17.3268
time/logging (s)                              0.00534317
time/saving (s)                               0.00237947
time/training (s)                             4.58863
time/epoch (s)                               25.3318
time/total (s)                             3014.39
Epoch                                       118
---------------------------------------  ----------------
2023-08-05 01:11:52.799519 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 119 finished
---------------------------------------  ----------------
epoch                                       119
replay_buffer/size                       240000
trainer/QF1 Loss                              0.949348
trainer/QF2 Loss                              0.950736
trainer/Policy Loss                          -8.8429
trainer/Q1 Predictions Mean                   7.63341
trainer/Q1 Predictions Std                    6.51514
trainer/Q1 Predictions Max                   25.4993
trainer/Q1 Predictions Min                  -10.8819
trainer/Q2 Predictions Mean                   7.63228
trainer/Q2 Predictions Std                    6.52017
trainer/Q2 Predictions Max                   25.5074
trainer/Q2 Predictions Min                  -10.9154
trainer/Q Targets Mean                        7.60081
trainer/Q Targets Std                         6.58824
trainer/Q Targets Max                        25.8194
trainer/Q Targets Min                       -11.692
trainer/Bellman Errors 1 Mean                 0.949348
trainer/Bellman Errors 1 Std                  6.50842
trainer/Bellman Errors 1 Max                104.165
trainer/Bellman Errors 1 Min                  1.10143e-07
trainer/Bellman Errors 2 Mean                 0.950736
trainer/Bellman Errors 2 Std                  6.81555
trainer/Bellman Errors 2 Max                112.874
trainer/Bellman Errors 2 Min                  5.82077e-09
trainer/Policy Action Mean                    0.448531
trainer/Policy Action Std                     0.714114
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     240000
expl/num paths total                       6000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.179751
expl/Rewards Std                              0.329058
expl/Rewards Max                              1.27164
expl/Rewards Min                              0
expl/Returns Mean                             7.19002
expl/Returns Std                              5.59077
expl/Returns Max                             13.293
expl/Returns Min                              0
expl/Actions Mean                             0.371843
expl/Actions Std                              0.745506
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          7.19002
expl/env_infos/final/reward_dist Mean         0.0258023
expl/env_infos/final/reward_dist Std          0.177982
expl/env_infos/final/reward_dist Max          1.27164
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000731296
expl/env_infos/initial/reward_dist Std        0.00411833
expl/env_infos/initial/reward_dist Max        0.029271
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.179751
expl/env_infos/reward_dist Std                0.329058
expl/env_infos/reward_dist Max                1.27164
expl/env_infos/reward_dist Min                0
eval/num steps total                      48000
eval/num paths total                       1200
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.145338
eval/Rewards Std                              0.303397
eval/Rewards Max                              1.1795
eval/Rewards Min                              0
eval/Returns Mean                             5.81352
eval/Returns Std                              5.78671
eval/Returns Max                             12.2522
eval/Returns Min                              0
eval/Actions Mean                             0.412835
eval/Actions Std                              0.763257
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          5.81352
eval/env_infos/final/reward_dist Mean         0.000125738
eval/env_infos/final/reward_dist Std          0.000267377
eval/env_infos/final/reward_dist Max          0.000831794
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00109099
eval/env_infos/initial/reward_dist Std        0.00222172
eval/env_infos/initial/reward_dist Max        0.00639031
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.145338
eval/env_infos/reward_dist Std                0.303397
eval/env_infos/reward_dist Max                1.1795
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00812522
time/evaluation sampling (s)                  3.48955
time/exploration sampling (s)                17.9601
time/logging (s)                              0.00532777
time/saving (s)                               0.00241792
time/training (s)                             4.84659
time/epoch (s)                               26.3121
time/total (s)                             3040.71
Epoch                                       119
---------------------------------------  ----------------
2023-08-05 01:12:18.964873 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 120 finished
---------------------------------------  ----------------
epoch                                       120
replay_buffer/size                       242000
trainer/QF1 Loss                              0.927428
trainer/QF2 Loss                              0.925691
trainer/Policy Loss                          -8.72475
trainer/Q1 Predictions Mean                   7.536
trainer/Q1 Predictions Std                    6.38538
trainer/Q1 Predictions Max                   24.9022
trainer/Q1 Predictions Min                  -12.344
trainer/Q2 Predictions Mean                   7.52635
trainer/Q2 Predictions Std                    6.37343
trainer/Q2 Predictions Max                   24.8757
trainer/Q2 Predictions Min                  -12.2272
trainer/Q Targets Mean                        7.50864
trainer/Q Targets Std                         6.44504
trainer/Q Targets Max                        25.3644
trainer/Q Targets Min                       -12.6127
trainer/Bellman Errors 1 Mean                 0.927428
trainer/Bellman Errors 1 Std                  5.91665
trainer/Bellman Errors 1 Max                 97.4869
trainer/Bellman Errors 1 Min                  1.40113e-09
trainer/Bellman Errors 2 Mean                 0.925691
trainer/Bellman Errors 2 Std                  6.10646
trainer/Bellman Errors 2 Max                101.55
trainer/Bellman Errors 2 Min                  1.30967e-10
trainer/Policy Action Mean                    0.447975
trainer/Policy Action Std                     0.71353
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     242000
expl/num paths total                       6050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.249964
expl/Rewards Std                              0.407693
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                             9.99854
expl/Returns Std                              8.72464
expl/Returns Max                             37.6532
expl/Returns Min                              0
expl/Actions Mean                             0.423871
expl/Actions Std                              0.71375
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          9.99854
expl/env_infos/final/reward_dist Mean         0.121032
expl/env_infos/final/reward_dist Std          0.410893
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00174989
expl/env_infos/initial/reward_dist Std        0.00384962
expl/env_infos/initial/reward_dist Max        0.0156684
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.249964
expl/env_infos/reward_dist Std                0.407693
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      48400
eval/num paths total                       1210
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.175718
eval/Rewards Std                              0.32982
eval/Rewards Max                              1.16895
eval/Rewards Min                              0
eval/Returns Mean                             7.02873
eval/Returns Std                              5.75081
eval/Returns Max                             12.3144
eval/Returns Min                              9.79665e-05
eval/Actions Mean                             0.400145
eval/Actions Std                              0.755712
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          7.02873
eval/env_infos/final/reward_dist Mean         1.45143e-07
eval/env_infos/final/reward_dist Std          4.35428e-07
eval/env_infos/final/reward_dist Max          1.45143e-06
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00115271
eval/env_infos/initial/reward_dist Std        0.00345814
eval/env_infos/initial/reward_dist Max        0.0115271
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.175718
eval/env_infos/reward_dist Std                0.32982
eval/env_infos/reward_dist Max                1.16895
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0056151
time/evaluation sampling (s)                  3.62154
time/exploration sampling (s)                17.8398
time/logging (s)                              0.00734542
time/saving (s)                               0.0110607
time/training (s)                             4.67942
time/epoch (s)                               26.1648
time/total (s)                             3066.87
Epoch                                       120
---------------------------------------  ----------------
2023-08-05 01:12:44.963230 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 121 finished
---------------------------------------  ----------------
epoch                                       121
replay_buffer/size                       244000
trainer/QF1 Loss                              0.877126
trainer/QF2 Loss                              0.867056
trainer/Policy Loss                          -8.48538
trainer/Q1 Predictions Mean                   7.246
trainer/Q1 Predictions Std                    6.49111
trainer/Q1 Predictions Max                   24.7718
trainer/Q1 Predictions Min                  -14.9942
trainer/Q2 Predictions Mean                   7.23657
trainer/Q2 Predictions Std                    6.49268
trainer/Q2 Predictions Max                   24.6659
trainer/Q2 Predictions Min                  -14.304
trainer/Q Targets Mean                        7.31279
trainer/Q Targets Std                         6.5951
trainer/Q Targets Max                        25.0839
trainer/Q Targets Min                       -14.7069
trainer/Bellman Errors 1 Mean                 0.877126
trainer/Bellman Errors 1 Std                  5.38331
trainer/Bellman Errors 1 Max                110.374
trainer/Bellman Errors 1 Min                  2.5517e-08
trainer/Bellman Errors 2 Mean                 0.867056
trainer/Bellman Errors 2 Std                  5.63289
trainer/Bellman Errors 2 Max                120.918
trainer/Bellman Errors 2 Min                  5.11591e-09
trainer/Policy Action Mean                    0.451138
trainer/Policy Action Std                     0.71497
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     244000
expl/num paths total                       6100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.202254
expl/Rewards Std                              0.370095
expl/Rewards Max                              1.56938
expl/Rewards Min                              0
expl/Returns Mean                             8.09015
expl/Returns Std                              7.73683
expl/Returns Max                             35.4922
expl/Returns Min                              0
expl/Actions Mean                             0.383139
expl/Actions Std                              0.742436
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.09015
expl/env_infos/final/reward_dist Mean         0.0744077
expl/env_infos/final/reward_dist Std          0.315174
expl/env_infos/final/reward_dist Max          1.56938
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00139404
expl/env_infos/initial/reward_dist Std        0.00366649
expl/env_infos/initial/reward_dist Max        0.0164866
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.202254
expl/env_infos/reward_dist Std                0.370095
expl/env_infos/reward_dist Max                1.56938
expl/env_infos/reward_dist Min                0
eval/num steps total                      48800
eval/num paths total                       1220
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.242727
eval/Rewards Std                              0.370989
eval/Rewards Max                              1.20381
eval/Rewards Min                              0
eval/Returns Mean                             9.70909
eval/Returns Std                              4.89429
eval/Returns Max                             13.0117
eval/Returns Min                              0
eval/Actions Mean                             0.432068
eval/Actions Std                              0.722507
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          9.70909
eval/env_infos/final/reward_dist Mean         0
eval/env_infos/final/reward_dist Std          0
eval/env_infos/final/reward_dist Max          0
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.242727
eval/env_infos/reward_dist Std                0.370989
eval/env_infos/reward_dist Max                1.20381
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585754
time/evaluation sampling (s)                  3.44988
time/exploration sampling (s)                18.0386
time/logging (s)                              0.00535803
time/saving (s)                               0.00241438
time/training (s)                             4.48994
time/epoch (s)                               25.9921
time/total (s)                             3092.87
Epoch                                       121
---------------------------------------  ----------------
2023-08-05 01:13:11.453357 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 122 finished
---------------------------------------  ----------------
epoch                                       122
replay_buffer/size                       246000
trainer/QF1 Loss                              0.849218
trainer/QF2 Loss                              0.872189
trainer/Policy Loss                          -8.34734
trainer/Q1 Predictions Mean                   7.18283
trainer/Q1 Predictions Std                    6.43373
trainer/Q1 Predictions Max                   23.8528
trainer/Q1 Predictions Min                  -13.0736
trainer/Q2 Predictions Mean                   7.18121
trainer/Q2 Predictions Std                    6.43015
trainer/Q2 Predictions Max                   23.8362
trainer/Q2 Predictions Min                  -13.1586
trainer/Q Targets Mean                        7.24158
trainer/Q Targets Std                         6.53227
trainer/Q Targets Max                        24.489
trainer/Q Targets Min                       -13.4368
trainer/Bellman Errors 1 Mean                 0.849218
trainer/Bellman Errors 1 Std                  5.47084
trainer/Bellman Errors 1 Max                103.852
trainer/Bellman Errors 1 Min                  2.32831e-10
trainer/Bellman Errors 2 Mean                 0.872189
trainer/Bellman Errors 2 Std                  5.79936
trainer/Bellman Errors 2 Max                117.16
trainer/Bellman Errors 2 Min                  9.04953e-09
trainer/Policy Action Mean                    0.468531
trainer/Policy Action Std                     0.709327
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     246000
expl/num paths total                       6150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.207185
expl/Rewards Std                              0.376287
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                             8.2874
expl/Returns Std                              8.2677
expl/Returns Max                             36.4656
expl/Returns Min                              0
expl/Actions Mean                             0.382914
expl/Actions Std                              0.745876
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.2874
expl/env_infos/final/reward_dist Mean         0.0900479
expl/env_infos/final/reward_dist Std          0.355431
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000989844
expl/env_infos/initial/reward_dist Std        0.0027129
expl/env_infos/initial/reward_dist Max        0.0123821
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.207185
expl/env_infos/reward_dist Std                0.376287
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      49200
eval/num paths total                       1230
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.128184
eval/Rewards Std                              0.300735
eval/Rewards Max                              1.28084
eval/Rewards Min                              0
eval/Returns Mean                             5.12735
eval/Returns Std                              6.25928
eval/Returns Max                             13.9073
eval/Returns Min                              0.00306359
eval/Actions Mean                             0.388564
eval/Actions Std                              0.784279
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          5.12735
eval/env_infos/final/reward_dist Mean         0.000304668
eval/env_infos/final/reward_dist Std          0.000914005
eval/env_infos/final/reward_dist Max          0.00304668
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000409412
eval/env_infos/initial/reward_dist Std        0.00122824
eval/env_infos/initial/reward_dist Max        0.00409412
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.128184
eval/env_infos/reward_dist Std                0.300735
eval/env_infos/reward_dist Max                1.28084
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00581214
time/evaluation sampling (s)                  3.43853
time/exploration sampling (s)                18.089
time/logging (s)                              0.00791496
time/saving (s)                               0.00331418
time/training (s)                             4.94545
time/epoch (s)                               26.49
time/total (s)                             3119.36
Epoch                                       122
---------------------------------------  ----------------
2023-08-05 01:13:37.142246 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 123 finished
---------------------------------------  ----------------
epoch                                       123
replay_buffer/size                       248000
trainer/QF1 Loss                              1.12165
trainer/QF2 Loss                              1.12165
trainer/Policy Loss                          -8.20049
trainer/Q1 Predictions Mean                   7.07716
trainer/Q1 Predictions Std                    6.42324
trainer/Q1 Predictions Max                   23.7935
trainer/Q1 Predictions Min                  -14.2662
trainer/Q2 Predictions Mean                   7.06657
trainer/Q2 Predictions Std                    6.41392
trainer/Q2 Predictions Max                   23.8736
trainer/Q2 Predictions Min                  -14.0129
trainer/Q Targets Mean                        7.05581
trainer/Q Targets Std                         6.5119
trainer/Q Targets Max                        24.0343
trainer/Q Targets Min                       -13.6769
trainer/Bellman Errors 1 Mean                 1.12165
trainer/Bellman Errors 1 Std                  6.62067
trainer/Bellman Errors 1 Max                111.984
trainer/Bellman Errors 1 Min                  3.59717e-08
trainer/Bellman Errors 2 Mean                 1.12165
trainer/Bellman Errors 2 Std                  6.75939
trainer/Bellman Errors 2 Max                116.068
trainer/Bellman Errors 2 Min                  7.0796e-08
trainer/Policy Action Mean                    0.469623
trainer/Policy Action Std                     0.715178
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     248000
expl/num paths total                       6200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.25052
expl/Rewards Std                              0.402829
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            10.0208
expl/Returns Std                              8.37999
expl/Returns Max                             36.0477
expl/Returns Min                              0
expl/Actions Mean                             0.415417
expl/Actions Std                              0.724655
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         10.0208
expl/env_infos/final/reward_dist Mean         0.0945858
expl/env_infos/final/reward_dist Std          0.372939
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00061649
expl/env_infos/initial/reward_dist Std        0.00232791
expl/env_infos/initial/reward_dist Max        0.0147537
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.25052
expl/env_infos/reward_dist Std                0.402829
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      49600
eval/num paths total                       1240
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.29848
eval/Rewards Std                              0.40568
eval/Rewards Max                              1.50485
eval/Rewards Min                              0
eval/Returns Mean                            11.9392
eval/Returns Std                              4.60592
eval/Returns Max                             19.882
eval/Returns Min                              0.00577902
eval/Actions Mean                             0.495926
eval/Actions Std                              0.681611
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.9392
eval/env_infos/final/reward_dist Mean         0.150317
eval/env_infos/final/reward_dist Std          0.45095
eval/env_infos/final/reward_dist Max          1.50317
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00161212
eval/env_infos/initial/reward_dist Std        0.00252719
eval/env_infos/initial/reward_dist Max        0.00734985
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.29848
eval/env_infos/reward_dist Std                0.40568
eval/env_infos/reward_dist Max                1.50485
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00566688
time/evaluation sampling (s)                  3.49549
time/exploration sampling (s)                17.6365
time/logging (s)                              0.00531246
time/saving (s)                               0.00243801
time/training (s)                             4.53632
time/epoch (s)                               25.6817
time/total (s)                             3145.04
Epoch                                       123
---------------------------------------  ----------------
2023-08-05 01:14:02.767282 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 124 finished
---------------------------------------  ----------------
epoch                                       124
replay_buffer/size                       250000
trainer/QF1 Loss                              1.03724
trainer/QF2 Loss                              1.0442
trainer/Policy Loss                          -8.01194
trainer/Q1 Predictions Mean                   6.7926
trainer/Q1 Predictions Std                    6.50928
trainer/Q1 Predictions Max                   23.2402
trainer/Q1 Predictions Min                  -16.181
trainer/Q2 Predictions Mean                   6.79131
trainer/Q2 Predictions Std                    6.51771
trainer/Q2 Predictions Max                   23.4528
trainer/Q2 Predictions Min                  -15.9395
trainer/Q Targets Mean                        6.86194
trainer/Q Targets Std                         6.63959
trainer/Q Targets Max                        23.9686
trainer/Q Targets Min                       -16.0959
trainer/Bellman Errors 1 Mean                 1.03724
trainer/Bellman Errors 1 Std                  6.07336
trainer/Bellman Errors 1 Max                104.596
trainer/Bellman Errors 1 Min                  1.0747e-09
trainer/Bellman Errors 2 Mean                 1.0442
trainer/Bellman Errors 2 Std                  6.43577
trainer/Bellman Errors 2 Max                115.948
trainer/Bellman Errors 2 Min                  1.68166e-09
trainer/Policy Action Mean                    0.466833
trainer/Policy Action Std                     0.713178
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     250000
expl/num paths total                       6250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.313363
expl/Rewards Std                              0.476106
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            12.5345
expl/Returns Std                             11.8538
expl/Returns Max                             37.9444
expl/Returns Min                              0
expl/Actions Mean                             0.428222
expl/Actions Std                              0.725173
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.5345
expl/env_infos/final/reward_dist Mean         0.305787
expl/env_infos/final/reward_dist Std          0.612214
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000716325
expl/env_infos/initial/reward_dist Std        0.00267673
expl/env_infos/initial/reward_dist Max        0.0140731
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.313363
expl/env_infos/reward_dist Std                0.476106
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      50000
eval/num paths total                       1250
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.375617
eval/Rewards Std                              0.492685
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            15.0247
eval/Returns Std                             10.7832
eval/Returns Max                             34.949
eval/Returns Min                              0.00175074
eval/Actions Mean                             0.500513
eval/Actions Std                              0.695867
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         15.0247
eval/env_infos/final/reward_dist Mean         0.306453
eval/env_infos/final/reward_dist Std          0.611994
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00260913
eval/env_infos/initial/reward_dist Std        0.00462455
eval/env_infos/initial/reward_dist Max        0.0132716
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.375617
eval/env_infos/reward_dist Std                0.492685
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00570044
time/evaluation sampling (s)                  3.46988
time/exploration sampling (s)                17.6461
time/logging (s)                              0.00536686
time/saving (s)                               0.00230693
time/training (s)                             4.49304
time/epoch (s)                               25.6224
time/total (s)                             3170.67
Epoch                                       124
---------------------------------------  ----------------
2023-08-05 01:14:28.644888 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 125 finished
---------------------------------------  ----------------
epoch                                       125
replay_buffer/size                       252000
trainer/QF1 Loss                              1.24618
trainer/QF2 Loss                              1.25691
trainer/Policy Loss                          -8.1435
trainer/Q1 Predictions Mean                   6.917
trainer/Q1 Predictions Std                    6.61768
trainer/Q1 Predictions Max                   23.4479
trainer/Q1 Predictions Min                  -15.617
trainer/Q2 Predictions Mean                   6.90955
trainer/Q2 Predictions Std                    6.61001
trainer/Q2 Predictions Max                   23.3689
trainer/Q2 Predictions Min                  -15.3424
trainer/Q Targets Mean                        6.88356
trainer/Q Targets Std                         6.70068
trainer/Q Targets Max                        23.9378
trainer/Q Targets Min                       -15.074
trainer/Bellman Errors 1 Mean                 1.24618
trainer/Bellman Errors 1 Std                  7.52675
trainer/Bellman Errors 1 Max                113.639
trainer/Bellman Errors 1 Min                  1.45519e-09
trainer/Bellman Errors 2 Mean                 1.25691
trainer/Bellman Errors 2 Std                  7.83306
trainer/Bellman Errors 2 Max                120.293
trainer/Bellman Errors 2 Min                  5.96719e-09
trainer/Policy Action Mean                    0.469034
trainer/Policy Action Std                     0.712868
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     252000
expl/num paths total                       6300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.299227
expl/Rewards Std                              0.487779
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            11.9691
expl/Returns Std                             13.253
expl/Returns Max                             38.6191
expl/Returns Min                              0
expl/Actions Mean                             0.38285
expl/Actions Std                              0.749501
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         11.9691
expl/env_infos/final/reward_dist Mean         0.30494
expl/env_infos/final/reward_dist Std          0.610559
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000362423
expl/env_infos/initial/reward_dist Std        0.00191555
expl/env_infos/initial/reward_dist Max        0.0126554
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.299227
expl/env_infos/reward_dist Std                0.487779
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      50400
eval/num paths total                       1260
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.235095
eval/Rewards Std                              0.43087
eval/Rewards Max                              1.56997
eval/Rewards Min                              0
eval/Returns Mean                             9.40382
eval/Returns Std                             11.3605
eval/Returns Max                             37.6416
eval/Returns Min                              0
eval/Actions Mean                             0.385955
eval/Actions Std                              0.76254
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          9.40382
eval/env_infos/final/reward_dist Mean         0.186335
eval/env_infos/final/reward_dist Std          0.468962
eval/env_infos/final/reward_dist Max          1.56997
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.235095
eval/env_infos/reward_dist Std                0.43087
eval/env_infos/reward_dist Max                1.56997
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00569476
time/evaluation sampling (s)                  3.39268
time/exploration sampling (s)                17.9631
time/logging (s)                              0.0053937
time/saving (s)                               0.00246794
time/training (s)                             4.50561
time/epoch (s)                               25.8749
time/total (s)                             3196.55
Epoch                                       125
---------------------------------------  ----------------
2023-08-05 01:14:54.791711 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 126 finished
---------------------------------------  ----------------
epoch                                       126
replay_buffer/size                       254000
trainer/QF1 Loss                              0.986548
trainer/QF2 Loss                              0.990384
trainer/Policy Loss                          -8.00461
trainer/Q1 Predictions Mean                   6.76319
trainer/Q1 Predictions Std                    6.63918
trainer/Q1 Predictions Max                   23.2836
trainer/Q1 Predictions Min                  -15.4209
trainer/Q2 Predictions Mean                   6.76792
trainer/Q2 Predictions Std                    6.64416
trainer/Q2 Predictions Max                   23.4226
trainer/Q2 Predictions Min                  -15.1804
trainer/Q Targets Mean                        6.7511
trainer/Q Targets Std                         6.7044
trainer/Q Targets Max                        23.5779
trainer/Q Targets Min                       -15.5957
trainer/Bellman Errors 1 Mean                 0.986548
trainer/Bellman Errors 1 Std                  6.88315
trainer/Bellman Errors 1 Max                119.335
trainer/Bellman Errors 1 Min                  6.13637e-08
trainer/Bellman Errors 2 Mean                 0.990384
trainer/Bellman Errors 2 Std                  7.16194
trainer/Bellman Errors 2 Max                123.392
trainer/Bellman Errors 2 Min                  4.64533e-08
trainer/Policy Action Mean                    0.466465
trainer/Policy Action Std                     0.718014
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     254000
expl/num paths total                       6350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.384922
expl/Rewards Std                              0.535489
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            15.3969
expl/Returns Std                             14.3011
expl/Returns Max                             38.3989
expl/Returns Min                              0
expl/Actions Mean                             0.4266
expl/Actions Std                              0.714285
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.3969
expl/env_infos/final/reward_dist Mean         0.45702
expl/env_infos/final/reward_dist Std          0.699128
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00065426
expl/env_infos/initial/reward_dist Std        0.00249421
expl/env_infos/initial/reward_dist Max        0.015886
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.384922
expl/env_infos/reward_dist Std                0.535489
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      50800
eval/num paths total                       1270
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.192571
eval/Rewards Std                              0.388532
eval/Rewards Max                              1.32185
eval/Rewards Min                              0
eval/Returns Mean                             7.70285
eval/Returns Std                             10.9643
eval/Returns Max                             34.6692
eval/Returns Min                              0
eval/Actions Mean                             0.391821
eval/Actions Std                              0.77202
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          7.70285
eval/env_infos/final/reward_dist Mean         0.132662
eval/env_infos/final/reward_dist Std          0.396396
eval/env_infos/final/reward_dist Max          1.32185
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00440073
eval/env_infos/initial/reward_dist Std        0.0068972
eval/env_infos/initial/reward_dist Max        0.0186392
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.192571
eval/env_infos/reward_dist Std                0.388532
eval/env_infos/reward_dist Max                1.32185
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588344
time/evaluation sampling (s)                  3.41712
time/exploration sampling (s)                18.1505
time/logging (s)                              0.00540861
time/saving (s)                               0.00243401
time/training (s)                             4.56288
time/epoch (s)                               26.1443
time/total (s)                             3222.69
Epoch                                       126
---------------------------------------  ----------------
2023-08-05 01:15:21.084557 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 127 finished
---------------------------------------  ----------------
epoch                                       127
replay_buffer/size                       256000
trainer/QF1 Loss                              0.993979
trainer/QF2 Loss                              0.999467
trainer/Policy Loss                          -7.78859
trainer/Q1 Predictions Mean                   6.64971
trainer/Q1 Predictions Std                    6.6604
trainer/Q1 Predictions Max                   22.6614
trainer/Q1 Predictions Min                  -16.9639
trainer/Q2 Predictions Mean                   6.6381
trainer/Q2 Predictions Std                    6.66034
trainer/Q2 Predictions Max                   22.809
trainer/Q2 Predictions Min                  -16.8892
trainer/Q Targets Mean                        6.67277
trainer/Q Targets Std                         6.77623
trainer/Q Targets Max                        23.392
trainer/Q Targets Min                       -17.1248
trainer/Bellman Errors 1 Mean                 0.993979
trainer/Bellman Errors 1 Std                  6.34805
trainer/Bellman Errors 1 Max                117.731
trainer/Bellman Errors 1 Min                  1.31331e-09
trainer/Bellman Errors 2 Mean                 0.999467
trainer/Bellman Errors 2 Std                  6.68533
trainer/Bellman Errors 2 Max                116.398
trainer/Bellman Errors 2 Min                  1.08057e-08
trainer/Policy Action Mean                    0.470498
trainer/Policy Action Std                     0.711171
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     256000
expl/num paths total                       6400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.609547
expl/Rewards Std                              0.622051
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            24.3819
expl/Returns Std                             15.2648
expl/Returns Max                             40.5343
expl/Returns Min                              0
expl/Actions Mean                             0.483389
expl/Actions Std                              0.67354
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.3819
expl/env_infos/final/reward_dist Mean         0.905525
expl/env_infos/final/reward_dist Std          0.770938
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000977392
expl/env_infos/initial/reward_dist Std        0.00308982
expl/env_infos/initial/reward_dist Max        0.0147911
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.609547
expl/env_infos/reward_dist Std                0.622051
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      51200
eval/num paths total                       1280
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.526155
eval/Rewards Std                              0.592327
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            21.0462
eval/Returns Std                             14.9642
eval/Returns Max                             41.4669
eval/Returns Min                              0
eval/Actions Mean                             0.472839
eval/Actions Std                              0.709663
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         21.0462
eval/env_infos/final/reward_dist Mean         0.628184
eval/env_infos/final/reward_dist Std          0.769365
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00168555
eval/env_infos/initial/reward_dist Std        0.00474097
eval/env_infos/initial/reward_dist Max        0.0158831
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.526155
eval/env_infos/reward_dist Std                0.592327
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590206
time/evaluation sampling (s)                  3.46279
time/exploration sampling (s)                17.847
time/logging (s)                              0.00793512
time/saving (s)                               0.00334242
time/training (s)                             4.96577
time/epoch (s)                               26.2928
time/total (s)                             3248.99
Epoch                                       127
---------------------------------------  ----------------
2023-08-05 01:15:46.884264 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 128 finished
---------------------------------------  ----------------
epoch                                       128
replay_buffer/size                       258000
trainer/QF1 Loss                              1.20042
trainer/QF2 Loss                              1.20412
trainer/Policy Loss                          -7.74495
trainer/Q1 Predictions Mean                   6.58002
trainer/Q1 Predictions Std                    6.76277
trainer/Q1 Predictions Max                   22.656
trainer/Q1 Predictions Min                  -19.7369
trainer/Q2 Predictions Mean                   6.56778
trainer/Q2 Predictions Std                    6.75734
trainer/Q2 Predictions Max                   22.7083
trainer/Q2 Predictions Min                  -17.7213
trainer/Q Targets Mean                        6.60666
trainer/Q Targets Std                         6.85797
trainer/Q Targets Max                        23.5494
trainer/Q Targets Min                       -17.6204
trainer/Bellman Errors 1 Mean                 1.20042
trainer/Bellman Errors 1 Std                  7.68796
trainer/Bellman Errors 1 Max                121.313
trainer/Bellman Errors 1 Min                  1.17871e-07
trainer/Bellman Errors 2 Mean                 1.20412
trainer/Bellman Errors 2 Std                  7.94094
trainer/Bellman Errors 2 Max                127.12
trainer/Bellman Errors 2 Min                  3.01261e-08
trainer/Policy Action Mean                    0.476691
trainer/Policy Action Std                     0.708429
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     258000
expl/num paths total                       6450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.668094
expl/Rewards Std                              0.614935
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            26.7238
expl/Returns Std                             14.0133
expl/Returns Max                             40.0244
expl/Returns Min                              0
expl/Actions Mean                             0.507009
expl/Actions Std                              0.643878
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.7238
expl/env_infos/final/reward_dist Mean         1.03851
expl/env_infos/final/reward_dist Std          0.715854
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000815257
expl/env_infos/initial/reward_dist Std        0.00246201
expl/env_infos/initial/reward_dist Max        0.011365
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.668094
expl/env_infos/reward_dist Std                0.614935
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      51600
eval/num paths total                       1290
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.412511
eval/Rewards Std                              0.561846
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            16.5005
eval/Returns Std                             15.1546
eval/Returns Max                             36.4218
eval/Returns Min                              0.00911873
eval/Actions Mean                             0.405264
eval/Actions Std                              0.780607
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.5005
eval/env_infos/final/reward_dist Mean         0.595643
eval/env_infos/final/reward_dist Std          0.730994
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000106462
eval/env_infos/initial/reward_dist Std        0.000319387
eval/env_infos/initial/reward_dist Max        0.00106462
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.412511
eval/env_infos/reward_dist Std                0.561846
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0058939
time/evaluation sampling (s)                  3.47319
time/exploration sampling (s)                17.915
time/logging (s)                              0.00533129
time/saving (s)                               0.00236791
time/training (s)                             4.39074
time/epoch (s)                               25.7926
time/total (s)                             3274.78
Epoch                                       128
---------------------------------------  ----------------
2023-08-05 01:16:11.674135 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 129 finished
---------------------------------------  ----------------
epoch                                       129
replay_buffer/size                       260000
trainer/QF1 Loss                              0.940282
trainer/QF2 Loss                              0.951488
trainer/Policy Loss                          -7.78511
trainer/Q1 Predictions Mean                   6.49646
trainer/Q1 Predictions Std                    6.91304
trainer/Q1 Predictions Max                   23.0231
trainer/Q1 Predictions Min                  -17.754
trainer/Q2 Predictions Mean                   6.50718
trainer/Q2 Predictions Std                    6.91896
trainer/Q2 Predictions Max                   22.9891
trainer/Q2 Predictions Min                  -17.0008
trainer/Q Targets Mean                        6.48005
trainer/Q Targets Std                         7.01682
trainer/Q Targets Max                        23.223
trainer/Q Targets Min                       -17.5993
trainer/Bellman Errors 1 Mean                 0.940282
trainer/Bellman Errors 1 Std                  5.64632
trainer/Bellman Errors 1 Max                103.294
trainer/Bellman Errors 1 Min                  5.55111e-09
trainer/Bellman Errors 2 Mean                 0.951488
trainer/Bellman Errors 2 Std                  5.89917
trainer/Bellman Errors 2 Max                107.698
trainer/Bellman Errors 2 Min                  8.20819e-09
trainer/Policy Action Mean                    0.470403
trainer/Policy Action Std                     0.710516
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     260000
expl/num paths total                       6500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.742276
expl/Rewards Std                              0.627669
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            29.6911
expl/Returns Std                             13.0992
expl/Returns Max                             38.755
expl/Returns Min                              0
expl/Actions Mean                             0.525389
expl/Actions Std                              0.626203
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.6911
expl/env_infos/final/reward_dist Mean         1.17883
expl/env_infos/final/reward_dist Std          0.664386
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000627567
expl/env_infos/initial/reward_dist Std        0.00240232
expl/env_infos/initial/reward_dist Max        0.0141109
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.742276
expl/env_infos/reward_dist Std                0.627669
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      52000
eval/num paths total                       1300
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.563592
eval/Rewards Std                              0.6505
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            22.5437
eval/Returns Std                             18.392
eval/Returns Max                             38.62
eval/Returns Min                              0.00403753
eval/Actions Mean                             0.447373
eval/Actions Std                              0.719365
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.5437
eval/env_infos/final/reward_dist Mean         0.941547
eval/env_infos/final/reward_dist Std          0.768494
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000542036
eval/env_infos/initial/reward_dist Std        0.00132233
eval/env_infos/initial/reward_dist Max        0.00440332
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.563592
eval/env_infos/reward_dist Std                0.6505
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00579763
time/evaluation sampling (s)                  3.40648
time/exploration sampling (s)                16.9696
time/logging (s)                              0.00531417
time/saving (s)                               0.00236341
time/training (s)                             4.39762
time/epoch (s)                               24.7872
time/total (s)                             3299.57
Epoch                                       129
---------------------------------------  ----------------
2023-08-05 01:16:37.484397 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 130 finished
---------------------------------------  ----------------
epoch                                       130
replay_buffer/size                       262000
trainer/QF1 Loss                              1.02915
trainer/QF2 Loss                              1.0228
trainer/Policy Loss                          -7.74884
trainer/Q1 Predictions Mean                   6.5084
trainer/Q1 Predictions Std                    7.11087
trainer/Q1 Predictions Max                   22.7396
trainer/Q1 Predictions Min                  -19.2113
trainer/Q2 Predictions Mean                   6.51191
trainer/Q2 Predictions Std                    7.10239
trainer/Q2 Predictions Max                   22.7946
trainer/Q2 Predictions Min                  -19.3021
trainer/Q Targets Mean                        6.47269
trainer/Q Targets Std                         7.17383
trainer/Q Targets Max                        24.0003
trainer/Q Targets Min                       -19.2565
trainer/Bellman Errors 1 Mean                 1.02915
trainer/Bellman Errors 1 Std                  6.67801
trainer/Bellman Errors 1 Max                118.942
trainer/Bellman Errors 1 Min                  9.27776e-09
trainer/Bellman Errors 2 Mean                 1.0228
trainer/Bellman Errors 2 Std                  6.89963
trainer/Bellman Errors 2 Max                120.998
trainer/Bellman Errors 2 Min                  3.14649e-08
trainer/Policy Action Mean                    0.470994
trainer/Policy Action Std                     0.710682
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     262000
expl/num paths total                       6550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.690268
expl/Rewards Std                              0.630707
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            27.6107
expl/Returns Std                             14.4692
expl/Returns Max                             37.726
expl/Returns Min                              0
expl/Actions Mean                             0.495689
expl/Actions Std                              0.651241
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         27.6107
expl/env_infos/final/reward_dist Mean         1.11598
expl/env_infos/final/reward_dist Std          0.697107
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000986163
expl/env_infos/initial/reward_dist Std        0.00265933
expl/env_infos/initial/reward_dist Max        0.0121503
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.690268
expl/env_infos/reward_dist Std                0.630707
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      52400
eval/num paths total                       1310
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.929505
eval/Rewards Std                              0.594677
eval/Rewards Max                              1.5708
eval/Rewards Min                              0
eval/Returns Mean                            37.1802
eval/Returns Std                              0.535332
eval/Returns Max                             37.6761
eval/Returns Min                             35.916
eval/Actions Mean                             0.586602
eval/Actions Std                              0.58524
eval/Actions Max                              1
eval/Actions Min                             -0.999795
eval/Num Paths                               10
eval/Average Returns                         37.1802
eval/env_infos/final/reward_dist Mean         1.57003
eval/env_infos/final/reward_dist Std          0.000935786
eval/env_infos/final/reward_dist Max          1.5708
eval/env_infos/final/reward_dist Min          1.56823
eval/env_infos/initial/reward_dist Mean       0.00109918
eval/env_infos/initial/reward_dist Std        0.00165728
eval/env_infos/initial/reward_dist Max        0.00479727
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.929505
eval/env_infos/reward_dist Std                0.594677
eval/env_infos/reward_dist Max                1.5708
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588861
time/evaluation sampling (s)                  3.37339
time/exploration sampling (s)                17.9094
time/logging (s)                              0.00531343
time/saving (s)                               0.00243778
time/training (s)                             4.51117
time/epoch (s)                               25.8076
time/total (s)                             3325.38
Epoch                                       130
---------------------------------------  ----------------
2023-08-05 01:17:03.394292 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 131 finished
---------------------------------------  ----------------
epoch                                       131
replay_buffer/size                       264000
trainer/QF1 Loss                              1.13611
trainer/QF2 Loss                              1.12769
trainer/Policy Loss                          -7.98814
trainer/Q1 Predictions Mean                   6.55011
trainer/Q1 Predictions Std                    7.13041
trainer/Q1 Predictions Max                   22.535
trainer/Q1 Predictions Min                  -18.2265
trainer/Q2 Predictions Mean                   6.55584
trainer/Q2 Predictions Std                    7.1269
trainer/Q2 Predictions Max                   22.5879
trainer/Q2 Predictions Min                  -18.3553
trainer/Q Targets Mean                        6.62608
trainer/Q Targets Std                         7.22866
trainer/Q Targets Max                        23.0796
trainer/Q Targets Min                       -18.151
trainer/Bellman Errors 1 Mean                 1.13611
trainer/Bellman Errors 1 Std                  6.33371
trainer/Bellman Errors 1 Max                117.368
trainer/Bellman Errors 1 Min                  1.77683e-07
trainer/Bellman Errors 2 Mean                 1.12769
trainer/Bellman Errors 2 Std                  6.55179
trainer/Bellman Errors 2 Max                123.436
trainer/Bellman Errors 2 Min                  1.85983e-08
trainer/Policy Action Mean                    0.470826
trainer/Policy Action Std                     0.71111
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     264000
expl/num paths total                       6600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.703839
expl/Rewards Std                              0.617992
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            28.1535
expl/Returns Std                             13.2475
expl/Returns Max                             38.8232
expl/Returns Min                              0
expl/Actions Mean                             0.476437
expl/Actions Std                              0.667354
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         28.1535
expl/env_infos/final/reward_dist Mean         1.13608
expl/env_infos/final/reward_dist Std          0.67659
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000338542
expl/env_infos/initial/reward_dist Std        0.00114607
expl/env_infos/initial/reward_dist Max        0.0062269
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.703839
expl/env_infos/reward_dist Std                0.617992
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      52800
eval/num paths total                       1320
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.90419
eval/Rewards Std                              0.591709
eval/Rewards Max                              1.5708
eval/Rewards Min                              0
eval/Returns Mean                            36.1676
eval/Returns Std                              1.24024
eval/Returns Max                             37.5726
eval/Returns Min                             33.0304
eval/Actions Mean                             0.564341
eval/Actions Std                              0.605586
eval/Actions Max                              1
eval/Actions Min                             -0.9997
eval/Num Paths                               10
eval/Average Returns                         36.1676
eval/env_infos/final/reward_dist Mean         1.54917
eval/env_infos/final/reward_dist Std          0.0575715
eval/env_infos/final/reward_dist Max          1.5708
eval/env_infos/final/reward_dist Min          1.37675
eval/env_infos/initial/reward_dist Mean       0.000931941
eval/env_infos/initial/reward_dist Std        0.00237872
eval/env_infos/initial/reward_dist Max        0.00796445
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.90419
eval/env_infos/reward_dist Std                0.591709
eval/env_infos/reward_dist Max                1.5708
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587542
time/evaluation sampling (s)                  3.42244
time/exploration sampling (s)                18.0279
time/logging (s)                              0.00533308
time/saving (s)                               0.00242542
time/training (s)                             4.44333
time/epoch (s)                               25.9073
time/total (s)                             3351.29
Epoch                                       131
---------------------------------------  ----------------
2023-08-05 01:17:29.464200 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 132 finished
---------------------------------------  ----------------
epoch                                       132
replay_buffer/size                       266000
trainer/QF1 Loss                              1.11614
trainer/QF2 Loss                              1.11922
trainer/Policy Loss                          -7.91617
trainer/Q1 Predictions Mean                   6.65406
trainer/Q1 Predictions Std                    7.10847
trainer/Q1 Predictions Max                   22.7725
trainer/Q1 Predictions Min                  -18.8851
trainer/Q2 Predictions Mean                   6.63896
trainer/Q2 Predictions Std                    7.11372
trainer/Q2 Predictions Max                   23.0796
trainer/Q2 Predictions Min                  -18.2747
trainer/Q Targets Mean                        6.63281
trainer/Q Targets Std                         7.20248
trainer/Q Targets Max                        24.0473
trainer/Q Targets Min                       -18.3504
trainer/Bellman Errors 1 Mean                 1.11614
trainer/Bellman Errors 1 Std                  7.16939
trainer/Bellman Errors 1 Max                125.31
trainer/Bellman Errors 1 Min                  1.62735e-07
trainer/Bellman Errors 2 Mean                 1.11922
trainer/Bellman Errors 2 Std                  7.41183
trainer/Bellman Errors 2 Max                130.755
trainer/Bellman Errors 2 Min                  1.90562e-08
trainer/Policy Action Mean                    0.489662
trainer/Policy Action Std                     0.69886
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     266000
expl/num paths total                       6650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.812007
expl/Rewards Std                              0.621801
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            32.4803
expl/Returns Std                             10.5228
expl/Returns Max                             38.6963
expl/Returns Min                              0
expl/Actions Mean                             0.505285
expl/Actions Std                              0.639486
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.4803
expl/env_infos/final/reward_dist Mean         1.37612
expl/env_infos/final/reward_dist Std          0.508856
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000933852
expl/env_infos/initial/reward_dist Std        0.00223689
expl/env_infos/initial/reward_dist Max        0.00801224
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.812007
expl/env_infos/reward_dist Std                0.621801
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      53200
eval/num paths total                       1330
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.818998
eval/Rewards Std                              0.622868
eval/Rewards Max                              1.5708
eval/Rewards Min                              0
eval/Returns Mean                            32.7599
eval/Returns Std                             10.9539
eval/Returns Max                             37.7623
eval/Returns Min                              0.0772043
eval/Actions Mean                             0.525677
eval/Actions Std                              0.651584
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         32.7599
eval/env_infos/final/reward_dist Mean         1.39488
eval/env_infos/final/reward_dist Std          0.466385
eval/env_infos/final/reward_dist Max          1.5708
eval/env_infos/final/reward_dist Min          0.00590178
eval/env_infos/initial/reward_dist Mean       0.000584686
eval/env_infos/initial/reward_dist Std        0.00175406
eval/env_infos/initial/reward_dist Max        0.00584686
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.818998
eval/env_infos/reward_dist Std                0.622868
eval/env_infos/reward_dist Max                1.5708
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00580629
time/evaluation sampling (s)                  3.44489
time/exploration sampling (s)                18.0079
time/logging (s)                              0.00740833
time/saving (s)                               0.00269717
time/training (s)                             4.60062
time/epoch (s)                               26.0693
time/total (s)                             3377.36
Epoch                                       132
---------------------------------------  ----------------
2023-08-05 01:17:55.325896 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 133 finished
---------------------------------------  ----------------
epoch                                       133
replay_buffer/size                       268000
trainer/QF1 Loss                              1.09868
trainer/QF2 Loss                              1.08512
trainer/Policy Loss                          -8.39332
trainer/Q1 Predictions Mean                   6.83895
trainer/Q1 Predictions Std                    7.23606
trainer/Q1 Predictions Max                   22.6667
trainer/Q1 Predictions Min                  -17.2133
trainer/Q2 Predictions Mean                   6.82496
trainer/Q2 Predictions Std                    7.23414
trainer/Q2 Predictions Max                   22.9591
trainer/Q2 Predictions Min                  -17.1296
trainer/Q Targets Mean                        6.80481
trainer/Q Targets Std                         7.3084
trainer/Q Targets Max                        23.396
trainer/Q Targets Min                       -17.275
trainer/Bellman Errors 1 Mean                 1.09868
trainer/Bellman Errors 1 Std                  7.08009
trainer/Bellman Errors 1 Max                147.222
trainer/Bellman Errors 1 Min                  7.53153e-09
trainer/Bellman Errors 2 Mean                 1.08512
trainer/Bellman Errors 2 Std                  7.1906
trainer/Bellman Errors 2 Max                147.041
trainer/Bellman Errors 2 Min                  8.74024e-10
trainer/Policy Action Mean                    0.448867
trainer/Policy Action Std                     0.695116
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     268000
expl/num paths total                       6700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.796539
expl/Rewards Std                              0.652489
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            31.8616
expl/Returns Std                             12.6751
expl/Returns Max                             38.2899
expl/Returns Min                              0
expl/Actions Mean                             0.473329
expl/Actions Std                              0.643535
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.8616
expl/env_infos/final/reward_dist Mean         1.34961
expl/env_infos/final/reward_dist Std          0.544479
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000979026
expl/env_infos/initial/reward_dist Std        0.00353927
expl/env_infos/initial/reward_dist Max        0.0196287
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.796539
expl/env_infos/reward_dist Std                0.652489
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      53600
eval/num paths total                       1340
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.9406
eval/Rewards Std                              0.610187
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            37.624
eval/Returns Std                              0.740094
eval/Returns Max                             38.8117
eval/Returns Min                             36.6028
eval/Actions Mean                             0.528766
eval/Actions Std                              0.614483
eval/Actions Max                              1
eval/Actions Min                             -0.991037
eval/Num Paths                               10
eval/Average Returns                         37.624
eval/env_infos/final/reward_dist Mean         1.56869
eval/env_infos/final/reward_dist Std          0.00219888
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          1.56402
eval/env_infos/initial/reward_dist Mean       0.00316998
eval/env_infos/initial/reward_dist Std        0.00507346
eval/env_infos/initial/reward_dist Max        0.0142576
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.9406
eval/env_infos/reward_dist Std                0.610187
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587219
time/evaluation sampling (s)                  3.37219
time/exploration sampling (s)                17.6454
time/logging (s)                              0.00738175
time/saving (s)                               0.00270422
time/training (s)                             4.82362
time/epoch (s)                               25.8572
time/total (s)                             3403.22
Epoch                                       133
---------------------------------------  ----------------
2023-08-05 01:18:20.955461 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 134 finished
---------------------------------------  ----------------
epoch                                       134
replay_buffer/size                       270000
trainer/QF1 Loss                              1.24394
trainer/QF2 Loss                              1.21857
trainer/Policy Loss                          -8.48007
trainer/Q1 Predictions Mean                   6.50038
trainer/Q1 Predictions Std                    7.40466
trainer/Q1 Predictions Max                   22.939
trainer/Q1 Predictions Min                  -18.2373
trainer/Q2 Predictions Mean                   6.49244
trainer/Q2 Predictions Std                    7.39971
trainer/Q2 Predictions Max                   22.8881
trainer/Q2 Predictions Min                  -17.6508
trainer/Q Targets Mean                        6.4591
trainer/Q Targets Std                         7.4772
trainer/Q Targets Max                        23.8913
trainer/Q Targets Min                       -17.2861
trainer/Bellman Errors 1 Mean                 1.24394
trainer/Bellman Errors 1 Std                  7.06306
trainer/Bellman Errors 1 Max                137.006
trainer/Bellman Errors 1 Min                  1.56638e-09
trainer/Bellman Errors 2 Mean                 1.21857
trainer/Bellman Errors 2 Std                  7.1226
trainer/Bellman Errors 2 Max                141.947
trainer/Bellman Errors 2 Min                  1.39757e-07
trainer/Policy Action Mean                    0.459227
trainer/Policy Action Std                     0.715065
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     270000
expl/num paths total                       6750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.508057
expl/Rewards Std                              0.666655
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            20.3223
expl/Returns Std                             20.2252
expl/Returns Max                             42.105
expl/Returns Min                              0
expl/Actions Mean                             0.418532
expl/Actions Std                              0.715967
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.3223
expl/env_infos/final/reward_dist Mean         0.784801
expl/env_infos/final/reward_dist Std          0.784412
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000611786
expl/env_infos/initial/reward_dist Std        0.00240685
expl/env_infos/initial/reward_dist Max        0.0137253
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.508057
expl/env_infos/reward_dist Std                0.666655
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      54000
eval/num paths total                       1350
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.61021
eval/Rewards Std                              0.689357
eval/Rewards Max                              1.57063
eval/Rewards Min                              0
eval/Returns Mean                            24.4084
eval/Returns Std                             19.9477
eval/Returns Max                             41.8024
eval/Returns Min                              0
eval/Actions Mean                             0.519939
eval/Actions Std                              0.66084
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.4084
eval/env_infos/final/reward_dist Mean         0.941659
eval/env_infos/final/reward_dist Std          0.768862
eval/env_infos/final/reward_dist Max          1.57063
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00017715
eval/env_infos/initial/reward_dist Std        0.000431596
eval/env_infos/initial/reward_dist Max        0.00143687
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.61021
eval/env_infos/reward_dist Std                0.689357
eval/env_infos/reward_dist Max                1.57063
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00569939
time/evaluation sampling (s)                  3.4532
time/exploration sampling (s)                17.3802
time/logging (s)                              0.00535417
time/saving (s)                               0.00235487
time/training (s)                             4.77624
time/epoch (s)                               25.623
time/total (s)                             3428.85
Epoch                                       134
---------------------------------------  ----------------
2023-08-05 01:18:46.429042 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 135 finished
---------------------------------------  ----------------
epoch                                       135
replay_buffer/size                       272000
trainer/QF1 Loss                              1.2828
trainer/QF2 Loss                              1.26728
trainer/Policy Loss                          -8.07479
trainer/Q1 Predictions Mean                   6.3234
trainer/Q1 Predictions Std                    7.324
trainer/Q1 Predictions Max                   22.6339
trainer/Q1 Predictions Min                  -16.0712
trainer/Q2 Predictions Mean                   6.32154
trainer/Q2 Predictions Std                    7.32142
trainer/Q2 Predictions Max                   22.8893
trainer/Q2 Predictions Min                  -15.9205
trainer/Q Targets Mean                        6.28039
trainer/Q Targets Std                         7.40958
trainer/Q Targets Max                        23.6395
trainer/Q Targets Min                       -18.6433
trainer/Bellman Errors 1 Mean                 1.2828
trainer/Bellman Errors 1 Std                  6.56762
trainer/Bellman Errors 1 Max                131.565
trainer/Bellman Errors 1 Min                  8.55744e-09
trainer/Bellman Errors 2 Mean                 1.26728
trainer/Bellman Errors 2 Std                  6.50116
trainer/Bellman Errors 2 Max                127.457
trainer/Bellman Errors 2 Min                  6.87805e-10
trainer/Policy Action Mean                    0.396906
trainer/Policy Action Std                     0.740955
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     272000
expl/num paths total                       6800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.219038
expl/Rewards Std                              0.47045
expl/Rewards Max                              1.5707
expl/Rewards Min                              0
expl/Returns Mean                             8.7615
expl/Returns Std                             12.5656
expl/Returns Max                             34.9371
expl/Returns Min                              0
expl/Actions Mean                             0.33466
expl/Actions Std                              0.751131
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.7615
expl/env_infos/final/reward_dist Mean         0.533534
expl/env_infos/final/reward_dist Std          0.743089
expl/env_infos/final/reward_dist Max          1.5707
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000891359
expl/env_infos/initial/reward_dist Std        0.00292774
expl/env_infos/initial/reward_dist Max        0.0168394
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.219038
expl/env_infos/reward_dist Std                0.47045
expl/env_infos/reward_dist Max                1.5707
expl/env_infos/reward_dist Min                0
eval/num steps total                      54400
eval/num paths total                       1360
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.400595
eval/Rewards Std                              0.559357
eval/Rewards Max                              1.56982
eval/Rewards Min                              0
eval/Returns Mean                            16.0238
eval/Returns Std                             11.1499
eval/Returns Max                             27.8556
eval/Returns Min                              0.0027118
eval/Actions Mean                             0.374081
eval/Actions Std                              0.715606
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.0238
eval/env_infos/final/reward_dist Mean         1.09794
eval/env_infos/final/reward_dist Std          0.718773
eval/env_infos/final/reward_dist Max          1.56982
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000380604
eval/env_infos/initial/reward_dist Std        0.00114181
eval/env_infos/initial/reward_dist Max        0.00380604
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.400595
eval/env_infos/reward_dist Std                0.559357
eval/env_infos/reward_dist Max                1.56982
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00583334
time/evaluation sampling (s)                  3.52088
time/exploration sampling (s)                17.6923
time/logging (s)                              0.00532597
time/saving (s)                               0.00234382
time/training (s)                             4.24422
time/epoch (s)                               25.4709
time/total (s)                             3454.32
Epoch                                       135
---------------------------------------  ----------------
2023-08-05 01:19:11.824986 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 136 finished
---------------------------------------  ----------------
epoch                                       136
replay_buffer/size                       274000
trainer/QF1 Loss                              1.31372
trainer/QF2 Loss                              1.2886
trainer/Policy Loss                          -7.75727
trainer/Q1 Predictions Mean                   6.20174
trainer/Q1 Predictions Std                    7.39745
trainer/Q1 Predictions Max                   22.2538
trainer/Q1 Predictions Min                  -16.9362
trainer/Q2 Predictions Mean                   6.20887
trainer/Q2 Predictions Std                    7.40649
trainer/Q2 Predictions Max                   22.4425
trainer/Q2 Predictions Min                  -16.6237
trainer/Q Targets Mean                        6.17136
trainer/Q Targets Std                         7.50683
trainer/Q Targets Max                        23.5608
trainer/Q Targets Min                       -16.2289
trainer/Bellman Errors 1 Mean                 1.31372
trainer/Bellman Errors 1 Std                  7.86554
trainer/Bellman Errors 1 Max                163.298
trainer/Bellman Errors 1 Min                  2.07374e-08
trainer/Bellman Errors 2 Mean                 1.2886
trainer/Bellman Errors 2 Std                  7.89705
trainer/Bellman Errors 2 Max                167.419
trainer/Bellman Errors 2 Min                  1.28794e-08
trainer/Policy Action Mean                    0.434242
trainer/Policy Action Std                     0.745666
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     274000
expl/num paths total                       6850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.499653
expl/Rewards Std                              0.664298
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            19.9861
expl/Returns Std                             19.9739
expl/Returns Max                             41.7964
expl/Returns Min                              0
expl/Actions Mean                             0.43686
expl/Actions Std                              0.736025
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.9861
expl/env_infos/final/reward_dist Mean         0.784797
expl/env_infos/final/reward_dist Std          0.784224
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00226064
expl/env_infos/initial/reward_dist Std        0.00488569
expl/env_infos/initial/reward_dist Max        0.0171878
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.499653
expl/env_infos/reward_dist Std                0.664298
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      54800
eval/num paths total                       1370
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.292593
eval/Rewards Std                              0.563821
eval/Rewards Max                              1.5708
eval/Rewards Min                              0
eval/Returns Mean                            11.7037
eval/Returns Std                             17.8755
eval/Returns Max                             40.6334
eval/Returns Min                              0
eval/Actions Mean                             0.334937
eval/Actions Std                              0.831954
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.7037
eval/env_infos/final/reward_dist Mean         0.470884
eval/env_infos/final/reward_dist Std          0.718892
eval/env_infos/final/reward_dist Max          1.5708
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000916464
eval/env_infos/initial/reward_dist Std        0.00167803
eval/env_infos/initial/reward_dist Max        0.00478081
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.292593
eval/env_infos/reward_dist Std                0.563821
eval/env_infos/reward_dist Max                1.5708
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00586268
time/evaluation sampling (s)                  3.39003
time/exploration sampling (s)                17.4348
time/logging (s)                              0.00529177
time/saving (s)                               0.00242203
time/training (s)                             4.5547
time/epoch (s)                               25.3931
time/total (s)                             3479.71
Epoch                                       136
---------------------------------------  ----------------
2023-08-05 01:19:37.277631 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 137 finished
---------------------------------------  ----------------
epoch                                       137
replay_buffer/size                       276000
trainer/QF1 Loss                              1.33544
trainer/QF2 Loss                              1.33896
trainer/Policy Loss                          -8.1268
trainer/Q1 Predictions Mean                   6.5163
trainer/Q1 Predictions Std                    7.38001
trainer/Q1 Predictions Max                   21.7596
trainer/Q1 Predictions Min                  -15.1414
trainer/Q2 Predictions Mean                   6.49827
trainer/Q2 Predictions Std                    7.39476
trainer/Q2 Predictions Max                   21.8638
trainer/Q2 Predictions Min                  -15.1536
trainer/Q Targets Mean                        6.54967
trainer/Q Targets Std                         7.50786
trainer/Q Targets Max                        22.8469
trainer/Q Targets Min                       -16.5863
trainer/Bellman Errors 1 Mean                 1.33544
trainer/Bellman Errors 1 Std                  7.6201
trainer/Bellman Errors 1 Max                142.687
trainer/Bellman Errors 1 Min                  6.24314e-08
trainer/Bellman Errors 2 Mean                 1.33896
trainer/Bellman Errors 2 Std                  7.72608
trainer/Bellman Errors 2 Max                144.832
trainer/Bellman Errors 2 Min                  1.38718e-08
trainer/Policy Action Mean                    0.434724
trainer/Policy Action Std                     0.728744
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     276000
expl/num paths total                       6900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.549784
expl/Rewards Std                              0.677143
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            21.9913
expl/Returns Std                             20.0707
expl/Returns Max                             41.9485
expl/Returns Min                              0
expl/Actions Mean                             0.455904
expl/Actions Std                              0.716684
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.9913
expl/env_infos/final/reward_dist Mean         0.866719
expl/env_infos/final/reward_dist Std          0.770142
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00150265
expl/env_infos/initial/reward_dist Std        0.00383669
expl/env_infos/initial/reward_dist Max        0.0158424
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.549784
expl/env_infos/reward_dist Std                0.677143
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      55200
eval/num paths total                       1380
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.713115
eval/Rewards Std                              0.694653
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            28.5246
eval/Returns Std                             18.6603
eval/Returns Max                             41.5366
eval/Returns Min                              0.00703216
eval/Actions Mean                             0.47954
eval/Actions Std                              0.724284
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.5246
eval/env_infos/final/reward_dist Mean         1.09835
eval/env_infos/final/reward_dist Std          0.718966
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00498412
eval/env_infos/initial/reward_dist Std        0.00632948
eval/env_infos/initial/reward_dist Max        0.0157184
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.713115
eval/env_infos/reward_dist Std                0.694653
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00596574
time/evaluation sampling (s)                  3.40927
time/exploration sampling (s)                17.3306
time/logging (s)                              0.00534576
time/saving (s)                               0.00241163
time/training (s)                             4.69633
time/epoch (s)                               25.45
time/total (s)                             3505.17
Epoch                                       137
---------------------------------------  ----------------
2023-08-05 01:20:03.699019 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 138 finished
---------------------------------------  ----------------
epoch                                       138
replay_buffer/size                       278000
trainer/QF1 Loss                              1.30602
trainer/QF2 Loss                              1.29852
trainer/Policy Loss                          -7.79014
trainer/Q1 Predictions Mean                   6.23205
trainer/Q1 Predictions Std                    7.55042
trainer/Q1 Predictions Max                   22.0106
trainer/Q1 Predictions Min                  -13.8131
trainer/Q2 Predictions Mean                   6.24603
trainer/Q2 Predictions Std                    7.54942
trainer/Q2 Predictions Max                   22.2755
trainer/Q2 Predictions Min                  -13.79
trainer/Q Targets Mean                        6.21795
trainer/Q Targets Std                         7.65054
trainer/Q Targets Max                        22.8412
trainer/Q Targets Min                       -15.1962
trainer/Bellman Errors 1 Mean                 1.30602
trainer/Bellman Errors 1 Std                  7.60153
trainer/Bellman Errors 1 Max                134.513
trainer/Bellman Errors 1 Min                  1.42109e-10
trainer/Bellman Errors 2 Mean                 1.29852
trainer/Bellman Errors 2 Std                  7.73837
trainer/Bellman Errors 2 Max                143.337
trainer/Bellman Errors 2 Min                  3.05954e-09
trainer/Policy Action Mean                    0.411986
trainer/Policy Action Std                     0.730325
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     278000
expl/num paths total                       6950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.323313
expl/Rewards Std                              0.58426
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            12.9325
expl/Returns Std                             18.8058
expl/Returns Max                             42.3286
expl/Returns Min                              0
expl/Actions Mean                             0.357604
expl/Actions Std                              0.77269
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.9325
expl/env_infos/final/reward_dist Mean         0.501686
expl/env_infos/final/reward_dist Std          0.73082
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00108512
expl/env_infos/initial/reward_dist Std        0.00383125
expl/env_infos/initial/reward_dist Max        0.0179844
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.323313
expl/env_infos/reward_dist Std                0.58426
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      55600
eval/num paths total                       1390
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.300588
eval/Rewards Std                              0.571172
eval/Rewards Max                              1.5705
eval/Rewards Min                              0
eval/Returns Mean                            12.0235
eval/Returns Std                             18.353
eval/Returns Max                             40.5583
eval/Returns Min                              0
eval/Actions Mean                             0.376661
eval/Actions Std                              0.801194
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         12.0235
eval/env_infos/final/reward_dist Mean         0.470949
eval/env_infos/final/reward_dist Std          0.719366
eval/env_infos/final/reward_dist Max          1.5705
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.300588
eval/env_infos/reward_dist Std                0.571172
eval/env_infos/reward_dist Max                1.5705
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00586619
time/evaluation sampling (s)                  3.31304
time/exploration sampling (s)                17.539
time/logging (s)                              0.00538762
time/saving (s)                               0.002401
time/training (s)                             5.5531
time/epoch (s)                               26.4188
time/total (s)                             3531.59
Epoch                                       138
---------------------------------------  ----------------
2023-08-05 01:20:29.113401 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 139 finished
---------------------------------------  ----------------
epoch                                       139
replay_buffer/size                       280000
trainer/QF1 Loss                              1.48084
trainer/QF2 Loss                              1.49022
trainer/Policy Loss                          -8.22506
trainer/Q1 Predictions Mean                   6.62209
trainer/Q1 Predictions Std                    7.50355
trainer/Q1 Predictions Max                   22.9171
trainer/Q1 Predictions Min                  -12.8834
trainer/Q2 Predictions Mean                   6.62276
trainer/Q2 Predictions Std                    7.50176
trainer/Q2 Predictions Max                   23.0676
trainer/Q2 Predictions Min                  -12.7457
trainer/Q Targets Mean                        6.60907
trainer/Q Targets Std                         7.60698
trainer/Q Targets Max                        23.4604
trainer/Q Targets Min                       -14.4071
trainer/Bellman Errors 1 Mean                 1.48084
trainer/Bellman Errors 1 Std                  9.47946
trainer/Bellman Errors 1 Max                180.048
trainer/Bellman Errors 1 Min                  7.70169e-08
trainer/Bellman Errors 2 Mean                 1.49022
trainer/Bellman Errors 2 Std                  9.62347
trainer/Bellman Errors 2 Max                182.928
trainer/Bellman Errors 2 Min                  9.08185e-08
trainer/Policy Action Mean                    0.401287
trainer/Policy Action Std                     0.727504
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     280000
expl/num paths total                       7000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.521398
expl/Rewards Std                              0.668067
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            20.8559
expl/Returns Std                             19.7865
expl/Returns Max                             40.7994
expl/Returns Min                              0
expl/Actions Mean                             0.410163
expl/Actions Std                              0.731983
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.8559
expl/env_infos/final/reward_dist Mean         0.834488
expl/env_infos/final/reward_dist Std          0.775463
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000567182
expl/env_infos/initial/reward_dist Std        0.00274539
expl/env_infos/initial/reward_dist Max        0.0158088
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.521398
expl/env_infos/reward_dist Std                0.668067
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      56000
eval/num paths total                       1400
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.376027
eval/Rewards Std                              0.607521
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            15.0411
eval/Returns Std                             18.6604
eval/Returns Max                             40.9216
eval/Returns Min                              8.29685e-05
eval/Actions Mean                             0.392509
eval/Actions Std                              0.762816
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         15.0411
eval/env_infos/final/reward_dist Mean         0.62094
eval/env_infos/final/reward_dist Std          0.760749
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0012306
eval/env_infos/initial/reward_dist Std        0.00369181
eval/env_infos/initial/reward_dist Max        0.012306
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.376027
eval/env_infos/reward_dist Std                0.607521
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00577001
time/evaluation sampling (s)                  3.45065
time/exploration sampling (s)                17.3395
time/logging (s)                              0.00537259
time/saving (s)                               0.00233076
time/training (s)                             4.6079
time/epoch (s)                               25.4116
time/total (s)                             3557
Epoch                                       139
---------------------------------------  ----------------
2023-08-05 01:20:55.177251 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 140 finished
---------------------------------------  ----------------
epoch                                       140
replay_buffer/size                       282000
trainer/QF1 Loss                              1.44812
trainer/QF2 Loss                              1.429
trainer/Policy Loss                          -8.32508
trainer/Q1 Predictions Mean                   6.62556
trainer/Q1 Predictions Std                    7.72492
trainer/Q1 Predictions Max                   22.8889
trainer/Q1 Predictions Min                  -11.9941
trainer/Q2 Predictions Mean                   6.59881
trainer/Q2 Predictions Std                    7.72346
trainer/Q2 Predictions Max                   22.8767
trainer/Q2 Predictions Min                  -13.8247
trainer/Q Targets Mean                        6.61781
trainer/Q Targets Std                         7.83207
trainer/Q Targets Max                        23.1613
trainer/Q Targets Min                       -12.0984
trainer/Bellman Errors 1 Mean                 1.44812
trainer/Bellman Errors 1 Std                  8.95291
trainer/Bellman Errors 1 Max                206.117
trainer/Bellman Errors 1 Min                  1.00399e-07
trainer/Bellman Errors 2 Mean                 1.429
trainer/Bellman Errors 2 Std                  8.98337
trainer/Bellman Errors 2 Max                213.516
trainer/Bellman Errors 2 Min                  2.24896e-08
trainer/Policy Action Mean                    0.403896
trainer/Policy Action Std                     0.731384
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     282000
expl/num paths total                       7050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.41033
expl/Rewards Std                              0.628635
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            16.4132
expl/Returns Std                             19.3427
expl/Returns Max                             40.6488
expl/Returns Min                              0
expl/Actions Mean                             0.371851
expl/Actions Std                              0.75231
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.4132
expl/env_infos/final/reward_dist Mean         0.657149
expl/env_infos/final/reward_dist Std          0.772295
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00108962
expl/env_infos/initial/reward_dist Std        0.00403927
expl/env_infos/initial/reward_dist Max        0.0203618
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.41033
expl/env_infos/reward_dist Std                0.628635
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      56400
eval/num paths total                       1410
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.400176
eval/Rewards Std                              0.627877
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            16.007
eval/Returns Std                             19.5903
eval/Returns Max                             40.4673
eval/Returns Min                              0
eval/Actions Mean                             0.33362
eval/Actions Std                              0.79033
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.007
eval/env_infos/final/reward_dist Mean         0.627694
eval/env_infos/final/reward_dist Std          0.768765
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.400176
eval/env_infos/reward_dist Std                0.627877
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585462
time/evaluation sampling (s)                  3.53193
time/exploration sampling (s)                17.8847
time/logging (s)                              0.00533541
time/saving (s)                               0.00234216
time/training (s)                             4.63095
time/epoch (s)                               26.0611
time/total (s)                             3583.06
Epoch                                       140
---------------------------------------  ----------------
2023-08-05 01:21:20.807610 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 141 finished
---------------------------------------  ----------------
epoch                                       141
replay_buffer/size                       284000
trainer/QF1 Loss                              1.24844
trainer/QF2 Loss                              1.22809
trainer/Policy Loss                          -8.29794
trainer/Q1 Predictions Mean                   6.67848
trainer/Q1 Predictions Std                    7.80404
trainer/Q1 Predictions Max                   23.092
trainer/Q1 Predictions Min                  -11.0394
trainer/Q2 Predictions Mean                   6.67124
trainer/Q2 Predictions Std                    7.80575
trainer/Q2 Predictions Max                   23.1333
trainer/Q2 Predictions Min                  -11.6789
trainer/Q Targets Mean                        6.65681
trainer/Q Targets Std                         7.88908
trainer/Q Targets Max                        23.4959
trainer/Q Targets Min                       -11.4975
trainer/Bellman Errors 1 Mean                 1.24844
trainer/Bellman Errors 1 Std                  7.72868
trainer/Bellman Errors 1 Max                160.889
trainer/Bellman Errors 1 Min                  2.74622e-07
trainer/Bellman Errors 2 Mean                 1.22809
trainer/Bellman Errors 2 Std                  7.81778
trainer/Bellman Errors 2 Max                162.053
trainer/Bellman Errors 2 Min                  6.38693e-08
trainer/Policy Action Mean                    0.398181
trainer/Policy Action Std                     0.738329
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     284000
expl/num paths total                       7100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.483995
expl/Rewards Std                              0.659718
expl/Rewards Max                              1.57073
expl/Rewards Min                              0
expl/Returns Mean                            19.3598
expl/Returns Std                             20.1293
expl/Returns Max                             42.4269
expl/Returns Min                              0
expl/Actions Mean                             0.396376
expl/Actions Std                              0.744177
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.3598
expl/env_infos/final/reward_dist Mean         0.751978
expl/env_infos/final/reward_dist Std          0.782583
expl/env_infos/final/reward_dist Max          1.57073
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00158607
expl/env_infos/initial/reward_dist Std        0.00444239
expl/env_infos/initial/reward_dist Max        0.0235255
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.483995
expl/env_infos/reward_dist Std                0.659718
expl/env_infos/reward_dist Max                1.57073
expl/env_infos/reward_dist Min                0
eval/num steps total                      56800
eval/num paths total                       1420
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.401146
eval/Rewards Std                              0.627956
eval/Rewards Max                              1.57062
eval/Rewards Min                              0
eval/Returns Mean                            16.0458
eval/Returns Std                             19.6089
eval/Returns Max                             40.235
eval/Returns Min                              6.78916e-05
eval/Actions Mean                             0.361081
eval/Actions Std                              0.795198
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.0458
eval/env_infos/final/reward_dist Mean         0.627274
eval/env_infos/final/reward_dist Std          0.768161
eval/env_infos/final/reward_dist Max          1.57062
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       7.213e-05
eval/env_infos/initial/reward_dist Std        0.00021639
eval/env_infos/initial/reward_dist Max        0.0007213
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.401146
eval/env_infos/reward_dist Std                0.627956
eval/env_infos/reward_dist Max                1.57062
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587731
time/evaluation sampling (s)                  3.513
time/exploration sampling (s)                17.6839
time/logging (s)                              0.00535094
time/saving (s)                               0.00237081
time/training (s)                             4.41714
time/epoch (s)                               25.6277
time/total (s)                             3608.69
Epoch                                       141
---------------------------------------  ----------------
2023-08-05 01:21:46.857305 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 142 finished
---------------------------------------  ----------------
epoch                                       142
replay_buffer/size                       286000
trainer/QF1 Loss                              1.24717
trainer/QF2 Loss                              1.26549
trainer/Policy Loss                          -8.21102
trainer/Q1 Predictions Mean                   6.59109
trainer/Q1 Predictions Std                    7.89214
trainer/Q1 Predictions Max                   23.076
trainer/Q1 Predictions Min                  -10.3486
trainer/Q2 Predictions Mean                   6.58057
trainer/Q2 Predictions Std                    7.90098
trainer/Q2 Predictions Max                   23.1413
trainer/Q2 Predictions Min                  -10.4547
trainer/Q Targets Mean                        6.58967
trainer/Q Targets Std                         7.96654
trainer/Q Targets Max                        23.7439
trainer/Q Targets Min                       -10.2884
trainer/Bellman Errors 1 Mean                 1.24717
trainer/Bellman Errors 1 Std                  8.21651
trainer/Bellman Errors 1 Max                185.002
trainer/Bellman Errors 1 Min                  3.32662e-10
trainer/Bellman Errors 2 Mean                 1.26549
trainer/Bellman Errors 2 Std                  8.32632
trainer/Bellman Errors 2 Max                191.014
trainer/Bellman Errors 2 Min                  1.1562e-08
trainer/Policy Action Mean                    0.384751
trainer/Policy Action Std                     0.742133
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     286000
expl/num paths total                       7150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.4993
expl/Rewards Std                              0.663135
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            19.972
expl/Returns Std                             19.9633
expl/Returns Max                             41.7119
expl/Returns Min                              0
expl/Actions Mean                             0.381311
expl/Actions Std                              0.749504
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.972
expl/env_infos/final/reward_dist Mean         0.783007
expl/env_infos/final/reward_dist Std          0.782826
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000845
expl/env_infos/initial/reward_dist Std        0.00259299
expl/env_infos/initial/reward_dist Max        0.0141941
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.4993
expl/env_infos/reward_dist Std                0.663135
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      57200
eval/num paths total                       1430
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.606653
eval/Rewards Std                              0.687815
eval/Rewards Max                              1.57017
eval/Rewards Min                              0
eval/Returns Mean                            24.2661
eval/Returns Std                             19.7989
eval/Returns Max                             41.1162
eval/Returns Min                              0
eval/Actions Mean                             0.366215
eval/Actions Std                              0.75216
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.2661
eval/env_infos/final/reward_dist Mean         0.94104
eval/env_infos/final/reward_dist Std          0.768077
eval/env_infos/final/reward_dist Max          1.57017
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.606653
eval/env_infos/reward_dist Std                0.687815
eval/env_infos/reward_dist Max                1.57017
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00592284
time/evaluation sampling (s)                  3.43913
time/exploration sampling (s)                18.1726
time/logging (s)                              0.00532651
time/saving (s)                               0.00236415
time/training (s)                             4.42167
time/epoch (s)                               26.047
time/total (s)                             3634.74
Epoch                                       142
---------------------------------------  ----------------
2023-08-05 01:22:13.261925 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 143 finished
---------------------------------------  ----------------
epoch                                       143
replay_buffer/size                       288000
trainer/QF1 Loss                              1.39103
trainer/QF2 Loss                              1.3933
trainer/Policy Loss                          -8.64331
trainer/Q1 Predictions Mean                   7.01669
trainer/Q1 Predictions Std                    8.09953
trainer/Q1 Predictions Max                   23.6211
trainer/Q1 Predictions Min                   -8.86988
trainer/Q2 Predictions Mean                   7.00653
trainer/Q2 Predictions Std                    8.10142
trainer/Q2 Predictions Max                   23.6822
trainer/Q2 Predictions Min                   -8.96059
trainer/Q Targets Mean                        6.96425
trainer/Q Targets Std                         8.18253
trainer/Q Targets Max                        24.2571
trainer/Q Targets Min                        -9.44509
trainer/Bellman Errors 1 Mean                 1.39103
trainer/Bellman Errors 1 Std                  9.29724
trainer/Bellman Errors 1 Max                201.044
trainer/Bellman Errors 1 Min                  1.60435e-09
trainer/Bellman Errors 2 Mean                 1.3933
trainer/Bellman Errors 2 Std                  9.6848
trainer/Bellman Errors 2 Max                205.765
trainer/Bellman Errors 2 Min                  2.43568e-09
trainer/Policy Action Mean                    0.382552
trainer/Policy Action Std                     0.744001
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     288000
expl/num paths total                       7200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.379558
expl/Rewards Std                              0.614366
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            15.1823
expl/Returns Std                             19.3682
expl/Returns Max                             41.2697
expl/Returns Min                              0
expl/Actions Mean                             0.377371
expl/Actions Std                              0.749269
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.1823
expl/env_infos/final/reward_dist Mean         0.594506
expl/env_infos/final/reward_dist Std          0.75941
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000343348
expl/env_infos/initial/reward_dist Std        0.00101282
expl/env_infos/initial/reward_dist Max        0.00444005
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.379558
expl/env_infos/reward_dist Std                0.614366
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      57600
eval/num paths total                       1440
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.301096
eval/Rewards Std                              0.569468
eval/Rewards Max                              1.57046
eval/Rewards Min                              0
eval/Returns Mean                            12.0438
eval/Returns Std                             18.3517
eval/Returns Max                             40.5084
eval/Returns Min                              0
eval/Actions Mean                             0.359753
eval/Actions Std                              0.768051
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         12.0438
eval/env_infos/final/reward_dist Mean         0.471287
eval/env_infos/final/reward_dist Std          0.719034
eval/env_infos/final/reward_dist Max          1.57046
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000141164
eval/env_infos/initial/reward_dist Std        0.000423493
eval/env_infos/initial/reward_dist Max        0.00141164
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.301096
eval/env_infos/reward_dist Std                0.569468
eval/env_infos/reward_dist Max                1.57046
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00570141
time/evaluation sampling (s)                  3.58553
time/exploration sampling (s)                18.2286
time/logging (s)                              0.00740051
time/saving (s)                               0.00272244
time/training (s)                             4.57398
time/epoch (s)                               26.4039
time/total (s)                             3661.15
Epoch                                       143
---------------------------------------  ----------------
2023-08-05 01:22:39.562969 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 144 finished
---------------------------------------  ----------------
epoch                                       144
replay_buffer/size                       290000
trainer/QF1 Loss                              1.79247
trainer/QF2 Loss                              1.78172
trainer/Policy Loss                          -8.58796
trainer/Q1 Predictions Mean                   6.83549
trainer/Q1 Predictions Std                    7.89772
trainer/Q1 Predictions Max                   23.8035
trainer/Q1 Predictions Min                   -9.77373
trainer/Q2 Predictions Mean                   6.83859
trainer/Q2 Predictions Std                    7.90082
trainer/Q2 Predictions Max                   23.8828
trainer/Q2 Predictions Min                   -8.81944
trainer/Q Targets Mean                        6.78281
trainer/Q Targets Std                         7.99083
trainer/Q Targets Max                        24.1219
trainer/Q Targets Min                        -8.7223
trainer/Bellman Errors 1 Mean                 1.79247
trainer/Bellman Errors 1 Std                 10.8637
trainer/Bellman Errors 1 Max                210.372
trainer/Bellman Errors 1 Min                  1.22382e-08
trainer/Bellman Errors 2 Mean                 1.78172
trainer/Bellman Errors 2 Std                 10.9629
trainer/Bellman Errors 2 Max                208.349
trainer/Bellman Errors 2 Min                  5.02268e-10
trainer/Policy Action Mean                    0.321378
trainer/Policy Action Std                     0.765604
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     290000
expl/num paths total                       7250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.207235
expl/Rewards Std                              0.451602
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                             8.28938
expl/Returns Std                             14.0489
expl/Returns Max                             35.6483
expl/Returns Min                              0
expl/Actions Mean                             0.296464
expl/Actions Std                              0.771431
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.28938
expl/env_infos/final/reward_dist Mean         0.405097
expl/env_infos/final/reward_dist Std          0.683111
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000862431
expl/env_infos/initial/reward_dist Std        0.00360519
expl/env_infos/initial/reward_dist Max        0.02052
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.207235
expl/env_infos/reward_dist Std                0.451602
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      58000
eval/num paths total                       1450
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.334634
eval/Rewards Std                              0.54183
eval/Rewards Max                              1.57065
eval/Rewards Min                              0
eval/Returns Mean                            13.3853
eval/Returns Std                             16.3709
eval/Returns Max                             33.8636
eval/Returns Min                              0
eval/Actions Mean                             0.323103
eval/Actions Std                              0.772513
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         13.3853
eval/env_infos/final/reward_dist Mean         0.627729
eval/env_infos/final/reward_dist Std          0.768808
eval/env_infos/final/reward_dist Max          1.57065
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00206876
eval/env_infos/initial/reward_dist Std        0.00466252
eval/env_infos/initial/reward_dist Max        0.0151501
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.334634
eval/env_infos/reward_dist Std                0.54183
eval/env_infos/reward_dist Max                1.57065
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00576675
time/evaluation sampling (s)                  3.51718
time/exploration sampling (s)                18.361
time/logging (s)                              0.00532244
time/saving (s)                               0.00230358
time/training (s)                             4.40272
time/epoch (s)                               26.2943
time/total (s)                             3687.44
Epoch                                       144
---------------------------------------  ----------------
2023-08-05 01:23:06.239972 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 145 finished
---------------------------------------  ----------------
epoch                                       145
replay_buffer/size                       292000
trainer/QF1 Loss                              1.49218
trainer/QF2 Loss                              1.47332
trainer/Policy Loss                          -7.91702
trainer/Q1 Predictions Mean                   6.40093
trainer/Q1 Predictions Std                    7.82623
trainer/Q1 Predictions Max                   22.9997
trainer/Q1 Predictions Min                   -8.01707
trainer/Q2 Predictions Mean                   6.41957
trainer/Q2 Predictions Std                    7.82952
trainer/Q2 Predictions Max                   23.0204
trainer/Q2 Predictions Min                   -8.19452
trainer/Q Targets Mean                        6.41661
trainer/Q Targets Std                         7.93484
trainer/Q Targets Max                        23.8031
trainer/Q Targets Min                        -9.97415
trainer/Bellman Errors 1 Mean                 1.49218
trainer/Bellman Errors 1 Std                  9.89747
trainer/Bellman Errors 1 Max                219.972
trainer/Bellman Errors 1 Min                  3.58361e-08
trainer/Bellman Errors 2 Mean                 1.47332
trainer/Bellman Errors 2 Std                  9.95092
trainer/Bellman Errors 2 Max                219.773
trainer/Bellman Errors 2 Min                  5.39239e-09
trainer/Policy Action Mean                    0.35511
trainer/Policy Action Std                     0.752339
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     292000
expl/num paths total                       7300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.269849
expl/Rewards Std                              0.519304
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            10.794
expl/Returns Std                             16.4317
expl/Returns Max                             37.3301
expl/Returns Min                              0
expl/Actions Mean                             0.328541
expl/Actions Std                              0.758742
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         10.794
expl/env_infos/final/reward_dist Mean         0.469659
expl/env_infos/final/reward_dist Std          0.716418
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000792531
expl/env_infos/initial/reward_dist Std        0.00239283
expl/env_infos/initial/reward_dist Max        0.0114826
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.269849
expl/env_infos/reward_dist Std                0.519304
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      58400
eval/num paths total                       1460
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.363881
eval/Rewards Std                              0.575772
eval/Rewards Max                              1.57067
eval/Rewards Min                              0
eval/Returns Mean                            14.5552
eval/Returns Std                             17.8172
eval/Returns Max                             37.4939
eval/Returns Min                              0.000275264
eval/Actions Mean                             0.355938
eval/Actions Std                              0.76104
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         14.5552
eval/env_infos/final/reward_dist Mean         0.627825
eval/env_infos/final/reward_dist Std          0.768894
eval/env_infos/final/reward_dist Max          1.57067
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00141785
eval/env_infos/initial/reward_dist Std        0.00354121
eval/env_infos/initial/reward_dist Max        0.0118321
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.363881
eval/env_infos/reward_dist Std                0.575772
eval/env_infos/reward_dist Max                1.57067
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589622
time/evaluation sampling (s)                  3.52241
time/exploration sampling (s)                18.1921
time/logging (s)                              0.00532747
time/saving (s)                               0.00238874
time/training (s)                             4.9461
time/epoch (s)                               26.6742
time/total (s)                             3714.12
Epoch                                       145
---------------------------------------  ----------------
2023-08-05 01:23:31.720379 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 146 finished
---------------------------------------  ----------------
epoch                                       146
replay_buffer/size                       294000
trainer/QF1 Loss                              1.36147
trainer/QF2 Loss                              1.35935
trainer/Policy Loss                          -8.20013
trainer/Q1 Predictions Mean                   6.59262
trainer/Q1 Predictions Std                    8.03038
trainer/Q1 Predictions Max                   23.8305
trainer/Q1 Predictions Min                   -8.83077
trainer/Q2 Predictions Mean                   6.59114
trainer/Q2 Predictions Std                    8.01263
trainer/Q2 Predictions Max                   23.9592
trainer/Q2 Predictions Min                   -8.43807
trainer/Q Targets Mean                        6.58994
trainer/Q Targets Std                         8.15246
trainer/Q Targets Max                        24.6641
trainer/Q Targets Min                        -7.95184
trainer/Bellman Errors 1 Mean                 1.36147
trainer/Bellman Errors 1 Std                  8.1236
trainer/Bellman Errors 1 Max                178.238
trainer/Bellman Errors 1 Min                  7.53153e-09
trainer/Bellman Errors 2 Mean                 1.35935
trainer/Bellman Errors 2 Std                  8.25274
trainer/Bellman Errors 2 Max                173.028
trainer/Bellman Errors 2 Min                  1.71951e-08
trainer/Policy Action Mean                    0.394474
trainer/Policy Action Std                     0.75054
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     294000
expl/num paths total                       7350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.299486
expl/Rewards Std                              0.565427
expl/Rewards Max                              1.57069
expl/Rewards Min                              0
expl/Returns Mean                            11.9794
expl/Returns Std                             18.3709
expl/Returns Max                             41.494
expl/Returns Min                              0
expl/Actions Mean                             0.370294
expl/Actions Std                              0.754382
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         11.9794
expl/env_infos/final/reward_dist Mean         0.47015
expl/env_infos/final/reward_dist Std          0.717565
expl/env_infos/final/reward_dist Max          1.57069
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000500331
expl/env_infos/initial/reward_dist Std        0.00200917
expl/env_infos/initial/reward_dist Max        0.0105764
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.299486
expl/env_infos/reward_dist Std                0.565427
expl/env_infos/reward_dist Max                1.57069
expl/env_infos/reward_dist Min                0
eval/num steps total                      58800
eval/num paths total                       1470
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.210057
eval/Rewards Std                              0.497048
eval/Rewards Max                              1.56962
eval/Rewards Min                              0
eval/Returns Mean                             8.40229
eval/Returns Std                             16.7971
eval/Returns Max                             42.1125
eval/Returns Min                              0
eval/Actions Mean                             0.403258
eval/Actions Std                              0.78136
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          8.40229
eval/env_infos/final/reward_dist Mean         0.31387
eval/env_infos/final/reward_dist Std          0.627739
eval/env_infos/final/reward_dist Max          1.56962
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000698272
eval/env_infos/initial/reward_dist Std        0.00209482
eval/env_infos/initial/reward_dist Max        0.00698272
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.210057
eval/env_infos/reward_dist Std                0.497048
eval/env_infos/reward_dist Max                1.56962
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00565987
time/evaluation sampling (s)                  3.30953
time/exploration sampling (s)                17.5313
time/logging (s)                              0.00539625
time/saving (s)                               0.00245974
time/training (s)                             4.62343
time/epoch (s)                               25.4777
time/total (s)                             3739.6
Epoch                                       146
---------------------------------------  ----------------
2023-08-05 01:23:57.942115 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 147 finished
---------------------------------------  ----------------
epoch                                       147
replay_buffer/size                       296000
trainer/QF1 Loss                              1.37024
trainer/QF2 Loss                              1.37638
trainer/Policy Loss                          -8.37541
trainer/Q1 Predictions Mean                   6.66776
trainer/Q1 Predictions Std                    8.15282
trainer/Q1 Predictions Max                   23.2945
trainer/Q1 Predictions Min                   -6.88122
trainer/Q2 Predictions Mean                   6.68027
trainer/Q2 Predictions Std                    8.15268
trainer/Q2 Predictions Max                   23.9328
trainer/Q2 Predictions Min                   -7.42441
trainer/Q Targets Mean                        6.62374
trainer/Q Targets Std                         8.24262
trainer/Q Targets Max                        24.0302
trainer/Q Targets Min                        -7.60306
trainer/Bellman Errors 1 Mean                 1.37024
trainer/Bellman Errors 1 Std                  9.56691
trainer/Bellman Errors 1 Max                210.763
trainer/Bellman Errors 1 Min                  1.10049e-08
trainer/Bellman Errors 2 Mean                 1.37638
trainer/Bellman Errors 2 Std                  9.87748
trainer/Bellman Errors 2 Max                219.897
trainer/Bellman Errors 2 Min                  7.44899e-09
trainer/Policy Action Mean                    0.386581
trainer/Policy Action Std                     0.761535
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     296000
expl/num paths total                       7400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.418066
expl/Rewards Std                              0.634921
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            16.7226
expl/Returns Std                             20.4225
expl/Returns Max                             43.9518
expl/Returns Min                              0
expl/Actions Mean                             0.391843
expl/Actions Std                              0.754375
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         16.7226
expl/env_infos/final/reward_dist Mean         0.627818
expl/env_infos/final/reward_dist Std          0.768316
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000341667
expl/env_infos/initial/reward_dist Std        0.0020198
expl/env_infos/initial/reward_dist Max        0.0142426
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.418066
expl/env_infos/reward_dist Std                0.634921
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      59200
eval/num paths total                       1480
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.420145
eval/Rewards Std                              0.637616
eval/Rewards Max                              1.57064
eval/Rewards Min                              0
eval/Returns Mean                            16.8058
eval/Returns Std                             20.5436
eval/Returns Max                             42.6805
eval/Returns Min                              0
eval/Actions Mean                             0.35199
eval/Actions Std                              0.79273
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.8058
eval/env_infos/final/reward_dist Mean         0.628371
eval/env_infos/final/reward_dist Std          0.769078
eval/env_infos/final/reward_dist Max          1.57064
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00161265
eval/env_infos/initial/reward_dist Std        0.00483796
eval/env_infos/initial/reward_dist Max        0.0161265
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.420145
eval/env_infos/reward_dist Std                0.637616
eval/env_infos/reward_dist Max                1.57064
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00583834
time/evaluation sampling (s)                  3.47891
time/exploration sampling (s)                17.7701
time/logging (s)                              0.0053183
time/saving (s)                               0.00236636
time/training (s)                             4.95628
time/epoch (s)                               26.2189
time/total (s)                             3765.82
Epoch                                       147
---------------------------------------  ----------------
2023-08-05 01:24:23.903266 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 148 finished
---------------------------------------  ----------------
epoch                                       148
replay_buffer/size                       298000
trainer/QF1 Loss                              1.50298
trainer/QF2 Loss                              1.52305
trainer/Policy Loss                          -8.83705
trainer/Q1 Predictions Mean                   7.13396
trainer/Q1 Predictions Std                    8.52682
trainer/Q1 Predictions Max                   23.9871
trainer/Q1 Predictions Min                   -6.27781
trainer/Q2 Predictions Mean                   7.13704
trainer/Q2 Predictions Std                    8.52254
trainer/Q2 Predictions Max                   24.0915
trainer/Q2 Predictions Min                   -6.74613
trainer/Q Targets Mean                        7.07051
trainer/Q Targets Std                         8.59093
trainer/Q Targets Max                        24.2473
trainer/Q Targets Min                        -7.04143
trainer/Bellman Errors 1 Mean                 1.50298
trainer/Bellman Errors 1 Std                 11.6306
trainer/Bellman Errors 1 Max                225.427
trainer/Bellman Errors 1 Min                  4.01087e-10
trainer/Bellman Errors 2 Mean                 1.52305
trainer/Bellman Errors 2 Std                 11.8708
trainer/Bellman Errors 2 Max                233.775
trainer/Bellman Errors 2 Min                  5.68434e-10
trainer/Policy Action Mean                    0.398743
trainer/Policy Action Std                     0.758357
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     298000
expl/num paths total                       7450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.315757
expl/Rewards Std                              0.576813
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            12.6303
expl/Returns Std                             18.7656
expl/Returns Max                             42.2274
expl/Returns Min                              0
expl/Actions Mean                             0.371741
expl/Actions Std                              0.764982
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.6303
expl/env_infos/final/reward_dist Mean         0.500606
expl/env_infos/final/reward_dist Std          0.729688
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000569767
expl/env_infos/initial/reward_dist Std        0.00244043
expl/env_infos/initial/reward_dist Max        0.0154701
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.315757
expl/env_infos/reward_dist Std                0.576813
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      59600
eval/num paths total                       1490
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.424538
eval/Rewards Std                              0.638832
eval/Rewards Max                              1.57039
eval/Rewards Min                              0
eval/Returns Mean                            16.9815
eval/Returns Std                             20.7245
eval/Returns Max                             43.6158
eval/Returns Min                              0
eval/Actions Mean                             0.401917
eval/Actions Std                              0.763916
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.9815
eval/env_infos/final/reward_dist Mean         0.627842
eval/env_infos/final/reward_dist Std          0.768947
eval/env_infos/final/reward_dist Max          1.57039
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00162888
eval/env_infos/initial/reward_dist Std        0.00312223
eval/env_infos/initial/reward_dist Max        0.00903859
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.424538
eval/env_infos/reward_dist Std                0.638832
eval/env_infos/reward_dist Max                1.57039
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0058765
time/evaluation sampling (s)                  3.48851
time/exploration sampling (s)                18.0639
time/logging (s)                              0.00535309
time/saving (s)                               0.00233679
time/training (s)                             4.39245
time/epoch (s)                               25.9584
time/total (s)                             3791.78
Epoch                                       148
---------------------------------------  ----------------
2023-08-05 01:24:49.945972 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 149 finished
---------------------------------------  ----------------
epoch                                       149
replay_buffer/size                       300000
trainer/QF1 Loss                              1.48154
trainer/QF2 Loss                              1.45545
trainer/Policy Loss                          -8.86898
trainer/Q1 Predictions Mean                   7.19892
trainer/Q1 Predictions Std                    8.53204
trainer/Q1 Predictions Max                   24.7266
trainer/Q1 Predictions Min                   -6.35827
trainer/Q2 Predictions Mean                   7.21472
trainer/Q2 Predictions Std                    8.5537
trainer/Q2 Predictions Max                   24.8582
trainer/Q2 Predictions Min                   -6.13545
trainer/Q Targets Mean                        7.20466
trainer/Q Targets Std                         8.61264
trainer/Q Targets Max                        25.9132
trainer/Q Targets Min                        -6.42663
trainer/Bellman Errors 1 Mean                 1.48154
trainer/Bellman Errors 1 Std                  9.97851
trainer/Bellman Errors 1 Max                184.146
trainer/Bellman Errors 1 Min                  1.07562e-08
trainer/Bellman Errors 2 Mean                 1.45545
trainer/Bellman Errors 2 Std                  9.94051
trainer/Bellman Errors 2 Max                180.263
trainer/Bellman Errors 2 Min                  4.5044e-09
trainer/Policy Action Mean                    0.38614
trainer/Policy Action Std                     0.761229
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     300000
expl/num paths total                       7500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.324917
expl/Rewards Std                              0.581784
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            12.9967
expl/Returns Std                             18.9089
expl/Returns Max                             42.8663
expl/Returns Min                              0
expl/Actions Mean                             0.352875
expl/Actions Std                              0.7706
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         12.9967
expl/env_infos/final/reward_dist Mean         0.501939
expl/env_infos/final/reward_dist Std          0.731559
expl/env_infos/final/reward_dist Max          1.57064
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00110392
expl/env_infos/initial/reward_dist Std        0.00338417
expl/env_infos/initial/reward_dist Max        0.0151446
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.324917
expl/env_infos/reward_dist Std                0.581784
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      60000
eval/num paths total                       1500
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.612185
eval/Rewards Std                              0.682031
eval/Rewards Max                              1.57071
eval/Rewards Min                              0
eval/Returns Mean                            24.4874
eval/Returns Std                             19.975
eval/Returns Max                             41.1219
eval/Returns Min                              0.000127699
eval/Actions Mean                             0.353492
eval/Actions Std                              0.783868
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.4874
eval/env_infos/final/reward_dist Mean         0.942009
eval/env_infos/final/reward_dist Std          0.768435
eval/env_infos/final/reward_dist Max          1.57071
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00131699
eval/env_infos/initial/reward_dist Std        0.00395097
eval/env_infos/initial/reward_dist Max        0.0131699
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.612185
eval/env_infos/reward_dist Std                0.682031
eval/env_infos/reward_dist Max                1.57071
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00578783
time/evaluation sampling (s)                  3.45905
time/exploration sampling (s)                17.9651
time/logging (s)                              0.00534014
time/saving (s)                               0.00237435
time/training (s)                             4.60229
time/epoch (s)                               26.0399
time/total (s)                             3817.82
Epoch                                       149
---------------------------------------  ----------------
2023-08-05 01:25:16.017428 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 150 finished
---------------------------------------  ----------------
epoch                                       150
replay_buffer/size                       302000
trainer/QF1 Loss                              1.61263
trainer/QF2 Loss                              1.61297
trainer/Policy Loss                          -8.93172
trainer/Q1 Predictions Mean                   7.40626
trainer/Q1 Predictions Std                    8.55016
trainer/Q1 Predictions Max                   26.0916
trainer/Q1 Predictions Min                   -6.21
trainer/Q2 Predictions Mean                   7.40619
trainer/Q2 Predictions Std                    8.55594
trainer/Q2 Predictions Max                   26.1265
trainer/Q2 Predictions Min                   -6.55979
trainer/Q Targets Mean                        7.44768
trainer/Q Targets Std                         8.68766
trainer/Q Targets Max                        26.4218
trainer/Q Targets Min                        -6.47696
trainer/Bellman Errors 1 Mean                 1.61263
trainer/Bellman Errors 1 Std                 10.6541
trainer/Bellman Errors 1 Max                187.081
trainer/Bellman Errors 1 Min                  4.30248e-10
trainer/Bellman Errors 2 Mean                 1.61297
trainer/Bellman Errors 2 Std                 10.8361
trainer/Bellman Errors 2 Max                195.802
trainer/Bellman Errors 2 Min                  2.09548e-09
trainer/Policy Action Mean                    0.380194
trainer/Policy Action Std                     0.766966
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     302000
expl/num paths total                       7550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.390071
expl/Rewards Std                              0.608547
expl/Rewards Max                              1.57073
expl/Rewards Min                              0
expl/Returns Mean                            15.6028
expl/Returns Std                             19.2039
expl/Returns Max                             41.2434
expl/Returns Min                              0
expl/Actions Mean                             0.361406
expl/Actions Std                              0.764951
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.6028
expl/env_infos/final/reward_dist Mean         0.624821
expl/env_infos/final/reward_dist Std          0.765092
expl/env_infos/final/reward_dist Max          1.57073
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00156696
expl/env_infos/initial/reward_dist Std        0.00393884
expl/env_infos/initial/reward_dist Max        0.0193733
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.390071
expl/env_infos/reward_dist Std                0.608547
expl/env_infos/reward_dist Max                1.57073
expl/env_infos/reward_dist Min                0
eval/num steps total                      60400
eval/num paths total                       1510
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.294857
eval/Rewards Std                              0.55314
eval/Rewards Max                              1.57059
eval/Rewards Min                              0
eval/Returns Mean                            11.7943
eval/Returns Std                             17.973
eval/Returns Max                             40.4975
eval/Returns Min                              0.0034326
eval/Actions Mean                             0.321651
eval/Actions Std                              0.799509
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.7943
eval/env_infos/final/reward_dist Mean         0.464007
eval/env_infos/final/reward_dist Std          0.707823
eval/env_infos/final/reward_dist Max          1.57059
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000168372
eval/env_infos/initial/reward_dist Std        0.000505117
eval/env_infos/initial/reward_dist Max        0.00168372
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.294857
eval/env_infos/reward_dist Std                0.55314
eval/env_infos/reward_dist Max                1.57059
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00627189
time/evaluation sampling (s)                  3.46602
time/exploration sampling (s)                18.0109
time/logging (s)                              0.00532807
time/saving (s)                               0.00236333
time/training (s)                             4.57752
time/epoch (s)                               26.0684
time/total (s)                             3843.89
Epoch                                       150
---------------------------------------  ----------------
2023-08-05 01:25:41.645504 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 151 finished
---------------------------------------  ----------------
epoch                                       151
replay_buffer/size                       304000
trainer/QF1 Loss                              1.60838
trainer/QF2 Loss                              1.598
trainer/Policy Loss                          -9.40855
trainer/Q1 Predictions Mean                   7.70322
trainer/Q1 Predictions Std                    8.59739
trainer/Q1 Predictions Max                   26.195
trainer/Q1 Predictions Min                   -9.05155
trainer/Q2 Predictions Mean                   7.69456
trainer/Q2 Predictions Std                    8.59051
trainer/Q2 Predictions Max                   26.0404
trainer/Q2 Predictions Min                   -9.1267
trainer/Q Targets Mean                        7.74468
trainer/Q Targets Std                         8.70147
trainer/Q Targets Max                        26.6098
trainer/Q Targets Min                        -9.05333
trainer/Bellman Errors 1 Mean                 1.60838
trainer/Bellman Errors 1 Std                 10.8618
trainer/Bellman Errors 1 Max                262.697
trainer/Bellman Errors 1 Min                  3.28328e-08
trainer/Bellman Errors 2 Mean                 1.598
trainer/Bellman Errors 2 Std                 10.9753
trainer/Bellman Errors 2 Max                257.726
trainer/Bellman Errors 2 Min                  4.01087e-10
trainer/Policy Action Mean                    0.36466
trainer/Policy Action Std                     0.755634
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     304000
expl/num paths total                       7600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.331435
expl/Rewards Std                              0.574516
expl/Rewards Max                              1.57069
expl/Rewards Min                              0
expl/Returns Mean                            13.2574
expl/Returns Std                             18.4121
expl/Returns Max                             40.206
expl/Returns Min                              0
expl/Actions Mean                             0.364848
expl/Actions Std                              0.764092
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.2574
expl/env_infos/final/reward_dist Mean         0.529828
expl/env_infos/final/reward_dist Std          0.738214
expl/env_infos/final/reward_dist Max          1.57069
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000751638
expl/env_infos/initial/reward_dist Std        0.00282667
expl/env_infos/initial/reward_dist Max        0.0132072
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.331435
expl/env_infos/reward_dist Std                0.574516
expl/env_infos/reward_dist Max                1.57069
expl/env_infos/reward_dist Min                0
eval/num steps total                      60800
eval/num paths total                       1520
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.2987
eval/Rewards Std                              0.556303
eval/Rewards Max                              1.57008
eval/Rewards Min                              0
eval/Returns Mean                            11.948
eval/Returns Std                             18.196
eval/Returns Max                             39.9351
eval/Returns Min                              0.00141661
eval/Actions Mean                             0.36973
eval/Actions Std                              0.783356
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.948
eval/env_infos/final/reward_dist Mean         0.470616
eval/env_infos/final/reward_dist Std          0.718879
eval/env_infos/final/reward_dist Max          1.57008
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000466751
eval/env_infos/initial/reward_dist Std        0.00120679
eval/env_infos/initial/reward_dist Max        0.00404388
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.2987
eval/env_infos/reward_dist Std                0.556303
eval/env_infos/reward_dist Max                1.57008
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590941
time/evaluation sampling (s)                  3.45497
time/exploration sampling (s)                17.17
time/logging (s)                              0.00413183
time/saving (s)                               0.0114484
time/training (s)                             4.97771
time/epoch (s)                               25.6241
time/total (s)                             3869.52
Epoch                                       151
---------------------------------------  ----------------
2023-08-05 01:26:06.599941 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 152 finished
---------------------------------------  ----------------
epoch                                       152
replay_buffer/size                       306000
trainer/QF1 Loss                              1.44924
trainer/QF2 Loss                              1.43708
trainer/Policy Loss                          -9.47052
trainer/Q1 Predictions Mean                   7.88205
trainer/Q1 Predictions Std                    8.53118
trainer/Q1 Predictions Max                   26.715
trainer/Q1 Predictions Min                   -9.60725
trainer/Q2 Predictions Mean                   7.86568
trainer/Q2 Predictions Std                    8.53665
trainer/Q2 Predictions Max                   26.6049
trainer/Q2 Predictions Min                  -10.245
trainer/Q Targets Mean                        7.86495
trainer/Q Targets Std                         8.59603
trainer/Q Targets Max                        27.7487
trainer/Q Targets Min                       -10.0908
trainer/Bellman Errors 1 Mean                 1.44924
trainer/Bellman Errors 1 Std                  9.86179
trainer/Bellman Errors 1 Max                222.308
trainer/Bellman Errors 1 Min                  5.44856e-07
trainer/Bellman Errors 2 Mean                 1.43708
trainer/Bellman Errors 2 Std                  9.96457
trainer/Bellman Errors 2 Max                221.017
trainer/Bellman Errors 2 Min                  7.44899e-09
trainer/Policy Action Mean                    0.363575
trainer/Policy Action Std                     0.755088
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     306000
expl/num paths total                       7650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.216932
expl/Rewards Std                              0.491448
expl/Rewards Max                              1.57057
expl/Rewards Min                              0
expl/Returns Mean                             8.67727
expl/Returns Std                             16.1861
expl/Returns Max                             40.7257
expl/Returns Min                              0
expl/Actions Mean                             0.336425
expl/Actions Std                              0.76764
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                          8.67727
expl/env_infos/final/reward_dist Mean         0.343569
expl/env_infos/final/reward_dist Std          0.646755
expl/env_infos/final/reward_dist Max          1.57057
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00093211
expl/env_infos/initial/reward_dist Std        0.00362973
expl/env_infos/initial/reward_dist Max        0.0186645
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.216932
expl/env_infos/reward_dist Std                0.491448
expl/env_infos/reward_dist Max                1.57057
expl/env_infos/reward_dist Min                0
eval/num steps total                      61200
eval/num paths total                       1530
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.896343
eval/Rewards Std                              0.632691
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            35.8537
eval/Returns Std                             11.6413
eval/Returns Max                             40.9274
eval/Returns Min                              0.957925
eval/Actions Mean                             0.376701
eval/Actions Std                              0.74047
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.8537
eval/env_infos/final/reward_dist Mean         1.41188
eval/env_infos/final/reward_dist Std          0.470629
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00209456
eval/env_infos/initial/reward_dist Std        0.00628369
eval/env_infos/initial/reward_dist Max        0.0209456
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.896343
eval/env_infos/reward_dist Std                0.632691
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00577274
time/evaluation sampling (s)                  3.40709
time/exploration sampling (s)                17.2086
time/logging (s)                              0.0053415
time/saving (s)                               0.00236269
time/training (s)                             4.32386
time/epoch (s)                               24.953
time/total (s)                             3894.47
Epoch                                       152
---------------------------------------  ----------------
2023-08-05 01:26:33.054869 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 153 finished
---------------------------------------  ----------------
epoch                                       153
replay_buffer/size                       308000
trainer/QF1 Loss                              1.57275
trainer/QF2 Loss                              1.57282
trainer/Policy Loss                          -9.54767
trainer/Q1 Predictions Mean                   7.92667
trainer/Q1 Predictions Std                    8.38618
trainer/Q1 Predictions Max                   26.5031
trainer/Q1 Predictions Min                   -6.54431
trainer/Q2 Predictions Mean                   7.9014
trainer/Q2 Predictions Std                    8.39132
trainer/Q2 Predictions Max                   26.4208
trainer/Q2 Predictions Min                   -6.50227
trainer/Q Targets Mean                        7.93739
trainer/Q Targets Std                         8.48855
trainer/Q Targets Max                        27.3118
trainer/Q Targets Min                        -6.48584
trainer/Bellman Errors 1 Mean                 1.57275
trainer/Bellman Errors 1 Std                 10.4157
trainer/Bellman Errors 1 Max                207.114
trainer/Bellman Errors 1 Min                  3.15495e-08
trainer/Bellman Errors 2 Mean                 1.57282
trainer/Bellman Errors 2 Std                 10.5394
trainer/Bellman Errors 2 Max                225.516
trainer/Bellman Errors 2 Min                  2.95495e-09
trainer/Policy Action Mean                    0.376144
trainer/Policy Action Std                     0.747446
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     308000
expl/num paths total                       7700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.394736
expl/Rewards Std                              0.61081
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            15.7894
expl/Returns Std                             19.2207
expl/Returns Max                             40.3688
expl/Returns Min                              0
expl/Actions Mean                             0.376139
expl/Actions Std                              0.738034
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.7894
expl/env_infos/final/reward_dist Mean         0.624734
expl/env_infos/final/reward_dist Std          0.765236
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00128906
expl/env_infos/initial/reward_dist Std        0.00395848
expl/env_infos/initial/reward_dist Max        0.0167655
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.394736
expl/env_infos/reward_dist Std                0.61081
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      61600
eval/num paths total                       1540
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.707601
eval/Rewards Std                              0.678241
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            28.304
eval/Returns Std                             18.3809
eval/Returns Max                             41.3014
eval/Returns Min                              0.00790541
eval/Actions Mean                             0.41467
eval/Actions Std                              0.740814
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.304
eval/env_infos/final/reward_dist Mean         1.09859
eval/env_infos/final/reward_dist Std          0.719193
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00256959
eval/env_infos/initial/reward_dist Std        0.0037344
eval/env_infos/initial/reward_dist Max        0.0105056
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.707601
eval/env_infos/reward_dist Std                0.678241
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00572924
time/evaluation sampling (s)                  3.44555
time/exploration sampling (s)                18.2331
time/logging (s)                              0.0054746
time/saving (s)                               0.00241497
time/training (s)                             4.76006
time/epoch (s)                               26.4523
time/total (s)                             3920.93
Epoch                                       153
---------------------------------------  ----------------
2023-08-05 01:26:58.423004 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 154 finished
---------------------------------------  ----------------
epoch                                       154
replay_buffer/size                       310000
trainer/QF1 Loss                              1.39416
trainer/QF2 Loss                              1.39497
trainer/Policy Loss                          -9.60821
trainer/Q1 Predictions Mean                   8.00133
trainer/Q1 Predictions Std                    8.41339
trainer/Q1 Predictions Max                   26.793
trainer/Q1 Predictions Min                   -5.32196
trainer/Q2 Predictions Mean                   8.00294
trainer/Q2 Predictions Std                    8.41785
trainer/Q2 Predictions Max                   26.8134
trainer/Q2 Predictions Min                   -5.65235
trainer/Q Targets Mean                        8.00217
trainer/Q Targets Std                         8.49239
trainer/Q Targets Max                        27.1059
trainer/Q Targets Min                        -5.53744
trainer/Bellman Errors 1 Mean                 1.39416
trainer/Bellman Errors 1 Std                 10.0229
trainer/Bellman Errors 1 Max                198.448
trainer/Bellman Errors 1 Min                  1.08174e-07
trainer/Bellman Errors 2 Mean                 1.39497
trainer/Bellman Errors 2 Std                 10.1727
trainer/Bellman Errors 2 Max                202.227
trainer/Bellman Errors 2 Min                  8.03629e-09
trainer/Policy Action Mean                    0.381791
trainer/Policy Action Std                     0.753681
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     310000
expl/num paths total                       7750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.476325
expl/Rewards Std                              0.646563
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            19.053
expl/Returns Std                             19.7822
expl/Returns Max                             41.5082
expl/Returns Min                              0
expl/Actions Mean                             0.390883
expl/Actions Std                              0.733892
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.053
expl/env_infos/final/reward_dist Mean         0.751394
expl/env_infos/final/reward_dist Std          0.78209
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00106993
expl/env_infos/initial/reward_dist Std        0.00281094
expl/env_infos/initial/reward_dist Max        0.0129286
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.476325
expl/env_infos/reward_dist Std                0.646563
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      62000
eval/num paths total                       1550
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.296028
eval/Rewards Std                              0.557764
eval/Rewards Max                              1.57068
eval/Rewards Min                              0
eval/Returns Mean                            11.8411
eval/Returns Std                             18.0307
eval/Returns Max                             40.2561
eval/Returns Min                              0.00212379
eval/Actions Mean                             0.387133
eval/Actions Std                              0.773246
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.8411
eval/env_infos/final/reward_dist Mean         0.472282
eval/env_infos/final/reward_dist Std          0.71856
eval/env_infos/final/reward_dist Max          1.57068
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000665348
eval/env_infos/initial/reward_dist Std        0.00199604
eval/env_infos/initial/reward_dist Max        0.00665348
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.296028
eval/env_infos/reward_dist Std                0.557764
eval/env_infos/reward_dist Max                1.57068
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594422
time/evaluation sampling (s)                  3.46679
time/exploration sampling (s)                17.4819
time/logging (s)                              0.00534729
time/saving (s)                               0.00233748
time/training (s)                             4.4029
time/epoch (s)                               25.3652
time/total (s)                             3946.29
Epoch                                       154
---------------------------------------  ----------------
2023-08-05 01:27:24.490703 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 155 finished
---------------------------------------  ----------------
epoch                                       155
replay_buffer/size                       312000
trainer/QF1 Loss                              1.31029
trainer/QF2 Loss                              1.30806
trainer/Policy Loss                          -9.71438
trainer/Q1 Predictions Mean                   8.10805
trainer/Q1 Predictions Std                    8.36748
trainer/Q1 Predictions Max                   26.76
trainer/Q1 Predictions Min                   -8.54145
trainer/Q2 Predictions Mean                   8.10351
trainer/Q2 Predictions Std                    8.36197
trainer/Q2 Predictions Max                   27.0409
trainer/Q2 Predictions Min                   -8.44291
trainer/Q Targets Mean                        8.06958
trainer/Q Targets Std                         8.4499
trainer/Q Targets Max                        27.4427
trainer/Q Targets Min                        -8.64995
trainer/Bellman Errors 1 Mean                 1.31029
trainer/Bellman Errors 1 Std                  9.84046
trainer/Bellman Errors 1 Max                214.742
trainer/Bellman Errors 1 Min                  8.50224e-08
trainer/Bellman Errors 2 Mean                 1.30806
trainer/Bellman Errors 2 Std                  9.72945
trainer/Bellman Errors 2 Max                212.065
trainer/Bellman Errors 2 Min                  2.21335e-08
trainer/Policy Action Mean                    0.378896
trainer/Policy Action Std                     0.754456
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     312000
expl/num paths total                       7800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.646577
expl/Rewards Std                              0.67654
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            25.8631
expl/Returns Std                             18.4934
expl/Returns Max                             41.3848
expl/Returns Min                              0
expl/Actions Mean                             0.397794
expl/Actions Std                              0.732208
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.8631
expl/env_infos/final/reward_dist Mean         1.03527
expl/env_infos/final/reward_dist Std          0.743057
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0014045
expl/env_infos/initial/reward_dist Std        0.00322745
expl/env_infos/initial/reward_dist Max        0.0115093
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.646577
expl/env_infos/reward_dist Std                0.67654
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      62400
eval/num paths total                       1560
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.391145
eval/Rewards Std                              0.612056
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            15.6458
eval/Returns Std                             18.9991
eval/Returns Max                             39.24
eval/Returns Min                              0.00214613
eval/Actions Mean                             0.392413
eval/Actions Std                              0.760384
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         15.6458
eval/env_infos/final/reward_dist Mean         0.627809
eval/env_infos/final/reward_dist Std          0.768906
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000455193
eval/env_infos/initial/reward_dist Std        0.00136558
eval/env_infos/initial/reward_dist Max        0.00455193
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.391145
eval/env_infos/reward_dist Std                0.612056
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590519
time/evaluation sampling (s)                  3.41796
time/exploration sampling (s)                17.8962
time/logging (s)                              0.0053559
time/saving (s)                               0.00239728
time/training (s)                             4.73698
time/epoch (s)                               26.0648
time/total (s)                             3972.36
Epoch                                       155
---------------------------------------  ----------------
2023-08-05 01:27:50.511084 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 156 finished
---------------------------------------  ----------------
epoch                                       156
replay_buffer/size                       314000
trainer/QF1 Loss                              1.50342
trainer/QF2 Loss                              1.51491
trainer/Policy Loss                         -10.0108
trainer/Q1 Predictions Mean                   8.28562
trainer/Q1 Predictions Std                    8.45099
trainer/Q1 Predictions Max                   27.1123
trainer/Q1 Predictions Min                   -6.62283
trainer/Q2 Predictions Mean                   8.30274
trainer/Q2 Predictions Std                    8.44457
trainer/Q2 Predictions Max                   27.2999
trainer/Q2 Predictions Min                   -6.97967
trainer/Q Targets Mean                        8.31031
trainer/Q Targets Std                         8.53997
trainer/Q Targets Max                        28.0109
trainer/Q Targets Min                        -6.26798
trainer/Bellman Errors 1 Mean                 1.50342
trainer/Bellman Errors 1 Std                 10.9211
trainer/Bellman Errors 1 Max                205.25
trainer/Bellman Errors 1 Min                  9.36696e-11
trainer/Bellman Errors 2 Mean                 1.51491
trainer/Bellman Errors 2 Std                 11.1854
trainer/Bellman Errors 2 Max                209.22
trainer/Bellman Errors 2 Min                  1.29609e-09
trainer/Policy Action Mean                    0.393158
trainer/Policy Action Std                     0.745709
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     314000
expl/num paths total                       7850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.69813
expl/Rewards Std                              0.674533
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            27.9252
expl/Returns Std                             17.2959
expl/Returns Max                             40.3138
expl/Returns Min                              0.000494341
expl/Actions Mean                             0.402499
expl/Actions Std                              0.720133
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         27.9252
expl/env_infos/final/reward_dist Mean         1.1295
expl/env_infos/final/reward_dist Std          0.704366
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000603283
expl/env_infos/initial/reward_dist Std        0.00201131
expl/env_infos/initial/reward_dist Max        0.0127033
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.69813
expl/env_infos/reward_dist Std                0.674533
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      62800
eval/num paths total                       1570
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.687758
eval/Rewards Std                              0.680342
eval/Rewards Max                              1.57059
eval/Rewards Min                              0
eval/Returns Mean                            27.5103
eval/Returns Std                             17.9837
eval/Returns Max                             41.1461
eval/Returns Min                              0.0289952
eval/Actions Mean                             0.437331
eval/Actions Std                              0.733521
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         27.5103
eval/env_infos/final/reward_dist Mean         1.09838
eval/env_infos/final/reward_dist Std          0.719063
eval/env_infos/final/reward_dist Max          1.57059
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000781688
eval/env_infos/initial/reward_dist Std        0.00182944
eval/env_infos/initial/reward_dist Max        0.00603296
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.687758
eval/env_infos/reward_dist Std                0.680342
eval/env_infos/reward_dist Max                1.57059
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00573154
time/evaluation sampling (s)                  3.48187
time/exploration sampling (s)                17.9449
time/logging (s)                              0.00738847
time/saving (s)                               0.00270253
time/training (s)                             4.57709
time/epoch (s)                               26.0197
time/total (s)                             3998.38
Epoch                                       156
---------------------------------------  ----------------
2023-08-05 01:28:16.414917 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 157 finished
---------------------------------------  ----------------
epoch                                       157
replay_buffer/size                       316000
trainer/QF1 Loss                              1.29913
trainer/QF2 Loss                              1.30934
trainer/Policy Loss                         -10.3584
trainer/Q1 Predictions Mean                   8.54267
trainer/Q1 Predictions Std                    8.45347
trainer/Q1 Predictions Max                   27.379
trainer/Q1 Predictions Min                   -9.2803
trainer/Q2 Predictions Mean                   8.54313
trainer/Q2 Predictions Std                    8.45375
trainer/Q2 Predictions Max                   27.4357
trainer/Q2 Predictions Min                  -10.1823
trainer/Q Targets Mean                        8.57233
trainer/Q Targets Std                         8.53531
trainer/Q Targets Max                        27.7142
trainer/Q Targets Min                        -9.59729
trainer/Bellman Errors 1 Mean                 1.29913
trainer/Bellman Errors 1 Std                  9.53845
trainer/Bellman Errors 1 Max                233.776
trainer/Bellman Errors 1 Min                  3.66075e-10
trainer/Bellman Errors 2 Mean                 1.30934
trainer/Bellman Errors 2 Std                  9.67145
trainer/Bellman Errors 2 Max                246.862
trainer/Bellman Errors 2 Min                  7.41331e-08
trainer/Policy Action Mean                    0.388388
trainer/Policy Action Std                     0.747683
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     316000
expl/num paths total                       7900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.644089
expl/Rewards Std                              0.676628
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            25.7636
expl/Returns Std                             18.4317
expl/Returns Max                             40.5839
expl/Returns Min                              0
expl/Actions Mean                             0.409836
expl/Actions Std                              0.721227
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.7636
expl/env_infos/final/reward_dist Mean         1.03526
expl/env_infos/final/reward_dist Std          0.743052
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00124211
expl/env_infos/initial/reward_dist Std        0.00313195
expl/env_infos/initial/reward_dist Max        0.0121241
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.644089
expl/env_infos/reward_dist Std                0.676628
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      63200
eval/num paths total                       1580
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.783749
eval/Rewards Std                              0.667316
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            31.35
eval/Returns Std                             15.5546
eval/Returns Max                             40.3906
eval/Returns Min                              0.0364958
eval/Actions Mean                             0.424455
eval/Actions Std                              0.740678
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.35
eval/env_infos/final/reward_dist Mean         1.2555
eval/env_infos/final/reward_dist Std          0.627751
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00220752
eval/env_infos/initial/reward_dist Std        0.00347988
eval/env_infos/initial/reward_dist Max        0.0100957
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.783749
eval/env_infos/reward_dist Std                0.667316
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589924
time/evaluation sampling (s)                  3.4526
time/exploration sampling (s)                17.8455
time/logging (s)                              0.00533339
time/saving (s)                               0.00237339
time/training (s)                             4.5854
time/epoch (s)                               25.8971
time/total (s)                             4024.28
Epoch                                       157
---------------------------------------  ----------------
2023-08-05 01:28:42.272415 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 158 finished
---------------------------------------  ----------------
epoch                                       158
replay_buffer/size                       318000
trainer/QF1 Loss                              1.33042
trainer/QF2 Loss                              1.35561
trainer/Policy Loss                         -10.3917
trainer/Q1 Predictions Mean                   8.57252
trainer/Q1 Predictions Std                    8.55197
trainer/Q1 Predictions Max                   27.6906
trainer/Q1 Predictions Min                   -8.95189
trainer/Q2 Predictions Mean                   8.54431
trainer/Q2 Predictions Std                    8.54986
trainer/Q2 Predictions Max                   27.8325
trainer/Q2 Predictions Min                   -9.52948
trainer/Q Targets Mean                        8.65002
trainer/Q Targets Std                         8.6479
trainer/Q Targets Max                        28.0475
trainer/Q Targets Min                        -9.38246
trainer/Bellman Errors 1 Mean                 1.33042
trainer/Bellman Errors 1 Std                  8.50046
trainer/Bellman Errors 1 Max                188.396
trainer/Bellman Errors 1 Min                  4.06116e-08
trainer/Bellman Errors 2 Mean                 1.35561
trainer/Bellman Errors 2 Std                  8.7495
trainer/Bellman Errors 2 Max                189.893
trainer/Bellman Errors 2 Min                  1.05138e-09
trainer/Policy Action Mean                    0.387497
trainer/Policy Action Std                     0.751634
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     318000
expl/num paths total                       7950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.591484
expl/Rewards Std                              0.673498
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            23.6594
expl/Returns Std                             19.1631
expl/Returns Max                             40.5701
expl/Returns Min                              0
expl/Actions Mean                             0.41361
expl/Actions Std                              0.720265
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         23.6594
expl/env_infos/final/reward_dist Mean         0.938077
expl/env_infos/final/reward_dist Std          0.76597
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000803694
expl/env_infos/initial/reward_dist Std        0.00217834
expl/env_infos/initial/reward_dist Max        0.0114866
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.591484
expl/env_infos/reward_dist Std                0.673498
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      63600
eval/num paths total                       1590
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.79656
eval/Rewards Std                              0.675357
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            31.8624
eval/Returns Std                             15.911
eval/Returns Max                             40.2349
eval/Returns Min                              0.0365592
eval/Actions Mean                             0.458645
eval/Actions Std                              0.723686
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.8624
eval/env_infos/final/reward_dist Mean         1.25555
eval/env_infos/final/reward_dist Std          0.627779
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000409345
eval/env_infos/initial/reward_dist Std        0.000682733
eval/env_infos/initial/reward_dist Max        0.00193484
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.79656
eval/env_infos/reward_dist Std                0.675357
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00581173
time/evaluation sampling (s)                  3.45347
time/exploration sampling (s)                17.7876
time/logging (s)                              0.00532472
time/saving (s)                               0.00232732
time/training (s)                             4.60014
time/epoch (s)                               25.8547
time/total (s)                             4050.14
Epoch                                       158
---------------------------------------  ----------------
2023-08-05 01:29:08.374370 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 159 finished
---------------------------------------  ----------------
epoch                                       159
replay_buffer/size                       320000
trainer/QF1 Loss                              1.05315
trainer/QF2 Loss                              1.05715
trainer/Policy Loss                         -10.9084
trainer/Q1 Predictions Mean                   9.18781
trainer/Q1 Predictions Std                    8.65923
trainer/Q1 Predictions Max                   28.169
trainer/Q1 Predictions Min                   -8.38243
trainer/Q2 Predictions Mean                   9.18467
trainer/Q2 Predictions Std                    8.65971
trainer/Q2 Predictions Max                   28.4033
trainer/Q2 Predictions Min                   -8.8765
trainer/Q Targets Mean                        9.1845
trainer/Q Targets Std                         8.7367
trainer/Q Targets Max                        27.8701
trainer/Q Targets Min                        -8.48304
trainer/Bellman Errors 1 Mean                 1.05315
trainer/Bellman Errors 1 Std                  6.70016
trainer/Bellman Errors 1 Max                185.053
trainer/Bellman Errors 1 Min                  3.40315e-10
trainer/Bellman Errors 2 Mean                 1.05715
trainer/Bellman Errors 2 Std                  6.83538
trainer/Bellman Errors 2 Max                183.432
trainer/Bellman Errors 2 Min                  4.26793e-08
trainer/Policy Action Mean                    0.393815
trainer/Policy Action Std                     0.749056
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     320000
expl/num paths total                       8000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.455564
expl/Rewards Std                              0.642963
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            18.2226
expl/Returns Std                             19.5455
expl/Returns Max                             41.0297
expl/Returns Min                              0
expl/Actions Mean                             0.400928
expl/Actions Std                              0.727172
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.2226
expl/env_infos/final/reward_dist Mean         0.722381
expl/env_infos/final/reward_dist Std          0.781438
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000609007
expl/env_infos/initial/reward_dist Std        0.00190856
expl/env_infos/initial/reward_dist Max        0.0086592
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.455564
expl/env_infos/reward_dist Std                0.642963
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      64000
eval/num paths total                       1600
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.693
eval/Rewards Std                              0.68007
eval/Rewards Max                              1.57055
eval/Rewards Min                              0
eval/Returns Mean                            27.72
eval/Returns Std                             17.9021
eval/Returns Max                             40.1494
eval/Returns Min                              0.121263
eval/Actions Mean                             0.416347
eval/Actions Std                              0.741738
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         27.72
eval/env_infos/final/reward_dist Mean         1.09922
eval/env_infos/final/reward_dist Std          0.718712
eval/env_infos/final/reward_dist Max          1.57055
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00200647
eval/env_infos/initial/reward_dist Std        0.00347128
eval/env_infos/initial/reward_dist Max        0.0115842
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.693
eval/env_infos/reward_dist Std                0.68007
eval/env_infos/reward_dist Max                1.57055
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00598963
time/evaluation sampling (s)                  3.42995
time/exploration sampling (s)                18.0365
time/logging (s)                              0.00532482
time/saving (s)                               0.00236945
time/training (s)                             4.61896
time/epoch (s)                               26.0991
time/total (s)                             4076.24
Epoch                                       159
---------------------------------------  ----------------
2023-08-05 01:29:34.268192 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 160 finished
---------------------------------------  ----------------
epoch                                       160
replay_buffer/size                       322000
trainer/QF1 Loss                              1.31335
trainer/QF2 Loss                              1.30122
trainer/Policy Loss                         -11.261
trainer/Q1 Predictions Mean                   9.52229
trainer/Q1 Predictions Std                    8.85444
trainer/Q1 Predictions Max                   28.5556
trainer/Q1 Predictions Min                   -5.95385
trainer/Q2 Predictions Mean                   9.50424
trainer/Q2 Predictions Std                    8.84575
trainer/Q2 Predictions Max                   28.6746
trainer/Q2 Predictions Min                   -5.61675
trainer/Q Targets Mean                        9.45501
trainer/Q Targets Std                         8.8998
trainer/Q Targets Max                        28.7996
trainer/Q Targets Min                        -5.30413
trainer/Bellman Errors 1 Mean                 1.31335
trainer/Bellman Errors 1 Std                  8.98947
trainer/Bellman Errors 1 Max                178.932
trainer/Bellman Errors 1 Min                  7.36794e-08
trainer/Bellman Errors 2 Mean                 1.30122
trainer/Bellman Errors 2 Std                  9.05642
trainer/Bellman Errors 2 Max                183
trainer/Bellman Errors 2 Min                  1.01109e-08
trainer/Policy Action Mean                    0.39439
trainer/Policy Action Std                     0.747016
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     322000
expl/num paths total                       8050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.608205
expl/Rewards Std                              0.675199
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            24.3282
expl/Returns Std                             18.7759
expl/Returns Max                             43.105
expl/Returns Min                              0
expl/Actions Mean                             0.443978
expl/Actions Std                              0.705058
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.3282
expl/env_infos/final/reward_dist Mean         0.987352
expl/env_infos/final/reward_dist Std          0.746716
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000615504
expl/env_infos/initial/reward_dist Std        0.00198852
expl/env_infos/initial/reward_dist Max        0.0123335
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.608205
expl/env_infos/reward_dist Std                0.675199
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      64400
eval/num paths total                       1610
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.492229
eval/Rewards Std                              0.653744
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            19.6892
eval/Returns Std                             19.3519
eval/Returns Max                             39.2996
eval/Returns Min                              0.000300582
eval/Actions Mean                             0.459036
eval/Actions Std                              0.743095
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         19.6892
eval/env_infos/final/reward_dist Mean         0.785372
eval/env_infos/final/reward_dist Std          0.784523
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000912079
eval/env_infos/initial/reward_dist Std        0.00152801
eval/env_infos/initial/reward_dist Max        0.00458325
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.492229
eval/env_infos/reward_dist Std                0.653744
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593062
time/evaluation sampling (s)                  3.51081
time/exploration sampling (s)                17.5856
time/logging (s)                              0.00745435
time/saving (s)                               0.00269642
time/training (s)                             4.78057
time/epoch (s)                               25.8931
time/total (s)                             4102.13
Epoch                                       160
---------------------------------------  ----------------
2023-08-05 01:29:59.848993 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 161 finished
---------------------------------------  ----------------
epoch                                       161
replay_buffer/size                       324000
trainer/QF1 Loss                              1.50889
trainer/QF2 Loss                              1.50908
trainer/Policy Loss                         -11.1098
trainer/Q1 Predictions Mean                   9.50155
trainer/Q1 Predictions Std                    8.89673
trainer/Q1 Predictions Max                   28.7062
trainer/Q1 Predictions Min                   -6.67631
trainer/Q2 Predictions Mean                   9.49572
trainer/Q2 Predictions Std                    8.90748
trainer/Q2 Predictions Max                   28.9898
trainer/Q2 Predictions Min                   -7.06307
trainer/Q Targets Mean                        9.44864
trainer/Q Targets Std                         8.95584
trainer/Q Targets Max                        29.2987
trainer/Q Targets Min                        -7.03252
trainer/Bellman Errors 1 Mean                 1.50889
trainer/Bellman Errors 1 Std                 10.6436
trainer/Bellman Errors 1 Max                171.21
trainer/Bellman Errors 1 Min                  3.11252e-09
trainer/Bellman Errors 2 Mean                 1.50908
trainer/Bellman Errors 2 Std                 10.95
trainer/Bellman Errors 2 Max                173.863
trainer/Bellman Errors 2 Min                  2.24823e-09
trainer/Policy Action Mean                    0.388029
trainer/Policy Action Std                     0.753994
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     324000
expl/num paths total                       8100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.617421
expl/Rewards Std                              0.67253
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            24.6969
expl/Returns Std                             18.4411
expl/Returns Max                             40.9441
expl/Returns Min                              0
expl/Actions Mean                             0.426992
expl/Actions Std                              0.720954
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.6969
expl/env_infos/final/reward_dist Mean         1.00083
expl/env_infos/final/reward_dist Std          0.750691
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0014622
expl/env_infos/initial/reward_dist Std        0.00287574
expl/env_infos/initial/reward_dist Max        0.010045
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.617421
expl/env_infos/reward_dist Std                0.67253
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      64800
eval/num paths total                       1620
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.583703
eval/Rewards Std                              0.670284
eval/Rewards Max                              1.56971
eval/Rewards Min                              0
eval/Returns Mean                            23.3481
eval/Returns Std                             18.9147
eval/Returns Max                             39.8398
eval/Returns Min                              0.00654397
eval/Actions Mean                             0.418172
eval/Actions Std                              0.752677
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         23.3481
eval/env_infos/final/reward_dist Mean         0.941058
eval/env_infos/final/reward_dist Std          0.768371
eval/env_infos/final/reward_dist Max          1.56971
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00145452
eval/env_infos/initial/reward_dist Std        0.00230733
eval/env_infos/initial/reward_dist Max        0.00644411
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.583703
eval/env_infos/reward_dist Std                0.670284
eval/env_infos/reward_dist Max                1.56971
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00586054
time/evaluation sampling (s)                  3.4757
time/exploration sampling (s)                17.5043
time/logging (s)                              0.00740929
time/saving (s)                               0.0026922
time/training (s)                             4.58004
time/epoch (s)                               25.576
time/total (s)                             4127.71
Epoch                                       161
---------------------------------------  ----------------
2023-08-05 01:30:25.456043 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 162 finished
---------------------------------------  ----------------
epoch                                       162
replay_buffer/size                       326000
trainer/QF1 Loss                              1.41864
trainer/QF2 Loss                              1.42783
trainer/Policy Loss                         -11.7729
trainer/Q1 Predictions Mean                  10.1886
trainer/Q1 Predictions Std                    8.92172
trainer/Q1 Predictions Max                   29.3835
trainer/Q1 Predictions Min                   -8.34508
trainer/Q2 Predictions Mean                  10.1964
trainer/Q2 Predictions Std                    8.93338
trainer/Q2 Predictions Max                   29.4569
trainer/Q2 Predictions Min                   -7.4801
trainer/Q Targets Mean                       10.1601
trainer/Q Targets Std                         8.99604
trainer/Q Targets Max                        29.8322
trainer/Q Targets Min                        -8.25179
trainer/Bellman Errors 1 Mean                 1.41864
trainer/Bellman Errors 1 Std                  9.52671
trainer/Bellman Errors 1 Max                204.704
trainer/Bellman Errors 1 Min                  2.78533e-08
trainer/Bellman Errors 2 Mean                 1.42783
trainer/Bellman Errors 2 Std                  9.68411
trainer/Bellman Errors 2 Max                208.283
trainer/Bellman Errors 2 Min                  2.49301e-08
trainer/Policy Action Mean                    0.384636
trainer/Policy Action Std                     0.760844
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     326000
expl/num paths total                       8150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.751474
expl/Rewards Std                              0.674627
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            30.059
expl/Returns Std                             15.9203
expl/Returns Max                             43.025
expl/Returns Min                              0.00359139
expl/Actions Mean                             0.458779
expl/Actions Std                              0.703943
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.059
expl/env_infos/final/reward_dist Mean         1.22363
expl/env_infos/final/reward_dist Std          0.64982
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00137663
expl/env_infos/initial/reward_dist Std        0.00306428
expl/env_infos/initial/reward_dist Max        0.0116634
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.751474
expl/env_infos/reward_dist Std                0.674627
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      65200
eval/num paths total                       1630
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.679228
eval/Rewards Std                              0.680818
eval/Rewards Max                              1.57062
eval/Rewards Min                              0
eval/Returns Mean                            27.1691
eval/Returns Std                             17.794
eval/Returns Max                             40.4894
eval/Returns Min                              0
eval/Actions Mean                             0.378694
eval/Actions Std                              0.77155
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         27.1691
eval/env_infos/final/reward_dist Mean         1.09751
eval/env_infos/final/reward_dist Std          0.718494
eval/env_infos/final/reward_dist Max          1.57062
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000885862
eval/env_infos/initial/reward_dist Std        0.00178439
eval/env_infos/initial/reward_dist Max        0.00490384
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.679228
eval/env_infos/reward_dist Std                0.680818
eval/env_infos/reward_dist Max                1.57062
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00582195
time/evaluation sampling (s)                  3.42685
time/exploration sampling (s)                17.5365
time/logging (s)                              0.00746689
time/saving (s)                               0.00270546
time/training (s)                             4.62304
time/epoch (s)                               25.6024
time/total (s)                             4153.32
Epoch                                       162
---------------------------------------  ----------------
2023-08-05 01:30:51.124545 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 163 finished
---------------------------------------  ----------------
epoch                                       163
replay_buffer/size                       328000
trainer/QF1 Loss                              1.25437
trainer/QF2 Loss                              1.26521
trainer/Policy Loss                         -11.8828
trainer/Q1 Predictions Mean                  10.2836
trainer/Q1 Predictions Std                    9.1393
trainer/Q1 Predictions Max                   29.8685
trainer/Q1 Predictions Min                   -7.8652
trainer/Q2 Predictions Mean                  10.2889
trainer/Q2 Predictions Std                    9.16631
trainer/Q2 Predictions Max                   30.122
trainer/Q2 Predictions Min                   -8.45752
trainer/Q Targets Mean                       10.3372
trainer/Q Targets Std                         9.23933
trainer/Q Targets Max                        30.3844
trainer/Q Targets Min                        -8.54197
trainer/Bellman Errors 1 Mean                 1.25437
trainer/Bellman Errors 1 Std                  8.77442
trainer/Bellman Errors 1 Max                192.523
trainer/Bellman Errors 1 Min                  9.83709e-09
trainer/Bellman Errors 2 Mean                 1.26521
trainer/Bellman Errors 2 Std                  9.09152
trainer/Bellman Errors 2 Max                190.896
trainer/Bellman Errors 2 Min                  1.05138e-09
trainer/Policy Action Mean                    0.374954
trainer/Policy Action Std                     0.765607
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     328000
expl/num paths total                       8200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.61825
expl/Rewards Std                              0.676487
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            24.73
expl/Returns Std                             18.4631
expl/Returns Max                             41.0272
expl/Returns Min                              0
expl/Actions Mean                             0.422616
expl/Actions Std                              0.730636
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.73
expl/env_infos/final/reward_dist Mean         1.00126
expl/env_infos/final/reward_dist Std          0.750886
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000789269
expl/env_infos/initial/reward_dist Std        0.00220229
expl/env_infos/initial/reward_dist Max        0.0101929
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.61825
expl/env_infos/reward_dist Std                0.676487
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      65600
eval/num paths total                       1640
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.670327
eval/Rewards Std                              0.677083
eval/Rewards Max                              1.57029
eval/Rewards Min                              0
eval/Returns Mean                            26.8131
eval/Returns Std                             17.5402
eval/Returns Max                             38.8164
eval/Returns Min                              0.0148464
eval/Actions Mean                             0.422661
eval/Actions Std                              0.738104
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.8131
eval/env_infos/final/reward_dist Mean         1.09665
eval/env_infos/final/reward_dist Std          0.717931
eval/env_infos/final/reward_dist Max          1.57029
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000530015
eval/env_infos/initial/reward_dist Std        0.000873431
eval/env_infos/initial/reward_dist Max        0.00258273
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.670327
eval/env_infos/reward_dist Std                0.677083
eval/env_infos/reward_dist Max                1.57029
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587807
time/evaluation sampling (s)                  3.52714
time/exploration sampling (s)                17.5731
time/logging (s)                              0.00532233
time/saving (s)                               0.00231173
time/training (s)                             4.54784
time/epoch (s)                               25.6616
time/total (s)                             4178.98
Epoch                                       163
---------------------------------------  ----------------
2023-08-05 01:31:16.642994 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 164 finished
---------------------------------------  ----------------
epoch                                       164
replay_buffer/size                       330000
trainer/QF1 Loss                              1.33623
trainer/QF2 Loss                              1.32389
trainer/Policy Loss                         -11.8583
trainer/Q1 Predictions Mean                  10.3179
trainer/Q1 Predictions Std                    9.21964
trainer/Q1 Predictions Max                   30.3804
trainer/Q1 Predictions Min                  -10.3424
trainer/Q2 Predictions Mean                  10.3266
trainer/Q2 Predictions Std                    9.22298
trainer/Q2 Predictions Max                   30.5724
trainer/Q2 Predictions Min                  -10.9875
trainer/Q Targets Mean                       10.403
trainer/Q Targets Std                         9.32281
trainer/Q Targets Max                        30.6389
trainer/Q Targets Min                       -10.4679
trainer/Bellman Errors 1 Mean                 1.33623
trainer/Bellman Errors 1 Std                  8.78464
trainer/Bellman Errors 1 Max                207.553
trainer/Bellman Errors 1 Min                  1.35786e-08
trainer/Bellman Errors 2 Mean                 1.32389
trainer/Bellman Errors 2 Std                  8.92707
trainer/Bellman Errors 2 Max                210.693
trainer/Bellman Errors 2 Min                  5.26054e-08
trainer/Policy Action Mean                    0.380838
trainer/Policy Action Std                     0.765235
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     330000
expl/num paths total                       8250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.448757
expl/Rewards Std                              0.639658
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            17.9503
expl/Returns Std                             19.3366
expl/Returns Max                             40.7941
expl/Returns Min                              0
expl/Actions Mean                             0.391185
expl/Actions Std                              0.743399
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         17.9503
expl/env_infos/final/reward_dist Mean         0.721804
expl/env_infos/final/reward_dist Std          0.781884
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000273061
expl/env_infos/initial/reward_dist Std        0.00131304
expl/env_infos/initial/reward_dist Max        0.00732402
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.448757
expl/env_infos/reward_dist Std                0.639658
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      66000
eval/num paths total                       1650
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.795973
eval/Rewards Std                              0.674649
eval/Rewards Max                              1.57068
eval/Rewards Min                              0
eval/Returns Mean                            31.8389
eval/Returns Std                             15.8435
eval/Returns Max                             41.4476
eval/Returns Min                              0.0431758
eval/Actions Mean                             0.469463
eval/Actions Std                              0.725046
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.8389
eval/env_infos/final/reward_dist Mean         1.25517
eval/env_infos/final/reward_dist Std          0.627584
eval/env_infos/final/reward_dist Max          1.57068
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00334188
eval/env_infos/initial/reward_dist Std        0.00489784
eval/env_infos/initial/reward_dist Max        0.0138383
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.795973
eval/env_infos/reward_dist Std                0.674649
eval/env_infos/reward_dist Max                1.57068
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00581108
time/evaluation sampling (s)                  3.41481
time/exploration sampling (s)                17.4274
time/logging (s)                              0.00536724
time/saving (s)                               0.00232267
time/training (s)                             4.65992
time/epoch (s)                               25.5157
time/total (s)                             4204.5
Epoch                                       164
---------------------------------------  ----------------
2023-08-05 01:31:42.687144 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 165 finished
---------------------------------------  ----------------
epoch                                       165
replay_buffer/size                       332000
trainer/QF1 Loss                              1.22452
trainer/QF2 Loss                              1.20339
trainer/Policy Loss                         -12.1937
trainer/Q1 Predictions Mean                  10.7218
trainer/Q1 Predictions Std                    9.43602
trainer/Q1 Predictions Max                   31.2063
trainer/Q1 Predictions Min                  -13.7634
trainer/Q2 Predictions Mean                  10.7182
trainer/Q2 Predictions Std                    9.44024
trainer/Q2 Predictions Max                   31.3681
trainer/Q2 Predictions Min                  -14.1521
trainer/Q Targets Mean                       10.7177
trainer/Q Targets Std                         9.48944
trainer/Q Targets Max                        30.6375
trainer/Q Targets Min                       -13.6065
trainer/Bellman Errors 1 Mean                 1.22452
trainer/Bellman Errors 1 Std                  7.41151
trainer/Bellman Errors 1 Max                190.951
trainer/Bellman Errors 1 Min                  1.11413e-09
trainer/Bellman Errors 2 Mean                 1.20339
trainer/Bellman Errors 2 Std                  7.48003
trainer/Bellman Errors 2 Max                188.283
trainer/Bellman Errors 2 Min                  1.53705e-10
trainer/Policy Action Mean                    0.377865
trainer/Policy Action Std                     0.764514
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     332000
expl/num paths total                       8300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.654657
expl/Rewards Std                              0.677634
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            26.1863
expl/Returns Std                             17.889
expl/Returns Max                             41.4088
expl/Returns Min                              0
expl/Actions Mean                             0.428563
expl/Actions Std                              0.723647
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.1863
expl/env_infos/final/reward_dist Mean         1.06674
expl/env_infos/final/reward_dist Std          0.731776
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00132433
expl/env_infos/initial/reward_dist Std        0.0033654
expl/env_infos/initial/reward_dist Max        0.0145544
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.654657
expl/env_infos/reward_dist Std                0.677634
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      66400
eval/num paths total                       1660
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.667107
eval/Rewards Std                              0.676208
eval/Rewards Max                              1.57066
eval/Rewards Min                              0
eval/Returns Mean                            26.6843
eval/Returns Std                             17.3496
eval/Returns Max                             39.1391
eval/Returns Min                              0.00905017
eval/Actions Mean                             0.446884
eval/Actions Std                              0.73823
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.6843
eval/env_infos/final/reward_dist Mean         1.09711
eval/env_infos/final/reward_dist Std          0.718235
eval/env_infos/final/reward_dist Max          1.57066
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00112288
eval/env_infos/initial/reward_dist Std        0.0023899
eval/env_infos/initial/reward_dist Max        0.00754254
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.667107
eval/env_infos/reward_dist Std                0.676208
eval/env_infos/reward_dist Max                1.57066
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593117
time/evaluation sampling (s)                  3.55716
time/exploration sampling (s)                18.2794
time/logging (s)                              0.00534998
time/saving (s)                               0.00232437
time/training (s)                             4.19104
time/epoch (s)                               26.0412
time/total (s)                             4230.54
Epoch                                       165
---------------------------------------  ----------------
2023-08-05 01:32:08.632173 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 166 finished
---------------------------------------  ----------------
epoch                                       166
replay_buffer/size                       334000
trainer/QF1 Loss                              1.39597
trainer/QF2 Loss                              1.38854
trainer/Policy Loss                         -12.4031
trainer/Q1 Predictions Mean                  10.939
trainer/Q1 Predictions Std                    9.52212
trainer/Q1 Predictions Max                   31.1645
trainer/Q1 Predictions Min                   -9.0987
trainer/Q2 Predictions Mean                  10.9385
trainer/Q2 Predictions Std                    9.50898
trainer/Q2 Predictions Max                   31.2778
trainer/Q2 Predictions Min                   -9.65499
trainer/Q Targets Mean                       10.8914
trainer/Q Targets Std                         9.60564
trainer/Q Targets Max                        31.4881
trainer/Q Targets Min                       -10.0827
trainer/Bellman Errors 1 Mean                 1.39597
trainer/Bellman Errors 1 Std                 10.0924
trainer/Bellman Errors 1 Max                229.697
trainer/Bellman Errors 1 Min                  3.05954e-09
trainer/Bellman Errors 2 Mean                 1.38854
trainer/Bellman Errors 2 Std                 10.1356
trainer/Bellman Errors 2 Max                226.486
trainer/Bellman Errors 2 Min                  1.40113e-09
trainer/Policy Action Mean                    0.375952
trainer/Policy Action Std                     0.770472
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     334000
expl/num paths total                       8350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.633568
expl/Rewards Std                              0.674986
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            25.3427
expl/Returns Std                             18.0558
expl/Returns Max                             41.3622
expl/Returns Min                              0
expl/Actions Mean                             0.420111
expl/Actions Std                              0.719415
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.3427
expl/env_infos/final/reward_dist Mean         1.03412
expl/env_infos/final/reward_dist Std          0.7421
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00165956
expl/env_infos/initial/reward_dist Std        0.00359118
expl/env_infos/initial/reward_dist Max        0.0133778
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.633568
expl/env_infos/reward_dist Std                0.674986
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      66800
eval/num paths total                       1670
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.483487
eval/Rewards Std                              0.653281
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            19.3395
eval/Returns Std                             19.265
eval/Returns Max                             40.422
eval/Returns Min                              0
eval/Actions Mean                             0.360554
eval/Actions Std                              0.783846
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         19.3395
eval/env_infos/final/reward_dist Mean         0.786126
eval/env_infos/final/reward_dist Std          0.784454
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.483487
eval/env_infos/reward_dist Std                0.653281
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00583231
time/evaluation sampling (s)                  3.42841
time/exploration sampling (s)                18.007
time/logging (s)                              0.0053853
time/saving (s)                               0.00236805
time/training (s)                             4.49324
time/epoch (s)                               25.9423
time/total (s)                             4256.49
Epoch                                       166
---------------------------------------  ----------------
2023-08-05 01:32:35.441707 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 167 finished
---------------------------------------  ----------------
epoch                                       167
replay_buffer/size                       336000
trainer/QF1 Loss                              1.39928
trainer/QF2 Loss                              1.39821
trainer/Policy Loss                         -12.6112
trainer/Q1 Predictions Mean                  11.1172
trainer/Q1 Predictions Std                    9.62199
trainer/Q1 Predictions Max                   31.1265
trainer/Q1 Predictions Min                  -12.4166
trainer/Q2 Predictions Mean                  11.1235
trainer/Q2 Predictions Std                    9.62501
trainer/Q2 Predictions Max                   30.8592
trainer/Q2 Predictions Min                  -12.7282
trainer/Q Targets Mean                       11.1979
trainer/Q Targets Std                         9.76405
trainer/Q Targets Max                        31.0663
trainer/Q Targets Min                       -12.8204
trainer/Bellman Errors 1 Mean                 1.39928
trainer/Bellman Errors 1 Std                  9.59577
trainer/Bellman Errors 1 Max                213.304
trainer/Bellman Errors 1 Min                  3.63798e-12
trainer/Bellman Errors 2 Mean                 1.39821
trainer/Bellman Errors 2 Std                  9.8936
trainer/Bellman Errors 2 Max                217.965
trainer/Bellman Errors 2 Min                  4.7072e-10
trainer/Policy Action Mean                    0.367812
trainer/Policy Action Std                     0.772375
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     336000
expl/num paths total                       8400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.726236
expl/Rewards Std                              0.676191
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            29.0494
expl/Returns Std                             16.1855
expl/Returns Max                             40.4988
expl/Returns Min                              0.00201199
expl/Actions Mean                             0.455822
expl/Actions Std                              0.701474
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.0494
expl/env_infos/final/reward_dist Mean         1.19248
expl/env_infos/final/reward_dist Std          0.670116
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000411657
expl/env_infos/initial/reward_dist Std        0.00202881
expl/env_infos/initial/reward_dist Max        0.0131252
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.726236
expl/env_infos/reward_dist Std                0.676191
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      67200
eval/num paths total                       1680
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.674769
eval/Rewards Std                              0.680799
eval/Rewards Max                              1.57043
eval/Rewards Min                              0
eval/Returns Mean                            26.9907
eval/Returns Std                             17.6795
eval/Returns Max                             40.323
eval/Returns Min                              0
eval/Actions Mean                             0.392791
eval/Actions Std                              0.769062
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.9907
eval/env_infos/final/reward_dist Mean         1.09686
eval/env_infos/final/reward_dist Std          0.718024
eval/env_infos/final/reward_dist Max          1.57043
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00146332
eval/env_infos/initial/reward_dist Std        0.00240909
eval/env_infos/initial/reward_dist Max        0.00718153
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.674769
eval/env_infos/reward_dist Std                0.680799
eval/env_infos/reward_dist Max                1.57043
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00576912
time/evaluation sampling (s)                  3.39996
time/exploration sampling (s)                17.9998
time/logging (s)                              0.00533773
time/saving (s)                               0.00230678
time/training (s)                             5.39348
time/epoch (s)                               26.8066
time/total (s)                             4283.3
Epoch                                       167
---------------------------------------  ----------------
2023-08-05 01:33:01.048450 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 168 finished
---------------------------------------  ----------------
epoch                                       168
replay_buffer/size                       338000
trainer/QF1 Loss                              1.88777
trainer/QF2 Loss                              1.91075
trainer/Policy Loss                         -12.539
trainer/Q1 Predictions Mean                  11.2206
trainer/Q1 Predictions Std                    9.58078
trainer/Q1 Predictions Max                   30.6038
trainer/Q1 Predictions Min                  -13.7987
trainer/Q2 Predictions Mean                  11.2042
trainer/Q2 Predictions Std                    9.57095
trainer/Q2 Predictions Max                   30.4621
trainer/Q2 Predictions Min                  -13.61
trainer/Q Targets Mean                       11.1666
trainer/Q Targets Std                         9.65284
trainer/Q Targets Max                        30.6502
trainer/Q Targets Min                       -13.8385
trainer/Bellman Errors 1 Mean                 1.88777
trainer/Bellman Errors 1 Std                 12.7867
trainer/Bellman Errors 1 Max                301.858
trainer/Bellman Errors 1 Min                  1.53705e-10
trainer/Bellman Errors 2 Mean                 1.91075
trainer/Bellman Errors 2 Std                 13.016
trainer/Bellman Errors 2 Max                307.061
trainer/Bellman Errors 2 Min                  6.508e-10
trainer/Policy Action Mean                    0.376841
trainer/Policy Action Std                     0.768329
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     338000
expl/num paths total                       8450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.486787
expl/Rewards Std                              0.644627
expl/Rewards Max                              1.57056
expl/Rewards Min                              0
expl/Returns Mean                            19.4715
expl/Returns Std                             18.6142
expl/Returns Max                             39.5354
expl/Returns Min                              0
expl/Actions Mean                             0.391478
expl/Actions Std                              0.743021
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.4715
expl/env_infos/final/reward_dist Mean         0.814043
expl/env_infos/final/reward_dist Std          0.782016
expl/env_infos/final/reward_dist Max          1.57056
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00148478
expl/env_infos/initial/reward_dist Std        0.00410483
expl/env_infos/initial/reward_dist Max        0.0177016
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.486787
expl/env_infos/reward_dist Std                0.644627
expl/env_infos/reward_dist Max                1.57056
expl/env_infos/reward_dist Min                0
eval/num steps total                      67600
eval/num paths total                       1690
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.568247
eval/Rewards Std                              0.66141
eval/Rewards Max                              1.57071
eval/Rewards Min                              0
eval/Returns Mean                            22.7299
eval/Returns Std                             18.1691
eval/Returns Max                             39.4692
eval/Returns Min                              0
eval/Actions Mean                             0.360911
eval/Actions Std                              0.786531
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.7299
eval/env_infos/final/reward_dist Mean         0.939814
eval/env_infos/final/reward_dist Std          0.76736
eval/env_infos/final/reward_dist Max          1.57071
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000520586
eval/env_infos/initial/reward_dist Std        0.00104191
eval/env_infos/initial/reward_dist Max        0.0026906
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.568247
eval/env_infos/reward_dist Std                0.66141
eval/env_infos/reward_dist Max                1.57071
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00577061
time/evaluation sampling (s)                  3.4832
time/exploration sampling (s)                17.7766
time/logging (s)                              0.00531847
time/saving (s)                               0.00239958
time/training (s)                             4.33061
time/epoch (s)                               25.6039
time/total (s)                             4308.9
Epoch                                       168
---------------------------------------  ----------------
2023-08-05 01:33:26.745575 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 169 finished
---------------------------------------  ----------------
epoch                                       169
replay_buffer/size                       340000
trainer/QF1 Loss                              1.73246
trainer/QF2 Loss                              1.74497
trainer/Policy Loss                         -12.7421
trainer/Q1 Predictions Mean                  11.3455
trainer/Q1 Predictions Std                    9.6196
trainer/Q1 Predictions Max                   30.5634
trainer/Q1 Predictions Min                   -9.9115
trainer/Q2 Predictions Mean                  11.3222
trainer/Q2 Predictions Std                    9.60813
trainer/Q2 Predictions Max                   30.1972
trainer/Q2 Predictions Min                   -9.97109
trainer/Q Targets Mean                       11.3369
trainer/Q Targets Std                         9.75765
trainer/Q Targets Max                        31.6441
trainer/Q Targets Min                       -10.2494
trainer/Bellman Errors 1 Mean                 1.73246
trainer/Bellman Errors 1 Std                 12.0392
trainer/Bellman Errors 1 Max                224.88
trainer/Bellman Errors 1 Min                  9.11241e-08
trainer/Bellman Errors 2 Mean                 1.74497
trainer/Bellman Errors 2 Std                 12.017
trainer/Bellman Errors 2 Max                236.837
trainer/Bellman Errors 2 Min                  7.82313e-08
trainer/Policy Action Mean                    0.378105
trainer/Policy Action Std                     0.768597
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     340000
expl/num paths total                       8500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.545114
expl/Rewards Std                              0.656561
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            21.8046
expl/Returns Std                             18.4585
expl/Returns Max                             42.5752
expl/Returns Min                              0.000126017
expl/Actions Mean                             0.399726
expl/Actions Std                              0.734503
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.8046
expl/env_infos/final/reward_dist Mean         0.90807
expl/env_infos/final/reward_dist Std          0.772708
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000400382
expl/env_infos/initial/reward_dist Std        0.00114732
expl/env_infos/initial/reward_dist Max        0.00500245
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.545114
expl/env_infos/reward_dist Std                0.656561
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      68000
eval/num paths total                       1700
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.846036
eval/Rewards Std                              0.650012
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            33.8414
eval/Returns Std                             11.426
eval/Returns Max                             40.7976
eval/Returns Min                              0.0288291
eval/Actions Mean                             0.481324
eval/Actions Std                              0.707093
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         33.8414
eval/env_infos/final/reward_dist Mean         1.40498
eval/env_infos/final/reward_dist Std          0.468919
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       6.82531e-05
eval/env_infos/initial/reward_dist Std        0.000204759
eval/env_infos/initial/reward_dist Max        0.000682531
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.846036
eval/env_infos/reward_dist Std                0.650012
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00575573
time/evaluation sampling (s)                  3.43451
time/exploration sampling (s)                17.4589
time/logging (s)                              0.00743624
time/saving (s)                               0.00272595
time/training (s)                             4.78708
time/epoch (s)                               25.6964
time/total (s)                             4334.6
Epoch                                       169
---------------------------------------  ----------------
2023-08-05 01:33:53.427899 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 170 finished
---------------------------------------  ----------------
epoch                                       170
replay_buffer/size                       342000
trainer/QF1 Loss                              1.74738
trainer/QF2 Loss                              1.71313
trainer/Policy Loss                         -12.6493
trainer/Q1 Predictions Mean                  11.4021
trainer/Q1 Predictions Std                    9.60902
trainer/Q1 Predictions Max                   30.2851
trainer/Q1 Predictions Min                  -13.8951
trainer/Q2 Predictions Mean                  11.429
trainer/Q2 Predictions Std                    9.59926
trainer/Q2 Predictions Max                   30.1678
trainer/Q2 Predictions Min                  -13.6965
trainer/Q Targets Mean                       11.3629
trainer/Q Targets Std                         9.70482
trainer/Q Targets Max                        30.7436
trainer/Q Targets Min                       -13.7015
trainer/Bellman Errors 1 Mean                 1.74738
trainer/Bellman Errors 1 Std                 12.2007
trainer/Bellman Errors 1 Max                242.967
trainer/Bellman Errors 1 Min                  2.45927e-09
trainer/Bellman Errors 2 Mean                 1.71313
trainer/Bellman Errors 2 Std                 12.1967
trainer/Bellman Errors 2 Max                252.472
trainer/Bellman Errors 2 Min                  6.00712e-08
trainer/Policy Action Mean                    0.372584
trainer/Policy Action Std                     0.767703
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     342000
expl/num paths total                       8550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.742223
expl/Rewards Std                              0.662222
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            29.6889
expl/Returns Std                             14.7571
expl/Returns Max                             39.9737
expl/Returns Min                              0.0011924
expl/Actions Mean                             0.429799
expl/Actions Std                              0.708705
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.6889
expl/env_infos/final/reward_dist Mean         1.2518
expl/env_infos/final/reward_dist Std          0.626007
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00131643
expl/env_infos/initial/reward_dist Std        0.00276247
expl/env_infos/initial/reward_dist Max        0.0108817
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.742223
expl/env_infos/reward_dist Std                0.662222
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      68400
eval/num paths total                       1710
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.45641
eval/Rewards Std                              0.627074
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            18.2564
eval/Returns Std                             18.1861
eval/Returns Max                             37.2468
eval/Returns Min                              0
eval/Actions Mean                             0.386055
eval/Actions Std                              0.765129
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         18.2564
eval/env_infos/final/reward_dist Mean         0.768711
eval/env_infos/final/reward_dist Std          0.769179
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.45641
eval/env_infos/reward_dist Std                0.627074
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595561
time/evaluation sampling (s)                  3.52595
time/exploration sampling (s)                17.756
time/logging (s)                              0.00531179
time/saving (s)                               0.0023485
time/training (s)                             5.37982
time/epoch (s)                               26.6754
time/total (s)                             4361.28
Epoch                                       170
---------------------------------------  ----------------
2023-08-05 01:34:18.962206 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 171 finished
---------------------------------------  ----------------
epoch                                       171
replay_buffer/size                       344000
trainer/QF1 Loss                              1.63239
trainer/QF2 Loss                              1.63574
trainer/Policy Loss                         -12.4158
trainer/Q1 Predictions Mean                  11.2617
trainer/Q1 Predictions Std                    9.78497
trainer/Q1 Predictions Max                   30.5887
trainer/Q1 Predictions Min                  -14.6057
trainer/Q2 Predictions Mean                  11.2593
trainer/Q2 Predictions Std                    9.78101
trainer/Q2 Predictions Max                   30.4663
trainer/Q2 Predictions Min                  -15.4253
trainer/Q Targets Mean                       11.2346
trainer/Q Targets Std                         9.82312
trainer/Q Targets Max                        31.3946
trainer/Q Targets Min                       -14.9138
trainer/Bellman Errors 1 Mean                 1.63239
trainer/Bellman Errors 1 Std                 11.9193
trainer/Bellman Errors 1 Max                240.624
trainer/Bellman Errors 1 Min                  4.36744e-09
trainer/Bellman Errors 2 Mean                 1.63574
trainer/Bellman Errors 2 Std                 12.0564
trainer/Bellman Errors 2 Max                238.228
trainer/Bellman Errors 2 Min                  1.04798e-08
trainer/Policy Action Mean                    0.347857
trainer/Policy Action Std                     0.785227
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     344000
expl/num paths total                       8600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.455524
expl/Rewards Std                              0.624438
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            18.221
expl/Returns Std                             17.2507
expl/Returns Max                             40.346
expl/Returns Min                              0
expl/Actions Mean                             0.334315
expl/Actions Std                              0.77641
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.221
expl/env_infos/final/reward_dist Mean         0.816256
expl/env_infos/final/reward_dist Std          0.78357
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00139937
expl/env_infos/initial/reward_dist Std        0.00394005
expl/env_infos/initial/reward_dist Max        0.0197124
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.455524
expl/env_infos/reward_dist Std                0.624438
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      68800
eval/num paths total                       1720
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.476124
eval/Rewards Std                              0.629364
eval/Rewards Max                              1.57066
eval/Rewards Min                              0
eval/Returns Mean                            19.045
eval/Returns Std                             17.7978
eval/Returns Max                             40.844
eval/Returns Min                              0.015505
eval/Actions Mean                             0.399556
eval/Actions Std                              0.766244
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         19.045
eval/env_infos/final/reward_dist Mean         0.86793
eval/env_infos/final/reward_dist Std          0.739798
eval/env_infos/final/reward_dist Max          1.57066
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00028644
eval/env_infos/initial/reward_dist Std        0.00085932
eval/env_infos/initial/reward_dist Max        0.0028644
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.476124
eval/env_infos/reward_dist Std                0.629364
eval/env_infos/reward_dist Max                1.57066
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00594992
time/evaluation sampling (s)                  3.37115
time/exploration sampling (s)                17.9189
time/logging (s)                              0.00530967
time/saving (s)                               0.00235362
time/training (s)                             4.22783
time/epoch (s)                               25.5314
time/total (s)                             4386.81
Epoch                                       171
---------------------------------------  ----------------
2023-08-05 01:34:45.203709 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 172 finished
---------------------------------------  ----------------
epoch                                       172
replay_buffer/size                       346000
trainer/QF1 Loss                              1.73458
trainer/QF2 Loss                              1.77421
trainer/Policy Loss                         -12.7774
trainer/Q1 Predictions Mean                  11.5106
trainer/Q1 Predictions Std                    9.81719
trainer/Q1 Predictions Max                   31.3472
trainer/Q1 Predictions Min                   -7.51326
trainer/Q2 Predictions Mean                  11.5047
trainer/Q2 Predictions Std                    9.83218
trainer/Q2 Predictions Max                   30.9958
trainer/Q2 Predictions Min                   -7.28334
trainer/Q Targets Mean                       11.4948
trainer/Q Targets Std                         9.91921
trainer/Q Targets Max                        31.7706
trainer/Q Targets Min                        -7.26702
trainer/Bellman Errors 1 Mean                 1.73458
trainer/Bellman Errors 1 Std                 11.9108
trainer/Bellman Errors 1 Max                246.728
trainer/Bellman Errors 1 Min                  8.51093e-08
trainer/Bellman Errors 2 Mean                 1.77421
trainer/Bellman Errors 2 Std                 12.3572
trainer/Bellman Errors 2 Max                255.195
trainer/Bellman Errors 2 Min                  2.09548e-09
trainer/Policy Action Mean                    0.343506
trainer/Policy Action Std                     0.799733
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     346000
expl/num paths total                       8650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.495846
expl/Rewards Std                              0.642145
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            19.8338
expl/Returns Std                             17.5606
expl/Returns Max                             42.6023
expl/Returns Min                              0
expl/Actions Mean                             0.351339
expl/Actions Std                              0.766079
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.8338
expl/env_infos/final/reward_dist Mean         0.878644
expl/env_infos/final/reward_dist Std          0.778612
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000789246
expl/env_infos/initial/reward_dist Std        0.00248135
expl/env_infos/initial/reward_dist Max        0.0124179
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.495846
expl/env_infos/reward_dist Std                0.642145
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      69200
eval/num paths total                       1730
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.72657
eval/Rewards Std                              0.665991
eval/Rewards Max                              1.57076
eval/Rewards Min                              0
eval/Returns Mean                            29.0628
eval/Returns Std                             14.6333
eval/Returns Max                             40.2104
eval/Returns Min                              0.0205505
eval/Actions Mean                             0.417945
eval/Actions Std                              0.738212
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         29.0628
eval/env_infos/final/reward_dist Mean         1.25418
eval/env_infos/final/reward_dist Std          0.627095
eval/env_infos/final/reward_dist Max          1.57076
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00144009
eval/env_infos/initial/reward_dist Std        0.00366202
eval/env_infos/initial/reward_dist Max        0.0123593
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.72657
eval/env_infos/reward_dist Std                0.665991
eval/env_infos/reward_dist Max                1.57076
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0060215
time/evaluation sampling (s)                  3.58437
time/exploration sampling (s)                18.1922
time/logging (s)                              0.00533627
time/saving (s)                               0.00231931
time/training (s)                             4.44845
time/epoch (s)                               26.2386
time/total (s)                             4413.05
Epoch                                       172
---------------------------------------  ----------------
2023-08-05 01:35:11.083089 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 173 finished
---------------------------------------  ----------------
epoch                                       173
replay_buffer/size                       348000
trainer/QF1 Loss                              1.61451
trainer/QF2 Loss                              1.58802
trainer/Policy Loss                         -13.1271
trainer/Q1 Predictions Mean                  11.8089
trainer/Q1 Predictions Std                    9.96217
trainer/Q1 Predictions Max                   31.7372
trainer/Q1 Predictions Min                  -10.2998
trainer/Q2 Predictions Mean                  11.8242
trainer/Q2 Predictions Std                    9.97226
trainer/Q2 Predictions Max                   31.4604
trainer/Q2 Predictions Min                  -11.5325
trainer/Q Targets Mean                       11.7984
trainer/Q Targets Std                        10.0527
trainer/Q Targets Max                        32.1759
trainer/Q Targets Min                       -11.3017
trainer/Bellman Errors 1 Mean                 1.61451
trainer/Bellman Errors 1 Std                 11.3281
trainer/Bellman Errors 1 Max                244.649
trainer/Bellman Errors 1 Min                  2.50149e-08
trainer/Bellman Errors 2 Mean                 1.58802
trainer/Bellman Errors 2 Std                 11.3609
trainer/Bellman Errors 2 Max                239.528
trainer/Bellman Errors 2 Min                  3.45835e-08
trainer/Policy Action Mean                    0.356137
trainer/Policy Action Std                     0.792633
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     348000
expl/num paths total                       8700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.733773
expl/Rewards Std                              0.669718
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            29.3509
expl/Returns Std                             15.5824
expl/Returns Max                             42.3912
expl/Returns Min                              0.0049633
expl/Actions Mean                             0.431866
expl/Actions Std                              0.712112
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.3509
expl/env_infos/final/reward_dist Mean         1.224
expl/env_infos/final/reward_dist Std          0.649943
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00236423
expl/env_infos/initial/reward_dist Std        0.00456285
expl/env_infos/initial/reward_dist Max        0.0169158
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.733773
expl/env_infos/reward_dist Std                0.669718
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      69600
eval/num paths total                       1740
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.661638
eval/Rewards Std                              0.670804
eval/Rewards Max                              1.57054
eval/Rewards Min                              0
eval/Returns Mean                            26.4655
eval/Returns Std                             17.1087
eval/Returns Max                             39.6931
eval/Returns Min                              0
eval/Actions Mean                             0.373632
eval/Actions Std                              0.777279
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.4655
eval/env_infos/final/reward_dist Mean         1.09757
eval/env_infos/final/reward_dist Std          0.718529
eval/env_infos/final/reward_dist Max          1.57054
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.661638
eval/env_infos/reward_dist Std                0.670804
eval/env_infos/reward_dist Max                1.57054
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584534
time/evaluation sampling (s)                  3.5901
time/exploration sampling (s)                17.8712
time/logging (s)                              0.00529159
time/saving (s)                               0.00237462
time/training (s)                             4.40153
time/epoch (s)                               25.8763
time/total (s)                             4438.93
Epoch                                       173
---------------------------------------  ----------------
2023-08-05 01:35:37.888271 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 174 finished
---------------------------------------  ----------------
epoch                                       174
replay_buffer/size                       350000
trainer/QF1 Loss                              1.53678
trainer/QF2 Loss                              1.53271
trainer/Policy Loss                         -13.2245
trainer/Q1 Predictions Mean                  12.0155
trainer/Q1 Predictions Std                   10.1297
trainer/Q1 Predictions Max                   32.0578
trainer/Q1 Predictions Min                  -13.2585
trainer/Q2 Predictions Mean                  12.042
trainer/Q2 Predictions Std                   10.1449
trainer/Q2 Predictions Max                   31.9974
trainer/Q2 Predictions Min                  -13.3885
trainer/Q Targets Mean                       11.9546
trainer/Q Targets Std                        10.1611
trainer/Q Targets Max                        32.4392
trainer/Q Targets Min                       -12.6406
trainer/Bellman Errors 1 Mean                 1.53678
trainer/Bellman Errors 1 Std                 10.2378
trainer/Bellman Errors 1 Max                241.401
trainer/Bellman Errors 1 Min                  4.98003e-08
trainer/Bellman Errors 2 Mean                 1.53271
trainer/Bellman Errors 2 Std                 10.7133
trainer/Bellman Errors 2 Max                252.493
trainer/Bellman Errors 2 Min                  5.16257e-08
trainer/Policy Action Mean                    0.343517
trainer/Policy Action Std                     0.80099
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     350000
expl/num paths total                       8750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.629654
expl/Rewards Std                              0.673029
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            25.1861
expl/Returns Std                             18.0539
expl/Returns Max                             41.0025
expl/Returns Min                              0
expl/Actions Mean                             0.392787
expl/Actions Std                              0.73924
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.1861
expl/env_infos/final/reward_dist Mean         1.03517
expl/env_infos/final/reward_dist Std          0.742986
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000698091
expl/env_infos/initial/reward_dist Std        0.00198979
expl/env_infos/initial/reward_dist Max        0.0097746
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.629654
expl/env_infos/reward_dist Std                0.673029
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      70000
eval/num paths total                       1750
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.579682
eval/Rewards Std                              0.67094
eval/Rewards Max                              1.57058
eval/Rewards Min                              0
eval/Returns Mean                            23.1873
eval/Returns Std                             18.9321
eval/Returns Max                             40.189
eval/Returns Min                              0.00674716
eval/Actions Mean                             0.428558
eval/Actions Std                              0.749705
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         23.1873
eval/env_infos/final/reward_dist Mean         0.941654
eval/env_infos/final/reward_dist Std          0.768858
eval/env_infos/final/reward_dist Max          1.57058
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000545737
eval/env_infos/initial/reward_dist Std        0.000881395
eval/env_infos/initial/reward_dist Max        0.00240143
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.579682
eval/env_infos/reward_dist Std                0.67094
eval/env_infos/reward_dist Max                1.57058
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584144
time/evaluation sampling (s)                  3.44159
time/exploration sampling (s)                18.7304
time/logging (s)                              0.00747256
time/saving (s)                               0.00271303
time/training (s)                             4.61645
time/epoch (s)                               26.8045
time/total (s)                             4465.74
Epoch                                       174
---------------------------------------  ----------------
2023-08-05 01:36:03.488629 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 175 finished
---------------------------------------  ----------------
epoch                                       175
replay_buffer/size                       352000
trainer/QF1 Loss                              1.44947
trainer/QF2 Loss                              1.44956
trainer/Policy Loss                         -13.1731
trainer/Q1 Predictions Mean                  11.9205
trainer/Q1 Predictions Std                   10.2361
trainer/Q1 Predictions Max                   31.9377
trainer/Q1 Predictions Min                   -7.49469
trainer/Q2 Predictions Mean                  11.9267
trainer/Q2 Predictions Std                   10.2364
trainer/Q2 Predictions Max                   31.6988
trainer/Q2 Predictions Min                   -7.63005
trainer/Q Targets Mean                       11.9525
trainer/Q Targets Std                        10.2986
trainer/Q Targets Max                        33.6943
trainer/Q Targets Min                        -8.17764
trainer/Bellman Errors 1 Mean                 1.44947
trainer/Bellman Errors 1 Std                  9.4431
trainer/Bellman Errors 1 Max                210.812
trainer/Bellman Errors 1 Min                  3.42297e-08
trainer/Bellman Errors 2 Mean                 1.44956
trainer/Bellman Errors 2 Std                  9.8826
trainer/Bellman Errors 2 Max                210.581
trainer/Bellman Errors 2 Min                  7.63534e-09
trainer/Policy Action Mean                    0.348498
trainer/Policy Action Std                     0.796697
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     352000
expl/num paths total                       8800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.651408
expl/Rewards Std                              0.673845
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            26.0563
expl/Returns Std                             17.8081
expl/Returns Max                             41.2747
expl/Returns Min                              0
expl/Actions Mean                             0.389832
expl/Actions Std                              0.74228
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.0563
expl/env_infos/final/reward_dist Mean         1.06659
expl/env_infos/final/reward_dist Std          0.731679
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00158023
expl/env_infos/initial/reward_dist Std        0.00412805
expl/env_infos/initial/reward_dist Max        0.0170302
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.651408
expl/env_infos/reward_dist Std                0.673845
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      70400
eval/num paths total                       1760
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.885461
eval/Rewards Std                              0.653791
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            35.4184
eval/Returns Std                             11.8376
eval/Returns Max                             40.7313
eval/Returns Min                              0.0112921
eval/Actions Mean                             0.496905
eval/Actions Std                              0.691759
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.4184
eval/env_infos/final/reward_dist Mean         1.41229
eval/env_infos/final/reward_dist Std          0.470766
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.885461
eval/env_infos/reward_dist Std                0.653791
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0057153
time/evaluation sampling (s)                  3.57456
time/exploration sampling (s)                17.6482
time/logging (s)                              0.00530823
time/saving (s)                               0.00234811
time/training (s)                             4.35723
time/epoch (s)                               25.5933
time/total (s)                             4491.33
Epoch                                       175
---------------------------------------  ----------------
2023-08-05 01:36:29.425362 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 176 finished
---------------------------------------  ----------------
epoch                                       176
replay_buffer/size                       354000
trainer/QF1 Loss                              2.01577
trainer/QF2 Loss                              2.02044
trainer/Policy Loss                         -13.1393
trainer/Q1 Predictions Mean                  12.0109
trainer/Q1 Predictions Std                   10.2217
trainer/Q1 Predictions Max                   32.2914
trainer/Q1 Predictions Min                   -8.52022
trainer/Q2 Predictions Mean                  12.0297
trainer/Q2 Predictions Std                   10.2353
trainer/Q2 Predictions Max                   31.8973
trainer/Q2 Predictions Min                   -8.61358
trainer/Q Targets Mean                       11.9511
trainer/Q Targets Std                        10.2954
trainer/Q Targets Max                        33.1053
trainer/Q Targets Min                        -7.84425
trainer/Bellman Errors 1 Mean                 2.01577
trainer/Bellman Errors 1 Std                 14.3006
trainer/Bellman Errors 1 Max                300.51
trainer/Bellman Errors 1 Min                  1.63842e-08
trainer/Bellman Errors 2 Mean                 2.02044
trainer/Bellman Errors 2 Std                 14.797
trainer/Bellman Errors 2 Max                301.25
trainer/Bellman Errors 2 Min                  2.18506e-08
trainer/Policy Action Mean                    0.345937
trainer/Policy Action Std                     0.795658
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     354000
expl/num paths total                       8850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.471789
expl/Rewards Std                              0.639183
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            18.8716
expl/Returns Std                             18.8166
expl/Returns Max                             41.367
expl/Returns Min                              0
expl/Actions Mean                             0.329755
expl/Actions Std                              0.779668
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         18.8716
expl/env_infos/final/reward_dist Mean         0.784915
expl/env_infos/final/reward_dist Std          0.783755
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000646156
expl/env_infos/initial/reward_dist Std        0.00240107
expl/env_infos/initial/reward_dist Max        0.0113279
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.471789
expl/env_infos/reward_dist Std                0.639183
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      70800
eval/num paths total                       1770
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.862884
eval/Rewards Std                              0.649656
eval/Rewards Max                              1.57065
eval/Rewards Min                              0
eval/Returns Mean                            34.5154
eval/Returns Std                             11.6601
eval/Returns Max                             40.9302
eval/Returns Min                              0.00297328
eval/Actions Mean                             0.464421
eval/Actions Std                              0.708109
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         34.5154
eval/env_infos/final/reward_dist Mean         1.40898
eval/env_infos/final/reward_dist Std          0.469721
eval/env_infos/final/reward_dist Max          1.57065
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000743798
eval/env_infos/initial/reward_dist Std        0.0022314
eval/env_infos/initial/reward_dist Max        0.00743798
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.862884
eval/env_infos/reward_dist Std                0.649656
eval/env_infos/reward_dist Max                1.57065
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00582985
time/evaluation sampling (s)                  3.53249
time/exploration sampling (s)                17.8845
time/logging (s)                              0.00532466
time/saving (s)                               0.00233868
time/training (s)                             4.50348
time/epoch (s)                               25.9339
time/total (s)                             4517.27
Epoch                                       176
---------------------------------------  ----------------
2023-08-05 01:36:55.213738 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 177 finished
---------------------------------------  ----------------
epoch                                       177
replay_buffer/size                       356000
trainer/QF1 Loss                              1.5181
trainer/QF2 Loss                              1.53354
trainer/Policy Loss                         -12.978
trainer/Q1 Predictions Mean                  11.7254
trainer/Q1 Predictions Std                   10.4038
trainer/Q1 Predictions Max                   32.1938
trainer/Q1 Predictions Min                   -7.11462
trainer/Q2 Predictions Mean                  11.707
trainer/Q2 Predictions Std                   10.4138
trainer/Q2 Predictions Max                   32.1536
trainer/Q2 Predictions Min                   -8.10936
trainer/Q Targets Mean                       11.6929
trainer/Q Targets Std                        10.5096
trainer/Q Targets Max                        33.1134
trainer/Q Targets Min                        -7.72092
trainer/Bellman Errors 1 Mean                 1.5181
trainer/Bellman Errors 1 Std                  9.95701
trainer/Bellman Errors 1 Max                234.149
trainer/Bellman Errors 1 Min                  1.14216e-09
trainer/Bellman Errors 2 Mean                 1.53354
trainer/Bellman Errors 2 Std                 10.3519
trainer/Bellman Errors 2 Max                236.217
trainer/Bellman Errors 2 Min                  4.20414e-10
trainer/Policy Action Mean                    0.352199
trainer/Policy Action Std                     0.79374
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     356000
expl/num paths total                       8900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.552258
expl/Rewards Std                              0.660559
expl/Rewards Max                              1.5707
expl/Rewards Min                              0
expl/Returns Mean                            22.0903
expl/Returns Std                             18.7165
expl/Returns Max                             40.1728
expl/Returns Min                              0
expl/Actions Mean                             0.372433
expl/Actions Std                              0.758316
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.0903
expl/env_infos/final/reward_dist Mean         0.909601
expl/env_infos/final/reward_dist Std          0.774025
expl/env_infos/final/reward_dist Max          1.5707
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000849095
expl/env_infos/initial/reward_dist Std        0.00263616
expl/env_infos/initial/reward_dist Max        0.0120444
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.552258
expl/env_infos/reward_dist Std                0.660559
expl/env_infos/reward_dist Max                1.5707
expl/env_infos/reward_dist Min                0
eval/num steps total                      71200
eval/num paths total                       1780
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.368048
eval/Rewards Std                              0.595365
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            14.7219
eval/Returns Std                             18.0484
eval/Returns Max                             39.2431
eval/Returns Min                              0
eval/Actions Mean                             0.390129
eval/Actions Std                              0.782552
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         14.7219
eval/env_infos/final/reward_dist Mean         0.618664
eval/env_infos/final/reward_dist Std          0.758049
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.368048
eval/env_infos/reward_dist Std                0.595365
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00571068
time/evaluation sampling (s)                  3.40287
time/exploration sampling (s)                17.3546
time/logging (s)                              0.00529272
time/saving (s)                               0.00236942
time/training (s)                             5.01465
time/epoch (s)                               25.7855
time/total (s)                             4543.06
Epoch                                       177
---------------------------------------  ----------------
2023-08-05 01:37:20.854492 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 178 finished
---------------------------------------  ----------------
epoch                                       178
replay_buffer/size                       358000
trainer/QF1 Loss                              1.62737
trainer/QF2 Loss                              1.61567
trainer/Policy Loss                         -12.9382
trainer/Q1 Predictions Mean                  11.7702
trainer/Q1 Predictions Std                   10.4801
trainer/Q1 Predictions Max                   32.4844
trainer/Q1 Predictions Min                   -7.68161
trainer/Q2 Predictions Mean                  11.7958
trainer/Q2 Predictions Std                   10.4812
trainer/Q2 Predictions Max                   32.6371
trainer/Q2 Predictions Min                   -7.04995
trainer/Q Targets Mean                       11.7814
trainer/Q Targets Std                        10.5617
trainer/Q Targets Max                        33.0602
trainer/Q Targets Min                        -7.22954
trainer/Bellman Errors 1 Mean                 1.62737
trainer/Bellman Errors 1 Std                 11.3564
trainer/Bellman Errors 1 Max                259.857
trainer/Bellman Errors 1 Min                  2.43657e-07
trainer/Bellman Errors 2 Mean                 1.61567
trainer/Bellman Errors 2 Std                 11.7137
trainer/Bellman Errors 2 Max                258.22
trainer/Bellman Errors 2 Min                  4.28005e-07
trainer/Policy Action Mean                    0.347843
trainer/Policy Action Std                     0.789757
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     358000
expl/num paths total                       8950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.475939
expl/Rewards Std                              0.640604
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            19.0375
expl/Returns Std                             19.0529
expl/Returns Max                             41.8568
expl/Returns Min                              0
expl/Actions Mean                             0.364283
expl/Actions Std                              0.759256
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.0375
expl/env_infos/final/reward_dist Mean         0.784163
expl/env_infos/final/reward_dist Std          0.784136
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00107947
expl/env_infos/initial/reward_dist Std        0.00314153
expl/env_infos/initial/reward_dist Max        0.0144094
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.475939
expl/env_infos/reward_dist Std                0.640604
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      71600
eval/num paths total                       1790
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.690923
eval/Rewards Std                              0.680525
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            27.6369
eval/Returns Std                             18.1231
eval/Returns Max                             42.2335
eval/Returns Min                              9.88228e-05
eval/Actions Mean                             0.464725
eval/Actions Std                              0.715923
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         27.6369
eval/env_infos/final/reward_dist Mean         1.09703
eval/env_infos/final/reward_dist Std          0.718176
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       2.65791e-05
eval/env_infos/initial/reward_dist Std        7.97374e-05
eval/env_infos/initial/reward_dist Max        0.000265791
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.690923
eval/env_infos/reward_dist Std                0.680525
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00581926
time/evaluation sampling (s)                  3.50961
time/exploration sampling (s)                17.78
time/logging (s)                              0.00530923
time/saving (s)                               0.00237339
time/training (s)                             4.33486
time/epoch (s)                               25.6379
time/total (s)                             4568.7
Epoch                                       178
---------------------------------------  ----------------
2023-08-05 01:37:46.748213 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 179 finished
---------------------------------------  ----------------
epoch                                       179
replay_buffer/size                       360000
trainer/QF1 Loss                              1.91842
trainer/QF2 Loss                              1.98126
trainer/Policy Loss                         -12.942
trainer/Q1 Predictions Mean                  11.7677
trainer/Q1 Predictions Std                   10.6252
trainer/Q1 Predictions Max                   32.7134
trainer/Q1 Predictions Min                   -8.93314
trainer/Q2 Predictions Mean                  11.7632
trainer/Q2 Predictions Std                   10.605
trainer/Q2 Predictions Max                   32.7618
trainer/Q2 Predictions Min                   -7.89567
trainer/Q Targets Mean                       11.7574
trainer/Q Targets Std                        10.7151
trainer/Q Targets Max                        34.0785
trainer/Q Targets Min                        -8.53703
trainer/Bellman Errors 1 Mean                 1.91842
trainer/Bellman Errors 1 Std                 13.4033
trainer/Bellman Errors 1 Max                261.214
trainer/Bellman Errors 1 Min                  4.83741e-10
trainer/Bellman Errors 2 Mean                 1.98126
trainer/Bellman Errors 2 Std                 13.8205
trainer/Bellman Errors 2 Max                259.818
trainer/Bellman Errors 2 Min                  2.1013e-08
trainer/Policy Action Mean                    0.369126
trainer/Policy Action Std                     0.781901
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     360000
expl/num paths total                       9000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.385519
expl/Rewards Std                              0.607791
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            15.4208
expl/Returns Std                             18.7813
expl/Returns Max                             40.2949
expl/Returns Min                              0
expl/Actions Mean                             0.381517
expl/Actions Std                              0.756717
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         15.4208
expl/env_infos/final/reward_dist Mean         0.627984
expl/env_infos/final/reward_dist Std          0.768494
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000968705
expl/env_infos/initial/reward_dist Std        0.00307676
expl/env_infos/initial/reward_dist Max        0.0149787
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.385519
expl/env_infos/reward_dist Std                0.607791
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      72000
eval/num paths total                       1800
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.293666
eval/Rewards Std                              0.553911
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            11.7466
eval/Returns Std                             17.7323
eval/Returns Max                             39.5525
eval/Returns Min                              0
eval/Actions Mean                             0.336385
eval/Actions Std                              0.801418
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.7466
eval/env_infos/final/reward_dist Mean         0.470504
eval/env_infos/final/reward_dist Std          0.718464
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00148517
eval/env_infos/initial/reward_dist Std        0.00445552
eval/env_infos/initial/reward_dist Max        0.0148517
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.293666
eval/env_infos/reward_dist Std                0.553911
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589972
time/evaluation sampling (s)                  3.52772
time/exploration sampling (s)                17.7934
time/logging (s)                              0.00535103
time/saving (s)                               0.00235964
time/training (s)                             4.55603
time/epoch (s)                               25.8908
time/total (s)                             4594.59
Epoch                                       179
---------------------------------------  ----------------
2023-08-05 01:38:12.229609 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 180 finished
---------------------------------------  ----------------
epoch                                       180
replay_buffer/size                       362000
trainer/QF1 Loss                              1.68801
trainer/QF2 Loss                              1.69593
trainer/Policy Loss                         -13.2141
trainer/Q1 Predictions Mean                  11.9354
trainer/Q1 Predictions Std                   10.733
trainer/Q1 Predictions Max                   32.8634
trainer/Q1 Predictions Min                   -8.80447
trainer/Q2 Predictions Mean                  11.9331
trainer/Q2 Predictions Std                   10.7238
trainer/Q2 Predictions Max                   32.7859
trainer/Q2 Predictions Min                   -9.7415
trainer/Q Targets Mean                       11.8789
trainer/Q Targets Std                        10.8358
trainer/Q Targets Max                        33.2738
trainer/Q Targets Min                       -10.0132
trainer/Bellman Errors 1 Mean                 1.68801
trainer/Bellman Errors 1 Std                 11.3971
trainer/Bellman Errors 1 Max                297.503
trainer/Bellman Errors 1 Min                  3.96176e-09
trainer/Bellman Errors 2 Mean                 1.69593
trainer/Bellman Errors 2 Std                 11.6879
trainer/Bellman Errors 2 Max                302.157
trainer/Bellman Errors 2 Min                  7.36691e-09
trainer/Policy Action Mean                    0.370242
trainer/Policy Action Std                     0.769037
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     362000
expl/num paths total                       9050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.28741
expl/Rewards Std                              0.551715
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            11.4964
expl/Returns Std                             17.4477
expl/Returns Max                             40.8114
expl/Returns Min                              0
expl/Actions Mean                             0.36268
expl/Actions Std                              0.759188
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         11.4964
expl/env_infos/final/reward_dist Mean         0.47097
expl/env_infos/final/reward_dist Std          0.718956
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000286378
expl/env_infos/initial/reward_dist Std        0.00104211
expl/env_infos/initial/reward_dist Max        0.00643572
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.28741
expl/env_infos/reward_dist Std                0.551715
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      72400
eval/num paths total                       1810
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.0992721
eval/Rewards Std                              0.34472
eval/Rewards Max                              1.56713
eval/Rewards Min                              0
eval/Returns Mean                             3.97088
eval/Returns Std                             11.3622
eval/Returns Max                             38.0388
eval/Returns Min                              0
eval/Actions Mean                             0.341219
eval/Actions Std                              0.805992
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                          3.97088
eval/env_infos/final/reward_dist Mean         0.156713
eval/env_infos/final/reward_dist Std          0.47014
eval/env_infos/final/reward_dist Max          1.56713
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.0992721
eval/env_infos/reward_dist Std                0.34472
eval/env_infos/reward_dist Max                1.56713
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00571474
time/evaluation sampling (s)                  3.32298
time/exploration sampling (s)                17.8233
time/logging (s)                              0.00743001
time/saving (s)                               0.00268538
time/training (s)                             4.31853
time/epoch (s)                               25.4806
time/total (s)                             4620.07
Epoch                                       180
---------------------------------------  ----------------
2023-08-05 01:38:38.390705 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 181 finished
---------------------------------------  ----------------
epoch                                       181
replay_buffer/size                       364000
trainer/QF1 Loss                              1.80798
trainer/QF2 Loss                              1.83856
trainer/Policy Loss                         -12.9974
trainer/Q1 Predictions Mean                  11.6798
trainer/Q1 Predictions Std                   10.8882
trainer/Q1 Predictions Max                   33.9864
trainer/Q1 Predictions Min                   -9.82466
trainer/Q2 Predictions Mean                  11.6872
trainer/Q2 Predictions Std                   10.8817
trainer/Q2 Predictions Max                   33.1653
trainer/Q2 Predictions Min                   -9.80915
trainer/Q Targets Mean                       11.6551
trainer/Q Targets Std                        10.959
trainer/Q Targets Max                        34.0834
trainer/Q Targets Min                        -9.44119
trainer/Bellman Errors 1 Mean                 1.80798
trainer/Bellman Errors 1 Std                 12.3069
trainer/Bellman Errors 1 Max                276.332
trainer/Bellman Errors 1 Min                  5.20153e-09
trainer/Bellman Errors 2 Mean                 1.83856
trainer/Bellman Errors 2 Std                 12.8141
trainer/Bellman Errors 2 Max                287.259
trainer/Bellman Errors 2 Min                  1.10149e-08
trainer/Policy Action Mean                    0.364349
trainer/Policy Action Std                     0.771618
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     364000
expl/num paths total                       9100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.336129
expl/Rewards Std                              0.583756
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            13.4451
expl/Returns Std                             17.9274
expl/Returns Max                             45.0418
expl/Returns Min                              0
expl/Actions Mean                             0.313953
expl/Actions Std                              0.779283
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         13.4451
expl/env_infos/final/reward_dist Mean         0.563564
expl/env_infos/final/reward_dist Std          0.750717
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000975537
expl/env_infos/initial/reward_dist Std        0.00577373
expl/env_infos/initial/reward_dist Max        0.0410366
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.336129
expl/env_infos/reward_dist Std                0.583756
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      72800
eval/num paths total                       1820
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.288596
eval/Rewards Std                              0.555232
eval/Rewards Max                              1.56932
eval/Rewards Min                              0
eval/Returns Mean                            11.5438
eval/Returns Std                             17.5675
eval/Returns Max                             38.7331
eval/Returns Min                              0
eval/Actions Mean                             0.368806
eval/Actions Std                              0.784409
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.5438
eval/env_infos/final/reward_dist Mean         0.47039
eval/env_infos/final/reward_dist Std          0.718534
eval/env_infos/final/reward_dist Max          1.56932
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000964733
eval/env_infos/initial/reward_dist Std        0.00193433
eval/env_infos/initial/reward_dist Max        0.00513023
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.288596
eval/env_infos/reward_dist Std                0.555232
eval/env_infos/reward_dist Max                1.56932
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593961
time/evaluation sampling (s)                  3.39588
time/exploration sampling (s)                18.0312
time/logging (s)                              0.00738731
time/saving (s)                               0.00269754
time/training (s)                             4.71304
time/epoch (s)                               26.1561
time/total (s)                             4646.23
Epoch                                       181
---------------------------------------  ----------------
2023-08-05 01:39:04.852353 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 182 finished
---------------------------------------  ----------------
epoch                                       182
replay_buffer/size                       366000
trainer/QF1 Loss                              2.06623
trainer/QF2 Loss                              2.03876
trainer/Policy Loss                         -13.0165
trainer/Q1 Predictions Mean                  11.7649
trainer/Q1 Predictions Std                   11.1264
trainer/Q1 Predictions Max                   32.972
trainer/Q1 Predictions Min                  -10.7038
trainer/Q2 Predictions Mean                  11.7559
trainer/Q2 Predictions Std                   11.1408
trainer/Q2 Predictions Max                   33.0565
trainer/Q2 Predictions Min                  -13.5172
trainer/Q Targets Mean                       11.7122
trainer/Q Targets Std                        11.2236
trainer/Q Targets Max                        34.2967
trainer/Q Targets Min                       -12.0944
trainer/Bellman Errors 1 Mean                 2.06623
trainer/Bellman Errors 1 Std                 13.9058
trainer/Bellman Errors 1 Max                262.791
trainer/Bellman Errors 1 Min                  1.47184e-07
trainer/Bellman Errors 2 Mean                 2.03876
trainer/Bellman Errors 2 Std                 14.1382
trainer/Bellman Errors 2 Max                256.254
trainer/Bellman Errors 2 Min                  2.79329e-08
trainer/Policy Action Mean                    0.388272
trainer/Policy Action Std                     0.761411
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     366000
expl/num paths total                       9150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.287283
expl/Rewards Std                              0.556485
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            11.4913
expl/Returns Std                             17.4894
expl/Returns Max                             41.6162
expl/Returns Min                              0
expl/Actions Mean                             0.365907
expl/Actions Std                              0.762886
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         11.4913
expl/env_infos/final/reward_dist Mean         0.470663
expl/env_infos/final/reward_dist Std          0.718439
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000496648
expl/env_infos/initial/reward_dist Std        0.00188886
expl/env_infos/initial/reward_dist Max        0.00910985
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.287283
expl/env_infos/reward_dist Std                0.556485
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      73200
eval/num paths total                       1830
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.473729
eval/Rewards Std                              0.649858
eval/Rewards Max                              1.57071
eval/Rewards Min                              0
eval/Returns Mean                            18.9492
eval/Returns Std                             18.9219
eval/Returns Max                             38.3301
eval/Returns Min                              0
eval/Actions Mean                             0.440321
eval/Actions Std                              0.751211
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         18.9492
eval/env_infos/final/reward_dist Mean         0.785505
eval/env_infos/final/reward_dist Std          0.784315
eval/env_infos/final/reward_dist Max          1.57071
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.473729
eval/env_infos/reward_dist Std                0.649858
eval/env_infos/reward_dist Max                1.57071
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00572912
time/evaluation sampling (s)                  3.56148
time/exploration sampling (s)                17.6783
time/logging (s)                              0.00533937
time/saving (s)                               0.00244683
time/training (s)                             5.20142
time/epoch (s)                               26.4547
time/total (s)                             4672.69
Epoch                                       182
---------------------------------------  ----------------
2023-08-05 01:39:31.017704 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 183 finished
---------------------------------------  ----------------
epoch                                       183
replay_buffer/size                       368000
trainer/QF1 Loss                              1.78173
trainer/QF2 Loss                              1.7655
trainer/Policy Loss                         -13.613
trainer/Q1 Predictions Mean                  12.1153
trainer/Q1 Predictions Std                   11.0797
trainer/Q1 Predictions Max                   33.7704
trainer/Q1 Predictions Min                  -11.3256
trainer/Q2 Predictions Mean                  12.1119
trainer/Q2 Predictions Std                   11.0752
trainer/Q2 Predictions Max                   33.4341
trainer/Q2 Predictions Min                  -10.4663
trainer/Q Targets Mean                       12.1424
trainer/Q Targets Std                        11.1761
trainer/Q Targets Max                        34.2057
trainer/Q Targets Min                       -11.461
trainer/Bellman Errors 1 Mean                 1.78173
trainer/Bellman Errors 1 Std                 12.1512
trainer/Bellman Errors 1 Max                320.678
trainer/Bellman Errors 1 Min                  3.63798e-12
trainer/Bellman Errors 2 Mean                 1.7655
trainer/Bellman Errors 2 Std                 12.6356
trainer/Bellman Errors 2 Max                349.747
trainer/Bellman Errors 2 Min                  5.5067e-08
trainer/Policy Action Mean                    0.336909
trainer/Policy Action Std                     0.791525
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     368000
expl/num paths total                       9200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.639983
expl/Rewards Std                              0.678315
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            25.5993
expl/Returns Std                             16.7392
expl/Returns Max                             39.5836
expl/Returns Min                              5.79973e-06
expl/Actions Mean                             0.428054
expl/Actions Std                              0.699332
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.5993
expl/env_infos/final/reward_dist Mean         1.09801
expl/env_infos/final/reward_dist Std          0.718814
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00055287
expl/env_infos/initial/reward_dist Std        0.00171473
expl/env_infos/initial/reward_dist Max        0.00948341
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.639983
expl/env_infos/reward_dist Std                0.678315
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      73600
eval/num paths total                       1840
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.840153
eval/Rewards Std                              0.664897
eval/Rewards Max                              1.5704
eval/Rewards Min                              0
eval/Returns Mean                            33.6061
eval/Returns Std                             11.3339
eval/Returns Max                             41.2486
eval/Returns Min                              0.0546381
eval/Actions Mean                             0.480722
eval/Actions Std                              0.686673
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         33.6061
eval/env_infos/final/reward_dist Mean         1.41137
eval/env_infos/final/reward_dist Std          0.470458
eval/env_infos/final/reward_dist Max          1.5704
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00161678
eval/env_infos/initial/reward_dist Std        0.00370251
eval/env_infos/initial/reward_dist Max        0.0121166
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.840153
eval/env_infos/reward_dist Std                0.664897
eval/env_infos/reward_dist Max                1.5704
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00604632
time/evaluation sampling (s)                  3.54273
time/exploration sampling (s)                17.491
time/logging (s)                              0.00786803
time/saving (s)                               0.00333601
time/training (s)                             5.11412
time/epoch (s)                               26.1651
time/total (s)                             4698.85
Epoch                                       183
---------------------------------------  ----------------
2023-08-05 01:39:58.136754 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 184 finished
---------------------------------------  ----------------
epoch                                       184
replay_buffer/size                       370000
trainer/QF1 Loss                              1.93908
trainer/QF2 Loss                              1.92785
trainer/Policy Loss                         -13.5537
trainer/Q1 Predictions Mean                  12.1354
trainer/Q1 Predictions Std                   11.0799
trainer/Q1 Predictions Max                   34.4775
trainer/Q1 Predictions Min                  -10.3207
trainer/Q2 Predictions Mean                  12.1066
trainer/Q2 Predictions Std                   11.0896
trainer/Q2 Predictions Max                   34.4376
trainer/Q2 Predictions Min                  -10.5874
trainer/Q Targets Mean                       12.0679
trainer/Q Targets Std                        11.1897
trainer/Q Targets Max                        35.0766
trainer/Q Targets Min                       -10.7096
trainer/Bellman Errors 1 Mean                 1.93908
trainer/Bellman Errors 1 Std                 11.9611
trainer/Bellman Errors 1 Max                289.472
trainer/Bellman Errors 1 Min                  5.41477e-08
trainer/Bellman Errors 2 Mean                 1.92785
trainer/Bellman Errors 2 Std                 12.0783
trainer/Bellman Errors 2 Max                280.949
trainer/Bellman Errors 2 Min                  2.25612e-10
trainer/Policy Action Mean                    0.32087
trainer/Policy Action Std                     0.793176
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     370000
expl/num paths total                       9250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.881631
expl/Rewards Std                              0.654545
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            35.2652
expl/Returns Std                              8.80721
expl/Returns Max                             39.0089
expl/Returns Min                              0.0521002
expl/Actions Mean                             0.450624
expl/Actions Std                              0.671384
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         35.2652
expl/env_infos/final/reward_dist Mean         1.47476
expl/env_infos/final/reward_dist Std          0.372596
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000764048
expl/env_infos/initial/reward_dist Std        0.00212564
expl/env_infos/initial/reward_dist Max        0.00816803
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.881631
expl/env_infos/reward_dist Std                0.654545
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      74000
eval/num paths total                       1850
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.948944
eval/Rewards Std                              0.631369
eval/Rewards Max                              1.57067
eval/Rewards Min                              0
eval/Returns Mean                            37.9578
eval/Returns Std                              0.904568
eval/Returns Max                             39.1655
eval/Returns Min                             36.0836
eval/Actions Mean                             0.455641
eval/Actions Std                              0.690305
eval/Actions Max                              0.999999
eval/Actions Min                             -0.999396
eval/Num Paths                               10
eval/Average Returns                         37.9578
eval/env_infos/final/reward_dist Mean         1.56815
eval/env_infos/final/reward_dist Std          0.00182025
eval/env_infos/final/reward_dist Max          1.57067
eval/env_infos/final/reward_dist Min          1.56428
eval/env_infos/initial/reward_dist Mean       0.00231803
eval/env_infos/initial/reward_dist Std        0.00460038
eval/env_infos/initial/reward_dist Max        0.0121553
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.948944
eval/env_infos/reward_dist Std                0.631369
eval/env_infos/reward_dist Max                1.57067
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00577732
time/evaluation sampling (s)                  3.49909
time/exploration sampling (s)                19.0255
time/logging (s)                              0.0074228
time/saving (s)                               0.002696
time/training (s)                             4.57295
time/epoch (s)                               27.1135
time/total (s)                             4725.97
Epoch                                       184
---------------------------------------  ----------------
2023-08-05 01:40:24.267646 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 185 finished
---------------------------------------  ----------------
epoch                                       185
replay_buffer/size                       372000
trainer/QF1 Loss                              1.99841
trainer/QF2 Loss                              2.04333
trainer/Policy Loss                         -13.7221
trainer/Q1 Predictions Mean                  12.3747
trainer/Q1 Predictions Std                   11.0327
trainer/Q1 Predictions Max                   34.7893
trainer/Q1 Predictions Min                  -11.6487
trainer/Q2 Predictions Mean                  12.4333
trainer/Q2 Predictions Std                   11.0537
trainer/Q2 Predictions Max                   35.2026
trainer/Q2 Predictions Min                  -11.4987
trainer/Q Targets Mean                       12.3806
trainer/Q Targets Std                        11.158
trainer/Q Targets Max                        35.5548
trainer/Q Targets Min                       -12.7146
trainer/Bellman Errors 1 Mean                 1.99841
trainer/Bellman Errors 1 Std                 13.15
trainer/Bellman Errors 1 Max                307.355
trainer/Bellman Errors 1 Min                  7.33562e-08
trainer/Bellman Errors 2 Mean                 2.04333
trainer/Bellman Errors 2 Std                 13.5006
trainer/Bellman Errors 2 Max                301.764
trainer/Bellman Errors 2 Min                  5.82077e-11
trainer/Policy Action Mean                    0.317291
trainer/Policy Action Std                     0.787511
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     372000
expl/num paths total                       9300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.843611
expl/Rewards Std                              0.663393
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            33.7444
expl/Returns Std                             11.1803
expl/Returns Max                             39.2957
expl/Returns Min                              2.70282e-06
expl/Actions Mean                             0.423968
expl/Actions Std                              0.683275
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         33.7444
expl/env_infos/final/reward_dist Mean         1.41152
expl/env_infos/final/reward_dist Std          0.47051
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000736872
expl/env_infos/initial/reward_dist Std        0.00176245
expl/env_infos/initial/reward_dist Max        0.00694133
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.843611
expl/env_infos/reward_dist Std                0.663393
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      74400
eval/num paths total                       1860
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.935746
eval/Rewards Std                              0.639888
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            37.4298
eval/Returns Std                              0.894026
eval/Returns Max                             38.9723
eval/Returns Min                             35.9217
eval/Actions Mean                             0.466084
eval/Actions Std                              0.664236
eval/Actions Max                              1
eval/Actions Min                             -0.998836
eval/Num Paths                               10
eval/Average Returns                         37.4298
eval/env_infos/final/reward_dist Mean         1.56986
eval/env_infos/final/reward_dist Std          0.000806811
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          1.56836
eval/env_infos/initial/reward_dist Mean       0.000509424
eval/env_infos/initial/reward_dist Std        0.00152827
eval/env_infos/initial/reward_dist Max        0.00509424
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.935746
eval/env_infos/reward_dist Std                0.639888
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589838
time/evaluation sampling (s)                  3.68069
time/exploration sampling (s)                18.0792
time/logging (s)                              0.00531432
time/saving (s)                               0.00240593
time/training (s)                             4.35025
time/epoch (s)                               26.1237
time/total (s)                             4752.1
Epoch                                       185
---------------------------------------  ----------------
2023-08-05 01:40:49.616580 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 186 finished
---------------------------------------  ----------------
epoch                                       186
replay_buffer/size                       374000
trainer/QF1 Loss                              1.80268
trainer/QF2 Loss                              1.84422
trainer/Policy Loss                         -13.2521
trainer/Q1 Predictions Mean                  11.8023
trainer/Q1 Predictions Std                   11.1115
trainer/Q1 Predictions Max                   35.309
trainer/Q1 Predictions Min                  -11.9476
trainer/Q2 Predictions Mean                  11.7957
trainer/Q2 Predictions Std                   11.1128
trainer/Q2 Predictions Max                   35.3504
trainer/Q2 Predictions Min                  -12.1196
trainer/Q Targets Mean                       11.8622
trainer/Q Targets Std                        11.2235
trainer/Q Targets Max                        36.9365
trainer/Q Targets Min                       -12.3576
trainer/Bellman Errors 1 Mean                 1.80268
trainer/Bellman Errors 1 Std                 10.9141
trainer/Bellman Errors 1 Max                243.414
trainer/Bellman Errors 1 Min                  1.78261e-08
trainer/Bellman Errors 2 Mean                 1.84422
trainer/Bellman Errors 2 Std                 11.1224
trainer/Bellman Errors 2 Max                251.664
trainer/Bellman Errors 2 Min                  1.14087e-08
trainer/Policy Action Mean                    0.317163
trainer/Policy Action Std                     0.784645
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     374000
expl/num paths total                       9350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.718301
expl/Rewards Std                              0.68098
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            28.732
expl/Returns Std                             15.989
expl/Returns Max                             40.3313
expl/Returns Min                              0
expl/Actions Mean                             0.382316
expl/Actions Std                              0.715698
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         28.732
expl/env_infos/final/reward_dist Mean         1.19269
expl/env_infos/final/reward_dist Std          0.66915
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000281413
expl/env_infos/initial/reward_dist Std        0.00117239
expl/env_infos/initial/reward_dist Max        0.00708573
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.718301
expl/env_infos/reward_dist Std                0.68098
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      74800
eval/num paths total                       1870
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.95725
eval/Rewards Std                              0.6304
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            38.29
eval/Returns Std                              1.2289
eval/Returns Max                             40.2457
eval/Returns Min                             36.6878
eval/Actions Mean                             0.463239
eval/Actions Std                              0.678818
eval/Actions Max                              1
eval/Actions Min                             -0.999742
eval/Num Paths                               10
eval/Average Returns                         38.29
eval/env_infos/final/reward_dist Mean         1.5695
eval/env_infos/final/reward_dist Std          0.00105539
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          1.56794
eval/env_infos/initial/reward_dist Mean       0.00105807
eval/env_infos/initial/reward_dist Std        0.00259106
eval/env_infos/initial/reward_dist Max        0.00868129
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.95725
eval/env_infos/reward_dist Std                0.6304
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00564964
time/evaluation sampling (s)                  3.59843
time/exploration sampling (s)                17.3382
time/logging (s)                              0.00534434
time/saving (s)                               0.00238449
time/training (s)                             4.39606
time/epoch (s)                               25.3461
time/total (s)                             4777.45
Epoch                                       186
---------------------------------------  ----------------
2023-08-05 01:41:16.254122 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 187 finished
---------------------------------------  ----------------
epoch                                       187
replay_buffer/size                       376000
trainer/QF1 Loss                              2.08173
trainer/QF2 Loss                              2.11217
trainer/Policy Loss                         -13.3422
trainer/Q1 Predictions Mean                  11.8658
trainer/Q1 Predictions Std                   11.0188
trainer/Q1 Predictions Max                   35.6957
trainer/Q1 Predictions Min                  -15.023
trainer/Q2 Predictions Mean                  11.8601
trainer/Q2 Predictions Std                   11.0162
trainer/Q2 Predictions Max                   35.1158
trainer/Q2 Predictions Min                  -12.7614
trainer/Q Targets Mean                       11.8967
trainer/Q Targets Std                        11.1742
trainer/Q Targets Max                        36.3428
trainer/Q Targets Min                       -12.0064
trainer/Bellman Errors 1 Mean                 2.08173
trainer/Bellman Errors 1 Std                 11.382
trainer/Bellman Errors 1 Max                242.165
trainer/Bellman Errors 1 Min                  3.63798e-10
trainer/Bellman Errors 2 Mean                 2.11217
trainer/Bellman Errors 2 Std                 11.9081
trainer/Bellman Errors 2 Max                249.598
trainer/Bellman Errors 2 Min                  4.03715e-09
trainer/Policy Action Mean                    0.312131
trainer/Policy Action Std                     0.783606
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     376000
expl/num paths total                       9400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.785525
expl/Rewards Std                              0.673088
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            31.421
expl/Returns Std                             14.5083
expl/Returns Max                             40.8414
expl/Returns Min                              0.00487637
expl/Actions Mean                             0.419322
expl/Actions Std                              0.696026
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.421
expl/env_infos/final/reward_dist Mean         1.28604
expl/env_infos/final/reward_dist Std          0.602541
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00177548
expl/env_infos/initial/reward_dist Std        0.00342974
expl/env_infos/initial/reward_dist Max        0.0123317
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.785525
expl/env_infos/reward_dist Std                0.673088
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      75200
eval/num paths total                       1880
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.657603
eval/Rewards Std                              0.682291
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            26.3041
eval/Returns Std                             17.1887
eval/Returns Max                             39.1094
eval/Returns Min                              0
eval/Actions Mean                             0.370797
eval/Actions Std                              0.724742
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.3041
eval/env_infos/final/reward_dist Mean         1.09867
eval/env_infos/final/reward_dist Std          0.719246
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.657603
eval/env_infos/reward_dist Std                0.682291
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589134
time/evaluation sampling (s)                  3.79364
time/exploration sampling (s)                17.6749
time/logging (s)                              0.0074465
time/saving (s)                               0.00269449
time/training (s)                             5.15194
time/epoch (s)                               26.6365
time/total (s)                             4804.08
Epoch                                       187
---------------------------------------  ----------------
2023-08-05 01:41:42.578266 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 188 finished
---------------------------------------  ----------------
epoch                                       188
replay_buffer/size                       378000
trainer/QF1 Loss                              2.05986
trainer/QF2 Loss                              2.07148
trainer/Policy Loss                         -13.6727
trainer/Q1 Predictions Mean                  12.0982
trainer/Q1 Predictions Std                   11.1642
trainer/Q1 Predictions Max                   35.6468
trainer/Q1 Predictions Min                  -11.3511
trainer/Q2 Predictions Mean                  12.1122
trainer/Q2 Predictions Std                   11.149
trainer/Q2 Predictions Max                   35.5345
trainer/Q2 Predictions Min                  -11.8003
trainer/Q Targets Mean                       12.1002
trainer/Q Targets Std                        11.3018
trainer/Q Targets Max                        36.7917
trainer/Q Targets Min                       -10.5464
trainer/Bellman Errors 1 Mean                 2.05986
trainer/Bellman Errors 1 Std                 13.7948
trainer/Bellman Errors 1 Max                365.645
trainer/Bellman Errors 1 Min                  4.98039e-09
trainer/Bellman Errors 2 Mean                 2.07148
trainer/Bellman Errors 2 Std                 13.8797
trainer/Bellman Errors 2 Max                359.92
trainer/Bellman Errors 2 Min                  1.65755e-10
trainer/Policy Action Mean                    0.307956
trainer/Policy Action Std                     0.782125
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     378000
expl/num paths total                       9450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.699857
expl/Rewards Std                              0.665222
expl/Rewards Max                              1.57069
expl/Rewards Min                              0
expl/Returns Mean                            27.9943
expl/Returns Std                             15.5268
expl/Returns Max                             39.6247
expl/Returns Min                              0
expl/Actions Mean                             0.348012
expl/Actions Std                              0.727254
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         27.9943
expl/env_infos/final/reward_dist Mean         1.19234
expl/env_infos/final/reward_dist Std          0.669435
expl/env_infos/final/reward_dist Max          1.57069
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000659352
expl/env_infos/initial/reward_dist Std        0.00220538
expl/env_infos/initial/reward_dist Max        0.0140499
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.699857
expl/env_infos/reward_dist Std                0.665222
expl/env_infos/reward_dist Max                1.57069
expl/env_infos/reward_dist Min                0
eval/num steps total                      75600
eval/num paths total                       1890
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.849399
eval/Rewards Std                              0.645873
eval/Rewards Max                              1.57067
eval/Rewards Min                              0
eval/Returns Mean                            33.976
eval/Returns Std                             11.0567
eval/Returns Max                             39.6209
eval/Returns Min                              1.07688
eval/Actions Mean                             0.412557
eval/Actions Std                              0.704508
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         33.976
eval/env_infos/final/reward_dist Mean         1.41183
eval/env_infos/final/reward_dist Std          0.470613
eval/env_infos/final/reward_dist Max          1.57067
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00231622
eval/env_infos/initial/reward_dist Std        0.00360227
eval/env_infos/initial/reward_dist Max        0.0101409
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.849399
eval/env_infos/reward_dist Std                0.645873
eval/env_infos/reward_dist Max                1.57067
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588673
time/evaluation sampling (s)                  3.92812
time/exploration sampling (s)                17.8929
time/logging (s)                              0.00743911
time/saving (s)                               0.00275778
time/training (s)                             4.48203
time/epoch (s)                               26.3191
time/total (s)                             4830.41
Epoch                                       188
---------------------------------------  ----------------
2023-08-05 01:42:08.661368 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 189 finished
---------------------------------------  ----------------
epoch                                       189
replay_buffer/size                       380000
trainer/QF1 Loss                              2.59241
trainer/QF2 Loss                              2.63593
trainer/Policy Loss                         -13.4359
trainer/Q1 Predictions Mean                  11.6396
trainer/Q1 Predictions Std                   11.0789
trainer/Q1 Predictions Max                   35.5885
trainer/Q1 Predictions Min                  -13.1096
trainer/Q2 Predictions Mean                  11.6135
trainer/Q2 Predictions Std                   11.0498
trainer/Q2 Predictions Max                   35.4427
trainer/Q2 Predictions Min                  -12.9735
trainer/Q Targets Mean                       11.6042
trainer/Q Targets Std                        11.1996
trainer/Q Targets Max                        36.1742
trainer/Q Targets Min                       -14.3843
trainer/Bellman Errors 1 Mean                 2.59241
trainer/Bellman Errors 1 Std                 15.2358
trainer/Bellman Errors 1 Max                332.014
trainer/Bellman Errors 1 Min                  2.80147e-09
trainer/Bellman Errors 2 Mean                 2.63593
trainer/Bellman Errors 2 Std                 15.3637
trainer/Bellman Errors 2 Max                320.375
trainer/Bellman Errors 2 Min                  4.78053e-09
trainer/Policy Action Mean                    0.28781
trainer/Policy Action Std                     0.796778
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     380000
expl/num paths total                       9500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.502511
expl/Rewards Std                              0.576916
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            20.1004
expl/Returns Std                             14.3063
expl/Returns Max                             34.1438
expl/Returns Min                              0
expl/Actions Mean                             0.267084
expl/Actions Std                              0.755846
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         20.1004
expl/env_infos/final/reward_dist Mean         1.03505
expl/env_infos/final/reward_dist Std          0.74287
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000478529
expl/env_infos/initial/reward_dist Std        0.0016995
expl/env_infos/initial/reward_dist Max        0.0075409
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.502511
expl/env_infos/reward_dist Std                0.576916
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      76000
eval/num paths total                       1900
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.623341
eval/Rewards Std                              0.590371
eval/Rewards Max                              1.5708
eval/Rewards Min                              0
eval/Returns Mean                            24.9336
eval/Returns Std                             12.3126
eval/Returns Max                             32.7106
eval/Returns Min                              0.0091722
eval/Actions Mean                             0.350134
eval/Actions Std                              0.739837
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.9336
eval/env_infos/final/reward_dist Mean         1.25506
eval/env_infos/final/reward_dist Std          0.627535
eval/env_infos/final/reward_dist Max          1.5708
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000904305
eval/env_infos/initial/reward_dist Std        0.00271292
eval/env_infos/initial/reward_dist Max        0.00904305
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.623341
eval/env_infos/reward_dist Std                0.590371
eval/env_infos/reward_dist Max                1.5708
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00570316
time/evaluation sampling (s)                  4.07766
time/exploration sampling (s)                17.7145
time/logging (s)                              0.00534773
time/saving (s)                               0.00235273
time/training (s)                             4.27044
time/epoch (s)                               26.076
time/total (s)                             4856.49
Epoch                                       189
---------------------------------------  ----------------
2023-08-05 01:42:35.319939 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 190 finished
---------------------------------------  ----------------
epoch                                       190
replay_buffer/size                       382000
trainer/QF1 Loss                              1.93869
trainer/QF2 Loss                              1.95099
trainer/Policy Loss                         -12.949
trainer/Q1 Predictions Mean                  11.4676
trainer/Q1 Predictions Std                   10.978
trainer/Q1 Predictions Max                   34.8144
trainer/Q1 Predictions Min                  -15.0355
trainer/Q2 Predictions Mean                  11.4546
trainer/Q2 Predictions Std                   10.9755
trainer/Q2 Predictions Max                   34.5961
trainer/Q2 Predictions Min                  -13.4304
trainer/Q Targets Mean                       11.4063
trainer/Q Targets Std                        11.1002
trainer/Q Targets Max                        35.5407
trainer/Q Targets Min                       -14.1229
trainer/Bellman Errors 1 Mean                 1.93869
trainer/Bellman Errors 1 Std                 12.1363
trainer/Bellman Errors 1 Max                263.272
trainer/Bellman Errors 1 Min                  1.75092e-08
trainer/Bellman Errors 2 Mean                 1.95099
trainer/Bellman Errors 2 Std                 12.1797
trainer/Bellman Errors 2 Max                278.001
trainer/Bellman Errors 2 Min                  7.69796e-09
trainer/Policy Action Mean                    0.296534
trainer/Policy Action Std                     0.797919
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     382000
expl/num paths total                       9550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.619531
expl/Rewards Std                              0.579737
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            24.7813
expl/Returns Std                             11.5509
expl/Returns Max                             34.2142
expl/Returns Min                              0
expl/Actions Mean                             0.337436
expl/Actions Std                              0.741328
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.7813
expl/env_infos/final/reward_dist Mean         1.28656
expl/env_infos/final/reward_dist Std          0.602785
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000873247
expl/env_infos/initial/reward_dist Std        0.00236586
expl/env_infos/initial/reward_dist Max        0.0108408
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.619531
expl/env_infos/reward_dist Std                0.579737
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      76400
eval/num paths total                       1910
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.742694
eval/Rewards Std                              0.555427
eval/Rewards Max                              1.57066
eval/Rewards Min                              0
eval/Returns Mean                            29.7077
eval/Returns Std                              1.03681
eval/Returns Max                             31.4363
eval/Returns Min                             28.4734
eval/Actions Mean                             0.360913
eval/Actions Std                              0.745719
eval/Actions Max                              1
eval/Actions Min                             -0.99934
eval/Num Paths                               10
eval/Average Returns                         29.7077
eval/env_infos/final/reward_dist Mean         1.56861
eval/env_infos/final/reward_dist Std          0.00262953
eval/env_infos/final/reward_dist Max          1.57066
eval/env_infos/final/reward_dist Min          1.5631
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.742694
eval/env_infos/reward_dist Std                0.555427
eval/env_infos/reward_dist Max                1.57066
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0058887
time/evaluation sampling (s)                  4.32344
time/exploration sampling (s)                17.7671
time/logging (s)                              0.00732043
time/saving (s)                               0.00331506
time/training (s)                             4.55058
time/epoch (s)                               26.6576
time/total (s)                             4883.15
Epoch                                       190
---------------------------------------  ----------------
2023-08-05 01:43:02.135080 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 191 finished
---------------------------------------  ----------------
epoch                                       191
replay_buffer/size                       384000
trainer/QF1 Loss                              2.07646
trainer/QF2 Loss                              2.0904
trainer/Policy Loss                         -12.4515
trainer/Q1 Predictions Mean                  10.9407
trainer/Q1 Predictions Std                   10.8444
trainer/Q1 Predictions Max                   33.7541
trainer/Q1 Predictions Min                  -13.1029
trainer/Q2 Predictions Mean                  10.9443
trainer/Q2 Predictions Std                   10.8381
trainer/Q2 Predictions Max                   33.8248
trainer/Q2 Predictions Min                  -12.9151
trainer/Q Targets Mean                       11.0189
trainer/Q Targets Std                        11.0268
trainer/Q Targets Max                        35.0082
trainer/Q Targets Min                       -12.539
trainer/Bellman Errors 1 Mean                 2.07646
trainer/Bellman Errors 1 Std                 14.3762
trainer/Bellman Errors 1 Max                322.681
trainer/Bellman Errors 1 Min                  3.27418e-09
trainer/Bellman Errors 2 Mean                 2.0904
trainer/Bellman Errors 2 Std                 14.629
trainer/Bellman Errors 2 Max                332.736
trainer/Bellman Errors 2 Min                  1.66678e-08
trainer/Policy Action Mean                    0.309142
trainer/Policy Action Std                     0.778034
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     384000
expl/num paths total                       9600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.662366
expl/Rewards Std                              0.598044
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            26.4947
expl/Returns Std                             11.5005
expl/Returns Max                             35.3828
expl/Returns Min                              0.0390161
expl/Actions Mean                             0.360437
expl/Actions Std                              0.706556
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.4947
expl/env_infos/final/reward_dist Mean         1.31752
expl/env_infos/final/reward_dist Std          0.574949
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00109952
expl/env_infos/initial/reward_dist Std        0.0029259
expl/env_infos/initial/reward_dist Max        0.0134361
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.662366
expl/env_infos/reward_dist Std                0.598044
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      76800
eval/num paths total                       1920
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.399643
eval/Rewards Std                              0.568445
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            15.9857
eval/Returns Std                             15.7052
eval/Returns Max                             33.7581
eval/Returns Min                              0.00743352
eval/Actions Mean                             0.335187
eval/Actions Std                              0.766216
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         15.9857
eval/env_infos/final/reward_dist Mean         0.784571
eval/env_infos/final/reward_dist Std          0.784571
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.399643
eval/env_infos/reward_dist Std                0.568445
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00575085
time/evaluation sampling (s)                  4.77834
time/exploration sampling (s)                17.5316
time/logging (s)                              0.00563795
time/saving (s)                               0.0144068
time/training (s)                             4.47294
time/epoch (s)                               26.8087
time/total (s)                             4909.96
Epoch                                       191
---------------------------------------  ----------------
2023-08-05 01:43:28.285708 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 192 finished
---------------------------------------  ----------------
epoch                                       192
replay_buffer/size                       386000
trainer/QF1 Loss                              1.81964
trainer/QF2 Loss                              1.87411
trainer/Policy Loss                         -12.5797
trainer/Q1 Predictions Mean                  11.1238
trainer/Q1 Predictions Std                   11.0578
trainer/Q1 Predictions Max                   33.5836
trainer/Q1 Predictions Min                  -13.6838
trainer/Q2 Predictions Mean                  11.1063
trainer/Q2 Predictions Std                   11.0597
trainer/Q2 Predictions Max                   34.0376
trainer/Q2 Predictions Min                  -13.4161
trainer/Q Targets Mean                       11.1099
trainer/Q Targets Std                        11.2019
trainer/Q Targets Max                        34.4316
trainer/Q Targets Min                       -13.0467
trainer/Bellman Errors 1 Mean                 1.81964
trainer/Bellman Errors 1 Std                 11.6602
trainer/Bellman Errors 1 Max                277.274
trainer/Bellman Errors 1 Min                  7.53153e-09
trainer/Bellman Errors 2 Mean                 1.87411
trainer/Bellman Errors 2 Std                 11.977
trainer/Bellman Errors 2 Max                260.669
trainer/Bellman Errors 2 Min                  2.98783e-08
trainer/Policy Action Mean                    0.320944
trainer/Policy Action Std                     0.775843
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     386000
expl/num paths total                       9650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.670004
expl/Rewards Std                              0.618235
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            26.8001
expl/Returns Std                             12.4588
expl/Returns Max                             35.2745
expl/Returns Min                              0
expl/Actions Mean                             0.348415
expl/Actions Std                              0.717435
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.8001
expl/env_infos/final/reward_dist Mean         1.28623
expl/env_infos/final/reward_dist Std          0.602629
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000813013
expl/env_infos/initial/reward_dist Std        0.00161043
expl/env_infos/initial/reward_dist Max        0.00557415
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.670004
expl/env_infos/reward_dist Std                0.618235
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      77200
eval/num paths total                       1930
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.841435
eval/Rewards Std                              0.594494
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            33.6574
eval/Returns Std                              1.0722
eval/Returns Max                             35.0444
eval/Returns Min                             31.9576
eval/Actions Mean                             0.411069
eval/Actions Std                              0.698731
eval/Actions Max                              1
eval/Actions Min                             -0.999698
eval/Num Paths                               10
eval/Average Returns                         33.6574
eval/env_infos/final/reward_dist Mean         1.569
eval/env_infos/final/reward_dist Std          0.00119814
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          1.56684
eval/env_infos/initial/reward_dist Mean       0.00100661
eval/env_infos/initial/reward_dist Std        0.00200116
eval/env_infos/initial/reward_dist Max        0.00512554
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.841435
eval/env_infos/reward_dist Std                0.594494
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585343
time/evaluation sampling (s)                  4.10639
time/exploration sampling (s)                17.4189
time/logging (s)                              0.00548538
time/saving (s)                               0.00235462
time/training (s)                             4.6046
time/epoch (s)                               26.1436
time/total (s)                             4936.11
Epoch                                       192
---------------------------------------  ----------------
2023-08-05 01:43:54.014283 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 193 finished
---------------------------------------  ----------------
epoch                                       193
replay_buffer/size                       388000
trainer/QF1 Loss                              1.69194
trainer/QF2 Loss                              1.63458
trainer/Policy Loss                         -13.3465
trainer/Q1 Predictions Mean                  11.7961
trainer/Q1 Predictions Std                   11.4085
trainer/Q1 Predictions Max                   34.3526
trainer/Q1 Predictions Min                  -23.9969
trainer/Q2 Predictions Mean                  11.829
trainer/Q2 Predictions Std                   11.4102
trainer/Q2 Predictions Max                   34.529
trainer/Q2 Predictions Min                  -25.9659
trainer/Q Targets Mean                       11.8252
trainer/Q Targets Std                        11.5128
trainer/Q Targets Max                        36.3191
trainer/Q Targets Min                       -26.2877
trainer/Bellman Errors 1 Mean                 1.69194
trainer/Bellman Errors 1 Std                 11.7837
trainer/Bellman Errors 1 Max                288.963
trainer/Bellman Errors 1 Min                  1.62927e-07
trainer/Bellman Errors 2 Mean                 1.63458
trainer/Bellman Errors 2 Std                 11.8815
trainer/Bellman Errors 2 Max                295.882
trainer/Bellman Errors 2 Min                  3.27418e-11
trainer/Policy Action Mean                    0.37859
trainer/Policy Action Std                     0.762722
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     388000
expl/num paths total                       9700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.816387
expl/Rewards Std                              0.677535
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            32.6555
expl/Returns Std                             13.1543
expl/Returns Max                             41.0368
expl/Returns Min                              0
expl/Actions Mean                             0.438439
expl/Actions Std                              0.684394
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.6555
expl/env_infos/final/reward_dist Mean         1.34893
expl/env_infos/final/reward_dist Std          0.543677
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00057808
expl/env_infos/initial/reward_dist Std        0.00185344
expl/env_infos/initial/reward_dist Max        0.00985997
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.816387
expl/env_infos/reward_dist Std                0.677535
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      77600
eval/num paths total                       1940
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.939397
eval/Rewards Std                              0.647289
eval/Rewards Max                              1.57036
eval/Rewards Min                              0
eval/Returns Mean                            37.5759
eval/Returns Std                              1.33955
eval/Returns Max                             40.4761
eval/Returns Min                             35.6032
eval/Actions Mean                             0.485759
eval/Actions Std                              0.668037
eval/Actions Max                              1
eval/Actions Min                             -0.999781
eval/Num Paths                               10
eval/Average Returns                         37.5759
eval/env_infos/final/reward_dist Mean         1.56917
eval/env_infos/final/reward_dist Std          0.00111859
eval/env_infos/final/reward_dist Max          1.57036
eval/env_infos/final/reward_dist Min          1.56628
eval/env_infos/initial/reward_dist Mean       0.000263577
eval/env_infos/initial/reward_dist Std        0.000790731
eval/env_infos/initial/reward_dist Max        0.00263577
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.939397
eval/env_infos/reward_dist Std                0.647289
eval/env_infos/reward_dist Max                1.57036
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00592268
time/evaluation sampling (s)                  3.59199
time/exploration sampling (s)                17.4858
time/logging (s)                              0.00537196
time/saving (s)                               0.00232999
time/training (s)                             4.63089
time/epoch (s)                               25.7223
time/total (s)                             4961.83
Epoch                                       193
---------------------------------------  ----------------
2023-08-05 01:44:19.963365 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 194 finished
---------------------------------------  ----------------
epoch                                       194
replay_buffer/size                       390000
trainer/QF1 Loss                              1.85633
trainer/QF2 Loss                              1.88065
trainer/Policy Loss                         -13.3545
trainer/Q1 Predictions Mean                  11.7866
trainer/Q1 Predictions Std                   11.7253
trainer/Q1 Predictions Max                   35.2213
trainer/Q1 Predictions Min                  -13.7896
trainer/Q2 Predictions Mean                  11.7778
trainer/Q2 Predictions Std                   11.7272
trainer/Q2 Predictions Max                   35.3881
trainer/Q2 Predictions Min                  -13.3074
trainer/Q Targets Mean                       11.8385
trainer/Q Targets Std                        11.8559
trainer/Q Targets Max                        37.7355
trainer/Q Targets Min                       -13.3777
trainer/Bellman Errors 1 Mean                 1.85633
trainer/Bellman Errors 1 Std                 12.5102
trainer/Bellman Errors 1 Max                327.911
trainer/Bellman Errors 1 Min                  2.32831e-08
trainer/Bellman Errors 2 Mean                 1.88065
trainer/Bellman Errors 2 Std                 12.6527
trainer/Bellman Errors 2 Max                326.012
trainer/Bellman Errors 2 Min                  1.65755e-10
trainer/Policy Action Mean                    0.304658
trainer/Policy Action Std                     0.797103
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     390000
expl/num paths total                       9750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.363138
expl/Rewards Std                              0.599612
expl/Rewards Max                              1.57068
expl/Rewards Min                              0
expl/Returns Mean                            14.5255
expl/Returns Std                             17.8299
expl/Returns Max                             39.3721
expl/Returns Min                              0
expl/Actions Mean                             0.237639
expl/Actions Std                              0.778808
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         14.5255
expl/env_infos/final/reward_dist Mean         0.630569
expl/env_infos/final/reward_dist Std          0.75839
expl/env_infos/final/reward_dist Max          1.57068
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       4.70907e-05
expl/env_infos/initial/reward_dist Std        0.000329635
expl/env_infos/initial/reward_dist Max        0.00235453
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.363138
expl/env_infos/reward_dist Std                0.599612
expl/env_infos/reward_dist Max                1.57068
expl/env_infos/reward_dist Min                0
eval/num steps total                      78000
eval/num paths total                       1950
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.282339
eval/Rewards Std                              0.554526
eval/Rewards Max                              1.57018
eval/Rewards Min                              0
eval/Returns Mean                            11.2936
eval/Returns Std                             17.0895
eval/Returns Max                             38.0916
eval/Returns Min                              0
eval/Actions Mean                             0.216368
eval/Actions Std                              0.803165
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         11.2936
eval/env_infos/final/reward_dist Mean         0.470265
eval/env_infos/final/reward_dist Std          0.718185
eval/env_infos/final/reward_dist Max          1.57018
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.282339
eval/env_infos/reward_dist Std                0.554526
eval/env_infos/reward_dist Max                1.57018
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00581115
time/evaluation sampling (s)                  3.98804
time/exploration sampling (s)                17.4259
time/logging (s)                              0.00542853
time/saving (s)                               0.00231395
time/training (s)                             4.51831
time/epoch (s)                               25.9458
time/total (s)                             4987.78
Epoch                                       194
---------------------------------------  ----------------
2023-08-05 01:44:45.301209 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 195 finished
---------------------------------------  ----------------
epoch                                       195
replay_buffer/size                       392000
trainer/QF1 Loss                              1.8789
trainer/QF2 Loss                              1.87541
trainer/Policy Loss                         -13.8033
trainer/Q1 Predictions Mean                  12.3669
trainer/Q1 Predictions Std                   12.3078
trainer/Q1 Predictions Max                   36.5839
trainer/Q1 Predictions Min                  -13.5076
trainer/Q2 Predictions Mean                  12.3649
trainer/Q2 Predictions Std                   12.2892
trainer/Q2 Predictions Max                   36.9093
trainer/Q2 Predictions Min                  -12.9564
trainer/Q Targets Mean                       12.3273
trainer/Q Targets Std                        12.3532
trainer/Q Targets Max                        38.0131
trainer/Q Targets Min                       -12.3171
trainer/Bellman Errors 1 Mean                 1.8789
trainer/Bellman Errors 1 Std                 12.2915
trainer/Bellman Errors 1 Max                361.797
trainer/Bellman Errors 1 Min                  2.75359e-08
trainer/Bellman Errors 2 Mean                 1.87541
trainer/Bellman Errors 2 Std                 12.3599
trainer/Bellman Errors 2 Max                368.061
trainer/Bellman Errors 2 Min                  4.00133e-08
trainer/Policy Action Mean                    0.351086
trainer/Policy Action Std                     0.784157
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     392000
expl/num paths total                       9800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.808483
expl/Rewards Std                              0.679425
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            32.3393
expl/Returns Std                             14.0188
expl/Returns Max                             41.2956
expl/Returns Min                              0.0118546
expl/Actions Mean                             0.395549
expl/Actions Std                              0.730714
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.3393
expl/env_infos/final/reward_dist Mean         1.3177
expl/env_infos/final/reward_dist Std          0.575097
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00101987
expl/env_infos/initial/reward_dist Std        0.00257024
expl/env_infos/initial/reward_dist Max        0.010012
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.808483
expl/env_infos/reward_dist Std                0.679425
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      78400
eval/num paths total                       1960
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.967839
eval/Rewards Std                              0.638508
eval/Rewards Max                              1.57054
eval/Rewards Min                              0
eval/Returns Mean                            38.7136
eval/Returns Std                              1.42638
eval/Returns Max                             41.6138
eval/Returns Min                             36.9779
eval/Actions Mean                             0.424924
eval/Actions Std                              0.730613
eval/Actions Max                              1
eval/Actions Min                             -0.999976
eval/Num Paths                               10
eval/Average Returns                         38.7136
eval/env_infos/final/reward_dist Mean         1.56986
eval/env_infos/final/reward_dist Std          0.000583745
eval/env_infos/final/reward_dist Max          1.57054
eval/env_infos/final/reward_dist Min          1.56868
eval/env_infos/initial/reward_dist Mean       0.0015209
eval/env_infos/initial/reward_dist Std        0.00320718
eval/env_infos/initial/reward_dist Max        0.0100033
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.967839
eval/env_infos/reward_dist Std                0.638508
eval/env_infos/reward_dist Max                1.57054
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00569051
time/evaluation sampling (s)                  3.57766
time/exploration sampling (s)                17.1896
time/logging (s)                              0.0055009
time/saving (s)                               0.00232138
time/training (s)                             4.55266
time/epoch (s)                               25.3335
time/total (s)                             5013.12
Epoch                                       195
---------------------------------------  ----------------
2023-08-05 01:45:10.912220 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 196 finished
---------------------------------------  ----------------
epoch                                       196
replay_buffer/size                       394000
trainer/QF1 Loss                              1.88964
trainer/QF2 Loss                              1.90595
trainer/Policy Loss                         -13.9084
trainer/Q1 Predictions Mean                  12.6105
trainer/Q1 Predictions Std                   12.6462
trainer/Q1 Predictions Max                   38.8381
trainer/Q1 Predictions Min                  -12.1007
trainer/Q2 Predictions Mean                  12.6294
trainer/Q2 Predictions Std                   12.6569
trainer/Q2 Predictions Max                   39.2953
trainer/Q2 Predictions Min                  -12.0793
trainer/Q Targets Mean                       12.4711
trainer/Q Targets Std                        12.6471
trainer/Q Targets Max                        39.6943
trainer/Q Targets Min                       -12.5568
trainer/Bellman Errors 1 Mean                 1.88964
trainer/Bellman Errors 1 Std                 13.3199
trainer/Bellman Errors 1 Max                468.89
trainer/Bellman Errors 1 Min                  3.90196e-09
trainer/Bellman Errors 2 Mean                 1.90595
trainer/Bellman Errors 2 Std                 13.1445
trainer/Bellman Errors 2 Max                427.058
trainer/Bellman Errors 2 Min                  1.30967e-10
trainer/Policy Action Mean                    0.361512
trainer/Policy Action Std                     0.789814
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     394000
expl/num paths total                       9850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.961091
expl/Rewards Std                              0.63823
expl/Rewards Max                              1.57069
expl/Rewards Min                              0
expl/Returns Mean                            38.4436
expl/Returns Std                              5.54706
expl/Returns Max                             41.8107
expl/Returns Min                              0.992363
expl/Actions Mean                             0.429978
expl/Actions Std                              0.726345
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         38.4436
expl/env_infos/final/reward_dist Mean         1.53703
expl/env_infos/final/reward_dist Std          0.219583
expl/env_infos/final/reward_dist Max          1.57069
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00123117
expl/env_infos/initial/reward_dist Std        0.00262014
expl/env_infos/initial/reward_dist Max        0.0114755
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.961091
expl/env_infos/reward_dist Std                0.63823
expl/env_infos/reward_dist Max                1.57069
expl/env_infos/reward_dist Min                0
eval/num steps total                      78800
eval/num paths total                       1970
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.987833
eval/Rewards Std                              0.631363
eval/Rewards Max                              1.57045
eval/Rewards Min                              0
eval/Returns Mean                            39.5133
eval/Returns Std                              1.32115
eval/Returns Max                             41.7055
eval/Returns Min                             37.3499
eval/Actions Mean                             0.445047
eval/Actions Std                              0.740099
eval/Actions Max                              1
eval/Actions Min                             -0.999801
eval/Num Paths                               10
eval/Average Returns                         39.5133
eval/env_infos/final/reward_dist Mean         1.56809
eval/env_infos/final/reward_dist Std          0.00553737
eval/env_infos/final/reward_dist Max          1.57045
eval/env_infos/final/reward_dist Min          1.55154
eval/env_infos/initial/reward_dist Mean       0.000820299
eval/env_infos/initial/reward_dist Std        0.00200772
eval/env_infos/initial/reward_dist Max        0.00668933
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.987833
eval/env_infos/reward_dist Std                0.631363
eval/env_infos/reward_dist Max                1.57045
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588043
time/evaluation sampling (s)                  3.53949
time/exploration sampling (s)                17.4326
time/logging (s)                              0.00392515
time/saving (s)                               0.00184299
time/training (s)                             4.62238
time/epoch (s)                               25.6061
time/total (s)                             5038.73
Epoch                                       196
---------------------------------------  ----------------
2023-08-05 01:45:36.226902 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 197 finished
---------------------------------------  ----------------
epoch                                       197
replay_buffer/size                       396000
trainer/QF1 Loss                              1.65138
trainer/QF2 Loss                              1.59663
trainer/Policy Loss                         -13.8794
trainer/Q1 Predictions Mean                  12.6967
trainer/Q1 Predictions Std                   12.7604
trainer/Q1 Predictions Max                   40.5336
trainer/Q1 Predictions Min                  -12.8956
trainer/Q2 Predictions Mean                  12.7246
trainer/Q2 Predictions Std                   12.7735
trainer/Q2 Predictions Max                   40.8224
trainer/Q2 Predictions Min                  -12.592
trainer/Q Targets Mean                       12.6904
trainer/Q Targets Std                        12.8141
trainer/Q Targets Max                        41.8276
trainer/Q Targets Min                       -13.5916
trainer/Bellman Errors 1 Mean                 1.65138
trainer/Bellman Errors 1 Std                 11.3825
trainer/Bellman Errors 1 Max                362.869
trainer/Bellman Errors 1 Min                  5.64029e-09
trainer/Bellman Errors 2 Mean                 1.59663
trainer/Bellman Errors 2 Std                 10.6573
trainer/Bellman Errors 2 Max                215.218
trainer/Bellman Errors 2 Min                  3.89709e-08
trainer/Policy Action Mean                    0.361752
trainer/Policy Action Std                     0.791509
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     396000
expl/num paths total                       9900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.946539
expl/Rewards Std                              0.646137
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            37.8616
expl/Returns Std                              7.69815
expl/Returns Max                             42.1431
expl/Returns Min                              0.599508
expl/Actions Mean                             0.431962
expl/Actions Std                              0.737667
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         37.8616
expl/env_infos/final/reward_dist Mean         1.50623
expl/env_infos/final/reward_dist Std          0.307461
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000905357
expl/env_infos/initial/reward_dist Std        0.0024028
expl/env_infos/initial/reward_dist Max        0.0112556
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.946539
expl/env_infos/reward_dist Std                0.646137
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      79200
eval/num paths total                       1980
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.881029
eval/Rewards Std                              0.668768
eval/Rewards Max                              1.5707
eval/Rewards Min                              0
eval/Returns Mean                            35.2412
eval/Returns Std                             11.4841
eval/Returns Max                             41.612
eval/Returns Min                              0.981096
eval/Actions Mean                             0.440608
eval/Actions Std                              0.744431
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.2412
eval/env_infos/final/reward_dist Mean         1.41183
eval/env_infos/final/reward_dist Std          0.470613
eval/env_infos/final/reward_dist Max          1.5707
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00124869
eval/env_infos/initial/reward_dist Std        0.00374608
eval/env_infos/initial/reward_dist Max        0.0124869
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.881029
eval/env_infos/reward_dist Std                0.668768
eval/env_infos/reward_dist Max                1.5707
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00809766
time/evaluation sampling (s)                  3.44147
time/exploration sampling (s)                17.1357
time/logging (s)                              0.00799879
time/saving (s)                               0.0032816
time/training (s)                             4.71921
time/epoch (s)                               25.3158
time/total (s)                             5064.04
Epoch                                       197
---------------------------------------  ----------------
2023-08-05 01:46:01.233221 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 198 finished
---------------------------------------  ----------------
epoch                                       198
replay_buffer/size                       398000
trainer/QF1 Loss                              1.94511
trainer/QF2 Loss                              1.89405
trainer/Policy Loss                         -14.6032
trainer/Q1 Predictions Mean                  13.4012
trainer/Q1 Predictions Std                   12.7228
trainer/Q1 Predictions Max                   41.3981
trainer/Q1 Predictions Min                  -12.7607
trainer/Q2 Predictions Mean                  13.4133
trainer/Q2 Predictions Std                   12.7212
trainer/Q2 Predictions Max                   41.7782
trainer/Q2 Predictions Min                  -11.0955
trainer/Q Targets Mean                       13.4876
trainer/Q Targets Std                        12.8513
trainer/Q Targets Max                        42.0971
trainer/Q Targets Min                       -12.3893
trainer/Bellman Errors 1 Mean                 1.94511
trainer/Bellman Errors 1 Std                 14.2612
trainer/Bellman Errors 1 Max                377.224
trainer/Bellman Errors 1 Min                  1.61583e-07
trainer/Bellman Errors 2 Mean                 1.89405
trainer/Bellman Errors 2 Std                 14.2174
trainer/Bellman Errors 2 Max                401.715
trainer/Bellman Errors 2 Min                  1.15108e-10
trainer/Policy Action Mean                    0.372747
trainer/Policy Action Std                     0.793622
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     398000
expl/num paths total                       9950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.915378
expl/Rewards Std                              0.65614
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            36.6151
expl/Returns Std                             10.7757
expl/Returns Max                             42.4605
expl/Returns Min                              0.00690077
expl/Actions Mean                             0.406433
expl/Actions Std                              0.75753
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         36.6151
expl/env_infos/final/reward_dist Mean         1.44081
expl/env_infos/final/reward_dist Std          0.425059
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000683011
expl/env_infos/initial/reward_dist Std        0.00178192
expl/env_infos/initial/reward_dist Max        0.00773736
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.915378
expl/env_infos/reward_dist Std                0.65614
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      79600
eval/num paths total                       1990
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.985487
eval/Rewards Std                              0.635874
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            39.4195
eval/Returns Std                              1.50999
eval/Returns Max                             42.1229
eval/Returns Min                             37.7051
eval/Actions Mean                             0.418826
eval/Actions Std                              0.767715
eval/Actions Max                              1
eval/Actions Min                             -0.999809
eval/Num Paths                               10
eval/Average Returns                         39.4195
eval/env_infos/final/reward_dist Mean         1.5688
eval/env_infos/final/reward_dist Std          0.00169939
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          1.5659
eval/env_infos/initial/reward_dist Mean       0.0015783
eval/env_infos/initial/reward_dist Std        0.0038843
eval/env_infos/initial/reward_dist Max        0.012953
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.985487
eval/env_infos/reward_dist Std                0.635874
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584864
time/evaluation sampling (s)                  3.49436
time/exploration sampling (s)                17.0075
time/logging (s)                              0.00549939
time/saving (s)                               0.00234495
time/training (s)                             4.48315
time/epoch (s)                               24.9987
time/total (s)                             5089.04
Epoch                                       198
---------------------------------------  ----------------
2023-08-05 01:46:26.699340 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 199 finished
---------------------------------------  ----------------
epoch                                       199
replay_buffer/size                       400000
trainer/QF1 Loss                              1.84665
trainer/QF2 Loss                              1.88774
trainer/Policy Loss                         -14.4032
trainer/Q1 Predictions Mean                  13.3067
trainer/Q1 Predictions Std                   12.6514
trainer/Q1 Predictions Max                   41.5943
trainer/Q1 Predictions Min                  -11.3673
trainer/Q2 Predictions Mean                  13.3226
trainer/Q2 Predictions Std                   12.6505
trainer/Q2 Predictions Max                   41.62
trainer/Q2 Predictions Min                  -11.8737
trainer/Q Targets Mean                       13.3376
trainer/Q Targets Std                        12.7599
trainer/Q Targets Max                        42.1847
trainer/Q Targets Min                       -10.7831
trainer/Bellman Errors 1 Mean                 1.84665
trainer/Bellman Errors 1 Std                 13.1486
trainer/Bellman Errors 1 Max                419.017
trainer/Bellman Errors 1 Min                  1.32196e-09
trainer/Bellman Errors 2 Mean                 1.88774
trainer/Bellman Errors 2 Std                 13.553
trainer/Bellman Errors 2 Max                483.866
trainer/Bellman Errors 2 Min                  6.62533e-07
trainer/Policy Action Mean                    0.393571
trainer/Policy Action Std                     0.780076
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     400000
expl/num paths total                      10000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.780902
expl/Rewards Std                              0.687657
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            31.2361
expl/Returns Std                             16.3704
expl/Returns Max                             41.6904
expl/Returns Min                              0
expl/Actions Mean                             0.403656
expl/Actions Std                              0.746651
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.2361
expl/env_infos/final/reward_dist Mean         1.22389
expl/env_infos/final/reward_dist Std          0.649986
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0012463
expl/env_infos/initial/reward_dist Std        0.00280458
expl/env_infos/initial/reward_dist Max        0.0099907
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.780902
expl/env_infos/reward_dist Std                0.687657
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      80000
eval/num paths total                       2000
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.01726
eval/Rewards Std                              0.619631
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            40.6905
eval/Returns Std                              0.71418
eval/Returns Max                             41.5386
eval/Returns Min                             39.3078
eval/Actions Mean                             0.434301
eval/Actions Std                              0.76236
eval/Actions Max                              1
eval/Actions Min                             -0.999863
eval/Num Paths                               10
eval/Average Returns                         40.6905
eval/env_infos/final/reward_dist Mean         1.56905
eval/env_infos/final/reward_dist Std          0.00122204
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          1.56725
eval/env_infos/initial/reward_dist Mean       0.00164191
eval/env_infos/initial/reward_dist Std        0.0025559
eval/env_infos/initial/reward_dist Max        0.00648514
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.01726
eval/env_infos/reward_dist Std                0.619631
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00811303
time/evaluation sampling (s)                  3.47958
time/exploration sampling (s)                17.3226
time/logging (s)                              0.00534893
time/saving (s)                               0.002437
time/training (s)                             4.64138
time/epoch (s)                               25.4594
time/total (s)                             5114.51
Epoch                                       199
---------------------------------------  ----------------
2023-08-05 01:46:52.347613 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 200 finished
---------------------------------------  ----------------
epoch                                       200
replay_buffer/size                       402000
trainer/QF1 Loss                              1.9778
trainer/QF2 Loss                              2.02894
trainer/Policy Loss                         -14.8884
trainer/Q1 Predictions Mean                  13.7533
trainer/Q1 Predictions Std                   12.5912
trainer/Q1 Predictions Max                   41.9336
trainer/Q1 Predictions Min                  -23.0531
trainer/Q2 Predictions Mean                  13.7298
trainer/Q2 Predictions Std                   12.5672
trainer/Q2 Predictions Max                   42.5233
trainer/Q2 Predictions Min                  -25.8307
trainer/Q Targets Mean                       13.6405
trainer/Q Targets Std                        12.6591
trainer/Q Targets Max                        43.2155
trainer/Q Targets Min                       -21.5349
trainer/Bellman Errors 1 Mean                 1.9778
trainer/Bellman Errors 1 Std                 13.5988
trainer/Bellman Errors 1 Max                361.533
trainer/Bellman Errors 1 Min                  5.91399e-10
trainer/Bellman Errors 2 Mean                 2.02894
trainer/Bellman Errors 2 Std                 13.7765
trainer/Bellman Errors 2 Max                329.17
trainer/Bellman Errors 2 Min                  6.49402e-09
trainer/Policy Action Mean                    0.396313
trainer/Policy Action Std                     0.782803
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     402000
expl/num paths total                      10050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.556484
expl/Rewards Std                              0.677655
expl/Rewards Max                              1.5707
expl/Rewards Min                              0
expl/Returns Mean                            22.2594
expl/Returns Std                             19.7315
expl/Returns Max                             41.7779
expl/Returns Min                              0
expl/Actions Mean                             0.379426
expl/Actions Std                              0.759452
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.2594
expl/env_infos/final/reward_dist Mean         0.875074
expl/env_infos/final/reward_dist Std          0.775739
expl/env_infos/final/reward_dist Max          1.5707
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000705067
expl/env_infos/initial/reward_dist Std        0.00218033
expl/env_infos/initial/reward_dist Max        0.0118884
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.556484
expl/env_infos/reward_dist Std                0.677655
expl/env_infos/reward_dist Max                1.5707
expl/env_infos/reward_dist Min                0
eval/num steps total                      80400
eval/num paths total                       2010
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.408064
eval/Rewards Std                              0.635176
eval/Rewards Max                              1.57055
eval/Rewards Min                              0
eval/Returns Mean                            16.3226
eval/Returns Std                             19.9729
eval/Returns Max                             41.2335
eval/Returns Min                              0
eval/Actions Mean                             0.392691
eval/Actions Std                              0.7896
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         16.3226
eval/env_infos/final/reward_dist Mean         0.627447
eval/env_infos/final/reward_dist Std          0.768411
eval/env_infos/final/reward_dist Max          1.57055
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000978993
eval/env_infos/initial/reward_dist Std        0.00293698
eval/env_infos/initial/reward_dist Max        0.00978993
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.408064
eval/env_infos/reward_dist Std                0.635176
eval/env_infos/reward_dist Max                1.57055
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00809805
time/evaluation sampling (s)                  3.41798
time/exploration sampling (s)                17.5306
time/logging (s)                              0.00794044
time/saving (s)                               0.0032982
time/training (s)                             4.67996
time/epoch (s)                               25.6478
time/total (s)                             5140.16
Epoch                                       200
---------------------------------------  ----------------
2023-08-05 01:47:18.322972 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 201 finished
---------------------------------------  ----------------
epoch                                       201
replay_buffer/size                       404000
trainer/QF1 Loss                              1.86561
trainer/QF2 Loss                              1.86558
trainer/Policy Loss                         -14.6653
trainer/Q1 Predictions Mean                  13.4459
trainer/Q1 Predictions Std                   12.4069
trainer/Q1 Predictions Max                   42.2193
trainer/Q1 Predictions Min                  -11.4378
trainer/Q2 Predictions Mean                  13.4563
trainer/Q2 Predictions Std                   12.434
trainer/Q2 Predictions Max                   42.5413
trainer/Q2 Predictions Min                  -11.6005
trainer/Q Targets Mean                       13.5481
trainer/Q Targets Std                        12.5281
trainer/Q Targets Max                        42.8491
trainer/Q Targets Min                       -12.6041
trainer/Bellman Errors 1 Mean                 1.86561
trainer/Bellman Errors 1 Std                 11.9891
trainer/Bellman Errors 1 Max                278.164
trainer/Bellman Errors 1 Min                  2.07374e-08
trainer/Bellman Errors 2 Mean                 1.86558
trainer/Bellman Errors 2 Std                 12.0781
trainer/Bellman Errors 2 Max                269.769
trainer/Bellman Errors 2 Min                  2.82677e-09
trainer/Policy Action Mean                    0.387024
trainer/Policy Action Std                     0.785477
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     404000
expl/num paths total                      10100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.658615
expl/Rewards Std                              0.693232
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            26.3446
expl/Returns Std                             18.8373
expl/Returns Max                             41.9562
expl/Returns Min                              0
expl/Actions Mean                             0.413144
expl/Actions Std                              0.746349
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.3446
expl/env_infos/final/reward_dist Mean         1.03395
expl/env_infos/final/reward_dist Std          0.742165
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00100197
expl/env_infos/initial/reward_dist Std        0.00333295
expl/env_infos/initial/reward_dist Max        0.0150347
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.658615
expl/env_infos/reward_dist Std                0.693232
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      80800
eval/num paths total                       2020
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.726838
eval/Rewards Std                              0.686917
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            29.0735
eval/Returns Std                             17.7763
eval/Returns Max                             41.6836
eval/Returns Min                              0.0124266
eval/Actions Mean                             0.427041
eval/Actions Std                              0.76098
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         29.0735
eval/env_infos/final/reward_dist Mean         1.17542
eval/env_infos/final/reward_dist Std          0.630279
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00103482
eval/env_infos/initial/reward_dist Std        0.00295233
eval/env_infos/initial/reward_dist Max        0.00988198
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.726838
eval/env_infos/reward_dist Std                0.686917
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00815058
time/evaluation sampling (s)                  3.51032
time/exploration sampling (s)                17.7658
time/logging (s)                              0.00532089
time/saving (s)                               0.00240651
time/training (s)                             4.67553
time/epoch (s)                               25.9675
time/total (s)                             5166.13
Epoch                                       201
---------------------------------------  ----------------
2023-08-05 01:47:43.920751 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 202 finished
---------------------------------------  ----------------
epoch                                       202
replay_buffer/size                       406000
trainer/QF1 Loss                              1.66424
trainer/QF2 Loss                              1.65576
trainer/Policy Loss                         -14.2632
trainer/Q1 Predictions Mean                  13.173
trainer/Q1 Predictions Std                   12.4514
trainer/Q1 Predictions Max                   42.4845
trainer/Q1 Predictions Min                  -14.3564
trainer/Q2 Predictions Mean                  13.1921
trainer/Q2 Predictions Std                   12.4318
trainer/Q2 Predictions Max                   42.7041
trainer/Q2 Predictions Min                  -13.3901
trainer/Q Targets Mean                       13.2544
trainer/Q Targets Std                        12.533
trainer/Q Targets Max                        43.5455
trainer/Q Targets Min                       -13.4568
trainer/Bellman Errors 1 Mean                 1.66424
trainer/Bellman Errors 1 Std                 10.0394
trainer/Bellman Errors 1 Max                241.881
trainer/Bellman Errors 1 Min                  4.71482e-09
trainer/Bellman Errors 2 Mean                 1.65576
trainer/Bellman Errors 2 Std                 10.1981
trainer/Bellman Errors 2 Max                238.627
trainer/Bellman Errors 2 Min                  9.09495e-09
trainer/Policy Action Mean                    0.393749
trainer/Policy Action Std                     0.781332
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     406000
expl/num paths total                      10150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.7285
expl/Rewards Std                              0.696808
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            29.14
expl/Returns Std                             18.1754
expl/Returns Max                             42.6808
expl/Returns Min                              0
expl/Actions Mean                             0.422608
expl/Actions Std                              0.737015
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.14
expl/env_infos/final/reward_dist Mean         1.12935
expl/env_infos/final/reward_dist Std          0.703978
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000771263
expl/env_infos/initial/reward_dist Std        0.0023197
expl/env_infos/initial/reward_dist Max        0.0109533
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.7285
expl/env_infos/reward_dist Std                0.696808
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      81200
eval/num paths total                       2030
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.914573
eval/Rewards Std                              0.665215
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            36.5829
eval/Returns Std                             12.1973
eval/Returns Max                             41.627
eval/Returns Min                              0.0107132
eval/Actions Mean                             0.437388
eval/Actions Std                              0.741307
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         36.5829
eval/env_infos/final/reward_dist Mean         1.41103
eval/env_infos/final/reward_dist Std          0.470356
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00114522
eval/env_infos/initial/reward_dist Std        0.00295359
eval/env_infos/initial/reward_dist Max        0.00989596
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.914573
eval/env_infos/reward_dist Std                0.665215
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589759
time/evaluation sampling (s)                  3.44583
time/exploration sampling (s)                17.4585
time/logging (s)                              0.00529016
time/saving (s)                               0.00238857
time/training (s)                             4.67669
time/epoch (s)                               25.5946
time/total (s)                             5191.73
Epoch                                       202
---------------------------------------  ----------------
2023-08-05 01:48:09.364851 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 203 finished
---------------------------------------  ----------------
epoch                                       203
replay_buffer/size                       408000
trainer/QF1 Loss                              1.84297
trainer/QF2 Loss                              1.86632
trainer/Policy Loss                         -14.7063
trainer/Q1 Predictions Mean                  13.7318
trainer/Q1 Predictions Std                   12.5572
trainer/Q1 Predictions Max                   43.3114
trainer/Q1 Predictions Min                  -14.9922
trainer/Q2 Predictions Mean                  13.732
trainer/Q2 Predictions Std                   12.5596
trainer/Q2 Predictions Max                   43.4494
trainer/Q2 Predictions Min                  -14.3358
trainer/Q Targets Mean                       13.7099
trainer/Q Targets Std                        12.6536
trainer/Q Targets Max                        43.821
trainer/Q Targets Min                       -15.9276
trainer/Bellman Errors 1 Mean                 1.84297
trainer/Bellman Errors 1 Std                 14.33
trainer/Bellman Errors 1 Max                394.43
trainer/Bellman Errors 1 Min                  4.05231e-09
trainer/Bellman Errors 2 Mean                 1.86632
trainer/Bellman Errors 2 Std                 14.7727
trainer/Bellman Errors 2 Max                394.561
trainer/Bellman Errors 2 Min                  3.72529e-09
trainer/Policy Action Mean                    0.398777
trainer/Policy Action Std                     0.780866
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     408000
expl/num paths total                      10200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.572959
expl/Rewards Std                              0.685788
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            22.9184
expl/Returns Std                             20.1571
expl/Returns Max                             43.7318
expl/Returns Min                              0
expl/Actions Mean                             0.420609
expl/Actions Std                              0.741353
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         22.9184
expl/env_infos/final/reward_dist Mean         0.878458
expl/env_infos/final/reward_dist Std          0.778614
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00114386
expl/env_infos/initial/reward_dist Std        0.00323086
expl/env_infos/initial/reward_dist Max        0.0151393
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.572959
expl/env_infos/reward_dist Std                0.685788
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      81600
eval/num paths total                       2040
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.720646
eval/Rewards Std                              0.698262
eval/Rewards Max                              1.57035
eval/Rewards Min                              0
eval/Returns Mean                            28.8259
eval/Returns Std                             18.7168
eval/Returns Max                             42.1277
eval/Returns Min                              0.0114998
eval/Actions Mean                             0.443765
eval/Actions Std                              0.754444
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.8259
eval/env_infos/final/reward_dist Mean         1.09723
eval/env_infos/final/reward_dist Std          0.71831
eval/env_infos/final/reward_dist Max          1.57035
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00194842
eval/env_infos/initial/reward_dist Std        0.00369668
eval/env_infos/initial/reward_dist Max        0.0104167
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.720646
eval/env_infos/reward_dist Std                0.698262
eval/env_infos/reward_dist Max                1.57035
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0080856
time/evaluation sampling (s)                  3.40539
time/exploration sampling (s)                17.4234
time/logging (s)                              0.00483535
time/saving (s)                               0.00964534
time/training (s)                             4.58922
time/epoch (s)                               25.4406
time/total (s)                             5217.17
Epoch                                       203
---------------------------------------  ----------------
2023-08-05 01:48:35.022422 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 204 finished
---------------------------------------  ----------------
epoch                                       204
replay_buffer/size                       410000
trainer/QF1 Loss                              2.24577
trainer/QF2 Loss                              2.20637
trainer/Policy Loss                         -14.6341
trainer/Q1 Predictions Mean                  13.5233
trainer/Q1 Predictions Std                   12.4439
trainer/Q1 Predictions Max                   42.638
trainer/Q1 Predictions Min                  -10.8409
trainer/Q2 Predictions Mean                  13.5126
trainer/Q2 Predictions Std                   12.4441
trainer/Q2 Predictions Max                   42.9965
trainer/Q2 Predictions Min                  -10.9749
trainer/Q Targets Mean                       13.5487
trainer/Q Targets Std                        12.5755
trainer/Q Targets Max                        42.9456
trainer/Q Targets Min                       -14.1446
trainer/Bellman Errors 1 Mean                 2.24577
trainer/Bellman Errors 1 Std                 15.5906
trainer/Bellman Errors 1 Max                459.968
trainer/Bellman Errors 1 Min                  1.4554e-08
trainer/Bellman Errors 2 Mean                 2.20637
trainer/Bellman Errors 2 Std                 15.4339
trainer/Bellman Errors 2 Max                452.721
trainer/Bellman Errors 2 Min                  1.17871e-09
trainer/Policy Action Mean                    0.380426
trainer/Policy Action Std                     0.787869
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     410000
expl/num paths total                      10250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.653962
expl/Rewards Std                              0.695404
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            26.1585
expl/Returns Std                             19.5379
expl/Returns Max                             44.0608
expl/Returns Min                              0
expl/Actions Mean                             0.403363
expl/Actions Std                              0.74833
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.1585
expl/env_infos/final/reward_dist Mean         1.00363
expl/env_infos/final/reward_dist Std          0.752729
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00120826
expl/env_infos/initial/reward_dist Std        0.00306148
expl/env_infos/initial/reward_dist Max        0.0123403
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.653962
expl/env_infos/reward_dist Std                0.695404
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      82000
eval/num paths total                       2050
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.606314
eval/Rewards Std                              0.694139
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            24.2526
eval/Returns Std                             19.7895
eval/Returns Max                             40.8891
eval/Returns Min                              0.00519206
eval/Actions Mean                             0.480812
eval/Actions Std                              0.725966
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.2526
eval/env_infos/final/reward_dist Mean         0.941544
eval/env_infos/final/reward_dist Std          0.768768
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.606314
eval/env_infos/reward_dist Std                0.694139
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00807639
time/evaluation sampling (s)                  3.39604
time/exploration sampling (s)                17.6026
time/logging (s)                              0.0053626
time/saving (s)                               0.00239919
time/training (s)                             4.64081
time/epoch (s)                               25.6553
time/total (s)                             5242.83
Epoch                                       204
---------------------------------------  ----------------
2023-08-05 01:49:00.665289 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 205 finished
---------------------------------------  ----------------
epoch                                       205
replay_buffer/size                       412000
trainer/QF1 Loss                              2.12774
trainer/QF2 Loss                              2.09771
trainer/Policy Loss                         -14.5174
trainer/Q1 Predictions Mean                  13.4128
trainer/Q1 Predictions Std                   12.5362
trainer/Q1 Predictions Max                   43.0519
trainer/Q1 Predictions Min                  -11.4372
trainer/Q2 Predictions Mean                  13.4052
trainer/Q2 Predictions Std                   12.537
trainer/Q2 Predictions Max                   43.197
trainer/Q2 Predictions Min                  -11.4835
trainer/Q Targets Mean                       13.4239
trainer/Q Targets Std                        12.6267
trainer/Q Targets Max                        43.6569
trainer/Q Targets Min                       -11.3903
trainer/Bellman Errors 1 Mean                 2.12774
trainer/Bellman Errors 1 Std                 14.9298
trainer/Bellman Errors 1 Max                466.079
trainer/Bellman Errors 1 Min                  2.2931e-07
trainer/Bellman Errors 2 Mean                 2.09771
trainer/Bellman Errors 2 Std                 14.4579
trainer/Bellman Errors 2 Max                395.292
trainer/Bellman Errors 2 Min                  3.00702e-09
trainer/Policy Action Mean                    0.366139
trainer/Policy Action Std                     0.795089
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     412000
expl/num paths total                      10300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.632887
expl/Rewards Std                              0.693244
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            25.3155
expl/Returns Std                             19.6997
expl/Returns Max                             42.6641
expl/Returns Min                              0
expl/Actions Mean                             0.415047
expl/Actions Std                              0.746103
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.3155
expl/env_infos/final/reward_dist Mean         0.97213
expl/env_infos/final/reward_dist Std          0.761068
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00134071
expl/env_infos/initial/reward_dist Std        0.0035371
expl/env_infos/initial/reward_dist Max        0.0148606
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.632887
expl/env_infos/reward_dist Std                0.693244
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      82400
eval/num paths total                       2060
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.923113
eval/Rewards Std                              0.663036
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            36.9245
eval/Returns Std                             12.3133
eval/Returns Max                             41.9423
eval/Returns Min                              0.0304138
eval/Actions Mean                             0.45452
eval/Actions Std                              0.732326
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         36.9245
eval/env_infos/final/reward_dist Mean         1.41148
eval/env_infos/final/reward_dist Std          0.470501
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00210961
eval/env_infos/initial/reward_dist Std        0.00371457
eval/env_infos/initial/reward_dist Max        0.0117946
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.923113
eval/env_infos/reward_dist Std                0.663036
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00812112
time/evaluation sampling (s)                  3.43408
time/exploration sampling (s)                17.5324
time/logging (s)                              0.00536092
time/saving (s)                               0.00236142
time/training (s)                             4.65759
time/epoch (s)                               25.6399
time/total (s)                             5268.47
Epoch                                       205
---------------------------------------  ----------------
2023-08-05 01:49:26.011593 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 206 finished
---------------------------------------  ----------------
epoch                                       206
replay_buffer/size                       414000
trainer/QF1 Loss                              2.13061
trainer/QF2 Loss                              2.12555
trainer/Policy Loss                         -14.5551
trainer/Q1 Predictions Mean                  13.3828
trainer/Q1 Predictions Std                   12.4788
trainer/Q1 Predictions Max                   42.3188
trainer/Q1 Predictions Min                  -13.5316
trainer/Q2 Predictions Mean                  13.3927
trainer/Q2 Predictions Std                   12.4874
trainer/Q2 Predictions Max                   42.5032
trainer/Q2 Predictions Min                  -13.0146
trainer/Q Targets Mean                       13.3747
trainer/Q Targets Std                        12.5349
trainer/Q Targets Max                        43.6253
trainer/Q Targets Min                       -12.5555
trainer/Bellman Errors 1 Mean                 2.13061
trainer/Bellman Errors 1 Std                 17.4519
trainer/Bellman Errors 1 Max                474.553
trainer/Bellman Errors 1 Min                  1.24268e-07
trainer/Bellman Errors 2 Mean                 2.12555
trainer/Bellman Errors 2 Std                 17.3855
trainer/Bellman Errors 2 Max                444.563
trainer/Bellman Errors 2 Min                  1.92449e-09
trainer/Policy Action Mean                    0.387043
trainer/Policy Action Std                     0.772095
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     414000
expl/num paths total                      10350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.643989
expl/Rewards Std                              0.694268
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            25.7596
expl/Returns Std                             19.3954
expl/Returns Max                             44.0838
expl/Returns Min                              0
expl/Actions Mean                             0.424715
expl/Actions Std                              0.700734
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.7596
expl/env_infos/final/reward_dist Mean         1.00262
expl/env_infos/final/reward_dist Std          0.752009
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000739996
expl/env_infos/initial/reward_dist Std        0.00301638
expl/env_infos/initial/reward_dist Max        0.0156384
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.643989
expl/env_infos/reward_dist Std                0.694268
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      82800
eval/num paths total                       2070
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.901681
eval/Rewards Std                              0.667996
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            36.0672
eval/Returns Std                             12.4689
eval/Returns Max                             44.6047
eval/Returns Min                              0.795489
eval/Actions Mean                             0.48744
eval/Actions Std                              0.669741
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         36.0672
eval/env_infos/final/reward_dist Mean         1.41191
eval/env_infos/final/reward_dist Std          0.470638
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.003139
eval/env_infos/initial/reward_dist Std        0.00605182
eval/env_infos/initial/reward_dist Max        0.017904
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.901681
eval/env_infos/reward_dist Std                0.667996
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00813125
time/evaluation sampling (s)                  3.39755
time/exploration sampling (s)                17.5635
time/logging (s)                              0.00533521
time/saving (s)                               0.00238927
time/training (s)                             4.36629
time/epoch (s)                               25.3432
time/total (s)                             5293.81
Epoch                                       206
---------------------------------------  ----------------
2023-08-05 01:49:51.582868 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 207 finished
---------------------------------------  ----------------
epoch                                       207
replay_buffer/size                       416000
trainer/QF1 Loss                              2.01996
trainer/QF2 Loss                              2.05003
trainer/Policy Loss                         -14.5588
trainer/Q1 Predictions Mean                  13.3269
trainer/Q1 Predictions Std                   12.0141
trainer/Q1 Predictions Max                   43.0087
trainer/Q1 Predictions Min                  -11.6412
trainer/Q2 Predictions Mean                  13.3473
trainer/Q2 Predictions Std                   12.0212
trainer/Q2 Predictions Max                   42.4458
trainer/Q2 Predictions Min                  -13.4129
trainer/Q Targets Mean                       13.3685
trainer/Q Targets Std                        12.1479
trainer/Q Targets Max                        43.2278
trainer/Q Targets Min                       -13.0488
trainer/Bellman Errors 1 Mean                 2.01996
trainer/Bellman Errors 1 Std                 15.5405
trainer/Bellman Errors 1 Max                456.156
trainer/Bellman Errors 1 Min                  2.39672e-07
trainer/Bellman Errors 2 Mean                 2.05003
trainer/Bellman Errors 2 Std                 15.2272
trainer/Bellman Errors 2 Max                443.924
trainer/Bellman Errors 2 Min                  1.04366e-09
trainer/Policy Action Mean                    0.388032
trainer/Policy Action Std                     0.759783
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     416000
expl/num paths total                      10400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.612189
expl/Rewards Std                              0.688807
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            24.4876
expl/Returns Std                             19.7513
expl/Returns Max                             42.5004
expl/Returns Min                              0
expl/Actions Mean                             0.416507
expl/Actions Std                              0.692919
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.4876
expl/env_infos/final/reward_dist Mean         0.93955
expl/env_infos/final/reward_dist Std          0.767188
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00103314
expl/env_infos/initial/reward_dist Std        0.00304328
expl/env_infos/initial/reward_dist Max        0.0136199
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.612189
expl/env_infos/reward_dist Std                0.688807
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      83200
eval/num paths total                       2080
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.726253
eval/Rewards Std                              0.699392
eval/Rewards Max                              1.57057
eval/Rewards Min                              0
eval/Returns Mean                            29.0501
eval/Returns Std                             18.8758
eval/Returns Max                             41.9229
eval/Returns Min                              0.0010038
eval/Actions Mean                             0.467364
eval/Actions Std                              0.66842
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         29.0501
eval/env_infos/final/reward_dist Mean         1.09839
eval/env_infos/final/reward_dist Std          0.719065
eval/env_infos/final/reward_dist Max          1.57057
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.726253
eval/env_infos/reward_dist Std                0.699392
eval/env_infos/reward_dist Max                1.57057
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00945692
time/evaluation sampling (s)                  3.42637
time/exploration sampling (s)                17.5233
time/logging (s)                              0.0053344
time/saving (s)                               0.00234389
time/training (s)                             4.60143
time/epoch (s)                               25.5683
time/total (s)                             5319.38
Epoch                                       207
---------------------------------------  ----------------
2023-08-05 01:50:16.908472 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 208 finished
---------------------------------------  ----------------
epoch                                       208
replay_buffer/size                       418000
trainer/QF1 Loss                              1.99789
trainer/QF2 Loss                              1.96516
trainer/Policy Loss                         -13.8711
trainer/Q1 Predictions Mean                  12.7447
trainer/Q1 Predictions Std                   12.1434
trainer/Q1 Predictions Max                   42.2499
trainer/Q1 Predictions Min                  -11.4948
trainer/Q2 Predictions Mean                  12.7623
trainer/Q2 Predictions Std                   12.1226
trainer/Q2 Predictions Max                   42.2519
trainer/Q2 Predictions Min                  -11.4287
trainer/Q Targets Mean                       12.7098
trainer/Q Targets Std                        12.2428
trainer/Q Targets Max                        43.2198
trainer/Q Targets Min                       -11.2572
trainer/Bellman Errors 1 Mean                 1.99789
trainer/Bellman Errors 1 Std                 14.3119
trainer/Bellman Errors 1 Max                380.588
trainer/Bellman Errors 1 Min                  3.00702e-11
trainer/Bellman Errors 2 Mean                 1.96516
trainer/Bellman Errors 2 Std                 14.4787
trainer/Bellman Errors 2 Max                399.457
trainer/Bellman Errors 2 Min                  7.91488e-10
trainer/Policy Action Mean                    0.387595
trainer/Policy Action Std                     0.759435
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     418000
expl/num paths total                      10450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.759159
expl/Rewards Std                              0.69275
expl/Rewards Max                              1.57073
expl/Rewards Min                              0
expl/Returns Mean                            30.3664
expl/Returns Std                             17.6746
expl/Returns Max                             42.7653
expl/Returns Min                              0.00278725
expl/Actions Mean                             0.476743
expl/Actions Std                              0.645911
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.3664
expl/env_infos/final/reward_dist Mean         1.16039
expl/env_infos/final/reward_dist Std          0.687823
expl/env_infos/final/reward_dist Max          1.57073
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0013831
expl/env_infos/initial/reward_dist Std        0.00344271
expl/env_infos/initial/reward_dist Max        0.014618
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.759159
expl/env_infos/reward_dist Std                0.69275
expl/env_infos/reward_dist Max                1.57073
expl/env_infos/reward_dist Min                0
eval/num steps total                      83600
eval/num paths total                       2090
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.517954
eval/Rewards Std                              0.675969
eval/Rewards Max                              1.56994
eval/Rewards Min                              0
eval/Returns Mean                            20.7182
eval/Returns Std                             20.717
eval/Returns Max                             42.4179
eval/Returns Min                              0
eval/Actions Mean                             0.418566
eval/Actions Std                              0.718343
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.7182
eval/env_infos/final/reward_dist Mean         0.78412
eval/env_infos/final/reward_dist Std          0.784121
eval/env_infos/final/reward_dist Max          1.56994
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000994276
eval/env_infos/initial/reward_dist Std        0.00298283
eval/env_infos/initial/reward_dist Max        0.00994276
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.517954
eval/env_infos/reward_dist Std                0.675969
eval/env_infos/reward_dist Max                1.56994
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595844
time/evaluation sampling (s)                  3.43542
time/exploration sampling (s)                17.1526
time/logging (s)                              0.00533371
time/saving (s)                               0.00238785
time/training (s)                             4.72082
time/epoch (s)                               25.3225
time/total (s)                             5344.71
Epoch                                       208
---------------------------------------  ----------------
2023-08-05 01:50:42.026448 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 209 finished
---------------------------------------  ----------------
epoch                                       209
replay_buffer/size                       420000
trainer/QF1 Loss                              2.12458
trainer/QF2 Loss                              2.13465
trainer/Policy Loss                         -13.4404
trainer/Q1 Predictions Mean                  12.4284
trainer/Q1 Predictions Std                   11.7251
trainer/Q1 Predictions Max                   42.0512
trainer/Q1 Predictions Min                  -16.1458
trainer/Q2 Predictions Mean                  12.4473
trainer/Q2 Predictions Std                   11.7581
trainer/Q2 Predictions Max                   41.9856
trainer/Q2 Predictions Min                  -15.0836
trainer/Q Targets Mean                       12.4222
trainer/Q Targets Std                        11.7952
trainer/Q Targets Max                        44.4363
trainer/Q Targets Min                       -15.5177
trainer/Bellman Errors 1 Mean                 2.12458
trainer/Bellman Errors 1 Std                 14.8434
trainer/Bellman Errors 1 Max                346.859
trainer/Bellman Errors 1 Min                  3.23067e-07
trainer/Bellman Errors 2 Mean                 2.13465
trainer/Bellman Errors 2 Std                 14.838
trainer/Bellman Errors 2 Max                374.726
trainer/Bellman Errors 2 Min                  1.46404e-10
trainer/Policy Action Mean                    0.374632
trainer/Policy Action Std                     0.764499
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     420000
expl/num paths total                      10500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.63717
expl/Rewards Std                              0.693139
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            25.4868
expl/Returns Std                             19.8571
expl/Returns Max                             42.5118
expl/Returns Min                              0
expl/Actions Mean                             0.428064
expl/Actions Std                              0.68728
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.4868
expl/env_infos/final/reward_dist Mean         0.971204
expl/env_infos/final/reward_dist Std          0.760274
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00105457
expl/env_infos/initial/reward_dist Std        0.00283845
expl/env_infos/initial/reward_dist Max        0.0128588
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.63717
expl/env_infos/reward_dist Std                0.693139
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      84000
eval/num paths total                       2100
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.916939
eval/Rewards Std                              0.663752
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            36.6776
eval/Returns Std                             11.9912
eval/Returns Max                             41.9564
eval/Returns Min                              0.81946
eval/Actions Mean                             0.503653
eval/Actions Std                              0.620451
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         36.6776
eval/env_infos/final/reward_dist Mean         1.41187
eval/env_infos/final/reward_dist Std          0.470628
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00132909
eval/env_infos/initial/reward_dist Std        0.00266309
eval/env_infos/initial/reward_dist Max        0.00700699
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.916939
eval/env_infos/reward_dist Std                0.663752
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00576975
time/evaluation sampling (s)                  3.42455
time/exploration sampling (s)                17.0674
time/logging (s)                              0.00742737
time/saving (s)                               0.00273666
time/training (s)                             4.6092
time/epoch (s)                               25.1171
time/total (s)                             5369.83
Epoch                                       209
---------------------------------------  ----------------
2023-08-05 01:51:07.027361 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 210 finished
---------------------------------------  ----------------
epoch                                       210
replay_buffer/size                       422000
trainer/QF1 Loss                              1.80187
trainer/QF2 Loss                              1.7825
trainer/Policy Loss                         -13.7573
trainer/Q1 Predictions Mean                  12.5526
trainer/Q1 Predictions Std                   11.5824
trainer/Q1 Predictions Max                   41.1934
trainer/Q1 Predictions Min                  -28.5486
trainer/Q2 Predictions Mean                  12.5617
trainer/Q2 Predictions Std                   11.5946
trainer/Q2 Predictions Max                   41.2362
trainer/Q2 Predictions Min                  -26.116
trainer/Q Targets Mean                       12.6532
trainer/Q Targets Std                        11.7024
trainer/Q Targets Max                        42.5008
trainer/Q Targets Min                       -28.0162
trainer/Bellman Errors 1 Mean                 1.80187
trainer/Bellman Errors 1 Std                 10.5266
trainer/Bellman Errors 1 Max                260.157
trainer/Bellman Errors 1 Min                  2.27374e-09
trainer/Bellman Errors 2 Mean                 1.7825
trainer/Bellman Errors 2 Std                 10.8222
trainer/Bellman Errors 2 Max                245.316
trainer/Bellman Errors 2 Min                  2.01977e-07
trainer/Policy Action Mean                    0.371739
trainer/Policy Action Std                     0.758657
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     422000
expl/num paths total                      10550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.584018
expl/Rewards Std                              0.6821
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            23.3607
expl/Returns Std                             19.2953
expl/Returns Max                             42.3485
expl/Returns Min                              0
expl/Actions Mean                             0.43018
expl/Actions Std                              0.690884
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         23.3607
expl/env_infos/final/reward_dist Mean         0.941987
expl/env_infos/final/reward_dist Std          0.768564
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000605116
expl/env_infos/initial/reward_dist Std        0.00204752
expl/env_infos/initial/reward_dist Max        0.00974274
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.584018
expl/env_infos/reward_dist Std                0.6821
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      84400
eval/num paths total                       2110
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.508632
eval/Rewards Std                              0.670822
eval/Rewards Max                              1.5701
eval/Rewards Min                              0
eval/Returns Mean                            20.3453
eval/Returns Std                             20.2015
eval/Returns Max                             41.6495
eval/Returns Min                              0
eval/Actions Mean                             0.40952
eval/Actions Std                              0.740359
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.3453
eval/env_infos/final/reward_dist Mean         0.784017
eval/env_infos/final/reward_dist Std          0.784018
eval/env_infos/final/reward_dist Max          1.5701
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00123545
eval/env_infos/initial/reward_dist Std        0.0024795
eval/env_infos/initial/reward_dist Max        0.00663891
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.508632
eval/env_infos/reward_dist Std                0.670822
eval/env_infos/reward_dist Max                1.5701
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00598302
time/evaluation sampling (s)                  3.35231
time/exploration sampling (s)                16.9338
time/logging (s)                              0.00535291
time/saving (s)                               0.00240916
time/training (s)                             4.69387
time/epoch (s)                               24.9937
time/total (s)                             5394.82
Epoch                                       210
---------------------------------------  ----------------
2023-08-05 01:51:32.479518 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 211 finished
---------------------------------------  ----------------
epoch                                       211
replay_buffer/size                       424000
trainer/QF1 Loss                              2.03407
trainer/QF2 Loss                              2.04316
trainer/Policy Loss                         -13.2155
trainer/Q1 Predictions Mean                  12.0739
trainer/Q1 Predictions Std                   11.4169
trainer/Q1 Predictions Max                   42.2044
trainer/Q1 Predictions Min                  -17.4927
trainer/Q2 Predictions Mean                  12.0564
trainer/Q2 Predictions Std                   11.4117
trainer/Q2 Predictions Max                   41.9747
trainer/Q2 Predictions Min                  -19.2924
trainer/Q Targets Mean                       12.1533
trainer/Q Targets Std                        11.542
trainer/Q Targets Max                        44.4352
trainer/Q Targets Min                       -15.8569
trainer/Bellman Errors 1 Mean                 2.03407
trainer/Bellman Errors 1 Std                 14.5236
trainer/Bellman Errors 1 Max                435.389
trainer/Bellman Errors 1 Min                  1.15266e-07
trainer/Bellman Errors 2 Mean                 2.04316
trainer/Bellman Errors 2 Std                 14.2017
trainer/Bellman Errors 2 Max                415.124
trainer/Bellman Errors 2 Min                  1.65755e-08
trainer/Policy Action Mean                    0.371819
trainer/Policy Action Std                     0.761176
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     424000
expl/num paths total                      10600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.767032
expl/Rewards Std                              0.684387
expl/Rewards Max                              1.57073
expl/Rewards Min                              0
expl/Returns Mean                            30.6813
expl/Returns Std                             16.5883
expl/Returns Max                             42.7194
expl/Returns Min                              0
expl/Actions Mean                             0.431591
expl/Actions Std                              0.67072
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.6813
expl/env_infos/final/reward_dist Mean         1.22267
expl/env_infos/final/reward_dist Std          0.649379
expl/env_infos/final/reward_dist Max          1.57073
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00109011
expl/env_infos/initial/reward_dist Std        0.00290279
expl/env_infos/initial/reward_dist Max        0.0144021
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.767032
expl/env_infos/reward_dist Std                0.684387
expl/env_infos/reward_dist Max                1.57073
expl/env_infos/reward_dist Min                0
eval/num steps total                      84800
eval/num paths total                       2120
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.508228
eval/Rewards Std                              0.66952
eval/Rewards Max                              1.56898
eval/Rewards Min                              0
eval/Returns Mean                            20.3291
eval/Returns Std                             20.3358
eval/Returns Max                             42.1228
eval/Returns Min                              0
eval/Actions Mean                             0.399016
eval/Actions Std                              0.74206
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         20.3291
eval/env_infos/final/reward_dist Mean         0.784244
eval/env_infos/final/reward_dist Std          0.784244
eval/env_infos/final/reward_dist Max          1.56898
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00156611
eval/env_infos/initial/reward_dist Std        0.00389392
eval/env_infos/initial/reward_dist Max        0.0130035
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.508228
eval/env_infos/reward_dist Std                0.66952
eval/env_infos/reward_dist Max                1.56898
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.006701
time/evaluation sampling (s)                  3.3824
time/exploration sampling (s)                17.3519
time/logging (s)                              0.00530589
time/saving (s)                               0.00235297
time/training (s)                             4.70042
time/epoch (s)                               25.4491
time/total (s)                             5420.27
Epoch                                       211
---------------------------------------  ----------------
2023-08-05 01:51:58.373202 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 212 finished
---------------------------------------  ----------------
epoch                                       212
replay_buffer/size                       426000
trainer/QF1 Loss                              1.98776
trainer/QF2 Loss                              1.94345
trainer/Policy Loss                         -13.0868
trainer/Q1 Predictions Mean                  12.0299
trainer/Q1 Predictions Std                   11.3712
trainer/Q1 Predictions Max                   41.4977
trainer/Q1 Predictions Min                  -11.6994
trainer/Q2 Predictions Mean                  12.0553
trainer/Q2 Predictions Std                   11.3936
trainer/Q2 Predictions Max                   41.2956
trainer/Q2 Predictions Min                  -11.5344
trainer/Q Targets Mean                       11.9597
trainer/Q Targets Std                        11.4533
trainer/Q Targets Max                        43.8988
trainer/Q Targets Min                       -12.5841
trainer/Bellman Errors 1 Mean                 1.98776
trainer/Bellman Errors 1 Std                 13.4002
trainer/Bellman Errors 1 Max                356.029
trainer/Bellman Errors 1 Min                  9.31323e-10
trainer/Bellman Errors 2 Mean                 1.94345
trainer/Bellman Errors 2 Std                 12.9853
trainer/Bellman Errors 2 Max                343.341
trainer/Bellman Errors 2 Min                  5.49272e-08
trainer/Policy Action Mean                    0.347423
trainer/Policy Action Std                     0.762764
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     426000
expl/num paths total                      10650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.530479
expl/Rewards Std                              0.656504
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            21.2192
expl/Returns Std                             18.0885
expl/Returns Max                             40.396
expl/Returns Min                              0
expl/Actions Mean                             0.391233
expl/Actions Std                              0.700694
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         21.2192
expl/env_infos/final/reward_dist Mean         0.908285
expl/env_infos/final/reward_dist Std          0.773025
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000891294
expl/env_infos/initial/reward_dist Std        0.00288154
expl/env_infos/initial/reward_dist Max        0.0141841
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.530479
expl/env_infos/reward_dist Std                0.656504
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      85200
eval/num paths total                       2130
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.664057
eval/Rewards Std                              0.678562
eval/Rewards Max                              1.57068
eval/Rewards Min                              0
eval/Returns Mean                            26.5623
eval/Returns Std                             17.1952
eval/Returns Max                             40.6419
eval/Returns Min                              0.0100859
eval/Actions Mean                             0.434142
eval/Actions Std                              0.679001
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.5623
eval/env_infos/final/reward_dist Mean         1.09904
eval/env_infos/final/reward_dist Std          0.719179
eval/env_infos/final/reward_dist Max          1.57068
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00195991
eval/env_infos/initial/reward_dist Std        0.00341525
eval/env_infos/initial/reward_dist Max        0.0107606
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.664057
eval/env_infos/reward_dist Std                0.678562
eval/env_infos/reward_dist Max                1.57068
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00807349
time/evaluation sampling (s)                  3.41058
time/exploration sampling (s)                17.4288
time/logging (s)                              0.00532032
time/saving (s)                               0.00235216
time/training (s)                             5.03557
time/epoch (s)                               25.8907
time/total (s)                             5446.17
Epoch                                       212
---------------------------------------  ----------------
2023-08-05 01:52:24.044578 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 213 finished
---------------------------------------  ----------------
epoch                                       213
replay_buffer/size                       428000
trainer/QF1 Loss                              1.9549
trainer/QF2 Loss                              1.94556
trainer/Policy Loss                         -12.925
trainer/Q1 Predictions Mean                  11.8692
trainer/Q1 Predictions Std                   11.034
trainer/Q1 Predictions Max                   41.1146
trainer/Q1 Predictions Min                  -12.093
trainer/Q2 Predictions Mean                  11.8555
trainer/Q2 Predictions Std                   11.0368
trainer/Q2 Predictions Max                   40.9971
trainer/Q2 Predictions Min                  -12.0133
trainer/Q Targets Mean                       11.8978
trainer/Q Targets Std                        11.1761
trainer/Q Targets Max                        43.1349
trainer/Q Targets Min                       -11.6832
trainer/Bellman Errors 1 Mean                 1.9549
trainer/Bellman Errors 1 Std                 14.5185
trainer/Bellman Errors 1 Max                629.937
trainer/Bellman Errors 1 Min                  2.21689e-08
trainer/Bellman Errors 2 Mean                 1.94556
trainer/Bellman Errors 2 Std                 13.7992
trainer/Bellman Errors 2 Max                590.532
trainer/Bellman Errors 2 Min                  1.78261e-10
trainer/Policy Action Mean                    0.344129
trainer/Policy Action Std                     0.757685
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     428000
expl/num paths total                      10700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.650944
expl/Rewards Std                              0.669809
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            26.0377
expl/Returns Std                             16.2658
expl/Returns Max                             40.154
expl/Returns Min                              0
expl/Actions Mean                             0.409357
expl/Actions Std                              0.671147
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.0377
expl/env_infos/final/reward_dist Mean         1.12963
expl/env_infos/final/reward_dist Std          0.70445
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000780511
expl/env_infos/initial/reward_dist Std        0.00217447
expl/env_infos/initial/reward_dist Max        0.0105753
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.650944
expl/env_infos/reward_dist Std                0.669809
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      85600
eval/num paths total                       2140
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.712498
eval/Rewards Std                              0.671286
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            28.4999
eval/Returns Std                             14.466
eval/Returns Max                             40.8158
eval/Returns Min                              0.00998007
eval/Actions Mean                             0.419752
eval/Actions Std                              0.681871
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.4999
eval/env_infos/final/reward_dist Mean         1.25556
eval/env_infos/final/reward_dist Std          0.62778
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000709168
eval/env_infos/initial/reward_dist Std        0.0021275
eval/env_infos/initial/reward_dist Max        0.00709168
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.712498
eval/env_infos/reward_dist Std                0.671286
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593462
time/evaluation sampling (s)                  3.7263
time/exploration sampling (s)                17.4348
time/logging (s)                              0.00531225
time/saving (s)                               0.00235399
time/training (s)                             4.49366
time/epoch (s)                               25.6683
time/total (s)                             5471.84
Epoch                                       213
---------------------------------------  ----------------
2023-08-05 01:52:49.249665 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 214 finished
---------------------------------------  ----------------
epoch                                       214
replay_buffer/size                       430000
trainer/QF1 Loss                              1.73068
trainer/QF2 Loss                              1.76516
trainer/Policy Loss                         -12.5649
trainer/Q1 Predictions Mean                  11.5315
trainer/Q1 Predictions Std                   10.9408
trainer/Q1 Predictions Max                   41.5211
trainer/Q1 Predictions Min                  -12.8188
trainer/Q2 Predictions Mean                  11.4856
trainer/Q2 Predictions Std                   10.9423
trainer/Q2 Predictions Max                   41.5455
trainer/Q2 Predictions Min                  -11.7976
trainer/Q Targets Mean                       11.5321
trainer/Q Targets Std                        11.0619
trainer/Q Targets Max                        44.2135
trainer/Q Targets Min                       -13.4871
trainer/Bellman Errors 1 Mean                 1.73068
trainer/Bellman Errors 1 Std                 10.5866
trainer/Bellman Errors 1 Max                242.937
trainer/Bellman Errors 1 Min                  1.4918e-09
trainer/Bellman Errors 2 Mean                 1.76516
trainer/Bellman Errors 2 Std                 10.848
trainer/Bellman Errors 2 Max                305.859
trainer/Bellman Errors 2 Min                  9.34678e-09
trainer/Policy Action Mean                    0.355751
trainer/Policy Action Std                     0.755764
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     430000
expl/num paths total                      10750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.64215
expl/Rewards Std                              0.675281
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            25.686
expl/Returns Std                             17.4777
expl/Returns Max                             40.4372
expl/Returns Min                              0
expl/Actions Mean                             0.384218
expl/Actions Std                              0.689907
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.686
expl/env_infos/final/reward_dist Mean         1.06516
expl/env_infos/final/reward_dist Std          0.730713
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000985443
expl/env_infos/initial/reward_dist Std        0.00276993
expl/env_infos/initial/reward_dist Max        0.0142679
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.64215
expl/env_infos/reward_dist Std                0.675281
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      86000
eval/num paths total                       2150
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.755235
eval/Rewards Std                              0.677848
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            30.2094
eval/Returns Std                             15.016
eval/Returns Max                             39.8121
eval/Returns Min                              0
eval/Actions Mean                             0.43233
eval/Actions Std                              0.672653
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.2094
eval/env_infos/final/reward_dist Mean         1.25525
eval/env_infos/final/reward_dist Std          0.627625
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000102202
eval/env_infos/initial/reward_dist Std        0.000306607
eval/env_infos/initial/reward_dist Max        0.00102202
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.755235
eval/env_infos/reward_dist Std                0.677848
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0060878
time/evaluation sampling (s)                  3.41299
time/exploration sampling (s)                17.215
time/logging (s)                              0.00531474
time/saving (s)                               0.00230845
time/training (s)                             4.56039
time/epoch (s)                               25.2021
time/total (s)                             5497.04
Epoch                                       214
---------------------------------------  ----------------
2023-08-05 01:53:14.444026 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 215 finished
---------------------------------------  ----------------
epoch                                       215
replay_buffer/size                       432000
trainer/QF1 Loss                              1.79272
trainer/QF2 Loss                              1.75047
trainer/Policy Loss                         -12.4156
trainer/Q1 Predictions Mean                  11.3606
trainer/Q1 Predictions Std                   10.7555
trainer/Q1 Predictions Max                   41.0622
trainer/Q1 Predictions Min                  -11.7723
trainer/Q2 Predictions Mean                  11.4201
trainer/Q2 Predictions Std                   10.7977
trainer/Q2 Predictions Max                   41.0483
trainer/Q2 Predictions Min                  -10.4834
trainer/Q Targets Mean                       11.4436
trainer/Q Targets Std                        10.9036
trainer/Q Targets Max                        42.68
trainer/Q Targets Min                       -11.8725
trainer/Bellman Errors 1 Mean                 1.79272
trainer/Bellman Errors 1 Std                 11.7397
trainer/Bellman Errors 1 Max                415.994
trainer/Bellman Errors 1 Min                  6.72662e-09
trainer/Bellman Errors 2 Mean                 1.75047
trainer/Bellman Errors 2 Std                 11.4859
trainer/Bellman Errors 2 Max                408.31
trainer/Bellman Errors 2 Min                  2.50679e-09
trainer/Policy Action Mean                    0.358781
trainer/Policy Action Std                     0.7517
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     432000
expl/num paths total                      10800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.814399
expl/Rewards Std                              0.667483
expl/Rewards Max                              1.57075
expl/Rewards Min                              0
expl/Returns Mean                            32.576
expl/Returns Std                             13.0898
expl/Returns Max                             40.1794
expl/Returns Min                              0
expl/Actions Mean                             0.441328
expl/Actions Std                              0.626819
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.576
expl/env_infos/final/reward_dist Mean         1.34922
expl/env_infos/final/reward_dist Std          0.544379
expl/env_infos/final/reward_dist Max          1.57075
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00148515
expl/env_infos/initial/reward_dist Std        0.00380881
expl/env_infos/initial/reward_dist Max        0.0160539
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.814399
expl/env_infos/reward_dist Std                0.667483
expl/env_infos/reward_dist Max                1.57075
expl/env_infos/reward_dist Min                0
eval/num steps total                      86400
eval/num paths total                       2160
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.867619
eval/Rewards Std                              0.659789
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            34.7048
eval/Returns Std                             11.4164
eval/Returns Max                             40.2162
eval/Returns Min                              0.689012
eval/Actions Mean                             0.462639
eval/Actions Std                              0.62914
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         34.7048
eval/env_infos/final/reward_dist Mean         1.41246
eval/env_infos/final/reward_dist Std          0.470822
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000749741
eval/env_infos/initial/reward_dist Std        0.00184664
eval/env_infos/initial/reward_dist Max        0.00615873
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.867619
eval/env_infos/reward_dist Std                0.659789
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0058232
time/evaluation sampling (s)                  3.4096
time/exploration sampling (s)                17.2393
time/logging (s)                              0.00744953
time/saving (s)                               0.00269137
time/training (s)                             4.52865
time/epoch (s)                               25.1935
time/total (s)                             5522.24
Epoch                                       215
---------------------------------------  ----------------
2023-08-05 01:53:39.806607 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 216 finished
---------------------------------------  ----------------
epoch                                       216
replay_buffer/size                       434000
trainer/QF1 Loss                              1.58566
trainer/QF2 Loss                              1.56622
trainer/Policy Loss                         -12.0624
trainer/Q1 Predictions Mean                  11.1187
trainer/Q1 Predictions Std                   10.7255
trainer/Q1 Predictions Max                   40.5825
trainer/Q1 Predictions Min                  -24.6634
trainer/Q2 Predictions Mean                  11.1331
trainer/Q2 Predictions Std                   10.7371
trainer/Q2 Predictions Max                   40.2722
trainer/Q2 Predictions Min                  -26.4328
trainer/Q Targets Mean                       11.1219
trainer/Q Targets Std                        10.8255
trainer/Q Targets Max                        41.5035
trainer/Q Targets Min                       -23.7151
trainer/Bellman Errors 1 Mean                 1.58566
trainer/Bellman Errors 1 Std                  8.73866
trainer/Bellman Errors 1 Max                221.106
trainer/Bellman Errors 1 Min                  3.85953e-08
trainer/Bellman Errors 2 Mean                 1.56622
trainer/Bellman Errors 2 Std                  8.50229
trainer/Bellman Errors 2 Max                213.403
trainer/Bellman Errors 2 Min                  1.08522e-08
trainer/Policy Action Mean                    0.370756
trainer/Policy Action Std                     0.746476
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     434000
expl/num paths total                      10850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.595416
expl/Rewards Std                              0.673472
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            23.8166
expl/Returns Std                             18.3592
expl/Returns Max                             41.0942
expl/Returns Min                              0
expl/Actions Mean                             0.419287
expl/Actions Std                              0.689243
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         23.8166
expl/env_infos/final/reward_dist Mean         0.969382
expl/env_infos/final/reward_dist Std          0.759058
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000935322
expl/env_infos/initial/reward_dist Std        0.00312119
expl/env_infos/initial/reward_dist Max        0.0180101
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.595416
expl/env_infos/reward_dist Std                0.673472
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      86800
eval/num paths total                       2170
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.469428
eval/Rewards Std                              0.644623
eval/Rewards Max                              1.57057
eval/Rewards Min                              0
eval/Returns Mean                            18.7771
eval/Returns Std                             18.5314
eval/Returns Max                             40.5066
eval/Returns Min                              0
eval/Actions Mean                             0.392594
eval/Actions Std                              0.750962
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         18.7771
eval/env_infos/final/reward_dist Mean         0.784479
eval/env_infos/final/reward_dist Std          0.78448
eval/env_infos/final/reward_dist Max          1.57057
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000489217
eval/env_infos/initial/reward_dist Std        0.00146765
eval/env_infos/initial/reward_dist Max        0.00489217
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.469428
eval/env_infos/reward_dist Std                0.644623
eval/env_infos/reward_dist Max                1.57057
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00808331
time/evaluation sampling (s)                  3.37538
time/exploration sampling (s)                17.4452
time/logging (s)                              0.00536225
time/saving (s)                               0.00242133
time/training (s)                             4.51884
time/epoch (s)                               25.3553
time/total (s)                             5547.59
Epoch                                       216
---------------------------------------  ----------------
2023-08-05 01:54:05.395649 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 217 finished
---------------------------------------  ----------------
epoch                                       217
replay_buffer/size                       436000
trainer/QF1 Loss                              1.95696
trainer/QF2 Loss                              1.93641
trainer/Policy Loss                         -11.8153
trainer/Q1 Predictions Mean                  10.8911
trainer/Q1 Predictions Std                   10.6671
trainer/Q1 Predictions Max                   41.4556
trainer/Q1 Predictions Min                  -15.4395
trainer/Q2 Predictions Mean                  10.9188
trainer/Q2 Predictions Std                   10.6726
trainer/Q2 Predictions Max                   41.3651
trainer/Q2 Predictions Min                  -13.956
trainer/Q Targets Mean                       10.8081
trainer/Q Targets Std                        10.7475
trainer/Q Targets Max                        41.6996
trainer/Q Targets Min                       -19.0556
trainer/Bellman Errors 1 Mean                 1.95696
trainer/Bellman Errors 1 Std                 13.6836
trainer/Bellman Errors 1 Max                402.923
trainer/Bellman Errors 1 Min                  2.27374e-09
trainer/Bellman Errors 2 Mean                 1.93641
trainer/Bellman Errors 2 Std                 13.75
trainer/Bellman Errors 2 Max                403.6
trainer/Bellman Errors 2 Min                  4.24334e-08
trainer/Policy Action Mean                    0.378184
trainer/Policy Action Std                     0.758618
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     436000
expl/num paths total                      10900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.636755
expl/Rewards Std                              0.681593
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            25.4702
expl/Returns Std                             18.3605
expl/Returns Max                             41.9306
expl/Returns Min                              0
expl/Actions Mean                             0.403227
expl/Actions Std                              0.711903
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.4702
expl/env_infos/final/reward_dist Mean         1.0308
expl/env_infos/final/reward_dist Std          0.739635
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000775465
expl/env_infos/initial/reward_dist Std        0.00226448
expl/env_infos/initial/reward_dist Max        0.0110886
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.636755
expl/env_infos/reward_dist Std                0.681593
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      87200
eval/num paths total                       2180
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.807808
eval/Rewards Std                              0.680607
eval/Rewards Max                              1.57066
eval/Rewards Min                              0
eval/Returns Mean                            32.3123
eval/Returns Std                             15.8302
eval/Returns Max                             41.9246
eval/Returns Min                              0.680073
eval/Actions Mean                             0.462566
eval/Actions Std                              0.681782
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         32.3123
eval/env_infos/final/reward_dist Mean         1.25391
eval/env_infos/final/reward_dist Std          0.626965
eval/env_infos/final/reward_dist Max          1.57066
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00178124
eval/env_infos/initial/reward_dist Std        0.00406801
eval/env_infos/initial/reward_dist Max        0.013713
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.807808
eval/env_infos/reward_dist Std                0.680607
eval/env_infos/reward_dist Max                1.57066
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00811548
time/evaluation sampling (s)                  3.45387
time/exploration sampling (s)                17.4312
time/logging (s)                              0.005361
time/saving (s)                               0.00237187
time/training (s)                             4.68519
time/epoch (s)                               25.5861
time/total (s)                             5573.18
Epoch                                       217
---------------------------------------  ----------------
2023-08-05 01:54:31.809596 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 218 finished
---------------------------------------  ----------------
epoch                                       218
replay_buffer/size                       438000
trainer/QF1 Loss                              1.63951
trainer/QF2 Loss                              1.57316
trainer/Policy Loss                         -12.1755
trainer/Q1 Predictions Mean                  11.0354
trainer/Q1 Predictions Std                   10.5481
trainer/Q1 Predictions Max                   40.9108
trainer/Q1 Predictions Min                  -11.7505
trainer/Q2 Predictions Mean                  11.0003
trainer/Q2 Predictions Std                   10.5348
trainer/Q2 Predictions Max                   40.7478
trainer/Q2 Predictions Min                  -11.7271
trainer/Q Targets Mean                       11.066
trainer/Q Targets Std                        10.6646
trainer/Q Targets Max                        41.1207
trainer/Q Targets Min                       -11.8333
trainer/Bellman Errors 1 Mean                 1.63951
trainer/Bellman Errors 1 Std                 10.8096
trainer/Bellman Errors 1 Max                341.774
trainer/Bellman Errors 1 Min                  3.45835e-08
trainer/Bellman Errors 2 Mean                 1.57316
trainer/Bellman Errors 2 Std                 10.272
trainer/Bellman Errors 2 Max                328.582
trainer/Bellman Errors 2 Min                  2.14819e-07
trainer/Policy Action Mean                    0.391197
trainer/Policy Action Std                     0.767789
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     438000
expl/num paths total                      10950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.79609
expl/Rewards Std                              0.68192
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            31.8436
expl/Returns Std                             15.7214
expl/Returns Max                             41.7062
expl/Returns Min                              0
expl/Actions Mean                             0.460067
expl/Actions Std                              0.686302
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.8436
expl/env_infos/final/reward_dist Mean         1.25456
expl/env_infos/final/reward_dist Std          0.626905
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0010291
expl/env_infos/initial/reward_dist Std        0.00251343
expl/env_infos/initial/reward_dist Max        0.010378
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.79609
expl/env_infos/reward_dist Std                0.68192
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      87600
eval/num paths total                       2190
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.811383
eval/Rewards Std                              0.682253
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            32.4553
eval/Returns Std                             15.8655
eval/Returns Max                             42.7424
eval/Returns Min                              0.628825
eval/Actions Mean                             0.483324
eval/Actions Std                              0.696462
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         32.4553
eval/env_infos/final/reward_dist Mean         1.25466
eval/env_infos/final/reward_dist Std          0.627333
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00271808
eval/env_infos/initial/reward_dist Std        0.00534168
eval/env_infos/initial/reward_dist Max        0.0166028
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.811383
eval/env_infos/reward_dist Std                0.682253
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00812895
time/evaluation sampling (s)                  3.42784
time/exploration sampling (s)                17.5337
time/logging (s)                              0.00788283
time/saving (s)                               0.00332111
time/training (s)                             5.43254
time/epoch (s)                               26.4134
time/total (s)                             5599.6
Epoch                                       218
---------------------------------------  ----------------
2023-08-05 01:54:57.376112 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 219 finished
---------------------------------------  ----------------
epoch                                       219
replay_buffer/size                       440000
trainer/QF1 Loss                              1.74898
trainer/QF2 Loss                              1.70687
trainer/Policy Loss                         -11.9356
trainer/Q1 Predictions Mean                  10.9615
trainer/Q1 Predictions Std                   10.3783
trainer/Q1 Predictions Max                   40.7091
trainer/Q1 Predictions Min                  -13.3126
trainer/Q2 Predictions Mean                  11.0418
trainer/Q2 Predictions Std                   10.3958
trainer/Q2 Predictions Max                   41.0293
trainer/Q2 Predictions Min                  -12.843
trainer/Q Targets Mean                       11.0079
trainer/Q Targets Std                        10.5018
trainer/Q Targets Max                        40.8061
trainer/Q Targets Min                       -13.5238
trainer/Bellman Errors 1 Mean                 1.74898
trainer/Bellman Errors 1 Std                 11.5461
trainer/Bellman Errors 1 Max                299.944
trainer/Bellman Errors 1 Min                  1.27216e-07
trainer/Bellman Errors 2 Mean                 1.70687
trainer/Bellman Errors 2 Std                 11.2252
trainer/Bellman Errors 2 Max                284.144
trainer/Bellman Errors 2 Min                  1.39844e-08
trainer/Policy Action Mean                    0.389561
trainer/Policy Action Std                     0.771412
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     440000
expl/num paths total                      11000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.670747
expl/Rewards Std                              0.688795
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            26.8299
expl/Returns Std                             18.2464
expl/Returns Max                             42.5208
expl/Returns Min                              0
expl/Actions Mean                             0.409227
expl/Actions Std                              0.719919
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.8299
expl/env_infos/final/reward_dist Mean         1.06492
expl/env_infos/final/reward_dist Std          0.730599
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000310984
expl/env_infos/initial/reward_dist Std        0.000936997
expl/env_infos/initial/reward_dist Max        0.00413003
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.670747
expl/env_infos/reward_dist Std                0.688795
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      88000
eval/num paths total                       2200
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.803826
eval/Rewards Std                              0.686582
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            32.153
eval/Returns Std                             16.1197
eval/Returns Max                             42.2367
eval/Returns Min                              0
eval/Actions Mean                             0.381262
eval/Actions Std                              0.750829
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         32.153
eval/env_infos/final/reward_dist Mean         1.25585
eval/env_infos/final/reward_dist Std          0.627927
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000397903
eval/env_infos/initial/reward_dist Std        0.00119371
eval/env_infos/initial/reward_dist Max        0.00397903
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.803826
eval/env_infos/reward_dist Std                0.686582
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00814292
time/evaluation sampling (s)                  3.4782
time/exploration sampling (s)                17.5611
time/logging (s)                              0.00532715
time/saving (s)                               0.00234817
time/training (s)                             4.50364
time/epoch (s)                               25.5587
time/total (s)                             5625.16
Epoch                                       219
---------------------------------------  ----------------
2023-08-05 01:55:22.690296 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 220 finished
---------------------------------------  ----------------
epoch                                       220
replay_buffer/size                       442000
trainer/QF1 Loss                              1.55536
trainer/QF2 Loss                              1.55264
trainer/Policy Loss                         -11.8779
trainer/Q1 Predictions Mean                  10.8723
trainer/Q1 Predictions Std                   10.1989
trainer/Q1 Predictions Max                   40.1928
trainer/Q1 Predictions Min                  -16.2473
trainer/Q2 Predictions Mean                  10.9542
trainer/Q2 Predictions Std                   10.2515
trainer/Q2 Predictions Max                   40.9208
trainer/Q2 Predictions Min                  -16.2364
trainer/Q Targets Mean                       10.886
trainer/Q Targets Std                        10.2872
trainer/Q Targets Max                        40.6772
trainer/Q Targets Min                       -18.6587
trainer/Bellman Errors 1 Mean                 1.55536
trainer/Bellman Errors 1 Std                  8.12841
trainer/Bellman Errors 1 Max                228.08
trainer/Bellman Errors 1 Min                  3.85953e-08
trainer/Bellman Errors 2 Mean                 1.55264
trainer/Bellman Errors 2 Std                  8.31842
trainer/Bellman Errors 2 Max                230.166
trainer/Bellman Errors 2 Min                  1.06083e-08
trainer/Policy Action Mean                    0.390199
trainer/Policy Action Std                     0.771641
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     442000
expl/num paths total                      11050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.65316
expl/Rewards Std                              0.685397
expl/Rewards Max                              1.57069
expl/Rewards Min                              0
expl/Returns Mean                            26.1264
expl/Returns Std                             18.4222
expl/Returns Max                             42.3629
expl/Returns Min                              0
expl/Actions Mean                             0.449331
expl/Actions Std                              0.709935
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.1264
expl/env_infos/final/reward_dist Mean         1.03374
expl/env_infos/final/reward_dist Std          0.742036
expl/env_infos/final/reward_dist Max          1.57069
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000917343
expl/env_infos/initial/reward_dist Std        0.00243215
expl/env_infos/initial/reward_dist Max        0.0122158
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.65316
expl/env_infos/reward_dist Std                0.685397
expl/env_infos/reward_dist Max                1.57069
expl/env_infos/reward_dist Min                0
eval/num steps total                      88400
eval/num paths total                       2210
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.799911
eval/Rewards Std                              0.683375
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            31.9964
eval/Returns Std                             15.579
eval/Returns Max                             41.1453
eval/Returns Min                              0.723971
eval/Actions Mean                             0.482273
eval/Actions Std                              0.702093
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.9964
eval/env_infos/final/reward_dist Mean         1.25523
eval/env_infos/final/reward_dist Std          0.627619
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00106891
eval/env_infos/initial/reward_dist Std        0.00320674
eval/env_infos/initial/reward_dist Max        0.0106891
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.799911
eval/env_infos/reward_dist Std                0.683375
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00816056
time/evaluation sampling (s)                  3.38308
time/exploration sampling (s)                17.5552
time/logging (s)                              0.00536968
time/saving (s)                               0.00231151
time/training (s)                             4.35716
time/epoch (s)                               25.3112
time/total (s)                             5650.47
Epoch                                       220
---------------------------------------  ----------------
2023-08-05 01:55:48.478524 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 221 finished
---------------------------------------  ----------------
epoch                                       221
replay_buffer/size                       444000
trainer/QF1 Loss                              1.48912
trainer/QF2 Loss                              1.42902
trainer/Policy Loss                         -12.0523
trainer/Q1 Predictions Mean                  11.1471
trainer/Q1 Predictions Std                   10.2983
trainer/Q1 Predictions Max                   41.2537
trainer/Q1 Predictions Min                  -12.4628
trainer/Q2 Predictions Mean                  11.1154
trainer/Q2 Predictions Std                   10.2796
trainer/Q2 Predictions Max                   41.3196
trainer/Q2 Predictions Min                  -13.3537
trainer/Q Targets Mean                       11.0392
trainer/Q Targets Std                        10.3104
trainer/Q Targets Max                        41.6838
trainer/Q Targets Min                       -14.2507
trainer/Bellman Errors 1 Mean                 1.48912
trainer/Bellman Errors 1 Std                  9.55801
trainer/Bellman Errors 1 Max                354.935
trainer/Bellman Errors 1 Min                  3.07919e-08
trainer/Bellman Errors 2 Mean                 1.42902
trainer/Bellman Errors 2 Std                  8.91583
trainer/Bellman Errors 2 Max                319.046
trainer/Bellman Errors 2 Min                  1.51027e-09
trainer/Policy Action Mean                    0.391039
trainer/Policy Action Std                     0.774202
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     444000
expl/num paths total                      11100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.798209
expl/Rewards Std                              0.684112
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            31.9284
expl/Returns Std                             15.6928
expl/Returns Max                             42.5553
expl/Returns Min                              0
expl/Actions Mean                             0.461667
expl/Actions Std                              0.683176
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.9284
expl/env_infos/final/reward_dist Mean         1.255
expl/env_infos/final/reward_dist Std          0.627501
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00103747
expl/env_infos/initial/reward_dist Std        0.00285726
expl/env_infos/initial/reward_dist Max        0.013078
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.798209
expl/env_infos/reward_dist Std                0.684112
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      88800
eval/num paths total                       2220
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.475704
eval/Rewards Std                              0.643213
eval/Rewards Max                              1.57064
eval/Rewards Min                              0
eval/Returns Mean                            19.0282
eval/Returns Std                             18.7279
eval/Returns Max                             41.2635
eval/Returns Min                              0
eval/Actions Mean                             0.443207
eval/Actions Std                              0.771547
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         19.0282
eval/env_infos/final/reward_dist Mean         0.777139
eval/env_infos/final/reward_dist Std          0.777431
eval/env_infos/final/reward_dist Max          1.57064
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000406806
eval/env_infos/initial/reward_dist Std        0.00122042
eval/env_infos/initial/reward_dist Max        0.00406806
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.475704
eval/env_infos/reward_dist Std                0.643213
eval/env_infos/reward_dist Max                1.57064
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00638078
time/evaluation sampling (s)                  3.40496
time/exploration sampling (s)                17.3805
time/logging (s)                              0.00533233
time/saving (s)                               0.00237728
time/training (s)                             4.9854
time/epoch (s)                               25.785
time/total (s)                             5676.26
Epoch                                       221
---------------------------------------  ----------------
2023-08-05 01:56:13.789935 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 222 finished
---------------------------------------  ----------------
epoch                                       222
replay_buffer/size                       446000
trainer/QF1 Loss                              1.76457
trainer/QF2 Loss                              1.70639
trainer/Policy Loss                         -11.515
trainer/Q1 Predictions Mean                  10.6092
trainer/Q1 Predictions Std                   10.197
trainer/Q1 Predictions Max                   40.2364
trainer/Q1 Predictions Min                  -15.9932
trainer/Q2 Predictions Mean                  10.6324
trainer/Q2 Predictions Std                   10.2222
trainer/Q2 Predictions Max                   40.4786
trainer/Q2 Predictions Min                  -15.7859
trainer/Q Targets Mean                       10.6261
trainer/Q Targets Std                        10.2996
trainer/Q Targets Max                        42.9135
trainer/Q Targets Min                       -16.4747
trainer/Bellman Errors 1 Mean                 1.76457
trainer/Bellman Errors 1 Std                 11.9848
trainer/Bellman Errors 1 Max                376.175
trainer/Bellman Errors 1 Min                  4.61711e-09
trainer/Bellman Errors 2 Mean                 1.70639
trainer/Bellman Errors 2 Std                 11.5384
trainer/Bellman Errors 2 Max                397.335
trainer/Bellman Errors 2 Min                  2.49113e-08
trainer/Policy Action Mean                    0.386583
trainer/Policy Action Std                     0.779329
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     446000
expl/num paths total                      11150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.779178
expl/Rewards Std                              0.686952
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            31.1671
expl/Returns Std                             16.3176
expl/Returns Max                             42.5607
expl/Returns Min                              0
expl/Actions Mean                             0.458849
expl/Actions Std                              0.693131
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.1671
expl/env_infos/final/reward_dist Mean         1.22366
expl/env_infos/final/reward_dist Std          0.649872
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000863977
expl/env_infos/initial/reward_dist Std        0.00271829
expl/env_infos/initial/reward_dist Max        0.0124431
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.779178
expl/env_infos/reward_dist Std                0.686952
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      89200
eval/num paths total                       2230
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.816441
eval/Rewards Std                              0.686392
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            32.6577
eval/Returns Std                             16.0392
eval/Returns Max                             42.9599
eval/Returns Min                              0.0383739
eval/Actions Mean                             0.468852
eval/Actions Std                              0.725913
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         32.6577
eval/env_infos/final/reward_dist Mean         1.25503
eval/env_infos/final/reward_dist Std          0.627517
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00144765
eval/env_infos/initial/reward_dist Std        0.00298795
eval/env_infos/initial/reward_dist Max        0.0088891
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.816441
eval/env_infos/reward_dist Std                0.686392
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00610913
time/evaluation sampling (s)                  3.40217
time/exploration sampling (s)                17.2171
time/logging (s)                              0.00536726
time/saving (s)                               0.00231111
time/training (s)                             4.67537
time/epoch (s)                               25.3084
time/total (s)                             5701.57
Epoch                                       222
---------------------------------------  ----------------
2023-08-05 01:56:39.126347 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 223 finished
---------------------------------------  ----------------
epoch                                       223
replay_buffer/size                       448000
trainer/QF1 Loss                              1.63562
trainer/QF2 Loss                              1.52305
trainer/Policy Loss                         -11.4618
trainer/Q1 Predictions Mean                  10.6435
trainer/Q1 Predictions Std                   10.164
trainer/Q1 Predictions Max                   39.688
trainer/Q1 Predictions Min                  -25.8774
trainer/Q2 Predictions Mean                  10.5559
trainer/Q2 Predictions Std                   10.1226
trainer/Q2 Predictions Max                   39.5964
trainer/Q2 Predictions Min                  -26.6385
trainer/Q Targets Mean                       10.5141
trainer/Q Targets Std                        10.2293
trainer/Q Targets Max                        40.7993
trainer/Q Targets Min                       -31.8959
trainer/Bellman Errors 1 Mean                 1.63562
trainer/Bellman Errors 1 Std                  9.38028
trainer/Bellman Errors 1 Max                177.214
trainer/Bellman Errors 1 Min                  7.14318e-08
trainer/Bellman Errors 2 Mean                 1.52305
trainer/Bellman Errors 2 Std                  8.6805
trainer/Bellman Errors 2 Max                175.271
trainer/Bellman Errors 2 Min                  8.81087e-08
trainer/Policy Action Mean                    0.381571
trainer/Policy Action Std                     0.780648
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     448000
expl/num paths total                      11200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.748755
expl/Rewards Std                              0.687087
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            29.9502
expl/Returns Std                             17.2109
expl/Returns Max                             43.1201
expl/Returns Min                              0
expl/Actions Mean                             0.437175
expl/Actions Std                              0.713827
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.9502
expl/env_infos/final/reward_dist Mean         1.17764
expl/env_infos/final/reward_dist Std          0.669648
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00130733
expl/env_infos/initial/reward_dist Std        0.00279638
expl/env_infos/initial/reward_dist Max        0.0109421
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.748755
expl/env_infos/reward_dist Std                0.687087
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      89600
eval/num paths total                       2240
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.00588
eval/Rewards Std                              0.625814
eval/Rewards Max                              1.5707
eval/Rewards Min                              0
eval/Returns Mean                            40.2352
eval/Returns Std                              1.47784
eval/Returns Max                             42.6086
eval/Returns Min                             38.2015
eval/Actions Mean                             0.5164
eval/Actions Std                              0.658027
eval/Actions Max                              1
eval/Actions Min                             -0.999986
eval/Num Paths                               10
eval/Average Returns                         40.2352
eval/env_infos/final/reward_dist Mean         1.56895
eval/env_infos/final/reward_dist Std          0.00141801
eval/env_infos/final/reward_dist Max          1.5707
eval/env_infos/final/reward_dist Min          1.56612
eval/env_infos/initial/reward_dist Mean       0.00136116
eval/env_infos/initial/reward_dist Std        0.00408347
eval/env_infos/initial/reward_dist Max        0.0136116
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.00588
eval/env_infos/reward_dist Std                0.625814
eval/env_infos/reward_dist Max                1.5707
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00592367
time/evaluation sampling (s)                  3.42182
time/exploration sampling (s)                17.261
time/logging (s)                              0.00532731
time/saving (s)                               0.00241064
time/training (s)                             4.63685
time/epoch (s)                               25.3334
time/total (s)                             5726.9
Epoch                                       223
---------------------------------------  ----------------
2023-08-05 01:57:04.327481 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 224 finished
---------------------------------------  ----------------
epoch                                       224
replay_buffer/size                       450000
trainer/QF1 Loss                              1.63749
trainer/QF2 Loss                              1.55326
trainer/Policy Loss                         -11.6165
trainer/Q1 Predictions Mean                  10.666
trainer/Q1 Predictions Std                   10.0704
trainer/Q1 Predictions Max                   38.9867
trainer/Q1 Predictions Min                  -31.1787
trainer/Q2 Predictions Mean                  10.6377
trainer/Q2 Predictions Std                   10.0678
trainer/Q2 Predictions Max                   39.1407
trainer/Q2 Predictions Min                  -28.0047
trainer/Q Targets Mean                       10.5909
trainer/Q Targets Std                        10.1432
trainer/Q Targets Max                        40.4747
trainer/Q Targets Min                       -40.0353
trainer/Bellman Errors 1 Mean                 1.63749
trainer/Bellman Errors 1 Std                 10.852
trainer/Bellman Errors 1 Max                343.002
trainer/Bellman Errors 1 Min                  1.30967e-08
trainer/Bellman Errors 2 Mean                 1.55326
trainer/Bellman Errors 2 Std                 10.2517
trainer/Bellman Errors 2 Max                309.787
trainer/Bellman Errors 2 Min                  8.42562e-09
trainer/Policy Action Mean                    0.40023
trainer/Policy Action Std                     0.774308
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     450000
expl/num paths total                      11250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.837252
expl/Rewards Std                              0.677787
expl/Rewards Max                              1.57067
expl/Rewards Min                              0
expl/Returns Mean                            33.4901
expl/Returns Std                             14.4739
expl/Returns Max                             42.7128
expl/Returns Min                              0.000695315
expl/Actions Mean                             0.483114
expl/Actions Std                              0.674489
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         33.4901
expl/env_infos/final/reward_dist Mean         1.31632
expl/env_infos/final/reward_dist Std          0.57459
expl/env_infos/final/reward_dist Max          1.57067
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000332454
expl/env_infos/initial/reward_dist Std        0.00128024
expl/env_infos/initial/reward_dist Max        0.00683571
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.837252
expl/env_infos/reward_dist Std                0.677787
expl/env_infos/reward_dist Max                1.57067
expl/env_infos/reward_dist Min                0
eval/num steps total                      90000
eval/num paths total                       2250
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.818567
eval/Rewards Std                              0.687365
eval/Rewards Max                              1.57068
eval/Rewards Min                              0
eval/Returns Mean                            32.7427
eval/Returns Std                             16.2651
eval/Returns Max                             42.8759
eval/Returns Min                              0.0140493
eval/Actions Mean                             0.505017
eval/Actions Std                              0.690201
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         32.7427
eval/env_infos/final/reward_dist Mean         1.25491
eval/env_infos/final/reward_dist Std          0.627457
eval/env_infos/final/reward_dist Max          1.57068
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00141355
eval/env_infos/initial/reward_dist Std        0.004055
eval/env_infos/initial/reward_dist Max        0.0135679
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.818567
eval/env_infos/reward_dist Std                0.687365
eval/env_infos/reward_dist Max                1.57068
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00663645
time/evaluation sampling (s)                  3.39016
time/exploration sampling (s)                17.3682
time/logging (s)                              0.00531618
time/saving (s)                               0.00233372
time/training (s)                             4.42545
time/epoch (s)                               25.1981
time/total (s)                             5752.1
Epoch                                       224
---------------------------------------  ----------------
2023-08-05 01:57:29.793883 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 225 finished
---------------------------------------  ----------------
epoch                                       225
replay_buffer/size                       452000
trainer/QF1 Loss                              1.53976
trainer/QF2 Loss                              1.50465
trainer/Policy Loss                         -11.3163
trainer/Q1 Predictions Mean                  10.4293
trainer/Q1 Predictions Std                   10.0018
trainer/Q1 Predictions Max                   39.7295
trainer/Q1 Predictions Min                  -33.5321
trainer/Q2 Predictions Mean                  10.4008
trainer/Q2 Predictions Std                    9.98863
trainer/Q2 Predictions Max                   40.0387
trainer/Q2 Predictions Min                  -35.8027
trainer/Q Targets Mean                       10.3472
trainer/Q Targets Std                        10.0406
trainer/Q Targets Max                        40.462
trainer/Q Targets Min                       -33.1205
trainer/Bellman Errors 1 Mean                 1.53976
trainer/Bellman Errors 1 Std                  9.38578
trainer/Bellman Errors 1 Max                257.211
trainer/Bellman Errors 1 Min                  1.06083e-08
trainer/Bellman Errors 2 Mean                 1.50465
trainer/Bellman Errors 2 Std                  9.54429
trainer/Bellman Errors 2 Max                242.138
trainer/Bellman Errors 2 Min                  1.27216e-07
trainer/Policy Action Mean                    0.385015
trainer/Policy Action Std                     0.779721
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     452000
expl/num paths total                      11300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.667778
expl/Rewards Std                              0.691222
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            26.7111
expl/Returns Std                             18.9237
expl/Returns Max                             42.5288
expl/Returns Min                              0
expl/Actions Mean                             0.426634
expl/Actions Std                              0.717383
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.7111
expl/env_infos/final/reward_dist Mean         1.0351
expl/env_infos/final/reward_dist Std          0.742928
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000851608
expl/env_infos/initial/reward_dist Std        0.00241083
expl/env_infos/initial/reward_dist Max        0.0125393
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.667778
expl/env_infos/reward_dist Std                0.691222
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      90400
eval/num paths total                       2260
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.00341
eval/Rewards Std                              0.627774
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            40.1365
eval/Returns Std                              1.60013
eval/Returns Max                             42.8555
eval/Returns Min                             38.1991
eval/Actions Mean                             0.533883
eval/Actions Std                              0.642212
eval/Actions Max                              1
eval/Actions Min                             -0.999968
eval/Num Paths                               10
eval/Average Returns                         40.1365
eval/env_infos/final/reward_dist Mean         1.56838
eval/env_infos/final/reward_dist Std          0.00351141
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          1.55881
eval/env_infos/initial/reward_dist Mean       0.00155153
eval/env_infos/initial/reward_dist Std        0.00357782
eval/env_infos/initial/reward_dist Max        0.01174
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.00341
eval/env_infos/reward_dist Std                0.627774
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00628768
time/evaluation sampling (s)                  3.46165
time/exploration sampling (s)                17.0458
time/logging (s)                              0.00534582
time/saving (s)                               0.00245085
time/training (s)                             4.94176
time/epoch (s)                               25.4633
time/total (s)                             5777.57
Epoch                                       225
---------------------------------------  ----------------
2023-08-05 01:57:55.457635 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 226 finished
---------------------------------------  ----------------
epoch                                       226
replay_buffer/size                       454000
trainer/QF1 Loss                              1.59265
trainer/QF2 Loss                              1.51725
trainer/Policy Loss                         -11.4863
trainer/Q1 Predictions Mean                  10.4533
trainer/Q1 Predictions Std                   10.1742
trainer/Q1 Predictions Max                   39.7103
trainer/Q1 Predictions Min                  -18.0482
trainer/Q2 Predictions Mean                  10.4857
trainer/Q2 Predictions Std                   10.1962
trainer/Q2 Predictions Max                   39.8536
trainer/Q2 Predictions Min                  -17.2785
trainer/Q Targets Mean                       10.4812
trainer/Q Targets Std                        10.275
trainer/Q Targets Max                        40.4902
trainer/Q Targets Min                       -25.7673
trainer/Bellman Errors 1 Mean                 1.59265
trainer/Bellman Errors 1 Std                  8.6159
trainer/Bellman Errors 1 Max                192.842
trainer/Bellman Errors 1 Min                  1.1285e-07
trainer/Bellman Errors 2 Mean                 1.51725
trainer/Bellman Errors 2 Std                  8.29248
trainer/Bellman Errors 2 Max                182.871
trainer/Bellman Errors 2 Min                  3.69275e-08
trainer/Policy Action Mean                    0.366118
trainer/Policy Action Std                     0.782589
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     454000
expl/num paths total                      11350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.854594
expl/Rewards Std                              0.676189
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            34.1838
expl/Returns Std                             14.6894
expl/Returns Max                             43.165
expl/Returns Min                              0
expl/Actions Mean                             0.434229
expl/Actions Std                              0.699523
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         34.1838
expl/env_infos/final/reward_dist Mean         1.31785
expl/env_infos/final/reward_dist Std          0.575159
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00139152
expl/env_infos/initial/reward_dist Std        0.00329891
expl/env_infos/initial/reward_dist Max        0.0148544
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.854594
expl/env_infos/reward_dist Std                0.676189
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      90800
eval/num paths total                       2270
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.01638
eval/Rewards Std                              0.621852
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            40.6553
eval/Returns Std                              0.947381
eval/Returns Max                             41.8837
eval/Returns Min                             38.8173
eval/Actions Mean                             0.484557
eval/Actions Std                              0.676886
eval/Actions Max                              1
eval/Actions Min                             -0.999976
eval/Num Paths                               10
eval/Average Returns                         40.6553
eval/env_infos/final/reward_dist Mean         1.5692
eval/env_infos/final/reward_dist Std          0.00149876
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          1.56636
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.01638
eval/env_infos/reward_dist Std                0.621852
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00933337
time/evaluation sampling (s)                  3.46169
time/exploration sampling (s)                17.511
time/logging (s)                              0.00531523
time/saving (s)                               0.00236643
time/training (s)                             4.67101
time/epoch (s)                               25.6607
time/total (s)                             5803.23
Epoch                                       226
---------------------------------------  ----------------
2023-08-05 01:58:20.858788 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 227 finished
---------------------------------------  ----------------
epoch                                       227
replay_buffer/size                       456000
trainer/QF1 Loss                              1.56168
trainer/QF2 Loss                              1.51925
trainer/Policy Loss                         -11.5715
trainer/Q1 Predictions Mean                  10.5646
trainer/Q1 Predictions Std                   10.0685
trainer/Q1 Predictions Max                   40.1204
trainer/Q1 Predictions Min                  -18.7442
trainer/Q2 Predictions Mean                  10.4795
trainer/Q2 Predictions Std                   10.0473
trainer/Q2 Predictions Max                   40.3361
trainer/Q2 Predictions Min                  -17.6462
trainer/Q Targets Mean                       10.5099
trainer/Q Targets Std                        10.1448
trainer/Q Targets Max                        41.0891
trainer/Q Targets Min                       -17.3027
trainer/Bellman Errors 1 Mean                 1.56168
trainer/Bellman Errors 1 Std                 10.5651
trainer/Bellman Errors 1 Max                346.83
trainer/Bellman Errors 1 Min                  1.35925e-08
trainer/Bellman Errors 2 Mean                 1.51925
trainer/Bellman Errors 2 Std                 10.0397
trainer/Bellman Errors 2 Max                343.587
trainer/Bellman Errors 2 Min                  1.60817e-07
trainer/Policy Action Mean                    0.36576
trainer/Policy Action Std                     0.777069
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     456000
expl/num paths total                      11400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.796357
expl/Rewards Std                              0.685423
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            31.8543
expl/Returns Std                             15.6337
expl/Returns Max                             42.4938
expl/Returns Min                              0
expl/Actions Mean                             0.433897
expl/Actions Std                              0.696176
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.8543
expl/env_infos/final/reward_dist Mean         1.25466
expl/env_infos/final/reward_dist Std          0.627335
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00100866
expl/env_infos/initial/reward_dist Std        0.00305322
expl/env_infos/initial/reward_dist Max        0.0132732
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.796357
expl/env_infos/reward_dist Std                0.685423
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      91200
eval/num paths total                       2280
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.708617
eval/Rewards Std                              0.696432
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            28.3447
eval/Returns Std                             18.3325
eval/Returns Max                             41.7211
eval/Returns Min                              0
eval/Actions Mean                             0.352055
eval/Actions Std                              0.771729
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.3447
eval/env_infos/final/reward_dist Mean         1.098
eval/env_infos/final/reward_dist Std          0.718814
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00031768
eval/env_infos/initial/reward_dist Std        0.000953039
eval/env_infos/initial/reward_dist Max        0.0031768
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.708617
eval/env_infos/reward_dist Std                0.696432
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00806714
time/evaluation sampling (s)                  3.3781
time/exploration sampling (s)                17.3629
time/logging (s)                              0.0053677
time/saving (s)                               0.00252861
time/training (s)                             4.64118
time/epoch (s)                               25.3982
time/total (s)                             5828.63
Epoch                                       227
---------------------------------------  ----------------
2023-08-05 01:58:46.609844 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 228 finished
---------------------------------------  ----------------
epoch                                       228
replay_buffer/size                       458000
trainer/QF1 Loss                              1.26042
trainer/QF2 Loss                              1.27621
trainer/Policy Loss                         -11.4787
trainer/Q1 Predictions Mean                  10.5242
trainer/Q1 Predictions Std                    9.86809
trainer/Q1 Predictions Max                   38.6821
trainer/Q1 Predictions Min                  -17.1159
trainer/Q2 Predictions Mean                  10.4973
trainer/Q2 Predictions Std                    9.84124
trainer/Q2 Predictions Max                   38.7094
trainer/Q2 Predictions Min                  -17.1385
trainer/Q Targets Mean                       10.4908
trainer/Q Targets Std                         9.91002
trainer/Q Targets Max                        40.2421
trainer/Q Targets Min                       -17.5645
trainer/Bellman Errors 1 Mean                 1.26042
trainer/Bellman Errors 1 Std                  7.17867
trainer/Bellman Errors 1 Max                202.225
trainer/Bellman Errors 1 Min                  9.38613e-08
trainer/Bellman Errors 2 Mean                 1.27621
trainer/Bellman Errors 2 Std                  7.38835
trainer/Bellman Errors 2 Max                214.488
trainer/Bellman Errors 2 Min                  2.69065e-08
trainer/Policy Action Mean                    0.355259
trainer/Policy Action Std                     0.781803
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     458000
expl/num paths total                      11450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.719208
expl/Rewards Std                              0.688979
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            28.7683
expl/Returns Std                             17.5982
expl/Returns Max                             42.6828
expl/Returns Min                              0
expl/Actions Mean                             0.419393
expl/Actions Std                              0.714996
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         28.7683
expl/env_infos/final/reward_dist Mean         1.12825
expl/env_infos/final/reward_dist Std          0.703552
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000926005
expl/env_infos/initial/reward_dist Std        0.00256684
expl/env_infos/initial/reward_dist Max        0.0105357
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.719208
expl/env_infos/reward_dist Std                0.688979
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      91600
eval/num paths total                       2290
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.871251
eval/Rewards Std                              0.664197
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            34.8501
eval/Returns Std                             12.8671
eval/Returns Max                             42.5043
eval/Returns Min                              0.000542381
eval/Actions Mean                             0.453887
eval/Actions Std                              0.710955
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         34.8501
eval/env_infos/final/reward_dist Mean         1.40186
eval/env_infos/final/reward_dist Std          0.46804
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0.000160493
eval/env_infos/initial/reward_dist Mean       0.00241804
eval/env_infos/initial/reward_dist Std        0.00426164
eval/env_infos/initial/reward_dist Max        0.0134327
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.871251
eval/env_infos/reward_dist Std                0.664197
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00813159
time/evaluation sampling (s)                  3.5003
time/exploration sampling (s)                17.5244
time/logging (s)                              0.00741073
time/saving (s)                               0.00268533
time/training (s)                             4.70726
time/epoch (s)                               25.7502
time/total (s)                             5854.38
Epoch                                       228
---------------------------------------  ----------------
2023-08-05 01:59:12.317388 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 229 finished
---------------------------------------  ----------------
epoch                                       229
replay_buffer/size                       460000
trainer/QF1 Loss                              1.43212
trainer/QF2 Loss                              1.38147
trainer/Policy Loss                         -11.128
trainer/Q1 Predictions Mean                  10.0435
trainer/Q1 Predictions Std                    9.94638
trainer/Q1 Predictions Max                   39.7766
trainer/Q1 Predictions Min                  -21.9475
trainer/Q2 Predictions Mean                  10.0601
trainer/Q2 Predictions Std                    9.94982
trainer/Q2 Predictions Max                   40.3244
trainer/Q2 Predictions Min                  -21.4473
trainer/Q Targets Mean                       10.0885
trainer/Q Targets Std                        10.0048
trainer/Q Targets Max                        40.1593
trainer/Q Targets Min                       -22.7876
trainer/Bellman Errors 1 Mean                 1.43212
trainer/Bellman Errors 1 Std                  8.6665
trainer/Bellman Errors 1 Max                220.128
trainer/Bellman Errors 1 Min                  5.23869e-08
trainer/Bellman Errors 2 Mean                 1.38147
trainer/Bellman Errors 2 Std                  8.47849
trainer/Bellman Errors 2 Max                235.884
trainer/Bellman Errors 2 Min                  6.14818e-08
trainer/Policy Action Mean                    0.350488
trainer/Policy Action Std                     0.779859
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     460000
expl/num paths total                      11500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.771221
expl/Rewards Std                              0.682197
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            30.8488
expl/Returns Std                             16.231
expl/Returns Max                             42.5997
expl/Returns Min                              0
expl/Actions Mean                             0.416935
expl/Actions Std                              0.715789
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.8488
expl/env_infos/final/reward_dist Mean         1.2205
expl/env_infos/final/reward_dist Std          0.648365
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000607058
expl/env_infos/initial/reward_dist Std        0.00201492
expl/env_infos/initial/reward_dist Max        0.0131299
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.771221
expl/env_infos/reward_dist Std                0.682197
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                      92000
eval/num paths total                       2300
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.00466
eval/Rewards Std                              0.622891
eval/Rewards Max                              1.5705
eval/Rewards Min                              0
eval/Returns Mean                            40.1863
eval/Returns Std                              1.33552
eval/Returns Max                             42.3271
eval/Returns Min                             38.0854
eval/Actions Mean                             0.449077
eval/Actions Std                              0.692335
eval/Actions Max                              1
eval/Actions Min                             -0.999989
eval/Num Paths                               10
eval/Average Returns                         40.1863
eval/env_infos/final/reward_dist Mean         1.56774
eval/env_infos/final/reward_dist Std          0.00254127
eval/env_infos/final/reward_dist Max          1.5705
eval/env_infos/final/reward_dist Min          1.56359
eval/env_infos/initial/reward_dist Mean       0.00119257
eval/env_infos/initial/reward_dist Std        0.00357771
eval/env_infos/initial/reward_dist Max        0.0119257
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.00466
eval/env_infos/reward_dist Std                0.622891
eval/env_infos/reward_dist Max                1.5705
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00813746
time/evaluation sampling (s)                  3.46077
time/exploration sampling (s)                17.5412
time/logging (s)                              0.00534129
time/saving (s)                               0.00246687
time/training (s)                             4.68226
time/epoch (s)                               25.7002
time/total (s)                             5880.09
Epoch                                       229
---------------------------------------  ----------------
2023-08-05 01:59:37.949675 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 230 finished
---------------------------------------  ----------------
epoch                                       230
replay_buffer/size                       462000
trainer/QF1 Loss                              1.56913
trainer/QF2 Loss                              1.52211
trainer/Policy Loss                         -11.1085
trainer/Q1 Predictions Mean                  10.0786
trainer/Q1 Predictions Std                   10.1081
trainer/Q1 Predictions Max                   39.3388
trainer/Q1 Predictions Min                  -25.0363
trainer/Q2 Predictions Mean                  10.0629
trainer/Q2 Predictions Std                   10.0926
trainer/Q2 Predictions Max                   39.5211
trainer/Q2 Predictions Min                  -23.7476
trainer/Q Targets Mean                       10.0166
trainer/Q Targets Std                        10.1457
trainer/Q Targets Max                        39.9097
trainer/Q Targets Min                       -26.6872
trainer/Bellman Errors 1 Mean                 1.56913
trainer/Bellman Errors 1 Std                 11.042
trainer/Bellman Errors 1 Max                287.214
trainer/Bellman Errors 1 Min                  6.14818e-08
trainer/Bellman Errors 2 Mean                 1.52211
trainer/Bellman Errors 2 Std                 10.4753
trainer/Bellman Errors 2 Max                271.695
trainer/Bellman Errors 2 Min                  6.41739e-09
trainer/Policy Action Mean                    0.342494
trainer/Policy Action Std                     0.790006
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     462000
expl/num paths total                      11550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.813827
expl/Rewards Std                              0.678245
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            32.5531
expl/Returns Std                             15.0442
expl/Returns Max                             43.7611
expl/Returns Min                              0
expl/Actions Mean                             0.400154
expl/Actions Std                              0.717876
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.5531
expl/env_infos/final/reward_dist Mean         1.28445
expl/env_infos/final/reward_dist Std          0.601925
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000964339
expl/env_infos/initial/reward_dist Std        0.00251485
expl/env_infos/initial/reward_dist Max        0.0125769
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.813827
expl/env_infos/reward_dist Std                0.678245
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      92400
eval/num paths total                       2310
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.904608
eval/Rewards Std                              0.661295
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            36.1843
eval/Returns Std                             11.8664
eval/Returns Max                             42.4251
eval/Returns Min                              0.848793
eval/Actions Mean                             0.442902
eval/Actions Std                              0.707932
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         36.1843
eval/env_infos/final/reward_dist Mean         1.4122
eval/env_infos/final/reward_dist Std          0.470737
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000917626
eval/env_infos/initial/reward_dist Std        0.00217707
eval/env_infos/initial/reward_dist Max        0.00735186
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.904608
eval/env_infos/reward_dist Std                0.661295
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00582626
time/evaluation sampling (s)                  3.47818
time/exploration sampling (s)                17.445
time/logging (s)                              0.00536961
time/saving (s)                               0.00240247
time/training (s)                             4.69252
time/epoch (s)                               25.6293
time/total (s)                             5905.72
Epoch                                       230
---------------------------------------  ----------------
2023-08-05 02:00:03.429542 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 231 finished
---------------------------------------  ----------------
epoch                                       231
replay_buffer/size                       464000
trainer/QF1 Loss                              1.47477
trainer/QF2 Loss                              1.48447
trainer/Policy Loss                         -11.0945
trainer/Q1 Predictions Mean                  10.1731
trainer/Q1 Predictions Std                   10.0202
trainer/Q1 Predictions Max                   38.995
trainer/Q1 Predictions Min                  -60.0727
trainer/Q2 Predictions Mean                  10.1926
trainer/Q2 Predictions Std                   10.0353
trainer/Q2 Predictions Max                   39.1763
trainer/Q2 Predictions Min                  -61.0173
trainer/Q Targets Mean                       10.1632
trainer/Q Targets Std                        10.0666
trainer/Q Targets Max                        40.265
trainer/Q Targets Min                       -57.5395
trainer/Bellman Errors 1 Mean                 1.47477
trainer/Bellman Errors 1 Std                  9.85066
trainer/Bellman Errors 1 Max                251.987
trainer/Bellman Errors 1 Min                  2.21335e-08
trainer/Bellman Errors 2 Mean                 1.48447
trainer/Bellman Errors 2 Std                 10.1382
trainer/Bellman Errors 2 Max                269.093
trainer/Bellman Errors 2 Min                  4.0288e-08
trainer/Policy Action Mean                    0.334212
trainer/Policy Action Std                     0.791756
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     464000
expl/num paths total                      11600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.753331
expl/Rewards Std                              0.686354
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            30.1332
expl/Returns Std                             16.9282
expl/Returns Max                             42.3317
expl/Returns Min                              0
expl/Actions Mean                             0.384887
expl/Actions Std                              0.73032
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.1332
expl/env_infos/final/reward_dist Mean         1.19087
expl/env_infos/final/reward_dist Std          0.66924
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000565652
expl/env_infos/initial/reward_dist Std        0.00195277
expl/env_infos/initial/reward_dist Max        0.0106874
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.753331
expl/env_infos/reward_dist Std                0.686354
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      92800
eval/num paths total                       2320
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.910659
eval/Rewards Std                              0.661284
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            36.4264
eval/Returns Std                             12.0167
eval/Returns Max                             42.2483
eval/Returns Min                              0.615278
eval/Actions Mean                             0.425902
eval/Actions Std                              0.723002
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         36.4264
eval/env_infos/final/reward_dist Mean         1.41063
eval/env_infos/final/reward_dist Std          0.47022
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00044674
eval/env_infos/initial/reward_dist Std        0.00134022
eval/env_infos/initial/reward_dist Max        0.0044674
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.910659
eval/env_infos/reward_dist Std                0.661284
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00586695
time/evaluation sampling (s)                  3.44882
time/exploration sampling (s)                17.3531
time/logging (s)                              0.00533956
time/saving (s)                               0.00246042
time/training (s)                             4.66116
time/epoch (s)                               25.4768
time/total (s)                             5931.2
Epoch                                       231
---------------------------------------  ----------------
2023-08-05 02:00:29.455211 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 232 finished
---------------------------------------  ----------------
epoch                                       232
replay_buffer/size                       466000
trainer/QF1 Loss                              1.37873
trainer/QF2 Loss                              1.37699
trainer/Policy Loss                         -10.9097
trainer/Q1 Predictions Mean                   9.93494
trainer/Q1 Predictions Std                   10.037
trainer/Q1 Predictions Max                   39.447
trainer/Q1 Predictions Min                  -23.3582
trainer/Q2 Predictions Mean                   9.91388
trainer/Q2 Predictions Std                   10.0338
trainer/Q2 Predictions Max                   39.4037
trainer/Q2 Predictions Min                  -23.066
trainer/Q Targets Mean                        9.94027
trainer/Q Targets Std                        10.1235
trainer/Q Targets Max                        39.6827
trainer/Q Targets Min                       -25.3789
trainer/Bellman Errors 1 Mean                 1.37873
trainer/Bellman Errors 1 Std                  9.03026
trainer/Bellman Errors 1 Max                332.07
trainer/Bellman Errors 1 Min                  3.35276e-08
trainer/Bellman Errors 2 Mean                 1.37699
trainer/Bellman Errors 2 Std                  9.26683
trainer/Bellman Errors 2 Max                339.521
trainer/Bellman Errors 2 Min                  5.59376e-08
trainer/Policy Action Mean                    0.335102
trainer/Policy Action Std                     0.787486
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     466000
expl/num paths total                      11650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.848773
expl/Rewards Std                              0.669635
expl/Rewards Max                              1.57074
expl/Rewards Min                              0
expl/Returns Mean                            33.9509
expl/Returns Std                             13.6445
expl/Returns Max                             42.2083
expl/Returns Min                              0
expl/Actions Mean                             0.402218
expl/Actions Std                              0.72019
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         33.9509
expl/env_infos/final/reward_dist Mean         1.34553
expl/env_infos/final/reward_dist Std          0.543103
expl/env_infos/final/reward_dist Max          1.57074
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000695564
expl/env_infos/initial/reward_dist Std        0.0019862
expl/env_infos/initial/reward_dist Max        0.0110202
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.848773
expl/env_infos/reward_dist Std                0.669635
expl/env_infos/reward_dist Max                1.57074
expl/env_infos/reward_dist Min                0
eval/num steps total                      93200
eval/num paths total                       2330
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.01091
eval/Rewards Std                              0.618104
eval/Rewards Max                              1.57016
eval/Rewards Min                              0
eval/Returns Mean                            40.4366
eval/Returns Std                              1.3896
eval/Returns Max                             42.6638
eval/Returns Min                             38.5743
eval/Actions Mean                             0.42925
eval/Actions Std                              0.709429
eval/Actions Max                              1
eval/Actions Min                             -0.999987
eval/Num Paths                               10
eval/Average Returns                         40.4366
eval/env_infos/final/reward_dist Mean         1.56881
eval/env_infos/final/reward_dist Std          0.00129421
eval/env_infos/final/reward_dist Max          1.57016
eval/env_infos/final/reward_dist Min          1.56619
eval/env_infos/initial/reward_dist Mean       0.0031613
eval/env_infos/initial/reward_dist Std        0.00505968
eval/env_infos/initial/reward_dist Max        0.0138958
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.01091
eval/env_infos/reward_dist Std                0.618104
eval/env_infos/reward_dist Max                1.57016
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00682093
time/evaluation sampling (s)                  3.48797
time/exploration sampling (s)                17.8683
time/logging (s)                              0.00534688
time/saving (s)                               0.00232129
time/training (s)                             4.65187
time/epoch (s)                               26.0226
time/total (s)                             5957.22
Epoch                                       232
---------------------------------------  ----------------
2023-08-05 02:00:55.594694 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 233 finished
---------------------------------------  ----------------
epoch                                       233
replay_buffer/size                       468000
trainer/QF1 Loss                              1.19002
trainer/QF2 Loss                              1.12991
trainer/Policy Loss                         -10.9471
trainer/Q1 Predictions Mean                   9.91555
trainer/Q1 Predictions Std                   10.1306
trainer/Q1 Predictions Max                   38.9005
trainer/Q1 Predictions Min                  -21.2724
trainer/Q2 Predictions Mean                   9.93346
trainer/Q2 Predictions Std                   10.1322
trainer/Q2 Predictions Max                   39.1037
trainer/Q2 Predictions Min                  -21.1281
trainer/Q Targets Mean                       10.01
trainer/Q Targets Std                        10.257
trainer/Q Targets Max                        38.7826
trainer/Q Targets Min                       -21.7932
trainer/Bellman Errors 1 Mean                 1.19002
trainer/Bellman Errors 1 Std                  5.73248
trainer/Bellman Errors 1 Max                164.636
trainer/Bellman Errors 1 Min                  4.82431e-10
trainer/Bellman Errors 2 Mean                 1.12991
trainer/Bellman Errors 2 Std                  5.81504
trainer/Bellman Errors 2 Max                190.589
trainer/Bellman Errors 2 Min                  2.5517e-10
trainer/Policy Action Mean                    0.324457
trainer/Policy Action Std                     0.794053
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     468000
expl/num paths total                      11700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.739726
expl/Rewards Std                              0.685467
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            29.5891
expl/Returns Std                             17.3312
expl/Returns Max                             42.3748
expl/Returns Min                              0
expl/Actions Mean                             0.354428
expl/Actions Std                              0.745072
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.5891
expl/env_infos/final/reward_dist Mean         1.15909
expl/env_infos/final/reward_dist Std          0.687154
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000745654
expl/env_infos/initial/reward_dist Std        0.00202937
expl/env_infos/initial/reward_dist Max        0.00840099
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.739726
expl/env_infos/reward_dist Std                0.685467
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      93600
eval/num paths total                       2340
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.800517
eval/Rewards Std                              0.683332
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            32.0207
eval/Returns Std                             15.8254
eval/Returns Max                             41.9615
eval/Returns Min                              0
eval/Actions Mean                             0.419506
eval/Actions Std                              0.727228
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         32.0207
eval/env_infos/final/reward_dist Mean         1.25575
eval/env_infos/final/reward_dist Std          0.627878
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00169675
eval/env_infos/initial/reward_dist Std        0.00412135
eval/env_infos/initial/reward_dist Max        0.0138381
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.800517
eval/env_infos/reward_dist Std                0.683332
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00580663
time/evaluation sampling (s)                  3.55632
time/exploration sampling (s)                18.1052
time/logging (s)                              0.00537902
time/saving (s)                               0.00238246
time/training (s)                             4.46125
time/epoch (s)                               26.1363
time/total (s)                             5983.36
Epoch                                       233
---------------------------------------  ----------------
2023-08-05 02:01:21.597346 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 234 finished
---------------------------------------  ----------------
epoch                                       234
replay_buffer/size                       470000
trainer/QF1 Loss                              2.07988
trainer/QF2 Loss                              2.04713
trainer/Policy Loss                         -10.839
trainer/Q1 Predictions Mean                  10.0019
trainer/Q1 Predictions Std                   10.451
trainer/Q1 Predictions Max                   39.0148
trainer/Q1 Predictions Min                  -24.5191
trainer/Q2 Predictions Mean                   9.96268
trainer/Q2 Predictions Std                   10.4231
trainer/Q2 Predictions Max                   39.1883
trainer/Q2 Predictions Min                  -24.8731
trainer/Q Targets Mean                        9.82236
trainer/Q Targets Std                        10.4932
trainer/Q Targets Max                        39.8117
trainer/Q Targets Min                       -23.4119
trainer/Bellman Errors 1 Mean                 2.07988
trainer/Bellman Errors 1 Std                 14.2508
trainer/Bellman Errors 1 Max                334.311
trainer/Bellman Errors 1 Min                  8.18545e-10
trainer/Bellman Errors 2 Mean                 2.04713
trainer/Bellman Errors 2 Std                 14.2722
trainer/Bellman Errors 2 Max                341.409
trainer/Bellman Errors 2 Min                  3.27418e-09
trainer/Policy Action Mean                    0.330048
trainer/Policy Action Std                     0.79069
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     470000
expl/num paths total                      11750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.760351
expl/Rewards Std                              0.68195
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            30.414
expl/Returns Std                             16.7737
expl/Returns Max                             42.5201
expl/Returns Min                              0
expl/Actions Mean                             0.384527
expl/Actions Std                              0.72858
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.414
expl/env_infos/final/reward_dist Mean         1.19085
expl/env_infos/final/reward_dist Std          0.669285
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00165693
expl/env_infos/initial/reward_dist Std        0.00348419
expl/env_infos/initial/reward_dist Max        0.0137016
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.760351
expl/env_infos/reward_dist Std                0.68195
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      94000
eval/num paths total                       2350
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.598826
eval/Rewards Std                              0.683753
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            23.9531
eval/Returns Std                             19.447
eval/Returns Max                             42.3541
eval/Returns Min                              0
eval/Actions Mean                             0.364302
eval/Actions Std                              0.745571
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         23.9531
eval/env_infos/final/reward_dist Mean         0.941985
eval/env_infos/final/reward_dist Std          0.768991
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00014167
eval/env_infos/initial/reward_dist Std        0.00042501
eval/env_infos/initial/reward_dist Max        0.0014167
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.598826
eval/env_infos/reward_dist Std                0.683753
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00581178
time/evaluation sampling (s)                  3.41569
time/exploration sampling (s)                17.9274
time/logging (s)                              0.00743479
time/saving (s)                               0.00271843
time/training (s)                             4.64251
time/epoch (s)                               26.0015
time/total (s)                             6009.36
Epoch                                       234
---------------------------------------  ----------------
2023-08-05 02:01:46.859074 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 235 finished
---------------------------------------  ----------------
epoch                                       235
replay_buffer/size                       472000
trainer/QF1 Loss                              1.48571
trainer/QF2 Loss                              1.44511
trainer/Policy Loss                         -10.8932
trainer/Q1 Predictions Mean                  10.0052
trainer/Q1 Predictions Std                   10.4034
trainer/Q1 Predictions Max                   39.0546
trainer/Q1 Predictions Min                  -25.2117
trainer/Q2 Predictions Mean                   9.98536
trainer/Q2 Predictions Std                   10.3873
trainer/Q2 Predictions Max                   39.2942
trainer/Q2 Predictions Min                  -24.8462
trainer/Q Targets Mean                        9.93017
trainer/Q Targets Std                        10.4569
trainer/Q Targets Max                        39.0984
trainer/Q Targets Min                       -23.8416
trainer/Bellman Errors 1 Mean                 1.48571
trainer/Bellman Errors 1 Std                  9.9239
trainer/Bellman Errors 1 Max                280.727
trainer/Bellman Errors 1 Min                  7.13044e-08
trainer/Bellman Errors 2 Mean                 1.44511
trainer/Bellman Errors 2 Std                  9.60678
trainer/Bellman Errors 2 Max                282.003
trainer/Bellman Errors 2 Min                  0
trainer/Policy Action Mean                    0.323052
trainer/Policy Action Std                     0.790925
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     472000
expl/num paths total                      11800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.669042
expl/Rewards Std                              0.683675
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            26.7617
expl/Returns Std                             18.2111
expl/Returns Max                             43.1232
expl/Returns Min                              0
expl/Actions Mean                             0.367752
expl/Actions Std                              0.745894
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.7617
expl/env_infos/final/reward_dist Mean         1.06482
expl/env_infos/final/reward_dist Std          0.730562
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000865355
expl/env_infos/initial/reward_dist Std        0.00240227
expl/env_infos/initial/reward_dist Max        0.0090794
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.669042
expl/env_infos/reward_dist Std                0.683675
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      94400
eval/num paths total                       2360
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.721543
eval/Rewards Std                              0.687835
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            28.8617
eval/Returns Std                             18.4911
eval/Returns Max                             42.5105
eval/Returns Min                              0.113807
eval/Actions Mean                             0.373294
eval/Actions Std                              0.764196
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.8617
eval/env_infos/final/reward_dist Mean         1.09824
eval/env_infos/final/reward_dist Std          0.718228
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00280499
eval/env_infos/initial/reward_dist Std        0.00430635
eval/env_infos/initial/reward_dist Max        0.0104502
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.721543
eval/env_infos/reward_dist Std                0.687835
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585191
time/evaluation sampling (s)                  3.44544
time/exploration sampling (s)                17.1857
time/logging (s)                              0.00530831
time/saving (s)                               0.00237208
time/training (s)                             4.60964
time/epoch (s)                               25.2543
time/total (s)                             6034.62
Epoch                                       235
---------------------------------------  ----------------
2023-08-05 02:02:12.957294 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 236 finished
---------------------------------------  ----------------
epoch                                       236
replay_buffer/size                       474000
trainer/QF1 Loss                              1.50449
trainer/QF2 Loss                              1.44697
trainer/Policy Loss                         -10.5821
trainer/Q1 Predictions Mean                   9.82486
trainer/Q1 Predictions Std                   10.4376
trainer/Q1 Predictions Max                   39.6018
trainer/Q1 Predictions Min                  -26.8461
trainer/Q2 Predictions Mean                   9.79401
trainer/Q2 Predictions Std                   10.4609
trainer/Q2 Predictions Max                   39.7913
trainer/Q2 Predictions Min                  -26.0113
trainer/Q Targets Mean                        9.69167
trainer/Q Targets Std                        10.4758
trainer/Q Targets Max                        40.0002
trainer/Q Targets Min                       -25.6373
trainer/Bellman Errors 1 Mean                 1.50449
trainer/Bellman Errors 1 Std                  9.11706
trainer/Bellman Errors 1 Max                268.79
trainer/Bellman Errors 1 Min                  9.21752e-08
trainer/Bellman Errors 2 Mean                 1.44697
trainer/Bellman Errors 2 Std                  8.59937
trainer/Bellman Errors 2 Max                255.422
trainer/Bellman Errors 2 Min                  1.94126e-07
trainer/Policy Action Mean                    0.308175
trainer/Policy Action Std                     0.794368
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     474000
expl/num paths total                      11850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.80518
expl/Rewards Std                              0.671038
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            32.2072
expl/Returns Std                             14.9811
expl/Returns Max                             41.4872
expl/Returns Min                              0
expl/Actions Mean                             0.34864
expl/Actions Std                              0.745855
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.2072
expl/env_infos/final/reward_dist Mean         1.28663
expl/env_infos/final/reward_dist Std          0.602779
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00102072
expl/env_infos/initial/reward_dist Std        0.00237853
expl/env_infos/initial/reward_dist Max        0.00982924
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.80518
expl/env_infos/reward_dist Std                0.671038
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      94800
eval/num paths total                       2370
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.79999
eval/Rewards Std                              0.671619
eval/Rewards Max                              1.57049
eval/Rewards Min                              0
eval/Returns Mean                            31.9996
eval/Returns Std                             15.6098
eval/Returns Max                             41.7785
eval/Returns Min                              0.734509
eval/Actions Mean                             0.377362
eval/Actions Std                              0.754967
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.9996
eval/env_infos/final/reward_dist Mean         1.25498
eval/env_infos/final/reward_dist Std          0.627493
eval/env_infos/final/reward_dist Max          1.57049
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00185938
eval/env_infos/initial/reward_dist Std        0.00289144
eval/env_infos/initial/reward_dist Max        0.0075693
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.79999
eval/env_infos/reward_dist Std                0.671619
eval/env_infos/reward_dist Max                1.57049
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00585081
time/evaluation sampling (s)                  3.39797
time/exploration sampling (s)                17.9706
time/logging (s)                              0.00535823
time/saving (s)                               0.00234206
time/training (s)                             4.7131
time/epoch (s)                               26.0952
time/total (s)                             6060.72
Epoch                                       236
---------------------------------------  ----------------
2023-08-05 02:02:38.597772 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 237 finished
---------------------------------------  ----------------
epoch                                       237
replay_buffer/size                       476000
trainer/QF1 Loss                              1.42307
trainer/QF2 Loss                              1.3734
trainer/Policy Loss                         -10.9806
trainer/Q1 Predictions Mean                   9.99895
trainer/Q1 Predictions Std                   10.5378
trainer/Q1 Predictions Max                   38.9854
trainer/Q1 Predictions Min                  -27.2224
trainer/Q2 Predictions Mean                  10.008
trainer/Q2 Predictions Std                   10.5493
trainer/Q2 Predictions Max                   39.2969
trainer/Q2 Predictions Min                  -27.1328
trainer/Q Targets Mean                       10.0093
trainer/Q Targets Std                        10.6093
trainer/Q Targets Max                        39.8473
trainer/Q Targets Min                       -26.0513
trainer/Bellman Errors 1 Mean                 1.42307
trainer/Bellman Errors 1 Std                 10.0327
trainer/Bellman Errors 1 Max                321.35
trainer/Bellman Errors 1 Min                  2.38419e-07
trainer/Bellman Errors 2 Mean                 1.3734
trainer/Bellman Errors 2 Std                 10.0102
trainer/Bellman Errors 2 Max                329.897
trainer/Bellman Errors 2 Min                  5.11591e-11
trainer/Policy Action Mean                    0.277226
trainer/Policy Action Std                     0.802762
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     476000
expl/num paths total                      11900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.702728
expl/Rewards Std                              0.652424
expl/Rewards Max                              1.5707
expl/Rewards Min                              0
expl/Returns Mean                            28.1091
expl/Returns Std                             15.6213
expl/Returns Max                             38.9965
expl/Returns Min                              0
expl/Actions Mean                             0.309568
expl/Actions Std                              0.755531
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         28.1091
expl/env_infos/final/reward_dist Mean         1.19262
expl/env_infos/final/reward_dist Std          0.670196
expl/env_infos/final/reward_dist Max          1.5707
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000399479
expl/env_infos/initial/reward_dist Std        0.00186765
expl/env_infos/initial/reward_dist Max        0.0121388
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.702728
expl/env_infos/reward_dist Std                0.652424
expl/env_infos/reward_dist Max                1.5707
expl/env_infos/reward_dist Min                0
eval/num steps total                      95200
eval/num paths total                       2380
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.930277
eval/Rewards Std                              0.601183
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            37.2111
eval/Returns Std                              1.79543
eval/Returns Max                             39.4297
eval/Returns Min                             34.8977
eval/Actions Mean                             0.363578
eval/Actions Std                              0.73568
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         37.2111
eval/env_infos/final/reward_dist Mean         1.56928
eval/env_infos/final/reward_dist Std          0.00120307
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          1.56699
eval/env_infos/initial/reward_dist Mean       0.000441695
eval/env_infos/initial/reward_dist Std        0.000702929
eval/env_infos/initial/reward_dist Max        0.00190326
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.930277
eval/env_infos/reward_dist Std                0.601183
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0056924
time/evaluation sampling (s)                  3.50951
time/exploration sampling (s)                17.9855
time/logging (s)                              0.00744741
time/saving (s)                               0.00268615
time/training (s)                             4.12858
time/epoch (s)                               25.6394
time/total (s)                             6086.36
Epoch                                       237
---------------------------------------  ----------------
2023-08-05 02:03:05.117544 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 238 finished
---------------------------------------  ----------------
epoch                                       238
replay_buffer/size                       478000
trainer/QF1 Loss                              1.45142
trainer/QF2 Loss                              1.42302
trainer/Policy Loss                         -11.0092
trainer/Q1 Predictions Mean                  10.0054
trainer/Q1 Predictions Std                   10.3927
trainer/Q1 Predictions Max                   40.2084
trainer/Q1 Predictions Min                  -30.5274
trainer/Q2 Predictions Mean                  10.0444
trainer/Q2 Predictions Std                   10.412
trainer/Q2 Predictions Max                   40.1673
trainer/Q2 Predictions Min                  -31.125
trainer/Q Targets Mean                        9.99341
trainer/Q Targets Std                        10.4443
trainer/Q Targets Max                        40.7237
trainer/Q Targets Min                       -32.703
trainer/Bellman Errors 1 Mean                 1.45142
trainer/Bellman Errors 1 Std                  8.44922
trainer/Bellman Errors 1 Max                287.813
trainer/Bellman Errors 1 Min                  1.95198e-08
trainer/Bellman Errors 2 Mean                 1.42302
trainer/Bellman Errors 2 Std                  8.52182
trainer/Bellman Errors 2 Max                272.21
trainer/Bellman Errors 2 Min                  2.21949e-07
trainer/Policy Action Mean                    0.279927
trainer/Policy Action Std                     0.798122
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     478000
expl/num paths total                      11950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.735103
expl/Rewards Std                              0.617555
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            29.4041
expl/Returns Std                             11.6594
expl/Returns Max                             36.6917
expl/Returns Min                              0
expl/Actions Mean                             0.313647
expl/Actions Std                              0.735562
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.4041
expl/env_infos/final/reward_dist Mean         1.34768
expl/env_infos/final/reward_dist Std          0.543852
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00037984
expl/env_infos/initial/reward_dist Std        0.00172853
expl/env_infos/initial/reward_dist Max        0.00980145
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.735103
expl/env_infos/reward_dist Std                0.617555
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      95600
eval/num paths total                       2390
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.794747
eval/Rewards Std                              0.609788
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            31.7899
eval/Returns Std                             10.1765
eval/Returns Max                             36.7149
eval/Returns Min                              1.38993
eval/Actions Mean                             0.315286
eval/Actions Std                              0.755289
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.7899
eval/env_infos/final/reward_dist Mean         1.41207
eval/env_infos/final/reward_dist Std          0.470693
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00216183
eval/env_infos/initial/reward_dist Std        0.00329592
eval/env_infos/initial/reward_dist Max        0.00941872
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.794747
eval/env_infos/reward_dist Std                0.609788
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584793
time/evaluation sampling (s)                  3.54866
time/exploration sampling (s)                18.6178
time/logging (s)                              0.00533409
time/saving (s)                               0.00236194
time/training (s)                             4.33212
time/epoch (s)                               26.5122
time/total (s)                             6112.87
Epoch                                       238
---------------------------------------  ----------------
2023-08-05 02:03:31.002541 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 239 finished
---------------------------------------  ----------------
epoch                                       239
replay_buffer/size                       480000
trainer/QF1 Loss                              1.66118
trainer/QF2 Loss                              1.62662
trainer/Policy Loss                         -10.6309
trainer/Q1 Predictions Mean                   9.69339
trainer/Q1 Predictions Std                   10.5147
trainer/Q1 Predictions Max                   38.0435
trainer/Q1 Predictions Min                  -46.4195
trainer/Q2 Predictions Mean                   9.73725
trainer/Q2 Predictions Std                   10.5435
trainer/Q2 Predictions Max                   38.3149
trainer/Q2 Predictions Min                  -46.1124
trainer/Q Targets Mean                        9.72894
trainer/Q Targets Std                        10.6555
trainer/Q Targets Max                        39.3177
trainer/Q Targets Min                       -62.2483
trainer/Bellman Errors 1 Mean                 1.66118
trainer/Bellman Errors 1 Std                 10.3593
trainer/Bellman Errors 1 Max                254.51
trainer/Bellman Errors 1 Min                  3.5476e-08
trainer/Bellman Errors 2 Mean                 1.62662
trainer/Bellman Errors 2 Std                 10.5732
trainer/Bellman Errors 2 Max                260.369
trainer/Bellman Errors 2 Min                  1.54889e-08
trainer/Policy Action Mean                    0.281482
trainer/Policy Action Std                     0.79809
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     480000
expl/num paths total                      12000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.600358
expl/Rewards Std                              0.626463
expl/Rewards Max                              1.5707
expl/Rewards Min                              0
expl/Returns Mean                            24.0143
expl/Returns Std                             15.4336
expl/Returns Max                             36.4553
expl/Returns Min                              0
expl/Actions Mean                             0.297228
expl/Actions Std                              0.750342
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.0143
expl/env_infos/final/reward_dist Mean         1.09786
expl/env_infos/final/reward_dist Std          0.718712
expl/env_infos/final/reward_dist Max          1.5707
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000464217
expl/env_infos/initial/reward_dist Std        0.00139183
expl/env_infos/initial/reward_dist Max        0.00704578
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.600358
expl/env_infos/reward_dist Std                0.626463
expl/env_infos/reward_dist Max                1.5707
expl/env_infos/reward_dist Min                0
eval/num steps total                      96000
eval/num paths total                       2400
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.778983
eval/Rewards Std                              0.615401
eval/Rewards Max                              1.5706
eval/Rewards Min                              0
eval/Returns Mean                            31.1593
eval/Returns Std                             10.0902
eval/Returns Max                             37.2255
eval/Returns Min                              1.16674
eval/Actions Mean                             0.343135
eval/Actions Std                              0.744725
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.1593
eval/env_infos/final/reward_dist Mean         1.41153
eval/env_infos/final/reward_dist Std          0.470517
eval/env_infos/final/reward_dist Max          1.5706
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00148324
eval/env_infos/initial/reward_dist Std        0.00300028
eval/env_infos/initial/reward_dist Max        0.00842042
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.778983
eval/env_infos/reward_dist Std                0.615401
eval/env_infos/reward_dist Max                1.5706
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593596
time/evaluation sampling (s)                  3.51701
time/exploration sampling (s)                17.9238
time/logging (s)                              0.00533261
time/saving (s)                               0.00234336
time/training (s)                             4.4275
time/epoch (s)                               25.8819
time/total (s)                             6138.76
Epoch                                       239
---------------------------------------  ----------------
2023-08-05 02:03:56.945670 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 240 finished
---------------------------------------  ----------------
epoch                                       240
replay_buffer/size                       482000
trainer/QF1 Loss                              1.64864
trainer/QF2 Loss                              1.59408
trainer/Policy Loss                         -10.6392
trainer/Q1 Predictions Mean                   9.63033
trainer/Q1 Predictions Std                   10.5034
trainer/Q1 Predictions Max                   39.3339
trainer/Q1 Predictions Min                  -26.8102
trainer/Q2 Predictions Mean                   9.62824
trainer/Q2 Predictions Std                   10.5081
trainer/Q2 Predictions Max                   39.3218
trainer/Q2 Predictions Min                  -26.877
trainer/Q Targets Mean                        9.65675
trainer/Q Targets Std                        10.6493
trainer/Q Targets Max                        41.5387
trainer/Q Targets Min                       -28.1143
trainer/Bellman Errors 1 Mean                 1.64864
trainer/Bellman Errors 1 Std                 10.4491
trainer/Bellman Errors 1 Max                318.574
trainer/Bellman Errors 1 Min                  4.56348e-08
trainer/Bellman Errors 2 Mean                 1.59408
trainer/Bellman Errors 2 Std                 10.081
trainer/Bellman Errors 2 Max                277.629
trainer/Bellman Errors 2 Min                  3.11252e-09
trainer/Policy Action Mean                    0.277881
trainer/Policy Action Std                     0.798295
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     482000
expl/num paths total                      12050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.664685
expl/Rewards Std                              0.625595
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            26.5874
expl/Returns Std                             14.0114
expl/Returns Max                             36.8926
expl/Returns Min                              0
expl/Actions Mean                             0.29582
expl/Actions Std                              0.757415
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         26.5874
expl/env_infos/final/reward_dist Mean         1.22366
expl/env_infos/final/reward_dist Std          0.649745
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000719134
expl/env_infos/initial/reward_dist Std        0.00225407
expl/env_infos/initial/reward_dist Max        0.0103904
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.664685
expl/env_infos/reward_dist Std                0.625595
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      96400
eval/num paths total                       2410
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.777129
eval/Rewards Std                              0.612689
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            31.0852
eval/Returns Std                             10.0945
eval/Returns Max                             36.3161
eval/Returns Min                              1.11911
eval/Actions Mean                             0.335987
eval/Actions Std                              0.744378
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.0852
eval/env_infos/final/reward_dist Mean         1.41254
eval/env_infos/final/reward_dist Std          0.470848
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0015919
eval/env_infos/initial/reward_dist Std        0.00243344
eval/env_infos/initial/reward_dist Max        0.00672847
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.777129
eval/env_infos/reward_dist Std                0.612689
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0056755
time/evaluation sampling (s)                  3.55098
time/exploration sampling (s)                17.7815
time/logging (s)                              0.00536724
time/saving (s)                               0.0023595
time/training (s)                             4.59413
time/epoch (s)                               25.94
time/total (s)                             6164.7
Epoch                                       240
---------------------------------------  ----------------
2023-08-05 02:04:22.998826 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 241 finished
---------------------------------------  ----------------
epoch                                       241
replay_buffer/size                       484000
trainer/QF1 Loss                              1.37769
trainer/QF2 Loss                              1.29289
trainer/Policy Loss                         -11.1127
trainer/Q1 Predictions Mean                  10.1418
trainer/Q1 Predictions Std                   10.6849
trainer/Q1 Predictions Max                   41.501
trainer/Q1 Predictions Min                  -28.392
trainer/Q2 Predictions Mean                  10.1296
trainer/Q2 Predictions Std                   10.6784
trainer/Q2 Predictions Max                   41.9765
trainer/Q2 Predictions Min                  -27.4175
trainer/Q Targets Mean                       10.117
trainer/Q Targets Std                        10.7483
trainer/Q Targets Max                        41.4942
trainer/Q Targets Min                       -32.1309
trainer/Bellman Errors 1 Mean                 1.37769
trainer/Bellman Errors 1 Std                  7.15243
trainer/Bellman Errors 1 Max                170.212
trainer/Bellman Errors 1 Min                  4.60432e-10
trainer/Bellman Errors 2 Mean                 1.29289
trainer/Bellman Errors 2 Std                  6.66671
trainer/Bellman Errors 2 Max                185.865
trainer/Bellman Errors 2 Min                  3.27418e-11
trainer/Policy Action Mean                    0.278889
trainer/Policy Action Std                     0.792806
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     484000
expl/num paths total                      12100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.691392
expl/Rewards Std                              0.628165
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            27.6557
expl/Returns Std                             13.5185
expl/Returns Max                             37.4661
expl/Returns Min                              0.0835313
expl/Actions Mean                             0.329803
expl/Actions Std                              0.732737
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         27.6557
expl/env_infos/final/reward_dist Mean         1.25457
expl/env_infos/final/reward_dist Std          0.627208
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000976772
expl/env_infos/initial/reward_dist Std        0.00248065
expl/env_infos/initial/reward_dist Max        0.0118483
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.691392
expl/env_infos/reward_dist Std                0.628165
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                      96800
eval/num paths total                       2420
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.710264
eval/Rewards Std                              0.629145
eval/Rewards Max                              1.57063
eval/Rewards Min                              0
eval/Returns Mean                            28.4105
eval/Returns Std                             13.6238
eval/Returns Max                             37.4643
eval/Returns Min                              0.967224
eval/Actions Mean                             0.33817
eval/Actions Std                              0.751046
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.4105
eval/env_infos/final/reward_dist Mean         1.27198
eval/env_infos/final/reward_dist Std          0.595269
eval/env_infos/final/reward_dist Max          1.57063
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00102337
eval/env_infos/initial/reward_dist Std        0.00151053
eval/env_infos/initial/reward_dist Max        0.00418692
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.710264
eval/env_infos/reward_dist Std                0.629145
eval/env_infos/reward_dist Max                1.57063
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584252
time/evaluation sampling (s)                  3.43362
time/exploration sampling (s)                18.2111
time/logging (s)                              0.00534389
time/saving (s)                               0.00244835
time/training (s)                             4.39163
time/epoch (s)                               26.05
time/total (s)                             6190.75
Epoch                                       241
---------------------------------------  ----------------
2023-08-05 02:04:49.609344 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 242 finished
---------------------------------------  ----------------
epoch                                       242
replay_buffer/size                       486000
trainer/QF1 Loss                              1.7414
trainer/QF2 Loss                              1.7678
trainer/Policy Loss                         -10.8236
trainer/Q1 Predictions Mean                   9.82628
trainer/Q1 Predictions Std                   11.0476
trainer/Q1 Predictions Max                   41.6235
trainer/Q1 Predictions Min                  -40.6168
trainer/Q2 Predictions Mean                   9.80418
trainer/Q2 Predictions Std                   11.0386
trainer/Q2 Predictions Max                   42.1657
trainer/Q2 Predictions Min                  -41.8944
trainer/Q Targets Mean                        9.86446
trainer/Q Targets Std                        11.1372
trainer/Q Targets Max                        42.9853
trainer/Q Targets Min                       -64.1292
trainer/Bellman Errors 1 Mean                 1.7414
trainer/Bellman Errors 1 Std                 14.7224
trainer/Bellman Errors 1 Max                683.685
trainer/Bellman Errors 1 Min                  1.12059e-08
trainer/Bellman Errors 2 Mean                 1.7678
trainer/Bellman Errors 2 Std                 15.645
trainer/Bellman Errors 2 Max                746.029
trainer/Bellman Errors 2 Min                  3.63798e-12
trainer/Policy Action Mean                    0.280402
trainer/Policy Action Std                     0.792984
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     486000
expl/num paths total                      12150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.498211
expl/Rewards Std                              0.618109
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            19.9284
expl/Returns Std                             16.8794
expl/Returns Max                             37.1499
expl/Returns Min                              0
expl/Actions Mean                             0.276245
expl/Actions Std                              0.774324
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         19.9284
expl/env_infos/final/reward_dist Mean         0.905328
expl/env_infos/final/reward_dist Std          0.770575
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00022676
expl/env_infos/initial/reward_dist Std        0.000808627
expl/env_infos/initial/reward_dist Max        0.00417039
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.498211
expl/env_infos/reward_dist Std                0.618109
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      97200
eval/num paths total                       2430
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.868333
eval/Rewards Std                              0.605131
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            34.7333
eval/Returns Std                              1.23858
eval/Returns Max                             37.7863
eval/Returns Min                             33.1359
eval/Actions Mean                             0.37991
eval/Actions Std                              0.709417
eval/Actions Max                              1
eval/Actions Min                             -0.999999
eval/Num Paths                               10
eval/Average Returns                         34.7333
eval/env_infos/final/reward_dist Mean         1.56876
eval/env_infos/final/reward_dist Std          0.00222138
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          1.5638
eval/env_infos/initial/reward_dist Mean       0.000577891
eval/env_infos/initial/reward_dist Std        0.00173367
eval/env_infos/initial/reward_dist Max        0.00577891
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.868333
eval/env_infos/reward_dist Std                0.605131
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00565344
time/evaluation sampling (s)                  3.54215
time/exploration sampling (s)                18.1385
time/logging (s)                              0.00537726
time/saving (s)                               0.00245882
time/training (s)                             4.91322
time/epoch (s)                               26.6074
time/total (s)                             6217.36
Epoch                                       242
---------------------------------------  ----------------
2023-08-05 02:05:16.243749 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 243 finished
---------------------------------------  ----------------
epoch                                       243
replay_buffer/size                       488000
trainer/QF1 Loss                              1.49555
trainer/QF2 Loss                              1.39291
trainer/Policy Loss                         -10.874
trainer/Q1 Predictions Mean                   9.87181
trainer/Q1 Predictions Std                   10.9322
trainer/Q1 Predictions Max                   42.2794
trainer/Q1 Predictions Min                  -29.5691
trainer/Q2 Predictions Mean                   9.83554
trainer/Q2 Predictions Std                   10.9296
trainer/Q2 Predictions Max                   42.1596
trainer/Q2 Predictions Min                  -29.3317
trainer/Q Targets Mean                        9.90451
trainer/Q Targets Std                        11.0218
trainer/Q Targets Max                        43.0723
trainer/Q Targets Min                       -29.8166
trainer/Bellman Errors 1 Mean                 1.49555
trainer/Bellman Errors 1 Std                  8.99313
trainer/Bellman Errors 1 Max                315.836
trainer/Bellman Errors 1 Min                  3.78495e-08
trainer/Bellman Errors 2 Mean                 1.39291
trainer/Bellman Errors 2 Std                  8.40815
trainer/Bellman Errors 2 Max                288.663
trainer/Bellman Errors 2 Min                  6.508e-08
trainer/Policy Action Mean                    0.290732
trainer/Policy Action Std                     0.786603
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     488000
expl/num paths total                      12200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.815619
expl/Rewards Std                              0.625517
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            32.6248
expl/Returns Std                              9.60151
expl/Returns Max                             38.8491
expl/Returns Min                              0
expl/Actions Mean                             0.347498
expl/Actions Std                              0.713555
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.6248
expl/env_infos/final/reward_dist Mean         1.44279
expl/env_infos/final/reward_dist Std          0.425465
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000312365
expl/env_infos/initial/reward_dist Std        0.0016475
expl/env_infos/initial/reward_dist Max        0.0112502
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.815619
expl/env_infos/reward_dist Std                0.625517
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      97600
eval/num paths total                       2440
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.636793
eval/Rewards Std                              0.650995
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            25.4717
eval/Returns Std                             16.4668
eval/Returns Max                             38.5691
eval/Returns Min                              0
eval/Actions Mean                             0.355868
eval/Actions Std                              0.73981
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         25.4717
eval/env_infos/final/reward_dist Mean         1.0989
eval/env_infos/final/reward_dist Std          0.719397
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000105022
eval/env_infos/initial/reward_dist Std        0.000315065
eval/env_infos/initial/reward_dist Max        0.00105022
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.636793
eval/env_infos/reward_dist Std                0.650995
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00602115
time/evaluation sampling (s)                  3.46515
time/exploration sampling (s)                18.5984
time/logging (s)                              0.00535087
time/saving (s)                               0.00242858
time/training (s)                             4.55399
time/epoch (s)                               26.6313
time/total (s)                             6243.99
Epoch                                       243
---------------------------------------  ----------------
2023-08-05 02:05:42.311166 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 244 finished
---------------------------------------  ----------------
epoch                                       244
replay_buffer/size                       490000
trainer/QF1 Loss                              1.63039
trainer/QF2 Loss                              1.53732
trainer/Policy Loss                         -10.8495
trainer/Q1 Predictions Mean                   9.8837
trainer/Q1 Predictions Std                   11.303
trainer/Q1 Predictions Max                   41.5849
trainer/Q1 Predictions Min                  -51.9434
trainer/Q2 Predictions Mean                   9.83738
trainer/Q2 Predictions Std                   11.2875
trainer/Q2 Predictions Max                   41.1556
trainer/Q2 Predictions Min                  -50.4492
trainer/Q Targets Mean                        9.86949
trainer/Q Targets Std                        11.364
trainer/Q Targets Max                        41.7551
trainer/Q Targets Min                       -58.3903
trainer/Bellman Errors 1 Mean                 1.63039
trainer/Bellman Errors 1 Std                  8.95713
trainer/Bellman Errors 1 Max                242.911
trainer/Bellman Errors 1 Min                  1.88593e-08
trainer/Bellman Errors 2 Mean                 1.53732
trainer/Bellman Errors 2 Std                  8.19608
trainer/Bellman Errors 2 Max                223.968
trainer/Bellman Errors 2 Min                  1.92449e-07
trainer/Policy Action Mean                    0.272409
trainer/Policy Action Std                     0.790321
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     490000
expl/num paths total                      12250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.796645
expl/Rewards Std                              0.632908
expl/Rewards Max                              1.57074
expl/Rewards Min                              0
expl/Returns Mean                            31.8658
expl/Returns Std                             11.5292
expl/Returns Max                             39.3512
expl/Returns Min                              0.611152
expl/Actions Mean                             0.357887
expl/Actions Std                              0.699436
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.8658
expl/env_infos/final/reward_dist Mean         1.38017
expl/env_infos/final/reward_dist Std          0.509666
expl/env_infos/final/reward_dist Max          1.57074
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0010293
expl/env_infos/initial/reward_dist Std        0.00277549
expl/env_infos/initial/reward_dist Max        0.0126211
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.796645
expl/env_infos/reward_dist Std                0.632908
expl/env_infos/reward_dist Max                1.57074
expl/env_infos/reward_dist Min                0
eval/num steps total                      98000
eval/num paths total                       2450
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.891439
eval/Rewards Std                              0.605496
eval/Rewards Max                              1.57056
eval/Rewards Min                              0
eval/Returns Mean                            35.6576
eval/Returns Std                              1.701
eval/Returns Max                             38.4787
eval/Returns Min                             33.432
eval/Actions Mean                             0.377705
eval/Actions Std                              0.700692
eval/Actions Max                              1
eval/Actions Min                             -0.999997
eval/Num Paths                               10
eval/Average Returns                         35.6576
eval/env_infos/final/reward_dist Mean         1.5682
eval/env_infos/final/reward_dist Std          0.0028291
eval/env_infos/final/reward_dist Max          1.57056
eval/env_infos/final/reward_dist Min          1.56259
eval/env_infos/initial/reward_dist Mean       0.000536917
eval/env_infos/initial/reward_dist Std        0.00142226
eval/env_infos/initial/reward_dist Max        0.00476991
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.891439
eval/env_infos/reward_dist Std                0.605496
eval/env_infos/reward_dist Max                1.57056
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00606638
time/evaluation sampling (s)                  3.52725
time/exploration sampling (s)                17.9631
time/logging (s)                              0.00746032
time/saving (s)                               0.00270189
time/training (s)                             4.55986
time/epoch (s)                               26.0665
time/total (s)                             6270.06
Epoch                                       244
---------------------------------------  ----------------
2023-08-05 02:06:08.513303 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 245 finished
---------------------------------------  ----------------
epoch                                       245
replay_buffer/size                       492000
trainer/QF1 Loss                              1.81019
trainer/QF2 Loss                              1.75401
trainer/Policy Loss                         -10.7277
trainer/Q1 Predictions Mean                   9.67249
trainer/Q1 Predictions Std                   11.8446
trainer/Q1 Predictions Max                   44.1439
trainer/Q1 Predictions Min                  -49.1181
trainer/Q2 Predictions Mean                   9.69193
trainer/Q2 Predictions Std                   11.8507
trainer/Q2 Predictions Max                   45.8537
trainer/Q2 Predictions Min                  -50.0271
trainer/Q Targets Mean                        9.70863
trainer/Q Targets Std                        11.9563
trainer/Q Targets Max                        46.3039
trainer/Q Targets Min                       -61.7567
trainer/Bellman Errors 1 Mean                 1.81019
trainer/Bellman Errors 1 Std                 10.2719
trainer/Bellman Errors 1 Max                243.353
trainer/Bellman Errors 1 Min                  1.28239e-07
trainer/Bellman Errors 2 Mean                 1.75401
trainer/Bellman Errors 2 Std                 10.4598
trainer/Bellman Errors 2 Max                258.047
trainer/Bellman Errors 2 Min                  9.09495e-11
trainer/Policy Action Mean                    0.266775
trainer/Policy Action Std                     0.793041
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     492000
expl/num paths total                      12300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.811745
expl/Rewards Std                              0.624888
expl/Rewards Max                              1.57067
expl/Rewards Min                              0
expl/Returns Mean                            32.4698
expl/Returns Std                              9.5694
expl/Returns Max                             38.7988
expl/Returns Min                              0
expl/Actions Mean                             0.34082
expl/Actions Std                              0.705267
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.4698
expl/env_infos/final/reward_dist Mean         1.44145
expl/env_infos/final/reward_dist Std          0.425139
expl/env_infos/final/reward_dist Max          1.57067
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000861064
expl/env_infos/initial/reward_dist Std        0.0021418
expl/env_infos/initial/reward_dist Max        0.00877765
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.811745
expl/env_infos/reward_dist Std                0.624888
expl/env_infos/reward_dist Max                1.57067
expl/env_infos/reward_dist Min                0
eval/num steps total                      98400
eval/num paths total                       2460
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.883081
eval/Rewards Std                              0.604025
eval/Rewards Max                              1.57076
eval/Rewards Min                              0
eval/Returns Mean                            35.3232
eval/Returns Std                              1.50701
eval/Returns Max                             38.1482
eval/Returns Min                             33.1339
eval/Actions Mean                             0.360293
eval/Actions Std                              0.70839
eval/Actions Max                              1
eval/Actions Min                             -0.999996
eval/Num Paths                               10
eval/Average Returns                         35.3232
eval/env_infos/final/reward_dist Mean         1.56876
eval/env_infos/final/reward_dist Std          0.00209679
eval/env_infos/final/reward_dist Max          1.57076
eval/env_infos/final/reward_dist Min          1.56379
eval/env_infos/initial/reward_dist Mean       0.0008473
eval/env_infos/initial/reward_dist Std        0.00148487
eval/env_infos/initial/reward_dist Max        0.00390845
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.883081
eval/env_infos/reward_dist Std                0.604025
eval/env_infos/reward_dist Max                1.57076
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587287
time/evaluation sampling (s)                  3.56108
time/exploration sampling (s)                18.0151
time/logging (s)                              0.00746139
time/saving (s)                               0.00270731
time/training (s)                             4.60443
time/epoch (s)                               26.1967
time/total (s)                             6296.26
Epoch                                       245
---------------------------------------  ----------------
2023-08-05 02:06:34.664514 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 246 finished
---------------------------------------  ----------------
epoch                                       246
replay_buffer/size                       494000
trainer/QF1 Loss                              1.77071
trainer/QF2 Loss                              1.67981
trainer/Policy Loss                         -11.004
trainer/Q1 Predictions Mean                  10.1121
trainer/Q1 Predictions Std                   11.9354
trainer/Q1 Predictions Max                   44.8976
trainer/Q1 Predictions Min                 -124.091
trainer/Q2 Predictions Mean                  10.0947
trainer/Q2 Predictions Std                   11.9457
trainer/Q2 Predictions Max                   45.2356
trainer/Q2 Predictions Min                 -127.516
trainer/Q Targets Mean                        9.97399
trainer/Q Targets Std                        11.9304
trainer/Q Targets Max                        46.2966
trainer/Q Targets Min                      -125.219
trainer/Bellman Errors 1 Mean                 1.77071
trainer/Bellman Errors 1 Std                 10.9893
trainer/Bellman Errors 1 Max                272.911
trainer/Bellman Errors 1 Min                  1.20281e-08
trainer/Bellman Errors 2 Mean                 1.67981
trainer/Bellman Errors 2 Std                 10.7167
trainer/Bellman Errors 2 Max                258.927
trainer/Bellman Errors 2 Min                  1.41186e-07
trainer/Policy Action Mean                    0.269973
trainer/Policy Action Std                     0.792161
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     494000
expl/num paths total                      12350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.718925
expl/Rewards Std                              0.640649
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            28.757
expl/Returns Std                             13.3347
expl/Returns Max                             38.6362
expl/Returns Min                              0
expl/Actions Mean                             0.320073
expl/Actions Std                              0.72711
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         28.757
expl/env_infos/final/reward_dist Mean         1.28629
expl/env_infos/final/reward_dist Std          0.602651
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00113773
expl/env_infos/initial/reward_dist Std        0.00280299
expl/env_infos/initial/reward_dist Max        0.0107663
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.718925
expl/env_infos/reward_dist Std                0.640649
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                      98800
eval/num paths total                       2470
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.894022
eval/Rewards Std                              0.602637
eval/Rewards Max                              1.57056
eval/Rewards Min                              0
eval/Returns Mean                            35.7609
eval/Returns Std                              1.89242
eval/Returns Max                             38.3666
eval/Returns Min                             32.5974
eval/Actions Mean                             0.360262
eval/Actions Std                              0.713619
eval/Actions Max                              1
eval/Actions Min                             -0.999998
eval/Num Paths                               10
eval/Average Returns                         35.7609
eval/env_infos/final/reward_dist Mean         1.56908
eval/env_infos/final/reward_dist Std          0.00148186
eval/env_infos/final/reward_dist Max          1.57056
eval/env_infos/final/reward_dist Min          1.56538
eval/env_infos/initial/reward_dist Mean       0.000596682
eval/env_infos/initial/reward_dist Std        0.00113007
eval/env_infos/initial/reward_dist Max        0.00369699
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.894022
eval/env_infos/reward_dist Std                0.602637
eval/env_infos/reward_dist Max                1.57056
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00583275
time/evaluation sampling (s)                  3.48103
time/exploration sampling (s)                17.9669
time/logging (s)                              0.00533876
time/saving (s)                               0.00240202
time/training (s)                             4.68215
time/epoch (s)                               26.1437
time/total (s)                             6322.41
Epoch                                       246
---------------------------------------  ----------------
2023-08-05 02:07:00.719585 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 247 finished
---------------------------------------  ----------------
epoch                                       247
replay_buffer/size                       496000
trainer/QF1 Loss                              1.77268
trainer/QF2 Loss                              1.68239
trainer/Policy Loss                         -10.9328
trainer/Q1 Predictions Mean                   9.84983
trainer/Q1 Predictions Std                   12.104
trainer/Q1 Predictions Max                   45.7225
trainer/Q1 Predictions Min                  -36.5929
trainer/Q2 Predictions Mean                   9.85856
trainer/Q2 Predictions Std                   12.1441
trainer/Q2 Predictions Max                   46.0629
trainer/Q2 Predictions Min                  -42.636
trainer/Q Targets Mean                        9.95564
trainer/Q Targets Std                        12.2149
trainer/Q Targets Max                        48.1847
trainer/Q Targets Min                       -43.4969
trainer/Bellman Errors 1 Mean                 1.77268
trainer/Bellman Errors 1 Std                 11.3652
trainer/Bellman Errors 1 Max                427.426
trainer/Bellman Errors 1 Min                  1.76078e-09
trainer/Bellman Errors 2 Mean                 1.68239
trainer/Bellman Errors 2 Std                 10.0405
trainer/Bellman Errors 2 Max                298.265
trainer/Bellman Errors 2 Min                  5.00735e-07
trainer/Policy Action Mean                    0.280618
trainer/Policy Action Std                     0.787625
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     496000
expl/num paths total                      12400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.793391
expl/Rewards Std                              0.633036
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            31.7356
expl/Returns Std                             10.5821
expl/Returns Max                             38.1934
expl/Returns Min                              0
expl/Actions Mean                             0.355334
expl/Actions Std                              0.70763
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.7356
expl/env_infos/final/reward_dist Mean         1.40993
expl/env_infos/final/reward_dist Std          0.470123
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00131289
expl/env_infos/initial/reward_dist Std        0.00299015
expl/env_infos/initial/reward_dist Max        0.0103652
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.793391
expl/env_infos/reward_dist Std                0.633036
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                      99200
eval/num paths total                       2480
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.909525
eval/Rewards Std                              0.605084
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            36.381
eval/Returns Std                              1.3724
eval/Returns Max                             38.4682
eval/Returns Min                             33.5423
eval/Actions Mean                             0.38319
eval/Actions Std                              0.70638
eval/Actions Max                              1
eval/Actions Min                             -0.999998
eval/Num Paths                               10
eval/Average Returns                         36.381
eval/env_infos/final/reward_dist Mean         1.56864
eval/env_infos/final/reward_dist Std          0.00200828
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          1.56433
eval/env_infos/initial/reward_dist Mean       0.000660628
eval/env_infos/initial/reward_dist Std        0.00160221
eval/env_infos/initial/reward_dist Max        0.00532966
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.909525
eval/env_infos/reward_dist Std                0.605084
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0057206
time/evaluation sampling (s)                  3.43026
time/exploration sampling (s)                17.8169
time/logging (s)                              0.00791635
time/saving (s)                               0.00331689
time/training (s)                             4.79039
time/epoch (s)                               26.0545
time/total (s)                             6348.46
Epoch                                       247
---------------------------------------  ----------------
2023-08-05 02:07:26.534771 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 248 finished
---------------------------------------  ----------------
epoch                                       248
replay_buffer/size                       498000
trainer/QF1 Loss                              1.99221
trainer/QF2 Loss                              1.94647
trainer/Policy Loss                         -10.9021
trainer/Q1 Predictions Mean                   9.78163
trainer/Q1 Predictions Std                   12.2135
trainer/Q1 Predictions Max                   46.3527
trainer/Q1 Predictions Min                  -35.9871
trainer/Q2 Predictions Mean                   9.77434
trainer/Q2 Predictions Std                   12.2087
trainer/Q2 Predictions Max                   47.1632
trainer/Q2 Predictions Min                  -37.7049
trainer/Q Targets Mean                        9.72399
trainer/Q Targets Std                        12.2927
trainer/Q Targets Max                        47.6032
trainer/Q Targets Min                       -37.4502
trainer/Bellman Errors 1 Mean                 1.99221
trainer/Bellman Errors 1 Std                 12.2647
trainer/Bellman Errors 1 Max                326.318
trainer/Bellman Errors 1 Min                  1.69734e-07
trainer/Bellman Errors 2 Mean                 1.94647
trainer/Bellman Errors 2 Std                 12.372
trainer/Bellman Errors 2 Max                324.28
trainer/Bellman Errors 2 Min                  3.21452e-08
trainer/Policy Action Mean                    0.276866
trainer/Policy Action Std                     0.800873
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     498000
expl/num paths total                      12450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.772496
expl/Rewards Std                              0.661102
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            30.8998
expl/Returns Std                             14.2411
expl/Returns Max                             40.3581
expl/Returns Min                              0
expl/Actions Mean                             0.368373
expl/Actions Std                              0.720373
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.8998
expl/env_infos/final/reward_dist Mean         1.28633
expl/env_infos/final/reward_dist Std          0.602677
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000788755
expl/env_infos/initial/reward_dist Std        0.0024525
expl/env_infos/initial/reward_dist Max        0.0112747
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.772496
expl/env_infos/reward_dist Std                0.661102
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                      99600
eval/num paths total                       2490
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.558277
eval/Rewards Std                              0.625875
eval/Rewards Max                              1.57058
eval/Rewards Min                              0
eval/Returns Mean                            22.3311
eval/Returns Std                             16.9717
eval/Returns Max                             39.4019
eval/Returns Min                              0
eval/Actions Mean                             0.222838
eval/Actions Std                              0.846137
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         22.3311
eval/env_infos/final/reward_dist Mean         1.02491
eval/env_infos/final/reward_dist Std          0.699356
eval/env_infos/final/reward_dist Max          1.57058
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.558277
eval/env_infos/reward_dist Std                0.625875
eval/env_infos/reward_dist Max                1.57058
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0057302
time/evaluation sampling (s)                  3.49727
time/exploration sampling (s)                17.8412
time/logging (s)                              0.00530205
time/saving (s)                               0.00235982
time/training (s)                             4.4553
time/epoch (s)                               25.8071
time/total (s)                             6374.27
Epoch                                       248
---------------------------------------  ----------------
2023-08-05 02:07:52.114690 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 249 finished
---------------------------------------  ----------------
epoch                                       249
replay_buffer/size                       500000
trainer/QF1 Loss                              1.73279
trainer/QF2 Loss                              1.69572
trainer/Policy Loss                         -11.3727
trainer/Q1 Predictions Mean                  10.185
trainer/Q1 Predictions Std                   12.2465
trainer/Q1 Predictions Max                   47.8547
trainer/Q1 Predictions Min                  -56.2377
trainer/Q2 Predictions Mean                  10.1632
trainer/Q2 Predictions Std                   12.2485
trainer/Q2 Predictions Max                   47.9175
trainer/Q2 Predictions Min                  -56.3359
trainer/Q Targets Mean                       10.1917
trainer/Q Targets Std                        12.3286
trainer/Q Targets Max                        46.7778
trainer/Q Targets Min                       -57.1382
trainer/Bellman Errors 1 Mean                 1.73279
trainer/Bellman Errors 1 Std                 10.6491
trainer/Bellman Errors 1 Max                289.602
trainer/Bellman Errors 1 Min                  1.11413e-09
trainer/Bellman Errors 2 Mean                 1.69572
trainer/Bellman Errors 2 Std                 10.8378
trainer/Bellman Errors 2 Max                288.63
trainer/Bellman Errors 2 Min                  2.85218e-07
trainer/Policy Action Mean                    0.279384
trainer/Policy Action Std                     0.801202
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     500000
expl/num paths total                      12500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.798309
expl/Rewards Std                              0.660553
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            31.9324
expl/Returns Std                             13.7166
expl/Returns Max                             41.019
expl/Returns Min                              0.00259279
expl/Actions Mean                             0.372387
expl/Actions Std                              0.718785
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.9324
expl/env_infos/final/reward_dist Mean         1.31736
expl/env_infos/final/reward_dist Std          0.574946
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000802774
expl/env_infos/initial/reward_dist Std        0.00202459
expl/env_infos/initial/reward_dist Max        0.0074353
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.798309
expl/env_infos/reward_dist Std                0.660553
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     100000
eval/num paths total                       2500
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.714335
eval/Rewards Std                              0.65266
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            28.5734
eval/Returns Std                             15.4902
eval/Returns Max                             41.0751
eval/Returns Min                              0.707945
eval/Actions Mean                             0.364497
eval/Actions Std                              0.766382
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         28.5734
eval/env_infos/final/reward_dist Mean         1.23093
eval/env_infos/final/reward_dist Std          0.619892
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00149948
eval/env_infos/initial/reward_dist Std        0.00292996
eval/env_infos/initial/reward_dist Max        0.00921514
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.714335
eval/env_infos/reward_dist Std                0.65266
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00583981
time/evaluation sampling (s)                  3.39814
time/exploration sampling (s)                17.9267
time/logging (s)                              0.00532256
time/saving (s)                               0.00235206
time/training (s)                             4.23831
time/epoch (s)                               25.5767
time/total (s)                             6399.85
Epoch                                       249
---------------------------------------  ----------------
2023-08-05 02:08:17.284389 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 250 finished
---------------------------------------  ----------------
epoch                                       250
replay_buffer/size                       502000
trainer/QF1 Loss                              2.10898
trainer/QF2 Loss                              1.9705
trainer/Policy Loss                         -11.2292
trainer/Q1 Predictions Mean                  10.1278
trainer/Q1 Predictions Std                   12.3166
trainer/Q1 Predictions Max                   49.2388
trainer/Q1 Predictions Min                  -46.8178
trainer/Q2 Predictions Mean                  10.1253
trainer/Q2 Predictions Std                   12.2897
trainer/Q2 Predictions Max                   48.7792
trainer/Q2 Predictions Min                  -47.9387
trainer/Q Targets Mean                       10.0842
trainer/Q Targets Std                        12.3555
trainer/Q Targets Max                        49.5252
trainer/Q Targets Min                       -44.8634
trainer/Bellman Errors 1 Mean                 2.10898
trainer/Bellman Errors 1 Std                 15.018
trainer/Bellman Errors 1 Max                362.873
trainer/Bellman Errors 1 Min                  9.27776e-07
trainer/Bellman Errors 2 Mean                 1.9705
trainer/Bellman Errors 2 Std                 14.4174
trainer/Bellman Errors 2 Max                361.779
trainer/Bellman Errors 2 Min                  1.78261e-08
trainer/Policy Action Mean                    0.273189
trainer/Policy Action Std                     0.802849
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     502000
expl/num paths total                      12550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.766093
expl/Rewards Std                              0.666319
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            30.6437
expl/Returns Std                             15.0336
expl/Returns Max                             41.6488
expl/Returns Min                              0
expl/Actions Mean                             0.375884
expl/Actions Std                              0.720088
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.6437
expl/env_infos/final/reward_dist Mean         1.25486
expl/env_infos/final/reward_dist Std          0.627432
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000797252
expl/env_infos/initial/reward_dist Std        0.00218497
expl/env_infos/initial/reward_dist Max        0.0089026
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.766093
expl/env_infos/reward_dist Std                0.666319
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     100400
eval/num paths total                       2510
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.966494
eval/Rewards Std                              0.614019
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            38.6598
eval/Returns Std                              1.66567
eval/Returns Max                             41.2328
eval/Returns Min                             35.1423
eval/Actions Mean                             0.406917
eval/Actions Std                              0.711991
eval/Actions Max                              1
eval/Actions Min                             -0.999999
eval/Num Paths                               10
eval/Average Returns                         38.6598
eval/env_infos/final/reward_dist Mean         1.56949
eval/env_infos/final/reward_dist Std          0.00146683
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          1.56648
eval/env_infos/initial/reward_dist Mean       0.0010163
eval/env_infos/initial/reward_dist Std        0.00234566
eval/env_infos/initial/reward_dist Max        0.00769937
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.966494
eval/env_infos/reward_dist Std                0.614019
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584892
time/evaluation sampling (s)                  3.3923
time/exploration sampling (s)                17.4373
time/logging (s)                              0.00532839
time/saving (s)                               0.00236501
time/training (s)                             4.32343
time/epoch (s)                               25.1665
time/total (s)                             6425.02
Epoch                                       250
---------------------------------------  ----------------
2023-08-05 02:08:43.170822 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 251 finished
---------------------------------------  ----------------
epoch                                       251
replay_buffer/size                       504000
trainer/QF1 Loss                              1.89169
trainer/QF2 Loss                              1.83096
trainer/Policy Loss                         -11.2691
trainer/Q1 Predictions Mean                  10.1156
trainer/Q1 Predictions Std                   12.5902
trainer/Q1 Predictions Max                   48.2028
trainer/Q1 Predictions Min                  -42.4733
trainer/Q2 Predictions Mean                  10.0932
trainer/Q2 Predictions Std                   12.5699
trainer/Q2 Predictions Max                   48.6783
trainer/Q2 Predictions Min                  -42.726
trainer/Q Targets Mean                       10.0983
trainer/Q Targets Std                        12.6647
trainer/Q Targets Max                        48.7742
trainer/Q Targets Min                       -41.458
trainer/Bellman Errors 1 Mean                 1.89169
trainer/Bellman Errors 1 Std                 13.326
trainer/Bellman Errors 1 Max                341.524
trainer/Bellman Errors 1 Min                  4.85315e-08
trainer/Bellman Errors 2 Mean                 1.83096
trainer/Bellman Errors 2 Std                 13.3645
trainer/Bellman Errors 2 Max                327.653
trainer/Bellman Errors 2 Min                  1.32717e-07
trainer/Policy Action Mean                    0.268792
trainer/Policy Action Std                     0.809522
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     504000
expl/num paths total                      12600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.893082
expl/Rewards Std                              0.637024
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            35.7233
expl/Returns Std                              8.91221
expl/Returns Max                             41.13
expl/Returns Min                              0.668014
expl/Actions Mean                             0.392914
expl/Actions Std                              0.701877
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         35.7233
expl/env_infos/final/reward_dist Mean         1.47482
expl/env_infos/final/reward_dist Std          0.372611
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00099881
expl/env_infos/initial/reward_dist Std        0.00256632
expl/env_infos/initial/reward_dist Max        0.00963715
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.893082
expl/env_infos/reward_dist Std                0.637024
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     100800
eval/num paths total                       2520
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.605621
eval/Rewards Std                              0.650287
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            24.2248
eval/Returns Std                             17.4655
eval/Returns Max                             40.8454
eval/Returns Min                              0.844029
eval/Actions Mean                             0.350331
eval/Actions Std                              0.787316
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         24.2248
eval/env_infos/final/reward_dist Mean         1.01983
eval/env_infos/final/reward_dist Std          0.705715
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00202685
eval/env_infos/initial/reward_dist Std        0.00341873
eval/env_infos/initial/reward_dist Max        0.00957897
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.605621
eval/env_infos/reward_dist Std                0.650287
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00565714
time/evaluation sampling (s)                  3.34074
time/exploration sampling (s)                18.0195
time/logging (s)                              0.00532882
time/saving (s)                               0.00239196
time/training (s)                             4.50963
time/epoch (s)                               25.8833
time/total (s)                             6450.9
Epoch                                       251
---------------------------------------  ----------------
2023-08-05 02:09:09.289459 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 252 finished
---------------------------------------  ----------------
epoch                                       252
replay_buffer/size                       506000
trainer/QF1 Loss                              2.06814
trainer/QF2 Loss                              1.9746
trainer/Policy Loss                         -11.4006
trainer/Q1 Predictions Mean                  10.0285
trainer/Q1 Predictions Std                   12.4426
trainer/Q1 Predictions Max                   48.5492
trainer/Q1 Predictions Min                  -59.886
trainer/Q2 Predictions Mean                  10.0002
trainer/Q2 Predictions Std                   12.477
trainer/Q2 Predictions Max                   49.4288
trainer/Q2 Predictions Min                  -61.4703
trainer/Q Targets Mean                       10.0896
trainer/Q Targets Std                        12.6673
trainer/Q Targets Max                        48.5799
trainer/Q Targets Min                       -90.7419
trainer/Bellman Errors 1 Mean                 2.06814
trainer/Bellman Errors 1 Std                 18.4327
trainer/Bellman Errors 1 Max                952.086
trainer/Bellman Errors 1 Min                  1.78236e-07
trainer/Bellman Errors 2 Mean                 1.9746
trainer/Bellman Errors 2 Std                 17.0688
trainer/Bellman Errors 2 Max                856.827
trainer/Bellman Errors 2 Min                  1.5847e-08
trainer/Policy Action Mean                    0.257189
trainer/Policy Action Std                     0.811485
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     506000
expl/num paths total                      12650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.647381
expl/Rewards Std                              0.667319
expl/Rewards Max                              1.57073
expl/Rewards Min                              0
expl/Returns Mean                            25.8952
expl/Returns Std                             17.2507
expl/Returns Max                             40.0934
expl/Returns Min                              0
expl/Actions Mean                             0.296342
expl/Actions Std                              0.780355
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.8952
expl/env_infos/final/reward_dist Mean         1.07915
expl/env_infos/final/reward_dist Std          0.718405
expl/env_infos/final/reward_dist Max          1.57073
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000481882
expl/env_infos/initial/reward_dist Std        0.00163391
expl/env_infos/initial/reward_dist Max        0.00948582
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.647381
expl/env_infos/reward_dist Std                0.667319
expl/env_infos/reward_dist Max                1.57073
expl/env_infos/reward_dist Min                0
eval/num steps total                     101200
eval/num paths total                       2530
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.67141
eval/Rewards Std                              0.674666
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            26.8564
eval/Returns Std                             17.4193
eval/Returns Max                             40.5863
eval/Returns Min                              0
eval/Actions Mean                             0.317223
eval/Actions Std                              0.806859
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.8564
eval/env_infos/final/reward_dist Mean         1.09842
eval/env_infos/final/reward_dist Std          0.719086
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00150643
eval/env_infos/initial/reward_dist Std        0.00236006
eval/env_infos/initial/reward_dist Max        0.00623883
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.67141
eval/env_infos/reward_dist Std                0.674666
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00564202
time/evaluation sampling (s)                  3.44749
time/exploration sampling (s)                17.9865
time/logging (s)                              0.00535944
time/saving (s)                               0.00241348
time/training (s)                             4.66806
time/epoch (s)                               26.1155
time/total (s)                             6477.02
Epoch                                       252
---------------------------------------  ----------------
2023-08-05 02:09:36.182102 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 253 finished
---------------------------------------  ----------------
epoch                                       253
replay_buffer/size                       508000
trainer/QF1 Loss                              1.9561
trainer/QF2 Loss                              1.79718
trainer/Policy Loss                         -11.2762
trainer/Q1 Predictions Mean                   9.98194
trainer/Q1 Predictions Std                   12.6292
trainer/Q1 Predictions Max                   49.5074
trainer/Q1 Predictions Min                  -48.9466
trainer/Q2 Predictions Mean                   9.96769
trainer/Q2 Predictions Std                   12.6432
trainer/Q2 Predictions Max                   49.6431
trainer/Q2 Predictions Min                  -50.7822
trainer/Q Targets Mean                        9.98033
trainer/Q Targets Std                        12.6942
trainer/Q Targets Max                        48.2762
trainer/Q Targets Min                       -67.2499
trainer/Bellman Errors 1 Mean                 1.9561
trainer/Bellman Errors 1 Std                 13.5103
trainer/Bellman Errors 1 Max                335.012
trainer/Bellman Errors 1 Min                  8.74024e-10
trainer/Bellman Errors 2 Mean                 1.79718
trainer/Bellman Errors 2 Std                 12.4003
trainer/Bellman Errors 2 Max                310.793
trainer/Bellman Errors 2 Min                  2.65209e-09
trainer/Policy Action Mean                    0.253763
trainer/Policy Action Std                     0.811931
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     508000
expl/num paths total                      12700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.790744
expl/Rewards Std                              0.659154
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            31.6298
expl/Returns Std                             13.6152
expl/Returns Max                             40.4192
expl/Returns Min                              0.000319313
expl/Actions Mean                             0.372322
expl/Actions Std                              0.719999
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.6298
expl/env_infos/final/reward_dist Mean         1.31781
expl/env_infos/final/reward_dist Std          0.575142
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00100831
expl/env_infos/initial/reward_dist Std        0.00234532
expl/env_infos/initial/reward_dist Max        0.00960952
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.790744
expl/env_infos/reward_dist Std                0.659154
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     101600
eval/num paths total                       2540
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.956939
eval/Rewards Std                              0.614081
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            38.2776
eval/Returns Std                              1.38025
eval/Returns Max                             40.5601
eval/Returns Min                             35.7598
eval/Actions Mean                             0.396321
eval/Actions Std                              0.717495
eval/Actions Max                              1
eval/Actions Min                             -0.999998
eval/Num Paths                               10
eval/Average Returns                         38.2776
eval/env_infos/final/reward_dist Mean         1.56958
eval/env_infos/final/reward_dist Std          0.00114849
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          1.56764
eval/env_infos/initial/reward_dist Mean       0.000147887
eval/env_infos/initial/reward_dist Std        0.00044366
eval/env_infos/initial/reward_dist Max        0.00147887
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.956939
eval/env_infos/reward_dist Std                0.614081
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00591156
time/evaluation sampling (s)                  3.47998
time/exploration sampling (s)                17.9051
time/logging (s)                              0.00787231
time/saving (s)                               0.00333841
time/training (s)                             5.48987
time/epoch (s)                               26.892
time/total (s)                             6503.92
Epoch                                       253
---------------------------------------  ----------------
2023-08-05 02:10:02.907726 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 254 finished
---------------------------------------  ----------------
epoch                                       254
replay_buffer/size                       510000
trainer/QF1 Loss                              2.20356
trainer/QF2 Loss                              2.08303
trainer/Policy Loss                         -11.2076
trainer/Q1 Predictions Mean                   9.82096
trainer/Q1 Predictions Std                   12.7013
trainer/Q1 Predictions Max                   48.5596
trainer/Q1 Predictions Min                  -52.3124
trainer/Q2 Predictions Mean                   9.84244
trainer/Q2 Predictions Std                   12.7382
trainer/Q2 Predictions Max                   47.8958
trainer/Q2 Predictions Min                  -55.308
trainer/Q Targets Mean                        9.87857
trainer/Q Targets Std                        12.8139
trainer/Q Targets Max                        48.7238
trainer/Q Targets Min                       -50.6311
trainer/Bellman Errors 1 Mean                 2.20356
trainer/Bellman Errors 1 Std                 13.116
trainer/Bellman Errors 1 Max                241.402
trainer/Bellman Errors 1 Min                  2.94676e-10
trainer/Bellman Errors 2 Mean                 2.08303
trainer/Bellman Errors 2 Std                 12.4253
trainer/Bellman Errors 2 Max                223.946
trainer/Bellman Errors 2 Min                  8.62783e-08
trainer/Policy Action Mean                    0.240336
trainer/Policy Action Std                     0.818699
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     510000
expl/num paths total                      12750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.827294
expl/Rewards Std                              0.648859
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            33.0917
expl/Returns Std                             11.9159
expl/Returns Max                             39.7043
expl/Returns Min                              0.746312
expl/Actions Mean                             0.36668
expl/Actions Std                              0.719235
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         33.0917
expl/env_infos/final/reward_dist Mean         1.38112
expl/env_infos/final/reward_dist Std          0.510015
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000744115
expl/env_infos/initial/reward_dist Std        0.00213056
expl/env_infos/initial/reward_dist Max        0.0100098
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.827294
expl/env_infos/reward_dist Std                0.648859
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     102000
eval/num paths total                       2550
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.973272
eval/Rewards Std                              0.604196
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            38.9309
eval/Returns Std                              0.998562
eval/Returns Max                             40.3746
eval/Returns Min                             37.1455
eval/Actions Mean                             0.376271
eval/Actions Std                              0.730345
eval/Actions Max                              1
eval/Actions Min                             -0.999998
eval/Num Paths                               10
eval/Average Returns                         38.9309
eval/env_infos/final/reward_dist Mean         1.56762
eval/env_infos/final/reward_dist Std          0.00284327
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          1.56232
eval/env_infos/initial/reward_dist Mean       0.00234395
eval/env_infos/initial/reward_dist Std        0.00339666
eval/env_infos/initial/reward_dist Max        0.0095823
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.973272
eval/env_infos/reward_dist Std                0.604196
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00577535
time/evaluation sampling (s)                  3.51353
time/exploration sampling (s)                18.1846
time/logging (s)                              0.00784358
time/saving (s)                               0.00332251
time/training (s)                             5.00492
time/epoch (s)                               26.72
time/total (s)                             6530.64
Epoch                                       254
---------------------------------------  ----------------
2023-08-05 02:10:29.283260 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 255 finished
---------------------------------------  ----------------
epoch                                       255
replay_buffer/size                       512000
trainer/QF1 Loss                              2.21172
trainer/QF2 Loss                              2.14354
trainer/Policy Loss                         -11.1109
trainer/Q1 Predictions Mean                   9.80119
trainer/Q1 Predictions Std                   12.7423
trainer/Q1 Predictions Max                   49.3266
trainer/Q1 Predictions Min                  -67.5802
trainer/Q2 Predictions Mean                   9.79836
trainer/Q2 Predictions Std                   12.7466
trainer/Q2 Predictions Max                   49.7715
trainer/Q2 Predictions Min                  -69.932
trainer/Q Targets Mean                        9.80754
trainer/Q Targets Std                        12.8885
trainer/Q Targets Max                        49.366
trainer/Q Targets Min                       -84.9898
trainer/Bellman Errors 1 Mean                 2.21172
trainer/Bellman Errors 1 Std                 16.1601
trainer/Bellman Errors 1 Max                455.636
trainer/Bellman Errors 1 Min                  1.19843e-07
trainer/Bellman Errors 2 Mean                 2.14354
trainer/Bellman Errors 2 Std                 15.4021
trainer/Bellman Errors 2 Max                474.469
trainer/Bellman Errors 2 Min                  1.82132e-07
trainer/Policy Action Mean                    0.233809
trainer/Policy Action Std                     0.823733
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     512000
expl/num paths total                      12800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.776292
expl/Rewards Std                              0.659578
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            31.0517
expl/Returns Std                             14.4019
expl/Returns Max                             41.0646
expl/Returns Min                              0
expl/Actions Mean                             0.324375
expl/Actions Std                              0.758075
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.0517
expl/env_infos/final/reward_dist Mean         1.28676
expl/env_infos/final/reward_dist Std          0.60225
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00144357
expl/env_infos/initial/reward_dist Std        0.00318061
expl/env_infos/initial/reward_dist Max        0.0136866
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.776292
expl/env_infos/reward_dist Std                0.659578
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     102400
eval/num paths total                       2560
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.939645
eval/Rewards Std                              0.614261
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            37.5858
eval/Returns Std                              1.54618
eval/Returns Max                             40.3441
eval/Returns Min                             35.252
eval/Actions Mean                             0.36924
eval/Actions Std                              0.742036
eval/Actions Max                              1
eval/Actions Min                             -0.999999
eval/Num Paths                               10
eval/Average Returns                         37.5858
eval/env_infos/final/reward_dist Mean         1.56924
eval/env_infos/final/reward_dist Std          0.00159204
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          1.56632
eval/env_infos/initial/reward_dist Mean       0.000650237
eval/env_infos/initial/reward_dist Std        0.00195071
eval/env_infos/initial/reward_dist Max        0.00650237
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.939645
eval/env_infos/reward_dist Std                0.614261
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00615603
time/evaluation sampling (s)                  3.5439
time/exploration sampling (s)                18.2382
time/logging (s)                              0.00535161
time/saving (s)                               0.00242878
time/training (s)                             4.57139
time/epoch (s)                               26.3675
time/total (s)                             6557.01
Epoch                                       255
---------------------------------------  ----------------
2023-08-05 02:10:55.827273 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 256 finished
---------------------------------------  ----------------
epoch                                       256
replay_buffer/size                       514000
trainer/QF1 Loss                              2.15564
trainer/QF2 Loss                              2.04998
trainer/Policy Loss                         -11.3955
trainer/Q1 Predictions Mean                  10.1129
trainer/Q1 Predictions Std                   13.0657
trainer/Q1 Predictions Max                   49.4785
trainer/Q1 Predictions Min                  -54.7211
trainer/Q2 Predictions Mean                  10.1048
trainer/Q2 Predictions Std                   13.0662
trainer/Q2 Predictions Max                   50.2351
trainer/Q2 Predictions Min                  -57.9046
trainer/Q Targets Mean                       10.1484
trainer/Q Targets Std                        13.1659
trainer/Q Targets Max                        48.7992
trainer/Q Targets Min                       -54.1334
trainer/Bellman Errors 1 Mean                 2.15564
trainer/Bellman Errors 1 Std                 14.622
trainer/Bellman Errors 1 Max                344.439
trainer/Bellman Errors 1 Min                  2.27374e-07
trainer/Bellman Errors 2 Mean                 2.04998
trainer/Bellman Errors 2 Std                 14.6044
trainer/Bellman Errors 2 Max                392.009
trainer/Bellman Errors 2 Min                  1.73204e-08
trainer/Policy Action Mean                    0.231902
trainer/Policy Action Std                     0.824059
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     514000
expl/num paths total                      12850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.636339
expl/Rewards Std                              0.658853
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            25.4535
expl/Returns Std                             16.981
expl/Returns Max                             40.0049
expl/Returns Min                              0
expl/Actions Mean                             0.29495
expl/Actions Std                              0.773044
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         25.4535
expl/env_infos/final/reward_dist Mean         1.07524
expl/env_infos/final/reward_dist Std          0.719652
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000795809
expl/env_infos/initial/reward_dist Std        0.00199245
expl/env_infos/initial/reward_dist Max        0.00850866
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.636339
expl/env_infos/reward_dist Std                0.658853
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                     102800
eval/num paths total                       2570
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.854026
eval/Rewards Std                              0.643106
eval/Rewards Max                              1.57057
eval/Rewards Min                              0
eval/Returns Mean                            34.161
eval/Returns Std                             11.2542
eval/Returns Max                             39.8855
eval/Returns Min                              0.634781
eval/Actions Mean                             0.36534
eval/Actions Std                              0.745949
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         34.161
eval/env_infos/final/reward_dist Mean         1.41245
eval/env_infos/final/reward_dist Std          0.470819
eval/env_infos/final/reward_dist Max          1.57057
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00236478
eval/env_infos/initial/reward_dist Std        0.00472957
eval/env_infos/initial/reward_dist Max        0.011831
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.854026
eval/env_infos/reward_dist Std                0.643106
eval/env_infos/reward_dist Max                1.57057
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00566973
time/evaluation sampling (s)                  3.50767
time/exploration sampling (s)                17.7581
time/logging (s)                              0.00798811
time/saving (s)                               0.00325266
time/training (s)                             5.26082
time/epoch (s)                               26.5435
time/total (s)                             6583.56
Epoch                                       256
---------------------------------------  ----------------
2023-08-05 02:11:21.793712 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 257 finished
---------------------------------------  ----------------
epoch                                       257
replay_buffer/size                       516000
trainer/QF1 Loss                              2.03753
trainer/QF2 Loss                              1.98012
trainer/Policy Loss                         -10.7364
trainer/Q1 Predictions Mean                   9.61378
trainer/Q1 Predictions Std                   12.8879
trainer/Q1 Predictions Max                   49.4807
trainer/Q1 Predictions Min                  -80.3779
trainer/Q2 Predictions Mean                   9.59306
trainer/Q2 Predictions Std                   12.8895
trainer/Q2 Predictions Max                   50.3537
trainer/Q2 Predictions Min                  -82.7692
trainer/Q Targets Mean                        9.60548
trainer/Q Targets Std                        12.9416
trainer/Q Targets Max                        49.6044
trainer/Q Targets Min                       -76.8744
trainer/Bellman Errors 1 Mean                 2.03753
trainer/Bellman Errors 1 Std                 12.7274
trainer/Bellman Errors 1 Max                346.602
trainer/Bellman Errors 1 Min                  2.44618e-08
trainer/Bellman Errors 2 Mean                 1.98012
trainer/Bellman Errors 2 Std                 12.5301
trainer/Bellman Errors 2 Max                342.513
trainer/Bellman Errors 2 Min                  1.6217e-07
trainer/Policy Action Mean                    0.233626
trainer/Policy Action Std                     0.825067
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     516000
expl/num paths total                      12900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.779281
expl/Rewards Std                              0.658041
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            31.1712
expl/Returns Std                             14.4106
expl/Returns Max                             40.188
expl/Returns Min                              0
expl/Actions Mean                             0.312936
expl/Actions Std                              0.757853
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.1712
expl/env_infos/final/reward_dist Mean         1.2862
expl/env_infos/final/reward_dist Std          0.602616
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00124203
expl/env_infos/initial/reward_dist Std        0.00333629
expl/env_infos/initial/reward_dist Max        0.015141
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.779281
expl/env_infos/reward_dist Std                0.658041
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     103200
eval/num paths total                       2580
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.43411
eval/Rewards Std                              0.605726
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            17.3644
eval/Returns Std                             18.3318
eval/Returns Max                             40.3537
eval/Returns Min                              0
eval/Actions Mean                             0.127361
eval/Actions Std                              0.87426
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         17.3644
eval/env_infos/final/reward_dist Mean         0.7555
eval/env_infos/final/reward_dist Std          0.759823
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00102157
eval/env_infos/initial/reward_dist Std        0.00175539
eval/env_infos/initial/reward_dist Max        0.00465013
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.43411
eval/env_infos/reward_dist Std                0.605726
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00564044
time/evaluation sampling (s)                  3.48739
time/exploration sampling (s)                17.6975
time/logging (s)                              0.00529615
time/saving (s)                               0.00239072
time/training (s)                             4.7599
time/epoch (s)                               25.9581
time/total (s)                             6609.52
Epoch                                       257
---------------------------------------  ----------------
2023-08-05 02:11:47.553282 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 258 finished
---------------------------------------  ----------------
epoch                                       258
replay_buffer/size                       518000
trainer/QF1 Loss                              2.03177
trainer/QF2 Loss                              1.96035
trainer/Policy Loss                         -11.5625
trainer/Q1 Predictions Mean                  10.1513
trainer/Q1 Predictions Std                   13.0923
trainer/Q1 Predictions Max                   51.8804
trainer/Q1 Predictions Min                  -52.5265
trainer/Q2 Predictions Mean                  10.1509
trainer/Q2 Predictions Std                   13.1186
trainer/Q2 Predictions Max                   52.2078
trainer/Q2 Predictions Min                  -52.0644
trainer/Q Targets Mean                       10.141
trainer/Q Targets Std                        13.2009
trainer/Q Targets Max                        50.5847
trainer/Q Targets Min                       -52.0107
trainer/Bellman Errors 1 Mean                 2.03177
trainer/Bellman Errors 1 Std                 14.626
trainer/Bellman Errors 1 Max                412.144
trainer/Bellman Errors 1 Min                  8.73479e-09
trainer/Bellman Errors 2 Mean                 1.96035
trainer/Bellman Errors 2 Std                 13.8359
trainer/Bellman Errors 2 Max                382.558
trainer/Bellman Errors 2 Min                  1.00248e-07
trainer/Policy Action Mean                    0.218963
trainer/Policy Action Std                     0.830224
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     518000
expl/num paths total                      12950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.800141
expl/Rewards Std                              0.653396
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            32.0056
expl/Returns Std                             13.8306
expl/Returns Max                             40.8905
expl/Returns Min                              0
expl/Actions Mean                             0.284388
expl/Actions Std                              0.77047
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.0056
expl/env_infos/final/reward_dist Mean         1.31769
expl/env_infos/final/reward_dist Std          0.574979
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00132372
expl/env_infos/initial/reward_dist Std        0.00343504
expl/env_infos/initial/reward_dist Max        0.0135348
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.800141
expl/env_infos/reward_dist Std                0.653396
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     103600
eval/num paths total                       2590
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.93203
eval/Rewards Std                              0.61404
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            37.2812
eval/Returns Std                              1.53622
eval/Returns Max                             40.3065
eval/Returns Min                             34.9678
eval/Actions Mean                             0.323143
eval/Actions Std                              0.759139
eval/Actions Max                              1
eval/Actions Min                             -0.999999
eval/Num Paths                               10
eval/Average Returns                         37.2812
eval/env_infos/final/reward_dist Mean         1.56897
eval/env_infos/final/reward_dist Std          0.00223189
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          1.56432
eval/env_infos/initial/reward_dist Mean       0.000522825
eval/env_infos/initial/reward_dist Std        0.00156847
eval/env_infos/initial/reward_dist Max        0.00522825
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.93203
eval/env_infos/reward_dist Std                0.61404
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00586729
time/evaluation sampling (s)                  3.55465
time/exploration sampling (s)                17.3994
time/logging (s)                              0.00536688
time/saving (s)                               0.00242984
time/training (s)                             4.78842
time/epoch (s)                               25.7561
time/total (s)                             6635.27
Epoch                                       258
---------------------------------------  ----------------
2023-08-05 02:12:12.984333 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 259 finished
---------------------------------------  ----------------
epoch                                       259
replay_buffer/size                       520000
trainer/QF1 Loss                              1.89363
trainer/QF2 Loss                              1.83101
trainer/Policy Loss                         -10.5768
trainer/Q1 Predictions Mean                   9.52991
trainer/Q1 Predictions Std                   12.8393
trainer/Q1 Predictions Max                   49.4773
trainer/Q1 Predictions Min                  -56.1622
trainer/Q2 Predictions Mean                   9.54879
trainer/Q2 Predictions Std                   12.8541
trainer/Q2 Predictions Max                   49.6718
trainer/Q2 Predictions Min                  -57.1398
trainer/Q Targets Mean                        9.47739
trainer/Q Targets Std                        12.9258
trainer/Q Targets Max                        51.403
trainer/Q Targets Min                       -57.1066
trainer/Bellman Errors 1 Mean                 1.89363
trainer/Bellman Errors 1 Std                 11.8055
trainer/Bellman Errors 1 Max                350.484
trainer/Bellman Errors 1 Min                  6.5711e-09
trainer/Bellman Errors 2 Mean                 1.83101
trainer/Bellman Errors 2 Std                 11.6576
trainer/Bellman Errors 2 Max                328.222
trainer/Bellman Errors 2 Min                  6.14818e-10
trainer/Policy Action Mean                    0.239606
trainer/Policy Action Std                     0.825907
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     520000
expl/num paths total                      13000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.730982
expl/Rewards Std                              0.66542
expl/Rewards Max                              1.57071
expl/Rewards Min                              0
expl/Returns Mean                            29.2393
expl/Returns Std                             16.159
expl/Returns Max                             40.4956
expl/Returns Min                              0
expl/Actions Mean                             0.309034
expl/Actions Std                              0.768853
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.2393
expl/env_infos/final/reward_dist Mean         1.19202
expl/env_infos/final/reward_dist Std          0.669862
expl/env_infos/final/reward_dist Max          1.57071
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00072904
expl/env_infos/initial/reward_dist Std        0.0024996
expl/env_infos/initial/reward_dist Max        0.0139451
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.730982
expl/env_infos/reward_dist Std                0.66542
expl/env_infos/reward_dist Max                1.57071
expl/env_infos/reward_dist Min                0
eval/num steps total                     104000
eval/num paths total                       2600
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.768221
eval/Rewards Std                              0.662811
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            30.7288
eval/Returns Std                             14.9332
eval/Returns Max                             40.0484
eval/Returns Min                              0.843836
eval/Actions Mean                             0.348554
eval/Actions Std                              0.768806
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         30.7288
eval/env_infos/final/reward_dist Mean         1.25523
eval/env_infos/final/reward_dist Std          0.627618
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00100355
eval/env_infos/initial/reward_dist Std        0.00223859
eval/env_infos/initial/reward_dist Max        0.0072345
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.768221
eval/env_infos/reward_dist Std                0.662811
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00568253
time/evaluation sampling (s)                  3.51277
time/exploration sampling (s)                17.4977
time/logging (s)                              0.00529007
time/saving (s)                               0.00239618
time/training (s)                             4.40399
time/epoch (s)                               25.4278
time/total (s)                             6660.7
Epoch                                       259
---------------------------------------  ----------------
2023-08-05 02:12:40.492276 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 260 finished
---------------------------------------  ----------------
epoch                                       260
replay_buffer/size                       522000
trainer/QF1 Loss                              2.20525
trainer/QF2 Loss                              2.1001
trainer/Policy Loss                         -10.6346
trainer/Q1 Predictions Mean                   9.35626
trainer/Q1 Predictions Std                   13.2786
trainer/Q1 Predictions Max                   48.9443
trainer/Q1 Predictions Min                  -54.5025
trainer/Q2 Predictions Mean                   9.35312
trainer/Q2 Predictions Std                   13.2903
trainer/Q2 Predictions Max                   49.7983
trainer/Q2 Predictions Min                  -55.0131
trainer/Q Targets Mean                        9.41394
trainer/Q Targets Std                        13.4367
trainer/Q Targets Max                        50.6368
trainer/Q Targets Min                       -55.7186
trainer/Bellman Errors 1 Mean                 2.20525
trainer/Bellman Errors 1 Std                 15.0081
trainer/Bellman Errors 1 Max                395.052
trainer/Bellman Errors 1 Min                  3.42297e-08
trainer/Bellman Errors 2 Mean                 2.1001
trainer/Bellman Errors 2 Std                 14.6845
trainer/Bellman Errors 2 Max                387.881
trainer/Bellman Errors 2 Min                  6.82812e-08
trainer/Policy Action Mean                    0.236178
trainer/Policy Action Std                     0.827869
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     522000
expl/num paths total                      13050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.765598
expl/Rewards Std                              0.662127
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            30.6239
expl/Returns Std                             15.0042
expl/Returns Max                             40.9335
expl/Returns Min                              0.0147035
expl/Actions Mean                             0.313125
expl/Actions Std                              0.769113
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.6239
expl/env_infos/final/reward_dist Mean         1.25549
expl/env_infos/final/reward_dist Std          0.627745
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00136233
expl/env_infos/initial/reward_dist Std        0.00320216
expl/env_infos/initial/reward_dist Max        0.0118252
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.765598
expl/env_infos/reward_dist Std                0.662127
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     104400
eval/num paths total                       2610
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.868954
eval/Rewards Std                              0.644388
eval/Rewards Max                              1.57076
eval/Rewards Min                              0
eval/Returns Mean                            34.7582
eval/Returns Std                             11.4205
eval/Returns Max                             40.2116
eval/Returns Min                              0.643517
eval/Actions Mean                             0.343409
eval/Actions Std                              0.764845
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         34.7582
eval/env_infos/final/reward_dist Mean         1.41282
eval/env_infos/final/reward_dist Std          0.470941
eval/env_infos/final/reward_dist Max          1.57076
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.868954
eval/env_infos/reward_dist Std                0.644388
eval/env_infos/reward_dist Max                1.57076
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00581009
time/evaluation sampling (s)                  4.11506
time/exploration sampling (s)                18.6176
time/logging (s)                              0.00535364
time/saving (s)                               0.00246842
time/training (s)                             4.75852
time/epoch (s)                               27.5048
time/total (s)                             6688.21
Epoch                                       260
---------------------------------------  ----------------
2023-08-05 02:13:06.906034 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 261 finished
---------------------------------------  ----------------
epoch                                       261
replay_buffer/size                       524000
trainer/QF1 Loss                              2.1526
trainer/QF2 Loss                              2.15532
trainer/Policy Loss                         -10.3078
trainer/Q1 Predictions Mean                   9.15449
trainer/Q1 Predictions Std                   13.4602
trainer/Q1 Predictions Max                   49.9379
trainer/Q1 Predictions Min                  -59.629
trainer/Q2 Predictions Mean                   9.15739
trainer/Q2 Predictions Std                   13.4606
trainer/Q2 Predictions Max                   49.9166
trainer/Q2 Predictions Min                  -60.4245
trainer/Q Targets Mean                        9.13736
trainer/Q Targets Std                        13.4908
trainer/Q Targets Max                        49.2926
trainer/Q Targets Min                       -65.4762
trainer/Bellman Errors 1 Mean                 2.1526
trainer/Bellman Errors 1 Std                 13.5305
trainer/Bellman Errors 1 Max                264.699
trainer/Bellman Errors 1 Min                  5.32259e-09
trainer/Bellman Errors 2 Mean                 2.15532
trainer/Bellman Errors 2 Std                 13.6274
trainer/Bellman Errors 2 Max                263.439
trainer/Bellman Errors 2 Min                  2.02621e-07
trainer/Policy Action Mean                    0.241603
trainer/Policy Action Std                     0.823002
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     524000
expl/num paths total                      13100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.701418
expl/Rewards Std                              0.659297
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            28.0567
expl/Returns Std                             16.0804
expl/Returns Max                             40.6563
expl/Returns Min                              0
expl/Actions Mean                             0.295539
expl/Actions Std                              0.779591
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         28.0567
expl/env_infos/final/reward_dist Mean         1.17233
expl/env_infos/final/reward_dist Std          0.670612
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00207205
expl/env_infos/initial/reward_dist Std        0.00471916
expl/env_infos/initial/reward_dist Max        0.0157416
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.701418
expl/env_infos/reward_dist Std                0.659297
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     104800
eval/num paths total                       2620
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.657547
eval/Rewards Std                              0.661852
eval/Rewards Max                              1.57068
eval/Rewards Min                              0
eval/Returns Mean                            26.3019
eval/Returns Std                             17.0547
eval/Returns Max                             40.6971
eval/Returns Min                              0
eval/Actions Mean                             0.26737
eval/Actions Std                              0.818612
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         26.3019
eval/env_infos/final/reward_dist Mean         1.09032
eval/env_infos/final/reward_dist Std          0.714174
eval/env_infos/final/reward_dist Max          1.57068
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00196592
eval/env_infos/initial/reward_dist Std        0.00314473
eval/env_infos/initial/reward_dist Max        0.00885226
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.657547
eval/env_infos/reward_dist Std                0.661852
eval/env_infos/reward_dist Max                1.57068
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00583151
time/evaluation sampling (s)                  3.98654
time/exploration sampling (s)                17.7687
time/logging (s)                              0.0074393
time/saving (s)                               0.00271639
time/training (s)                             4.64145
time/epoch (s)                               26.4127
time/total (s)                             6714.63
Epoch                                       261
---------------------------------------  ----------------
2023-08-05 02:13:33.434884 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 262 finished
---------------------------------------  ----------------
epoch                                       262
replay_buffer/size                       526000
trainer/QF1 Loss                              1.78388
trainer/QF2 Loss                              1.77345
trainer/Policy Loss                         -10.8333
trainer/Q1 Predictions Mean                   9.47456
trainer/Q1 Predictions Std                   13.4338
trainer/Q1 Predictions Max                   48.3466
trainer/Q1 Predictions Min                  -52.2976
trainer/Q2 Predictions Mean                   9.45963
trainer/Q2 Predictions Std                   13.4171
trainer/Q2 Predictions Max                   48.3636
trainer/Q2 Predictions Min                  -53.4951
trainer/Q Targets Mean                        9.47651
trainer/Q Targets Std                        13.4844
trainer/Q Targets Max                        49.0404
trainer/Q Targets Min                       -49.4996
trainer/Bellman Errors 1 Mean                 1.78388
trainer/Bellman Errors 1 Std                  9.51372
trainer/Bellman Errors 1 Max                206.373
trainer/Bellman Errors 1 Min                  3.49392e-08
trainer/Bellman Errors 2 Mean                 1.77345
trainer/Bellman Errors 2 Std                  9.99822
trainer/Bellman Errors 2 Max                255.776
trainer/Bellman Errors 2 Min                  2.94676e-10
trainer/Policy Action Mean                    0.233381
trainer/Policy Action Std                     0.819945
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     526000
expl/num paths total                      13150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.624777
expl/Rewards Std                              0.661623
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            24.9911
expl/Returns Std                             17.6449
expl/Returns Max                             41.9572
expl/Returns Min                              0
expl/Actions Mean                             0.265498
expl/Actions Std                              0.779357
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.9911
expl/env_infos/final/reward_dist Mean         1.03576
expl/env_infos/final/reward_dist Std          0.742741
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00172922
expl/env_infos/initial/reward_dist Std        0.00408525
expl/env_infos/initial/reward_dist Max        0.0154827
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.624777
expl/env_infos/reward_dist Std                0.661623
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     105200
eval/num paths total                       2630
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.497672
eval/Rewards Std                              0.631404
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            19.9069
eval/Returns Std                             18.2129
eval/Returns Max                             40.4411
eval/Returns Min                              0
eval/Actions Mean                             0.199354
eval/Actions Std                              0.854612
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         19.9069
eval/env_infos/final/reward_dist Mean         0.852738
eval/env_infos/final/reward_dist Std          0.742702
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00187523
eval/env_infos/initial/reward_dist Std        0.0037688
eval/env_infos/initial/reward_dist Max        0.0102066
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.497672
eval/env_infos/reward_dist Std                0.631404
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00575377
time/evaluation sampling (s)                  4.15574
time/exploration sampling (s)                17.532
time/logging (s)                              0.00659142
time/saving (s)                               0.00230126
time/training (s)                             4.82004
time/epoch (s)                               26.5225
time/total (s)                             6741.15
Epoch                                       262
---------------------------------------  ----------------
2023-08-05 02:13:59.202755 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 263 finished
---------------------------------------  ----------------
epoch                                       263
replay_buffer/size                       528000
trainer/QF1 Loss                              2.09338
trainer/QF2 Loss                              1.98128
trainer/Policy Loss                         -10.3993
trainer/Q1 Predictions Mean                   9.00616
trainer/Q1 Predictions Std                   13.5553
trainer/Q1 Predictions Max                   48.466
trainer/Q1 Predictions Min                  -77.3976
trainer/Q2 Predictions Mean                   8.9819
trainer/Q2 Predictions Std                   13.5531
trainer/Q2 Predictions Max                   48.7817
trainer/Q2 Predictions Min                  -80.4046
trainer/Q Targets Mean                        9.09579
trainer/Q Targets Std                        13.718
trainer/Q Targets Max                        50.6855
trainer/Q Targets Min                       -77.6048
trainer/Bellman Errors 1 Mean                 2.09338
trainer/Bellman Errors 1 Std                 13.8649
trainer/Bellman Errors 1 Max                432.882
trainer/Bellman Errors 1 Min                  1.04981e-08
trainer/Bellman Errors 2 Mean                 1.98128
trainer/Bellman Errors 2 Std                 12.6479
trainer/Bellman Errors 2 Max                419.315
trainer/Bellman Errors 2 Min                  8.03629e-09
trainer/Policy Action Mean                    0.235984
trainer/Policy Action Std                     0.819735
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     528000
expl/num paths total                      13200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.879867
expl/Rewards Std                              0.630705
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            35.1947
expl/Returns Std                              9.32306
expl/Returns Max                             40.4915
expl/Returns Min                              0
expl/Actions Mean                             0.299475
expl/Actions Std                              0.752835
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         35.1947
expl/env_infos/final/reward_dist Mean         1.47236
expl/env_infos/final/reward_dist Std          0.372425
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000674423
expl/env_infos/initial/reward_dist Std        0.00246796
expl/env_infos/initial/reward_dist Max        0.0153562
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.879867
expl/env_infos/reward_dist Std                0.630705
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     105600
eval/num paths total                       2640
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.850383
eval/Rewards Std                              0.641616
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            34.0153
eval/Returns Std                             11.141
eval/Returns Max                             41.0562
eval/Returns Min                              1.01579
eval/Actions Mean                             0.328033
eval/Actions Std                              0.754317
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         34.0153
eval/env_infos/final/reward_dist Mean         1.41186
eval/env_infos/final/reward_dist Std          0.470626
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00142614
eval/env_infos/initial/reward_dist Std        0.00369386
eval/env_infos/initial/reward_dist Max        0.0123791
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.850383
eval/env_infos/reward_dist Std                0.641616
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00583393
time/evaluation sampling (s)                  3.99968
time/exploration sampling (s)                17.4235
time/logging (s)                              0.00536604
time/saving (s)                               0.0023503
time/training (s)                             4.32545
time/epoch (s)                               25.7621
time/total (s)                             6766.92
Epoch                                       263
---------------------------------------  ----------------
2023-08-05 02:14:24.884316 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 264 finished
---------------------------------------  ----------------
epoch                                       264
replay_buffer/size                       530000
trainer/QF1 Loss                              2.10068
trainer/QF2 Loss                              1.9764
trainer/Policy Loss                         -10.3512
trainer/Q1 Predictions Mean                   9.09031
trainer/Q1 Predictions Std                   13.6805
trainer/Q1 Predictions Max                   49.4259
trainer/Q1 Predictions Min                  -58.3148
trainer/Q2 Predictions Mean                   9.07187
trainer/Q2 Predictions Std                   13.674
trainer/Q2 Predictions Max                   49.6343
trainer/Q2 Predictions Min                  -58.6541
trainer/Q Targets Mean                        9.19667
trainer/Q Targets Std                        13.7095
trainer/Q Targets Max                        48.9212
trainer/Q Targets Min                       -54.3432
trainer/Bellman Errors 1 Mean                 2.10068
trainer/Bellman Errors 1 Std                 15.3964
trainer/Bellman Errors 1 Max                520.986
trainer/Bellman Errors 1 Min                  2.21335e-08
trainer/Bellman Errors 2 Mean                 1.9764
trainer/Bellman Errors 2 Std                 13.8927
trainer/Bellman Errors 2 Max                454.53
trainer/Bellman Errors 2 Min                  2.9796e-08
trainer/Policy Action Mean                    0.24046
trainer/Policy Action Std                     0.817829
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     530000
expl/num paths total                      13250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.897153
expl/Rewards Std                              0.63114
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            35.8861
expl/Returns Std                              8.9538
expl/Returns Max                             40.1497
expl/Returns Min                              0.626869
expl/Actions Mean                             0.318126
expl/Actions Std                              0.743544
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         35.8861
expl/env_infos/final/reward_dist Mean         1.47467
expl/env_infos/final/reward_dist Std          0.372573
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       2.94194e-05
expl/env_infos/initial/reward_dist Std        0.000205936
expl/env_infos/initial/reward_dist Max        0.00147097
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.897153
expl/env_infos/reward_dist Std                0.63114
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     106000
eval/num paths total                       2650
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.787502
eval/Rewards Std                              0.662816
eval/Rewards Max                              1.57069
eval/Rewards Min                              0
eval/Returns Mean                            31.5001
eval/Returns Std                             15.4708
eval/Returns Max                             40.8637
eval/Returns Min                              0.611827
eval/Actions Mean                             0.342106
eval/Actions Std                              0.760294
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.5001
eval/env_infos/final/reward_dist Mean         1.25539
eval/env_infos/final/reward_dist Std          0.627695
eval/env_infos/final/reward_dist Max          1.57069
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00128824
eval/env_infos/initial/reward_dist Std        0.00307369
eval/env_infos/initial/reward_dist Max        0.010381
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.787502
eval/env_infos/reward_dist Std                0.662816
eval/env_infos/reward_dist Max                1.57069
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00568685
time/evaluation sampling (s)                  3.54188
time/exploration sampling (s)                17.4297
time/logging (s)                              0.00539258
time/saving (s)                               0.00236467
time/training (s)                             4.693
time/epoch (s)                               25.6781
time/total (s)                             6792.6
Epoch                                       264
---------------------------------------  ----------------
2023-08-05 02:14:52.898739 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 265 finished
---------------------------------------  ----------------
epoch                                       265
replay_buffer/size                       532000
trainer/QF1 Loss                              2.65185
trainer/QF2 Loss                              2.50477
trainer/Policy Loss                         -10.1826
trainer/Q1 Predictions Mean                   8.95173
trainer/Q1 Predictions Std                   13.6958
trainer/Q1 Predictions Max                   47.6274
trainer/Q1 Predictions Min                  -65.5101
trainer/Q2 Predictions Mean                   8.8842
trainer/Q2 Predictions Std                   13.6761
trainer/Q2 Predictions Max                   48.3183
trainer/Q2 Predictions Min                  -66.5957
trainer/Q Targets Mean                        8.961
trainer/Q Targets Std                        13.8114
trainer/Q Targets Max                        47.9011
trainer/Q Targets Min                       -66.5186
trainer/Bellman Errors 1 Mean                 2.65185
trainer/Bellman Errors 1 Std                 18.9105
trainer/Bellman Errors 1 Max                439.867
trainer/Bellman Errors 1 Min                  1.3481e-07
trainer/Bellman Errors 2 Mean                 2.50477
trainer/Bellman Errors 2 Std                 17.9344
trainer/Bellman Errors 2 Max                415.83
trainer/Bellman Errors 2 Min                  3.44553e-07
trainer/Policy Action Mean                    0.257843
trainer/Policy Action Std                     0.817568
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     532000
expl/num paths total                      13300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.927232
expl/Rewards Std                              0.622881
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            37.0893
expl/Returns Std                              7.56228
expl/Returns Max                             41.0603
expl/Returns Min                              0.5021
expl/Actions Mean                             0.329442
expl/Actions Std                              0.736439
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         37.0893
expl/env_infos/final/reward_dist Mean         1.50628
expl/env_infos/final/reward_dist Std          0.307474
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000484624
expl/env_infos/initial/reward_dist Std        0.00163937
expl/env_infos/initial/reward_dist Max        0.00848168
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.927232
expl/env_infos/reward_dist Std                0.622881
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     106400
eval/num paths total                       2660
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.949086
eval/Rewards Std                              0.614296
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            37.9634
eval/Returns Std                              1.65825
eval/Returns Max                             41.0732
eval/Returns Min                             36.2218
eval/Actions Mean                             0.345345
eval/Actions Std                              0.748275
eval/Actions Max                              1
eval/Actions Min                             -0.999998
eval/Num Paths                               10
eval/Average Returns                         37.9634
eval/env_infos/final/reward_dist Mean         1.56789
eval/env_infos/final/reward_dist Std          0.00280397
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          1.56248
eval/env_infos/initial/reward_dist Mean       0.00147658
eval/env_infos/initial/reward_dist Std        0.00318004
eval/env_infos/initial/reward_dist Max        0.0100206
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.949086
eval/env_infos/reward_dist Std                0.614296
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00578812
time/evaluation sampling (s)                  4.32733
time/exploration sampling (s)                17.7251
time/logging (s)                              0.00738161
time/saving (s)                               0.00343118
time/training (s)                             5.94405
time/epoch (s)                               28.013
time/total (s)                             6820.61
Epoch                                       265
---------------------------------------  ----------------
2023-08-05 02:15:18.507532 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 266 finished
---------------------------------------  ----------------
epoch                                       266
replay_buffer/size                       534000
trainer/QF1 Loss                              1.97153
trainer/QF2 Loss                              1.82907
trainer/Policy Loss                         -10.4435
trainer/Q1 Predictions Mean                   9.06292
trainer/Q1 Predictions Std                   13.7765
trainer/Q1 Predictions Max                   49.1878
trainer/Q1 Predictions Min                  -62.0987
trainer/Q2 Predictions Mean                   9.05557
trainer/Q2 Predictions Std                   13.7941
trainer/Q2 Predictions Max                   49.7854
trainer/Q2 Predictions Min                  -63.5335
trainer/Q Targets Mean                        9.13264
trainer/Q Targets Std                        13.8804
trainer/Q Targets Max                        51.2596
trainer/Q Targets Min                       -61.954
trainer/Bellman Errors 1 Mean                 1.97153
trainer/Bellman Errors 1 Std                 11.9215
trainer/Bellman Errors 1 Max                415.77
trainer/Bellman Errors 1 Min                  2.45927e-09
trainer/Bellman Errors 2 Mean                 1.82907
trainer/Bellman Errors 2 Std                 11.0735
trainer/Bellman Errors 2 Max                386.153
trainer/Bellman Errors 2 Min                  4.54694e-08
trainer/Policy Action Mean                    0.265117
trainer/Policy Action Std                     0.818559
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     534000
expl/num paths total                      13350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.858067
expl/Rewards Std                              0.648739
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            34.3227
expl/Returns Std                             12.5675
expl/Returns Max                             41.8223
expl/Returns Min                              0
expl/Actions Mean                             0.320888
expl/Actions Std                              0.750981
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         34.3227
expl/env_infos/final/reward_dist Mean         1.38046
expl/env_infos/final/reward_dist Std          0.509773
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0012986
expl/env_infos/initial/reward_dist Std        0.00378435
expl/env_infos/initial/reward_dist Max        0.0160868
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.858067
expl/env_infos/reward_dist Std                0.648739
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     106800
eval/num paths total                       2670
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.966703
eval/Rewards Std                              0.610772
eval/Rewards Max                              1.57067
eval/Rewards Min                              0
eval/Returns Mean                            38.6681
eval/Returns Std                              1.21354
eval/Returns Max                             41.4171
eval/Returns Min                             37.4426
eval/Actions Mean                             0.353228
eval/Actions Std                              0.748974
eval/Actions Max                              1
eval/Actions Min                             -0.999996
eval/Num Paths                               10
eval/Average Returns                         38.6681
eval/env_infos/final/reward_dist Mean         1.56914
eval/env_infos/final/reward_dist Std          0.00188577
eval/env_infos/final/reward_dist Max          1.57067
eval/env_infos/final/reward_dist Min          1.56407
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.966703
eval/env_infos/reward_dist Std                0.610772
eval/env_infos/reward_dist Max                1.57067
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587509
time/evaluation sampling (s)                  3.6049
time/exploration sampling (s)                17.3785
time/logging (s)                              0.00541415
time/saving (s)                               0.00234837
time/training (s)                             4.60444
time/epoch (s)                               25.6014
time/total (s)                             6846.22
Epoch                                       266
---------------------------------------  ----------------
2023-08-05 02:15:44.225434 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 267 finished
---------------------------------------  ----------------
epoch                                       267
replay_buffer/size                       536000
trainer/QF1 Loss                              2.93052
trainer/QF2 Loss                              2.92281
trainer/Policy Loss                         -10.4107
trainer/Q1 Predictions Mean                   9.27589
trainer/Q1 Predictions Std                   13.9022
trainer/Q1 Predictions Max                   49.5777
trainer/Q1 Predictions Min                  -52.2407
trainer/Q2 Predictions Mean                   9.26997
trainer/Q2 Predictions Std                   13.9082
trainer/Q2 Predictions Max                   49.3981
trainer/Q2 Predictions Min                  -56.1813
trainer/Q Targets Mean                        9.15018
trainer/Q Targets Std                        13.9924
trainer/Q Targets Max                        50.7898
trainer/Q Targets Min                       -52.3379
trainer/Bellman Errors 1 Mean                 2.93052
trainer/Bellman Errors 1 Std                 22.0789
trainer/Bellman Errors 1 Max                493.062
trainer/Bellman Errors 1 Min                  4.22372e-08
trainer/Bellman Errors 2 Mean                 2.92281
trainer/Bellman Errors 2 Std                 22.5566
trainer/Bellman Errors 2 Max                525.777
trainer/Bellman Errors 2 Min                  4.72792e-08
trainer/Policy Action Mean                    0.267954
trainer/Policy Action Std                     0.815122
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     536000
expl/num paths total                      13400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.801195
expl/Rewards Std                              0.661256
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            32.0478
expl/Returns Std                             14.784
expl/Returns Max                             41.5385
expl/Returns Min                              0
expl/Actions Mean                             0.33336
expl/Actions Std                              0.749685
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.0478
expl/env_infos/final/reward_dist Mean         1.28681
expl/env_infos/final/reward_dist Std          0.6029
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00166179
expl/env_infos/initial/reward_dist Std        0.00346273
expl/env_infos/initial/reward_dist Max        0.0129777
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.801195
expl/env_infos/reward_dist Std                0.661256
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     107200
eval/num paths total                       2680
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.788649
eval/Rewards Std                              0.665746
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            31.546
eval/Returns Std                             15.4558
eval/Returns Max                             40.8866
eval/Returns Min                              0.684311
eval/Actions Mean                             0.372314
eval/Actions Std                              0.760829
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         31.546
eval/env_infos/final/reward_dist Mean         1.25539
eval/env_infos/final/reward_dist Std          0.627696
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000497321
eval/env_infos/initial/reward_dist Std        0.00149196
eval/env_infos/initial/reward_dist Max        0.00497321
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.788649
eval/env_infos/reward_dist Std                0.665746
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593774
time/evaluation sampling (s)                  3.67837
time/exploration sampling (s)                17.4182
time/logging (s)                              0.00548434
time/saving (s)                               0.00234943
time/training (s)                             4.60153
time/epoch (s)                               25.7119
time/total (s)                             6871.93
Epoch                                       267
---------------------------------------  ----------------
2023-08-05 02:16:10.214409 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 268 finished
---------------------------------------  ----------------
epoch                                       268
replay_buffer/size                       538000
trainer/QF1 Loss                              2.57039
trainer/QF2 Loss                              2.4507
trainer/Policy Loss                         -10.511
trainer/Q1 Predictions Mean                   9.20595
trainer/Q1 Predictions Std                   13.7291
trainer/Q1 Predictions Max                   49.4432
trainer/Q1 Predictions Min                  -66.9749
trainer/Q2 Predictions Mean                   9.19582
trainer/Q2 Predictions Std                   13.7332
trainer/Q2 Predictions Max                   50.0921
trainer/Q2 Predictions Min                  -66.4102
trainer/Q Targets Mean                        9.16146
trainer/Q Targets Std                        13.7653
trainer/Q Targets Max                        49.1021
trainer/Q Targets Min                       -60.5071
trainer/Bellman Errors 1 Mean                 2.57039
trainer/Bellman Errors 1 Std                 19.8236
trainer/Bellman Errors 1 Max                516.501
trainer/Bellman Errors 1 Min                  5.41477e-08
trainer/Bellman Errors 2 Mean                 2.4507
trainer/Bellman Errors 2 Std                 19.2005
trainer/Bellman Errors 2 Max                507.952
trainer/Bellman Errors 2 Min                  2.32831e-10
trainer/Policy Action Mean                    0.271539
trainer/Policy Action Std                     0.816538
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     538000
expl/num paths total                      13450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.834911
expl/Rewards Std                              0.65439
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            33.3964
expl/Returns Std                             13.3404
expl/Returns Max                             42.3967
expl/Returns Min                              0
expl/Actions Mean                             0.331442
expl/Actions Std                              0.748282
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         33.3964
expl/env_infos/final/reward_dist Mean         1.34952
expl/env_infos/final/reward_dist Std          0.544496
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00139141
expl/env_infos/initial/reward_dist Std        0.00366883
expl/env_infos/initial/reward_dist Max        0.0138078
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.834911
expl/env_infos/reward_dist Std                0.65439
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     107600
eval/num paths total                       2690
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.88962
eval/Rewards Std                              0.63911
eval/Rewards Max                              1.57071
eval/Rewards Min                              0
eval/Returns Mean                            35.5848
eval/Returns Std                             12.3461
eval/Returns Max                             41.7908
eval/Returns Min                              0
eval/Actions Mean                             0.275022
eval/Actions Std                              0.81094
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.5848
eval/env_infos/final/reward_dist Mean         1.41123
eval/env_infos/final/reward_dist Std          0.470419
eval/env_infos/final/reward_dist Max          1.57071
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.002578
eval/env_infos/initial/reward_dist Std        0.00420879
eval/env_infos/initial/reward_dist Max        0.0138878
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.88962
eval/env_infos/reward_dist Std                0.63911
eval/env_infos/reward_dist Max                1.57071
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00595939
time/evaluation sampling (s)                  3.60341
time/exploration sampling (s)                17.618
time/logging (s)                              0.00529842
time/saving (s)                               0.00235676
time/training (s)                             4.75022
time/epoch (s)                               25.9852
time/total (s)                             6897.92
Epoch                                       268
---------------------------------------  ----------------
2023-08-05 02:16:36.221031 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 269 finished
---------------------------------------  ----------------
epoch                                       269
replay_buffer/size                       540000
trainer/QF1 Loss                              2.24794
trainer/QF2 Loss                              2.16587
trainer/Policy Loss                         -10.2421
trainer/Q1 Predictions Mean                   9.18308
trainer/Q1 Predictions Std                   14.0218
trainer/Q1 Predictions Max                   51.1332
trainer/Q1 Predictions Min                  -59.4501
trainer/Q2 Predictions Mean                   9.19165
trainer/Q2 Predictions Std                   14.0456
trainer/Q2 Predictions Max                   51.0208
trainer/Q2 Predictions Min                  -59.3831
trainer/Q Targets Mean                        9.0884
trainer/Q Targets Std                        14.0992
trainer/Q Targets Max                        49.486
trainer/Q Targets Min                       -60.6614
trainer/Bellman Errors 1 Mean                 2.24794
trainer/Bellman Errors 1 Std                 14.1881
trainer/Bellman Errors 1 Max                460.761
trainer/Bellman Errors 1 Min                  5.10854e-08
trainer/Bellman Errors 2 Mean                 2.16587
trainer/Bellman Errors 2 Std                 13.638
trainer/Bellman Errors 2 Max                442.415
trainer/Bellman Errors 2 Min                  1.92449e-09
trainer/Policy Action Mean                    0.271919
trainer/Policy Action Std                     0.810301
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     540000
expl/num paths total                      13500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.878561
expl/Rewards Std                              0.644269
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            35.1424
expl/Returns Std                             11.6198
expl/Returns Max                             41.8158
expl/Returns Min                              0
expl/Actions Mean                             0.332379
expl/Actions Std                              0.747679
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         35.1424
expl/env_infos/final/reward_dist Mean         1.41153
expl/env_infos/final/reward_dist Std          0.470515
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00129172
expl/env_infos/initial/reward_dist Std        0.00361205
expl/env_infos/initial/reward_dist Max        0.0153008
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.878561
expl/env_infos/reward_dist Std                0.644269
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     108000
eval/num paths total                       2700
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.888819
eval/Rewards Std                              0.644586
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            35.5527
eval/Returns Std                             11.7087
eval/Returns Max                             42.6239
eval/Returns Min                              0.703629
eval/Actions Mean                             0.353439
eval/Actions Std                              0.755627
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.5527
eval/env_infos/final/reward_dist Mean         1.41324
eval/env_infos/final/reward_dist Std          0.471081
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000777122
eval/env_infos/initial/reward_dist Std        0.00233137
eval/env_infos/initial/reward_dist Max        0.00777122
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.888819
eval/env_infos/reward_dist Std                0.644586
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00604503
time/evaluation sampling (s)                  3.50431
time/exploration sampling (s)                17.7635
time/logging (s)                              0.00536261
time/saving (s)                               0.00238239
time/training (s)                             4.72173
time/epoch (s)                               26.0034
time/total (s)                             6923.92
Epoch                                       269
---------------------------------------  ----------------
2023-08-05 02:17:02.910754 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 270 finished
---------------------------------------  ----------------
epoch                                       270
replay_buffer/size                       542000
trainer/QF1 Loss                              2.38339
trainer/QF2 Loss                              2.31239
trainer/Policy Loss                         -10.1981
trainer/Q1 Predictions Mean                   8.92493
trainer/Q1 Predictions Std                   14.3648
trainer/Q1 Predictions Max                   49.9209
trainer/Q1 Predictions Min                  -73.5927
trainer/Q2 Predictions Mean                   8.90943
trainer/Q2 Predictions Std                   14.3882
trainer/Q2 Predictions Max                   50.1184
trainer/Q2 Predictions Min                  -76.6013
trainer/Q Targets Mean                        8.9235
trainer/Q Targets Std                        14.4628
trainer/Q Targets Max                        50.1501
trainer/Q Targets Min                       -70.0407
trainer/Bellman Errors 1 Mean                 2.38339
trainer/Bellman Errors 1 Std                 15.5379
trainer/Bellman Errors 1 Max                503.039
trainer/Bellman Errors 1 Min                  5.53337e-09
trainer/Bellman Errors 2 Mean                 2.31239
trainer/Bellman Errors 2 Std                 15.3674
trainer/Bellman Errors 2 Max                492.891
trainer/Bellman Errors 2 Min                  9.31323e-10
trainer/Policy Action Mean                    0.280445
trainer/Policy Action Std                     0.812254
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     542000
expl/num paths total                      13550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.734672
expl/Rewards Std                              0.669574
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            29.3869
expl/Returns Std                             16.9137
expl/Returns Max                             42.1207
expl/Returns Min                              0
expl/Actions Mean                             0.311013
expl/Actions Std                              0.765525
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         29.3869
expl/env_infos/final/reward_dist Mean         1.17719
expl/env_infos/final/reward_dist Std          0.670399
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0015692
expl/env_infos/initial/reward_dist Std        0.00392748
expl/env_infos/initial/reward_dist Max        0.0150107
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.734672
expl/env_infos/reward_dist Std                0.669574
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     108400
eval/num paths total                       2710
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.889989
eval/Rewards Std                              0.642008
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            35.5995
eval/Returns Std                             11.7192
eval/Returns Max                             40.9394
eval/Returns Min                              0.657135
eval/Actions Mean                             0.353291
eval/Actions Std                              0.754742
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.5995
eval/env_infos/final/reward_dist Mean         1.41202
eval/env_infos/final/reward_dist Std          0.470676
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00161148
eval/env_infos/initial/reward_dist Std        0.00462731
eval/env_infos/initial/reward_dist Max        0.0154819
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.889989
eval/env_infos/reward_dist Std                0.642008
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00812693
time/evaluation sampling (s)                  3.50465
time/exploration sampling (s)                18.2449
time/logging (s)                              0.00533128
time/saving (s)                               0.00241231
time/training (s)                             4.92092
time/epoch (s)                               26.6864
time/total (s)                             6950.61
Epoch                                       270
---------------------------------------  ----------------
2023-08-05 02:17:28.774153 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 271 finished
---------------------------------------  ----------------
epoch                                       271
replay_buffer/size                       544000
trainer/QF1 Loss                              2.1689
trainer/QF2 Loss                              2.04936
trainer/Policy Loss                         -10.2427
trainer/Q1 Predictions Mean                   8.99178
trainer/Q1 Predictions Std                   14.0626
trainer/Q1 Predictions Max                   51.0582
trainer/Q1 Predictions Min                  -62.4323
trainer/Q2 Predictions Mean                   8.98914
trainer/Q2 Predictions Std                   14.0604
trainer/Q2 Predictions Max                   51.7926
trainer/Q2 Predictions Min                  -63.1843
trainer/Q Targets Mean                        8.92515
trainer/Q Targets Std                        14.1598
trainer/Q Targets Max                        51.7662
trainer/Q Targets Min                       -60.3401
trainer/Bellman Errors 1 Mean                 2.1689
trainer/Bellman Errors 1 Std                 14.1712
trainer/Bellman Errors 1 Max                409.955
trainer/Bellman Errors 1 Min                  1.39844e-08
trainer/Bellman Errors 2 Mean                 2.04936
trainer/Bellman Errors 2 Std                 13.7014
trainer/Bellman Errors 2 Max                425.872
trainer/Bellman Errors 2 Min                  4.55253e-09
trainer/Policy Action Mean                    0.275991
trainer/Policy Action Std                     0.810154
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     544000
expl/num paths total                      13600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.865342
expl/Rewards Std                              0.647968
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            34.6137
expl/Returns Std                             12.5914
expl/Returns Max                             42.3216
expl/Returns Min                              0.62509
expl/Actions Mean                             0.347137
expl/Actions Std                              0.737826
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         34.6137
expl/env_infos/final/reward_dist Mean         1.38098
expl/env_infos/final/reward_dist Std          0.509963
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00176458
expl/env_infos/initial/reward_dist Std        0.00376178
expl/env_infos/initial/reward_dist Max        0.0149292
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.865342
expl/env_infos/reward_dist Std                0.647968
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     108800
eval/num paths total                       2720
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.884143
eval/Rewards Std                              0.644076
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            35.3657
eval/Returns Std                             11.6253
eval/Returns Max                             41.5037
eval/Returns Min                              0.902345
eval/Actions Mean                             0.35603
eval/Actions Std                              0.755223
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.3657
eval/env_infos/final/reward_dist Mean         1.41141
eval/env_infos/final/reward_dist Std          0.470475
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0028567
eval/env_infos/initial/reward_dist Std        0.00509905
eval/env_infos/initial/reward_dist Max        0.0169615
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.884143
eval/env_infos/reward_dist Std                0.644076
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00645455
time/evaluation sampling (s)                  3.52017
time/exploration sampling (s)                17.6013
time/logging (s)                              0.00531912
time/saving (s)                               0.00238029
time/training (s)                             4.72444
time/epoch (s)                               25.8601
time/total (s)                             6976.47
Epoch                                       271
---------------------------------------  ----------------
2023-08-05 02:17:54.775142 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 272 finished
---------------------------------------  ----------------
epoch                                       272
replay_buffer/size                       546000
trainer/QF1 Loss                              2.99314
trainer/QF2 Loss                              2.90718
trainer/Policy Loss                         -10.1368
trainer/Q1 Predictions Mean                   8.8632
trainer/Q1 Predictions Std                   14.5501
trainer/Q1 Predictions Max                   48.6221
trainer/Q1 Predictions Min                  -75.324
trainer/Q2 Predictions Mean                   8.88825
trainer/Q2 Predictions Std                   14.5698
trainer/Q2 Predictions Max                   48.9765
trainer/Q2 Predictions Min                  -77.8762
trainer/Q Targets Mean                        8.85093
trainer/Q Targets Std                        14.6234
trainer/Q Targets Max                        49.6122
trainer/Q Targets Min                       -71.2994
trainer/Bellman Errors 1 Mean                 2.99314
trainer/Bellman Errors 1 Std                 20.4071
trainer/Bellman Errors 1 Max                511.462
trainer/Bellman Errors 1 Min                  4.68214e-09
trainer/Bellman Errors 2 Mean                 2.90718
trainer/Bellman Errors 2 Std                 20.1741
trainer/Bellman Errors 2 Max                507.294
trainer/Bellman Errors 2 Min                  7.04313e-09
trainer/Policy Action Mean                    0.275892
trainer/Policy Action Std                     0.811671
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     546000
expl/num paths total                      13650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.878692
expl/Rewards Std                              0.643154
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            35.1477
expl/Returns Std                             11.5492
expl/Returns Max                             41.7709
expl/Returns Min                              0.620519
expl/Actions Mean                             0.345249
expl/Actions Std                              0.737166
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         35.1477
expl/env_infos/final/reward_dist Mean         1.41163
expl/env_infos/final/reward_dist Std          0.470548
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00153898
expl/env_infos/initial/reward_dist Std        0.00344676
expl/env_infos/initial/reward_dist Max        0.0137343
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.878692
expl/env_infos/reward_dist Std                0.643154
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     109200
eval/num paths total                       2730
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.879162
eval/Rewards Std                              0.646319
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            35.1665
eval/Returns Std                             11.5062
eval/Returns Max                             41.4253
eval/Returns Min                              0.905682
eval/Actions Mean                             0.357318
eval/Actions Std                              0.752072
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         35.1665
eval/env_infos/final/reward_dist Mean         1.41261
eval/env_infos/final/reward_dist Std          0.470873
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00172453
eval/env_infos/initial/reward_dist Std        0.00304255
eval/env_infos/initial/reward_dist Max        0.00882057
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.879162
eval/env_infos/reward_dist Std                0.646319
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00807624
time/evaluation sampling (s)                  3.43595
time/exploration sampling (s)                18.0085
time/logging (s)                              0.00531469
time/saving (s)                               0.00240872
time/training (s)                             4.53755
time/epoch (s)                               25.9978
time/total (s)                             7002.47
Epoch                                       272
---------------------------------------  ----------------
2023-08-05 02:18:20.797229 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 273 finished
---------------------------------------  ----------------
epoch                                       273
replay_buffer/size                       548000
trainer/QF1 Loss                              2.42955
trainer/QF2 Loss                              2.41139
trainer/Policy Loss                         -10.8023
trainer/Q1 Predictions Mean                   9.42377
trainer/Q1 Predictions Std                   13.7741
trainer/Q1 Predictions Max                   48.9753
trainer/Q1 Predictions Min                  -71.8755
trainer/Q2 Predictions Mean                   9.43708
trainer/Q2 Predictions Std                   13.7825
trainer/Q2 Predictions Max                   49.1284
trainer/Q2 Predictions Min                  -71.6681
trainer/Q Targets Mean                        9.54309
trainer/Q Targets Std                        13.8909
trainer/Q Targets Max                        49.748
trainer/Q Targets Min                       -67.9357
trainer/Bellman Errors 1 Mean                 2.42955
trainer/Bellman Errors 1 Std                 17.755
trainer/Bellman Errors 1 Max                502.997
trainer/Bellman Errors 1 Min                  6.14818e-10
trainer/Bellman Errors 2 Mean                 2.41139
trainer/Bellman Errors 2 Std                 18.1379
trainer/Bellman Errors 2 Max                491.548
trainer/Bellman Errors 2 Min                  2.21335e-08
trainer/Policy Action Mean                    0.261381
trainer/Policy Action Std                     0.813603
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     548000
expl/num paths total                      13700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.828813
expl/Rewards Std                              0.655252
expl/Rewards Max                              1.57076
expl/Rewards Min                              0
expl/Returns Mean                            33.1525
expl/Returns Std                             13.2501
expl/Returns Max                             41.4419
expl/Returns Min                              0
expl/Actions Mean                             0.319157
expl/Actions Std                              0.751901
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         33.1525
expl/env_infos/final/reward_dist Mean         1.34863
expl/env_infos/final/reward_dist Std          0.54414
expl/env_infos/final/reward_dist Max          1.57076
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000709351
expl/env_infos/initial/reward_dist Std        0.00259304
expl/env_infos/initial/reward_dist Max        0.0122739
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.828813
expl/env_infos/reward_dist Std                0.655252
expl/env_infos/reward_dist Max                1.57076
expl/env_infos/reward_dist Min                0
eval/num steps total                     109600
eval/num paths total                       2740
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.986636
eval/Rewards Std                              0.605025
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            39.4654
eval/Returns Std                              1.46274
eval/Returns Max                             41.3051
eval/Returns Min                             36.3293
eval/Actions Mean                             0.330335
eval/Actions Std                              0.759508
eval/Actions Max                              1
eval/Actions Min                             -0.999976
eval/Num Paths                               10
eval/Average Returns                         39.4654
eval/env_infos/final/reward_dist Mean         1.56981
eval/env_infos/final/reward_dist Std          0.000874404
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          1.56847
eval/env_infos/initial/reward_dist Mean       0.00241013
eval/env_infos/initial/reward_dist Std        0.00398461
eval/env_infos/initial/reward_dist Max        0.0118736
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.986636
eval/env_infos/reward_dist Std                0.605025
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00583399
time/evaluation sampling (s)                  3.4921
time/exploration sampling (s)                18.0518
time/logging (s)                              0.0053316
time/saving (s)                               0.00233717
time/training (s)                             4.46154
time/epoch (s)                               26.0189
time/total (s)                             7028.49
Epoch                                       273
---------------------------------------  ----------------
2023-08-05 02:18:46.863050 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 274 finished
---------------------------------------  ----------------
epoch                                       274
replay_buffer/size                       550000
trainer/QF1 Loss                              2.65004
trainer/QF2 Loss                              2.57021
trainer/Policy Loss                         -10.1398
trainer/Q1 Predictions Mean                   8.84921
trainer/Q1 Predictions Std                   14.1079
trainer/Q1 Predictions Max                   51.4663
trainer/Q1 Predictions Min                  -68.4831
trainer/Q2 Predictions Mean                   8.82253
trainer/Q2 Predictions Std                   14.0776
trainer/Q2 Predictions Max                   52.1173
trainer/Q2 Predictions Min                  -68.5731
trainer/Q Targets Mean                        8.75589
trainer/Q Targets Std                        14.1393
trainer/Q Targets Max                        52.8886
trainer/Q Targets Min                       -66.7529
trainer/Bellman Errors 1 Mean                 2.65004
trainer/Bellman Errors 1 Std                 17.8649
trainer/Bellman Errors 1 Max                433.744
trainer/Bellman Errors 1 Min                  3.33999e-07
trainer/Bellman Errors 2 Mean                 2.57021
trainer/Bellman Errors 2 Std                 17.5378
trainer/Bellman Errors 2 Max                426.366
trainer/Bellman Errors 2 Min                  1.93868e-08
trainer/Policy Action Mean                    0.251414
trainer/Policy Action Std                     0.817817
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     550000
expl/num paths total                      13750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.930471
expl/Rewards Std                              0.626025
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            37.2188
expl/Returns Std                              7.7486
expl/Returns Max                             42.1219
expl/Returns Min                              0.711579
expl/Actions Mean                             0.326189
expl/Actions Std                              0.749096
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         37.2188
expl/env_infos/final/reward_dist Mean         1.50562
expl/env_infos/final/reward_dist Std          0.307343
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000794421
expl/env_infos/initial/reward_dist Std        0.00255469
expl/env_infos/initial/reward_dist Max        0.0133028
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.930471
expl/env_infos/reward_dist Std                0.626025
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     110000
eval/num paths total                       2750
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.987449
eval/Rewards Std                              0.607626
eval/Rewards Max                              1.57077
eval/Rewards Min                              0
eval/Returns Mean                            39.498
eval/Returns Std                              1.196
eval/Returns Max                             41.0949
eval/Returns Min                             36.8882
eval/Actions Mean                             0.347291
eval/Actions Std                              0.755486
eval/Actions Max                              1
eval/Actions Min                             -0.999979
eval/Num Paths                               10
eval/Average Returns                         39.498
eval/env_infos/final/reward_dist Mean         1.56942
eval/env_infos/final/reward_dist Std          0.00131151
eval/env_infos/final/reward_dist Max          1.57077
eval/env_infos/final/reward_dist Min          1.56636
eval/env_infos/initial/reward_dist Mean       0.000810409
eval/env_infos/initial/reward_dist Std        0.00243123
eval/env_infos/initial/reward_dist Max        0.00810409
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.987449
eval/env_infos/reward_dist Std                0.607626
eval/env_infos/reward_dist Max                1.57077
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00578984
time/evaluation sampling (s)                  3.4282
time/exploration sampling (s)                18.0656
time/logging (s)                              0.0053611
time/saving (s)                               0.00228906
time/training (s)                             4.55534
time/epoch (s)                               26.0626
time/total (s)                             7054.56
Epoch                                       274
---------------------------------------  ----------------
2023-08-05 02:19:12.734186 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 275 finished
---------------------------------------  ----------------
epoch                                       275
replay_buffer/size                       552000
trainer/QF1 Loss                              2.04708
trainer/QF2 Loss                              1.9739
trainer/Policy Loss                         -10.1978
trainer/Q1 Predictions Mean                   8.87447
trainer/Q1 Predictions Std                   13.7926
trainer/Q1 Predictions Max                   50.9956
trainer/Q1 Predictions Min                  -63.8866
trainer/Q2 Predictions Mean                   8.84004
trainer/Q2 Predictions Std                   13.7844
trainer/Q2 Predictions Max                   51.2129
trainer/Q2 Predictions Min                  -63.681
trainer/Q Targets Mean                        8.82281
trainer/Q Targets Std                        13.8037
trainer/Q Targets Max                        50.9575
trainer/Q Targets Min                       -57.764
trainer/Bellman Errors 1 Mean                 2.04708
trainer/Bellman Errors 1 Std                 13.3276
trainer/Bellman Errors 1 Max                416.978
trainer/Bellman Errors 1 Min                  7.54371e-08
trainer/Bellman Errors 2 Mean                 1.9739
trainer/Bellman Errors 2 Std                 12.8021
trainer/Bellman Errors 2 Max                449.056
trainer/Bellman Errors 2 Min                  0
trainer/Policy Action Mean                    0.259848
trainer/Policy Action Std                     0.815257
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     552000
expl/num paths total                      13800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.801868
expl/Rewards Std                              0.663593
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            32.0747
expl/Returns Std                             14.838
expl/Returns Max                             41.6627
expl/Returns Min                              0
expl/Actions Mean                             0.319566
expl/Actions Std                              0.758059
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.0747
expl/env_infos/final/reward_dist Mean         1.2862
expl/env_infos/final/reward_dist Std          0.602615
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0009048
expl/env_infos/initial/reward_dist Std        0.0026886
expl/env_infos/initial/reward_dist Max        0.0129904
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.801868
expl/env_infos/reward_dist Std                0.663593
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     110400
eval/num paths total                       2760
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.984708
eval/Rewards Std                              0.607216
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            39.3883
eval/Returns Std                              1.31688
eval/Returns Max                             41.9189
eval/Returns Min                             37.6791
eval/Actions Mean                             0.326578
eval/Actions Std                              0.769023
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         39.3883
eval/env_infos/final/reward_dist Mean         1.56862
eval/env_infos/final/reward_dist Std          0.00263227
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          1.56161
eval/env_infos/initial/reward_dist Mean       0.00182751
eval/env_infos/initial/reward_dist Std        0.00487785
eval/env_infos/initial/reward_dist Max        0.0163605
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.984708
eval/env_infos/reward_dist Std                0.607216
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00564914
time/evaluation sampling (s)                  3.42094
time/exploration sampling (s)                17.9439
time/logging (s)                              0.00408502
time/saving (s)                               0.0114125
time/training (s)                             4.48055
time/epoch (s)                               25.8666
time/total (s)                             7080.43
Epoch                                       275
---------------------------------------  ----------------
2023-08-05 02:19:38.777256 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 276 finished
---------------------------------------  ----------------
epoch                                       276
replay_buffer/size                       554000
trainer/QF1 Loss                              2.58007
trainer/QF2 Loss                              2.4752
trainer/Policy Loss                         -10.0312
trainer/Q1 Predictions Mean                   8.73628
trainer/Q1 Predictions Std                   13.791
trainer/Q1 Predictions Max                   51.4219
trainer/Q1 Predictions Min                  -93.4203
trainer/Q2 Predictions Mean                   8.75809
trainer/Q2 Predictions Std                   13.8085
trainer/Q2 Predictions Max                   52.138
trainer/Q2 Predictions Min                  -94.9702
trainer/Q Targets Mean                        8.80926
trainer/Q Targets Std                        13.9067
trainer/Q Targets Max                        53.3579
trainer/Q Targets Min                       -89.3746
trainer/Bellman Errors 1 Mean                 2.58007
trainer/Bellman Errors 1 Std                 17.7695
trainer/Bellman Errors 1 Max                488.567
trainer/Bellman Errors 1 Min                  6.97846e-08
trainer/Bellman Errors 2 Mean                 2.4752
trainer/Bellman Errors 2 Std                 17.5525
trainer/Bellman Errors 2 Max                472.223
trainer/Bellman Errors 2 Min                  4.72792e-08
trainer/Policy Action Mean                    0.260703
trainer/Policy Action Std                     0.815066
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     554000
expl/num paths total                      13850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.773365
expl/Rewards Std                              0.671833
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            30.9346
expl/Returns Std                             15.4536
expl/Returns Max                             41.6952
expl/Returns Min                              0
expl/Actions Mean                             0.305541
expl/Actions Std                              0.766623
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.9346
expl/env_infos/final/reward_dist Mean         1.25567
expl/env_infos/final/reward_dist Std          0.627836
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000852297
expl/env_infos/initial/reward_dist Std        0.00314893
expl/env_infos/initial/reward_dist Max        0.0152374
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.773365
expl/env_infos/reward_dist Std                0.671833
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     110800
eval/num paths total                       2770
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.599371
eval/Rewards Std                              0.67717
eval/Rewards Max                              1.57053
eval/Rewards Min                              0
eval/Returns Mean                            23.9749
eval/Returns Std                             19.4056
eval/Returns Max                             41.7238
eval/Returns Min                              0.00021135
eval/Actions Mean                             0.286378
eval/Actions Std                              0.801612
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         23.9749
eval/env_infos/final/reward_dist Mean         0.941427
eval/env_infos/final/reward_dist Std          0.768667
eval/env_infos/final/reward_dist Max          1.57053
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00142683
eval/env_infos/initial/reward_dist Std        0.00285558
eval/env_infos/initial/reward_dist Max        0.00736832
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.599371
eval/env_infos/reward_dist Std                0.67717
eval/env_infos/reward_dist Max                1.57053
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00593214
time/evaluation sampling (s)                  3.40991
time/exploration sampling (s)                17.9094
time/logging (s)                              0.0074643
time/saving (s)                               0.00271419
time/training (s)                             4.70796
time/epoch (s)                               26.0434
time/total (s)                             7106.47
Epoch                                       276
---------------------------------------  ----------------
2023-08-05 02:20:05.706969 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 277 finished
---------------------------------------  ----------------
epoch                                       277
replay_buffer/size                       556000
trainer/QF1 Loss                              2.44765
trainer/QF2 Loss                              2.38968
trainer/Policy Loss                         -10.0584
trainer/Q1 Predictions Mean                   8.69964
trainer/Q1 Predictions Std                   13.7722
trainer/Q1 Predictions Max                   51.7156
trainer/Q1 Predictions Min                  -54.2694
trainer/Q2 Predictions Mean                   8.67054
trainer/Q2 Predictions Std                   13.7907
trainer/Q2 Predictions Max                   52.4503
trainer/Q2 Predictions Min                  -54.5264
trainer/Q Targets Mean                        8.71159
trainer/Q Targets Std                        13.8741
trainer/Q Targets Max                        52.9339
trainer/Q Targets Min                       -51.2332
trainer/Bellman Errors 1 Mean                 2.44765
trainer/Bellman Errors 1 Std                 14.7215
trainer/Bellman Errors 1 Max                447.589
trainer/Bellman Errors 1 Min                  6.92817e-08
trainer/Bellman Errors 2 Mean                 2.38968
trainer/Bellman Errors 2 Std                 14.4758
trainer/Bellman Errors 2 Max                401.989
trainer/Bellman Errors 2 Min                  3.27418e-09
trainer/Policy Action Mean                    0.260059
trainer/Policy Action Std                     0.815381
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     556000
expl/num paths total                      13900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.923566
expl/Rewards Std                              0.636946
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            36.9426
expl/Returns Std                              9.25869
expl/Returns Max                             41.5961
expl/Returns Min                              0.676
expl/Actions Mean                             0.340019
expl/Actions Std                              0.745727
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         36.9426
expl/env_infos/final/reward_dist Mean         1.47428
expl/env_infos/final/reward_dist Std          0.372479
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000323523
expl/env_infos/initial/reward_dist Std        0.00147882
expl/env_infos/initial/reward_dist Max        0.00877571
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.923566
expl/env_infos/reward_dist Std                0.636946
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     111200
eval/num paths total                       2780
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.00937
eval/Rewards Std                              0.607202
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            40.375
eval/Returns Std                              1.44393
eval/Returns Max                             42.4086
eval/Returns Min                             38.1486
eval/Actions Mean                             0.359045
eval/Actions Std                              0.761355
eval/Actions Max                              1
eval/Actions Min                             -0.999976
eval/Num Paths                               10
eval/Average Returns                         40.375
eval/env_infos/final/reward_dist Mean         1.5682
eval/env_infos/final/reward_dist Std          0.00248311
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          1.56334
eval/env_infos/initial/reward_dist Mean       0.00150654
eval/env_infos/initial/reward_dist Std        0.00303534
eval/env_infos/initial/reward_dist Max        0.00835323
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.00937
eval/env_infos/reward_dist Std                0.607202
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00583742
time/evaluation sampling (s)                  3.45177
time/exploration sampling (s)                18.1643
time/logging (s)                              0.00792239
time/saving (s)                               0.00327994
time/training (s)                             5.29139
time/epoch (s)                               26.9245
time/total (s)                             7133.4
Epoch                                       277
---------------------------------------  ----------------
2023-08-05 02:20:31.423217 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 278 finished
---------------------------------------  ----------------
epoch                                       278
replay_buffer/size                       558000
trainer/QF1 Loss                              3.73659
trainer/QF2 Loss                              3.41281
trainer/Policy Loss                         -10.105
trainer/Q1 Predictions Mean                   8.79756
trainer/Q1 Predictions Std                   13.8581
trainer/Q1 Predictions Max                   50.8744
trainer/Q1 Predictions Min                 -118.387
trainer/Q2 Predictions Mean                   8.84402
trainer/Q2 Predictions Std                   13.8708
trainer/Q2 Predictions Max                   51.0238
trainer/Q2 Predictions Min                 -125.192
trainer/Q Targets Mean                        8.83012
trainer/Q Targets Std                        14.0468
trainer/Q Targets Max                        52.5844
trainer/Q Targets Min                      -159.057
trainer/Bellman Errors 1 Mean                 3.73659
trainer/Bellman Errors 1 Std                 34.258
trainer/Bellman Errors 1 Max               1654.05
trainer/Bellman Errors 1 Min                  5.67298e-08
trainer/Bellman Errors 2 Mean                 3.41281
trainer/Bellman Errors 2 Std                 28.1519
trainer/Bellman Errors 2 Max               1146.8
trainer/Bellman Errors 2 Min                  7.69796e-09
trainer/Policy Action Mean                    0.254261
trainer/Policy Action Std                     0.817091
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     558000
expl/num paths total                      13950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.923689
expl/Rewards Std                              0.640388
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            36.9475
expl/Returns Std                             10.3474
expl/Returns Max                             42.6687
expl/Returns Min                              0.0147212
expl/Actions Mean                             0.34036
expl/Actions Std                              0.75538
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         36.9475
expl/env_infos/final/reward_dist Mean         1.45655
expl/env_infos/final/reward_dist Std          0.38929
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00080319
expl/env_infos/initial/reward_dist Std        0.00240343
expl/env_infos/initial/reward_dist Max        0.0118628
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.923689
expl/env_infos/reward_dist Std                0.640388
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     111600
eval/num paths total                       2790
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.913126
eval/Rewards Std                              0.650476
eval/Rewards Max                              1.57062
eval/Rewards Min                              0
eval/Returns Mean                            36.525
eval/Returns Std                             12.0565
eval/Returns Max                             42.9237
eval/Returns Min                              0.742072
eval/Actions Mean                             0.361312
eval/Actions Std                              0.765671
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                               10
eval/Average Returns                         36.525
eval/env_infos/final/reward_dist Mean         1.41223
eval/env_infos/final/reward_dist Std          0.470744
eval/env_infos/final/reward_dist Max          1.57062
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00222952
eval/env_infos/initial/reward_dist Std        0.00495506
eval/env_infos/initial/reward_dist Max        0.0159795
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.913126
eval/env_infos/reward_dist Std                0.650476
eval/env_infos/reward_dist Max                1.57062
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00586128
time/evaluation sampling (s)                  3.46336
time/exploration sampling (s)                17.5465
time/logging (s)                              0.00533493
time/saving (s)                               0.00232355
time/training (s)                             4.68452
time/epoch (s)                               25.7079
time/total (s)                             7159.11
Epoch                                       278
---------------------------------------  ----------------
2023-08-05 02:20:57.307142 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 279 finished
---------------------------------------  ----------------
epoch                                       279
replay_buffer/size                       560000
trainer/QF1 Loss                              2.5719
trainer/QF2 Loss                              2.51271
trainer/Policy Loss                         -10.443
trainer/Q1 Predictions Mean                   8.80336
trainer/Q1 Predictions Std                   14.0321
trainer/Q1 Predictions Max                   52.4209
trainer/Q1 Predictions Min                  -60.1294
trainer/Q2 Predictions Mean                   8.77581
trainer/Q2 Predictions Std                   14.0443
trainer/Q2 Predictions Max                   52.7423
trainer/Q2 Predictions Min                  -60.6165
trainer/Q Targets Mean                        8.79831
trainer/Q Targets Std                        14.1002
trainer/Q Targets Max                        54.3158
trainer/Q Targets Min                       -61.5265
trainer/Bellman Errors 1 Mean                 2.5719
trainer/Bellman Errors 1 Std                 14.9194
trainer/Bellman Errors 1 Max                317.631
trainer/Bellman Errors 1 Min                  1.42109e-10
trainer/Bellman Errors 2 Mean                 2.51271
trainer/Bellman Errors 2 Std                 14.5997
trainer/Bellman Errors 2 Max                322.388
trainer/Bellman Errors 2 Min                  8.6699e-08
trainer/Policy Action Mean                    0.19969
trainer/Policy Action Std                     0.835703
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     560000
expl/num paths total                      14000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.936061
expl/Rewards Std                              0.639085
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            37.4424
expl/Returns Std                              9.41686
expl/Returns Max                             42.7387
expl/Returns Min                              0.595905
expl/Actions Mean                             0.328483
expl/Actions Std                              0.750749
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         37.4424
expl/env_infos/final/reward_dist Mean         1.47533
expl/env_infos/final/reward_dist Std          0.372737
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.0011299
expl/env_infos/initial/reward_dist Std        0.00337277
expl/env_infos/initial/reward_dist Max        0.016568
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.936061
expl/env_infos/reward_dist Std                0.639085
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     112000
eval/num paths total                       2800
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.922929
eval/Rewards Std                              0.646842
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            36.9172
eval/Returns Std                             11.6839
eval/Returns Max                             42.4503
eval/Returns Min                              1.97223
eval/Actions Mean                             0.32508
eval/Actions Std                              0.781159
eval/Actions Max                              1
eval/Actions Min                             -0.999984
eval/Num Paths                               10
eval/Average Returns                         36.9172
eval/env_infos/final/reward_dist Mean         1.41257
eval/env_infos/final/reward_dist Std          0.470858
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000383547
eval/env_infos/initial/reward_dist Std        0.00115064
eval/env_infos/initial/reward_dist Max        0.00383547
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.922929
eval/env_infos/reward_dist Std                0.646842
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584902
time/evaluation sampling (s)                  3.44321
time/exploration sampling (s)                17.9811
time/logging (s)                              0.00532518
time/saving (s)                               0.00237738
time/training (s)                             4.44242
time/epoch (s)                               25.8803
time/total (s)                             7184.99
Epoch                                       279
---------------------------------------  ----------------
2023-08-05 02:21:23.950458 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 280 finished
---------------------------------------  ----------------
epoch                                       280
replay_buffer/size                       562000
trainer/QF1 Loss                              3.48308
trainer/QF2 Loss                              3.34678
trainer/Policy Loss                         -10.9153
trainer/Q1 Predictions Mean                   9.30683
trainer/Q1 Predictions Std                   13.7481
trainer/Q1 Predictions Max                   53.8321
trainer/Q1 Predictions Min                  -84.5493
trainer/Q2 Predictions Mean                   9.29795
trainer/Q2 Predictions Std                   13.7549
trainer/Q2 Predictions Max                   53.7816
trainer/Q2 Predictions Min                  -85.2834
trainer/Q Targets Mean                        9.22914
trainer/Q Targets Std                        13.9277
trainer/Q Targets Max                        55.3212
trainer/Q Targets Min                      -149.102
trainer/Bellman Errors 1 Mean                 3.48308
trainer/Bellman Errors 1 Std                 67.4464
trainer/Bellman Errors 1 Max               4166.99
trainer/Bellman Errors 1 Min                  2.77127e-07
trainer/Bellman Errors 2 Mean                 3.34678
trainer/Bellman Errors 2 Std                 66.1286
trainer/Bellman Errors 2 Max               4072.75
trainer/Bellman Errors 2 Min                  1.97872e-10
trainer/Policy Action Mean                    0.211995
trainer/Policy Action Std                     0.835797
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     562000
expl/num paths total                      14050
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.926665
expl/Rewards Std                              0.642517
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            37.0666
expl/Returns Std                             10.8195
expl/Returns Max                             42.6558
expl/Returns Min                              0.59508
expl/Actions Mean                             0.333003
expl/Actions Std                              0.745574
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         37.0666
expl/env_infos/final/reward_dist Mean         1.44378
expl/env_infos/final/reward_dist Std          0.425752
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000900889
expl/env_infos/initial/reward_dist Std        0.00296707
expl/env_infos/initial/reward_dist Max        0.0156856
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.926665
expl/env_infos/reward_dist Std                0.642517
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     112400
eval/num paths total                       2810
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.947193
eval/Rewards Std                              0.639575
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            37.8877
eval/Returns Std                             12.316
eval/Returns Max                             43.0276
eval/Returns Min                              1.15599
eval/Actions Mean                             0.328752
eval/Actions Std                              0.769042
eval/Actions Max                              1
eval/Actions Min                             -0.999997
eval/Num Paths                               10
eval/Average Returns                         37.8877
eval/env_infos/final/reward_dist Mean         1.4113
eval/env_infos/final/reward_dist Std          0.470441
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0083517
eval/env_infos/initial/reward_dist Std        0.00599347
eval/env_infos/initial/reward_dist Max        0.0156128
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.947193
eval/env_infos/reward_dist Std                0.639575
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584333
time/evaluation sampling (s)                  3.53081
time/exploration sampling (s)                18.3076
time/logging (s)                              0.00532885
time/saving (s)                               0.00238659
time/training (s)                             4.78813
time/epoch (s)                               26.6401
time/total (s)                             7211.63
Epoch                                       280
---------------------------------------  ----------------
2023-08-05 02:21:49.371873 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 281 finished
---------------------------------------  ----------------
epoch                                       281
replay_buffer/size                       564000
trainer/QF1 Loss                              2.5957
trainer/QF2 Loss                              2.51437
trainer/Policy Loss                         -10.8753
trainer/Q1 Predictions Mean                   9.14514
trainer/Q1 Predictions Std                   13.3561
trainer/Q1 Predictions Max                   53.1949
trainer/Q1 Predictions Min                 -134.565
trainer/Q2 Predictions Mean                   9.15182
trainer/Q2 Predictions Std                   13.3664
trainer/Q2 Predictions Max                   53.4682
trainer/Q2 Predictions Min                 -137.04
trainer/Q Targets Mean                        9.24116
trainer/Q Targets Std                        13.407
trainer/Q Targets Max                        53.5105
trainer/Q Targets Min                      -135.448
trainer/Bellman Errors 1 Mean                 2.5957
trainer/Bellman Errors 1 Std                 15.5554
trainer/Bellman Errors 1 Max                475.421
trainer/Bellman Errors 1 Min                  2.94676e-10
trainer/Bellman Errors 2 Mean                 2.51437
trainer/Bellman Errors 2 Std                 15.6522
trainer/Bellman Errors 2 Max                470.943
trainer/Bellman Errors 2 Min                  2.94676e-10
trainer/Policy Action Mean                    0.211563
trainer/Policy Action Std                     0.834258
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     564000
expl/num paths total                      14100
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.857134
expl/Rewards Std                              0.66189
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            34.2854
expl/Returns Std                             13.5766
expl/Returns Max                             42.5257
expl/Returns Min                              0.527392
expl/Actions Mean                             0.321033
expl/Actions Std                              0.743344
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         34.2854
expl/env_infos/final/reward_dist Mean         1.34958
expl/env_infos/final/reward_dist Std          0.544524
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000646185
expl/env_infos/initial/reward_dist Std        0.0024738
expl/env_infos/initial/reward_dist Max        0.013722
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.857134
expl/env_infos/reward_dist Std                0.66189
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     112800
eval/num paths total                       2820
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.02656
eval/Rewards Std                              0.601672
eval/Rewards Max                              1.57072
eval/Rewards Min                              0
eval/Returns Mean                            41.0626
eval/Returns Std                              1.56443
eval/Returns Max                             42.7846
eval/Returns Min                             37.8967
eval/Actions Mean                             0.36146
eval/Actions Std                              0.765077
eval/Actions Max                              1
eval/Actions Min                             -0.999986
eval/Num Paths                               10
eval/Average Returns                         41.0626
eval/env_infos/final/reward_dist Mean         1.56921
eval/env_infos/final/reward_dist Std          0.00109496
eval/env_infos/final/reward_dist Max          1.57072
eval/env_infos/final/reward_dist Min          1.5675
eval/env_infos/initial/reward_dist Mean       0.00287213
eval/env_infos/initial/reward_dist Std        0.00489303
eval/env_infos/initial/reward_dist Max        0.015581
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.02656
eval/env_infos/reward_dist Std                0.601672
eval/env_infos/reward_dist Max                1.57072
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0058343
time/evaluation sampling (s)                  3.52195
time/exploration sampling (s)                18.0766
time/logging (s)                              0.00529162
time/saving (s)                               0.00231242
time/training (s)                             3.8061
time/epoch (s)                               25.4181
time/total (s)                             7237.05
Epoch                                       281
---------------------------------------  ----------------
2023-08-05 02:22:14.780556 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 282 finished
---------------------------------------  ----------------
epoch                                       282
replay_buffer/size                       566000
trainer/QF1 Loss                              2.87597
trainer/QF2 Loss                              2.77716
trainer/Policy Loss                         -11.0815
trainer/Q1 Predictions Mean                   9.39044
trainer/Q1 Predictions Std                   13.6421
trainer/Q1 Predictions Max                   55.9876
trainer/Q1 Predictions Min                  -87.3763
trainer/Q2 Predictions Mean                   9.34737
trainer/Q2 Predictions Std                   13.6159
trainer/Q2 Predictions Max                   55.7674
trainer/Q2 Predictions Min                  -86.0268
trainer/Q Targets Mean                        9.38338
trainer/Q Targets Std                        13.7311
trainer/Q Targets Max                        55.6082
trainer/Q Targets Min                       -72.4435
trainer/Bellman Errors 1 Mean                 2.87597
trainer/Bellman Errors 1 Std                 18.5983
trainer/Bellman Errors 1 Max                418.677
trainer/Bellman Errors 1 Min                  2.14297e-08
trainer/Bellman Errors 2 Mean                 2.77716
trainer/Bellman Errors 2 Std                 18.3942
trainer/Bellman Errors 2 Max                431.188
trainer/Bellman Errors 2 Min                  1.39757e-07
trainer/Policy Action Mean                    0.189445
trainer/Policy Action Std                     0.841223
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     566000
expl/num paths total                      14150
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.90629
expl/Rewards Std                              0.649184
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            36.2516
expl/Returns Std                             11.9296
expl/Returns Max                             42.839
expl/Returns Min                              0.432963
expl/Actions Mean                             0.335841
expl/Actions Std                              0.738975
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         36.2516
expl/env_infos/final/reward_dist Mean         1.41195
expl/env_infos/final/reward_dist Std          0.470654
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00101003
expl/env_infos/initial/reward_dist Std        0.00356422
expl/env_infos/initial/reward_dist Max        0.0188426
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.90629
expl/env_infos/reward_dist Std                0.649184
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     113200
eval/num paths total                       2830
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.903784
eval/Rewards Std                              0.65195
eval/Rewards Max                              1.5708
eval/Rewards Min                              0
eval/Returns Mean                            36.1514
eval/Returns Std                             11.7503
eval/Returns Max                             42.7818
eval/Returns Min                              1.15329
eval/Actions Mean                             0.355642
eval/Actions Std                              0.750566
eval/Actions Max                              1
eval/Actions Min                             -0.99999
eval/Num Paths                               10
eval/Average Returns                         36.1514
eval/env_infos/final/reward_dist Mean         1.41213
eval/env_infos/final/reward_dist Std          0.470711
eval/env_infos/final/reward_dist Max          1.5708
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000813826
eval/env_infos/initial/reward_dist Std        0.00212117
eval/env_infos/initial/reward_dist Max        0.00711059
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.903784
eval/env_infos/reward_dist Std                0.65195
eval/env_infos/reward_dist Max                1.5708
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00586217
time/evaluation sampling (s)                  3.42476
time/exploration sampling (s)                17.6668
time/logging (s)                              0.00534277
time/saving (s)                               0.00238523
time/training (s)                             4.30023
time/epoch (s)                               25.4054
time/total (s)                             7262.46
Epoch                                       282
---------------------------------------  ----------------
2023-08-05 02:22:40.817625 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 283 finished
---------------------------------------  ---------------
epoch                                       283
replay_buffer/size                       568000
trainer/QF1 Loss                              2.56016
trainer/QF2 Loss                              2.48514
trainer/Policy Loss                         -11.6569
trainer/Q1 Predictions Mean                   9.79047
trainer/Q1 Predictions Std                   14.156
trainer/Q1 Predictions Max                   56.9767
trainer/Q1 Predictions Min                 -104.188
trainer/Q2 Predictions Mean                   9.81207
trainer/Q2 Predictions Std                   14.1541
trainer/Q2 Predictions Max                   56.9405
trainer/Q2 Predictions Min                 -105.066
trainer/Q Targets Mean                        9.75422
trainer/Q Targets Std                        14.2361
trainer/Q Targets Max                        58.7249
trainer/Q Targets Min                       -97.1279
trainer/Bellman Errors 1 Mean                 2.56016
trainer/Bellman Errors 1 Std                 13.2488
trainer/Bellman Errors 1 Max                296.499
trainer/Bellman Errors 1 Min                  5.031e-07
trainer/Bellman Errors 2 Mean                 2.48514
trainer/Bellman Errors 2 Std                 13.699
trainer/Bellman Errors 2 Max                334.121
trainer/Bellman Errors 2 Min                  2.6032e-09
trainer/Policy Action Mean                    0.193946
trainer/Policy Action Std                     0.837178
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     568000
expl/num paths total                      14200
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.978785
expl/Rewards Std                              0.620104
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            39.1514
expl/Returns Std                              5.77322
expl/Returns Max                             42.5774
expl/Returns Min                              0.528536
expl/Actions Mean                             0.35044
expl/Actions Std                              0.738101
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         39.1514
expl/env_infos/final/reward_dist Mean         1.5375
expl/env_infos/final/reward_dist Std          0.219655
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00150573
expl/env_infos/initial/reward_dist Std        0.00342317
expl/env_infos/initial/reward_dist Max        0.0169414
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.978785
expl/env_infos/reward_dist Std                0.620104
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     113600
eval/num paths total                       2840
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             1.00314
eval/Rewards Std                              0.611284
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            40.1255
eval/Returns Std                              1.78348
eval/Returns Max                             42.5958
eval/Returns Min                             37.5825
eval/Actions Mean                             0.377317
eval/Actions Std                              0.747485
eval/Actions Max                              1
eval/Actions Min                             -0.999974
eval/Num Paths                               10
eval/Average Returns                         40.1255
eval/env_infos/final/reward_dist Mean         1.56871
eval/env_infos/final/reward_dist Std          0.0027492
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          1.56257
eval/env_infos/initial/reward_dist Mean       0.00122925
eval/env_infos/initial/reward_dist Std        0.00252745
eval/env_infos/initial/reward_dist Max        0.00747552
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               1.00314
eval/env_infos/reward_dist Std                0.611284
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0057817
time/evaluation sampling (s)                  3.45526
time/exploration sampling (s)                17.9537
time/logging (s)                              0.00533607
time/saving (s)                               0.00243429
time/training (s)                             4.61119
time/epoch (s)                               26.0337
time/total (s)                             7288.5
Epoch                                       283
---------------------------------------  ---------------
2023-08-05 02:23:07.312387 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 284 finished
---------------------------------------  ----------------
epoch                                       284
replay_buffer/size                       570000
trainer/QF1 Loss                              2.78245
trainer/QF2 Loss                              2.53952
trainer/Policy Loss                         -12.028
trainer/Q1 Predictions Mean                  10.0403
trainer/Q1 Predictions Std                   14.2424
trainer/Q1 Predictions Max                   57.2983
trainer/Q1 Predictions Min                 -132.342
trainer/Q2 Predictions Mean                  10.0439
trainer/Q2 Predictions Std                   14.2573
trainer/Q2 Predictions Max                   56.8258
trainer/Q2 Predictions Min                 -150.54
trainer/Q Targets Mean                       10.2058
trainer/Q Targets Std                        14.2776
trainer/Q Targets Max                        57.7898
trainer/Q Targets Min                      -152.692
trainer/Bellman Errors 1 Mean                 2.78245
trainer/Bellman Errors 1 Std                 15.2239
trainer/Bellman Errors 1 Max                414.089
trainer/Bellman Errors 1 Min                  5.04792e-07
trainer/Bellman Errors 2 Mean                 2.53952
trainer/Bellman Errors 2 Std                 13.6388
trainer/Bellman Errors 2 Max                289.292
trainer/Bellman Errors 2 Min                  9.83709e-09
trainer/Policy Action Mean                    0.172221
trainer/Policy Action Std                     0.838202
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     570000
expl/num paths total                      14250
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.821507
expl/Rewards Std                              0.6563
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            32.8603
expl/Returns Std                             14.0954
expl/Returns Max                             41.8879
expl/Returns Min                              0.669696
expl/Actions Mean                             0.278988
expl/Actions Std                              0.743957
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.8603
expl/env_infos/final/reward_dist Mean         1.31805
expl/env_infos/final/reward_dist Std          0.575248
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00166541
expl/env_infos/initial/reward_dist Std        0.00395244
expl/env_infos/initial/reward_dist Max        0.014789
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.821507
expl/env_infos/reward_dist Std                0.6563
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                     114000
eval/num paths total                       2850
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.980525
eval/Rewards Std                              0.607571
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            39.221
eval/Returns Std                              1.39379
eval/Returns Max                             41.074
eval/Returns Min                             36.6361
eval/Actions Mean                             0.330316
eval/Actions Std                              0.758109
eval/Actions Max                              1
eval/Actions Min                             -0.999941
eval/Num Paths                               10
eval/Average Returns                         39.221
eval/env_infos/final/reward_dist Mean         1.56972
eval/env_infos/final/reward_dist Std          0.0018998
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          1.56504
eval/env_infos/initial/reward_dist Mean       0.000746839
eval/env_infos/initial/reward_dist Std        0.00224052
eval/env_infos/initial/reward_dist Max        0.00746839
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.980525
eval/env_infos/reward_dist Std                0.607571
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00598003
time/evaluation sampling (s)                  3.58131
time/exploration sampling (s)                18.4331
time/logging (s)                              0.00532991
time/saving (s)                               0.00239283
time/training (s)                             4.46339
time/epoch (s)                               26.4915
time/total (s)                             7314.99
Epoch                                       284
---------------------------------------  ----------------
2023-08-05 02:23:34.469184 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 285 finished
---------------------------------------  ----------------
epoch                                       285
replay_buffer/size                       572000
trainer/QF1 Loss                              3.76788
trainer/QF2 Loss                              3.65896
trainer/Policy Loss                         -11.319
trainer/Q1 Predictions Mean                   9.42706
trainer/Q1 Predictions Std                   14.6309
trainer/Q1 Predictions Max                   56.7503
trainer/Q1 Predictions Min                 -120.414
trainer/Q2 Predictions Mean                   9.44034
trainer/Q2 Predictions Std                   14.6722
trainer/Q2 Predictions Max                   56.8441
trainer/Q2 Predictions Min                 -119.837
trainer/Q Targets Mean                        9.47153
trainer/Q Targets Std                        14.7756
trainer/Q Targets Max                        59.1364
trainer/Q Targets Min                      -119.391
trainer/Bellman Errors 1 Mean                 3.76788
trainer/Bellman Errors 1 Std                 50.7211
trainer/Bellman Errors 1 Max               3025.85
trainer/Bellman Errors 1 Min                  1.05593e-08
trainer/Bellman Errors 2 Mean                 3.65896
trainer/Bellman Errors 2 Std                 48.1267
trainer/Bellman Errors 2 Max               2860.52
trainer/Bellman Errors 2 Min                  4.72792e-08
trainer/Policy Action Mean                    0.179626
trainer/Policy Action Std                     0.834253
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     572000
expl/num paths total                      14300
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.89504
expl/Rewards Std                              0.625427
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            35.8016
expl/Returns Std                              9.01043
expl/Returns Max                             41.0882
expl/Returns Min                              0.643578
expl/Actions Mean                             0.293865
expl/Actions Std                              0.741109
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         35.8016
expl/env_infos/final/reward_dist Mean         1.4749
expl/env_infos/final/reward_dist Std          0.372632
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00164326
expl/env_infos/initial/reward_dist Std        0.00364656
expl/env_infos/initial/reward_dist Max        0.0135908
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.89504
expl/env_infos/reward_dist Std                0.625427
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                     114400
eval/num paths total                       2860
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.953511
eval/Rewards Std                              0.608043
eval/Rewards Max                              1.57076
eval/Rewards Min                              0
eval/Returns Mean                            38.1405
eval/Returns Std                              1.20364
eval/Returns Max                             40.0073
eval/Returns Min                             36.1936
eval/Actions Mean                             0.328594
eval/Actions Std                              0.753366
eval/Actions Max                              1
eval/Actions Min                             -0.99999
eval/Num Paths                               10
eval/Average Returns                         38.1405
eval/env_infos/final/reward_dist Mean         1.56914
eval/env_infos/final/reward_dist Std          0.00160966
eval/env_infos/final/reward_dist Max          1.57076
eval/env_infos/final/reward_dist Min          1.56621
eval/env_infos/initial/reward_dist Mean       0.000570138
eval/env_infos/initial/reward_dist Std        0.00171041
eval/env_infos/initial/reward_dist Max        0.00570138
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.953511
eval/env_infos/reward_dist Std                0.608043
eval/env_infos/reward_dist Max                1.57076
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00590214
time/evaluation sampling (s)                  3.48978
time/exploration sampling (s)                18.2644
time/logging (s)                              0.00786816
time/saving (s)                               0.0033097
time/training (s)                             5.38469
time/epoch (s)                               27.156
time/total (s)                             7342.15
Epoch                                       285
---------------------------------------  ----------------
2023-08-05 02:24:01.354040 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 286 finished
---------------------------------------  ----------------
epoch                                       286
replay_buffer/size                       574000
trainer/QF1 Loss                              3.22876
trainer/QF2 Loss                              3.13765
trainer/Policy Loss                         -12.1262
trainer/Q1 Predictions Mean                  10.1805
trainer/Q1 Predictions Std                   15.1994
trainer/Q1 Predictions Max                   58.4639
trainer/Q1 Predictions Min                 -109.824
trainer/Q2 Predictions Mean                  10.1913
trainer/Q2 Predictions Std                   15.1685
trainer/Q2 Predictions Max                   58.4627
trainer/Q2 Predictions Min                 -108.47
trainer/Q Targets Mean                       10.2457
trainer/Q Targets Std                        15.2565
trainer/Q Targets Max                        59.2353
trainer/Q Targets Min                      -127.743
trainer/Bellman Errors 1 Mean                 3.22876
trainer/Bellman Errors 1 Std                 22.7747
trainer/Bellman Errors 1 Max                838.28
trainer/Bellman Errors 1 Min                  2.5062e-08
trainer/Bellman Errors 2 Mean                 3.13765
trainer/Bellman Errors 2 Std                 22.3957
trainer/Bellman Errors 2 Max                809.607
trainer/Bellman Errors 2 Min                  2.38768e-07
trainer/Policy Action Mean                    0.218008
trainer/Policy Action Std                     0.840023
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     574000
expl/num paths total                      14350
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.852261
expl/Rewards Std                              0.60354
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            34.0904
expl/Returns Std                              5.04461
expl/Returns Max                             38.255
expl/Returns Min                              0.668638
expl/Actions Mean                             0.355059
expl/Actions Std                              0.76286
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         34.0904
expl/env_infos/final/reward_dist Mean         1.53717
expl/env_infos/final/reward_dist Std          0.219606
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000700852
expl/env_infos/initial/reward_dist Std        0.0018478
expl/env_infos/initial/reward_dist Max        0.00879973
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.852261
expl/env_infos/reward_dist Std                0.60354
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     114800
eval/num paths total                       2870
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.88151
eval/Rewards Std                              0.607325
eval/Rewards Max                              1.57078
eval/Rewards Min                              0
eval/Returns Mean                            35.2604
eval/Returns Std                              1.21679
eval/Returns Max                             37.2359
eval/Returns Min                             32.8105
eval/Actions Mean                             0.385903
eval/Actions Std                              0.772309
eval/Actions Max                              1
eval/Actions Min                             -0.999525
eval/Num Paths                               10
eval/Average Returns                         35.2604
eval/env_infos/final/reward_dist Mean         1.56895
eval/env_infos/final/reward_dist Std          0.0015233
eval/env_infos/final/reward_dist Max          1.57078
eval/env_infos/final/reward_dist Min          1.56513
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.88151
eval/env_infos/reward_dist Std                0.607325
eval/env_infos/reward_dist Max                1.57078
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00584689
time/evaluation sampling (s)                  3.55127
time/exploration sampling (s)                18.5935
time/logging (s)                              0.00408274
time/saving (s)                               0.0115562
time/training (s)                             4.70899
time/epoch (s)                               26.8752
time/total (s)                             7369.03
Epoch                                       286
---------------------------------------  ----------------
2023-08-05 02:24:27.894329 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 287 finished
---------------------------------------  ----------------
epoch                                       287
replay_buffer/size                       576000
trainer/QF1 Loss                              3.19127
trainer/QF2 Loss                              3.08654
trainer/Policy Loss                         -12.0477
trainer/Q1 Predictions Mean                  10.1606
trainer/Q1 Predictions Std                   15.2661
trainer/Q1 Predictions Max                   59.6837
trainer/Q1 Predictions Min                 -113.312
trainer/Q2 Predictions Mean                  10.158
trainer/Q2 Predictions Std                   15.249
trainer/Q2 Predictions Max                   60.3613
trainer/Q2 Predictions Min                 -112.355
trainer/Q Targets Mean                       10.1565
trainer/Q Targets Std                        15.1879
trainer/Q Targets Max                        59.6122
trainer/Q Targets Min                      -110.286
trainer/Bellman Errors 1 Mean                 3.19127
trainer/Bellman Errors 1 Std                 17.0139
trainer/Bellman Errors 1 Max                422.262
trainer/Bellman Errors 1 Min                  3.39811e-09
trainer/Bellman Errors 2 Mean                 3.08654
trainer/Bellman Errors 2 Std                 16.871
trainer/Bellman Errors 2 Max                447.504
trainer/Bellman Errors 2 Min                  3.7111e-08
trainer/Policy Action Mean                    0.215949
trainer/Policy Action Std                     0.843308
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     576000
expl/num paths total                      14400
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.851546
expl/Rewards Std                              0.6218
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            34.0618
expl/Returns Std                              7.03268
expl/Returns Max                             39.437
expl/Returns Min                              0.8038
expl/Actions Mean                             0.352178
expl/Actions Std                              0.759735
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         34.0618
expl/env_infos/final/reward_dist Mean         1.5064
expl/env_infos/final/reward_dist Std          0.307496
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000473785
expl/env_infos/initial/reward_dist Std        0.0016857
expl/env_infos/initial/reward_dist Max        0.00917482
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.851546
expl/env_infos/reward_dist Std                0.6218
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     115200
eval/num paths total                       2880
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.921985
eval/Rewards Std                              0.604565
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            36.8794
eval/Returns Std                              1.73208
eval/Returns Max                             39.5683
eval/Returns Min                             33.5363
eval/Actions Mean                             0.366473
eval/Actions Std                              0.78456
eval/Actions Max                              1
eval/Actions Min                             -0.999996
eval/Num Paths                               10
eval/Average Returns                         36.8794
eval/env_infos/final/reward_dist Mean         1.5694
eval/env_infos/final/reward_dist Std          0.00186439
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          1.56541
eval/env_infos/initial/reward_dist Mean       0.0015535
eval/env_infos/initial/reward_dist Std        0.00311246
eval/env_infos/initial/reward_dist Max        0.0104228
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.921985
eval/env_infos/reward_dist Std                0.604565
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.005859
time/evaluation sampling (s)                  3.47333
time/exploration sampling (s)                18.1142
time/logging (s)                              0.00530823
time/saving (s)                               0.00244438
time/training (s)                             4.93732
time/epoch (s)                               26.5384
time/total (s)                             7395.57
Epoch                                       287
---------------------------------------  ----------------
2023-08-05 02:24:54.118750 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 288 finished
---------------------------------------  ----------------
epoch                                       288
replay_buffer/size                       578000
trainer/QF1 Loss                              3.68893
trainer/QF2 Loss                              3.49211
trainer/Policy Loss                         -11.9861
trainer/Q1 Predictions Mean                  10.3252
trainer/Q1 Predictions Std                   15.1414
trainer/Q1 Predictions Max                   60.6193
trainer/Q1 Predictions Min                 -164.483
trainer/Q2 Predictions Mean                  10.3111
trainer/Q2 Predictions Std                   15.1618
trainer/Q2 Predictions Max                   60.8974
trainer/Q2 Predictions Min                 -176.954
trainer/Q Targets Mean                       10.3211
trainer/Q Targets Std                        15.2548
trainer/Q Targets Max                        59.9049
trainer/Q Targets Min                      -183.959
trainer/Bellman Errors 1 Mean                 3.68893
trainer/Bellman Errors 1 Std                 25.0928
trainer/Bellman Errors 1 Max                626.53
trainer/Bellman Errors 1 Min                  1.22382e-08
trainer/Bellman Errors 2 Mean                 3.49211
trainer/Bellman Errors 2 Std                 23.84
trainer/Bellman Errors 2 Max                562.388
trainer/Bellman Errors 2 Min                  2.47823e-07
trainer/Policy Action Mean                    0.222907
trainer/Policy Action Std                     0.842463
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     578000
expl/num paths total                      14450
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.824885
expl/Rewards Std                              0.638116
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            32.9954
expl/Returns Std                             10.8349
expl/Returns Max                             40.1688
expl/Returns Min                              0.636814
expl/Actions Mean                             0.326179
expl/Actions Std                              0.767814
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.9954
expl/env_infos/final/reward_dist Mean         1.41203
expl/env_infos/final/reward_dist Std          0.47068
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00110166
expl/env_infos/initial/reward_dist Std        0.00259318
expl/env_infos/initial/reward_dist Max        0.0105755
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.824885
expl/env_infos/reward_dist Std                0.638116
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     115600
eval/num paths total                       2890
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.934193
eval/Rewards Std                              0.606396
eval/Rewards Max                              1.57066
eval/Rewards Min                              0
eval/Returns Mean                            37.3677
eval/Returns Std                              1.02129
eval/Returns Max                             38.5092
eval/Returns Min                             35.4803
eval/Actions Mean                             0.366684
eval/Actions Std                              0.784974
eval/Actions Max                              1
eval/Actions Min                             -0.999958
eval/Num Paths                               10
eval/Average Returns                         37.3677
eval/env_infos/final/reward_dist Mean         1.56916
eval/env_infos/final/reward_dist Std          0.0012826
eval/env_infos/final/reward_dist Max          1.57066
eval/env_infos/final/reward_dist Min          1.56629
eval/env_infos/initial/reward_dist Mean       0.00119293
eval/env_infos/initial/reward_dist Std        0.00353828
eval/env_infos/initial/reward_dist Max        0.0118072
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.934193
eval/env_infos/reward_dist Std                0.606396
eval/env_infos/reward_dist Max                1.57066
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00571639
time/evaluation sampling (s)                  3.58242
time/exploration sampling (s)                17.9718
time/logging (s)                              0.00530757
time/saving (s)                               0.00243687
time/training (s)                             4.65345
time/epoch (s)                               26.2212
time/total (s)                             7421.79
Epoch                                       288
---------------------------------------  ----------------
2023-08-05 02:25:20.821897 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 289 finished
---------------------------------------  ----------------
epoch                                       289
replay_buffer/size                       580000
trainer/QF1 Loss                              3.66905
trainer/QF2 Loss                              3.54594
trainer/Policy Loss                         -11.7827
trainer/Q1 Predictions Mean                  10.0493
trainer/Q1 Predictions Std                   15.844
trainer/Q1 Predictions Max                   58.0646
trainer/Q1 Predictions Min                 -152.813
trainer/Q2 Predictions Mean                  10.0265
trainer/Q2 Predictions Std                   15.8517
trainer/Q2 Predictions Max                   58.5555
trainer/Q2 Predictions Min                 -151.944
trainer/Q Targets Mean                       10.1011
trainer/Q Targets Std                        15.9692
trainer/Q Targets Max                        57.6985
trainer/Q Targets Min                      -141.117
trainer/Bellman Errors 1 Mean                 3.66904
trainer/Bellman Errors 1 Std                 29.9151
trainer/Bellman Errors 1 Max                906.824
trainer/Bellman Errors 1 Min                  1.44391e-08
trainer/Bellman Errors 2 Mean                 3.54594
trainer/Bellman Errors 2 Std                 29.2519
trainer/Bellman Errors 2 Max                877.668
trainer/Bellman Errors 2 Min                  3.63798e-12
trainer/Policy Action Mean                    0.225621
trainer/Policy Action Std                     0.840913
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     580000
expl/num paths total                      14500
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.819626
expl/Rewards Std                              0.636852
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            32.785
expl/Returns Std                             10.8381
expl/Returns Max                             40.5193
expl/Returns Min                              0.707673
expl/Actions Mean                             0.325232
expl/Actions Std                              0.767307
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.785
expl/env_infos/final/reward_dist Mean         1.41227
expl/env_infos/final/reward_dist Std          0.470759
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000555735
expl/env_infos/initial/reward_dist Std        0.00170942
expl/env_infos/initial/reward_dist Max        0.00921063
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.819626
expl/env_infos/reward_dist Std                0.636852
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     116000
eval/num paths total                       2900
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.745511
eval/Rewards Std                              0.656004
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            29.8205
eval/Returns Std                             14.5492
eval/Returns Max                             39.5718
eval/Returns Min                              0.864225
eval/Actions Mean                             0.30577
eval/Actions Std                              0.784331
eval/Actions Max                              1
eval/Actions Min                             -0.999999
eval/Num Paths                               10
eval/Average Returns                         29.8205
eval/env_infos/final/reward_dist Mean         1.25486
eval/env_infos/final/reward_dist Std          0.627429
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.00103876
eval/env_infos/initial/reward_dist Std        0.00306098
eval/env_infos/initial/reward_dist Max        0.0102205
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.745511
eval/env_infos/reward_dist Std                0.656004
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587868
time/evaluation sampling (s)                  3.56457
time/exploration sampling (s)                18.4866
time/logging (s)                              0.00741054
time/saving (s)                               0.00269417
time/training (s)                             4.63486
time/epoch (s)                               26.702
time/total (s)                             7448.49
Epoch                                       289
---------------------------------------  ----------------
2023-08-05 02:25:47.838765 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 290 finished
---------------------------------------  ----------------
epoch                                       290
replay_buffer/size                       582000
trainer/QF1 Loss                              3.77986
trainer/QF2 Loss                              3.64272
trainer/Policy Loss                         -12.1632
trainer/Q1 Predictions Mean                  10.3229
trainer/Q1 Predictions Std                   15.917
trainer/Q1 Predictions Max                   58.6604
trainer/Q1 Predictions Min                 -134.566
trainer/Q2 Predictions Mean                  10.3525
trainer/Q2 Predictions Std                   15.9474
trainer/Q2 Predictions Max                   59.5528
trainer/Q2 Predictions Min                 -135.022
trainer/Q Targets Mean                       10.3751
trainer/Q Targets Std                        15.8782
trainer/Q Targets Max                        57.9466
trainer/Q Targets Min                      -114.163
trainer/Bellman Errors 1 Mean                 3.77986
trainer/Bellman Errors 1 Std                 28.4185
trainer/Bellman Errors 1 Max                747.763
trainer/Bellman Errors 1 Min                  2.09548e-07
trainer/Bellman Errors 2 Mean                 3.64272
trainer/Bellman Errors 2 Std                 28.3973
trainer/Bellman Errors 2 Max                805.709
trainer/Bellman Errors 2 Min                  8.29496e-08
trainer/Policy Action Mean                    0.219414
trainer/Policy Action Std                     0.84135
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     582000
expl/num paths total                      14550
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.794612
expl/Rewards Std                              0.650448
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            31.7845
expl/Returns Std                             12.5557
expl/Returns Max                             40.264
expl/Returns Min                              0.613609
expl/Actions Mean                             0.315866
expl/Actions Std                              0.765253
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.7845
expl/env_infos/final/reward_dist Mean         1.34921
expl/env_infos/final/reward_dist Std          0.544375
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       1.43432e-06
expl/env_infos/initial/reward_dist Std        1.00402e-05
expl/env_infos/initial/reward_dist Max        7.17158e-05
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.794612
expl/env_infos/reward_dist Std                0.650448
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     116400
eval/num paths total                       2910
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.934765
eval/Rewards Std                              0.614643
eval/Rewards Max                              1.57064
eval/Rewards Min                              0
eval/Returns Mean                            37.3906
eval/Returns Std                              1.54639
eval/Returns Max                             39.7504
eval/Returns Min                             34.6521
eval/Actions Mean                             0.374639
eval/Actions Std                              0.773086
eval/Actions Max                              1
eval/Actions Min                             -0.999995
eval/Num Paths                               10
eval/Average Returns                         37.3906
eval/env_infos/final/reward_dist Mean         1.56888
eval/env_infos/final/reward_dist Std          0.0016883
eval/env_infos/final/reward_dist Max          1.57064
eval/env_infos/final/reward_dist Min          1.5657
eval/env_infos/initial/reward_dist Mean       0.00124033
eval/env_infos/initial/reward_dist Std        0.0024858
eval/env_infos/initial/reward_dist Max        0.00655869
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.934765
eval/env_infos/reward_dist Std                0.614643
eval/env_infos/reward_dist Max                1.57064
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00577353
time/evaluation sampling (s)                  3.5349
time/exploration sampling (s)                18.3217
time/logging (s)                              0.00785988
time/saving (s)                               0.0032907
time/training (s)                             5.13801
time/epoch (s)                               27.0116
time/total (s)                             7475.51
Epoch                                       290
---------------------------------------  ----------------
2023-08-05 02:26:13.185027 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 291 finished
---------------------------------------  ----------------
epoch                                       291
replay_buffer/size                       584000
trainer/QF1 Loss                              4.03031
trainer/QF2 Loss                              3.8783
trainer/Policy Loss                         -12.1248
trainer/Q1 Predictions Mean                  10.5163
trainer/Q1 Predictions Std                   16.1295
trainer/Q1 Predictions Max                   58.2639
trainer/Q1 Predictions Min                 -166.108
trainer/Q2 Predictions Mean                  10.5135
trainer/Q2 Predictions Std                   16.1122
trainer/Q2 Predictions Max                   58.8776
trainer/Q2 Predictions Min                 -163.021
trainer/Q Targets Mean                       10.4419
trainer/Q Targets Std                        16.1456
trainer/Q Targets Max                        59.006
trainer/Q Targets Min                      -152.033
trainer/Bellman Errors 1 Mean                 4.03031
trainer/Bellman Errors 1 Std                 30.4986
trainer/Bellman Errors 1 Max                963.442
trainer/Bellman Errors 1 Min                  2.94676e-10
trainer/Bellman Errors 2 Mean                 3.8783
trainer/Bellman Errors 2 Std                 29.9743
trainer/Bellman Errors 2 Max                873.927
trainer/Bellman Errors 2 Min                  5.18435e-09
trainer/Policy Action Mean                    0.234904
trainer/Policy Action Std                     0.833364
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     584000
expl/num paths total                      14600
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.704334
expl/Rewards Std                              0.658628
expl/Rewards Max                              1.5708
expl/Rewards Min                              0
expl/Returns Mean                            28.1733
expl/Returns Std                             15.4408
expl/Returns Max                             40.1875
expl/Returns Min                              0.621186
expl/Actions Mean                             0.28011
expl/Actions Std                              0.770491
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         28.1733
expl/env_infos/final/reward_dist Mean         1.19236
expl/env_infos/final/reward_dist Std          0.67005
expl/env_infos/final/reward_dist Max          1.5708
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00051865
expl/env_infos/initial/reward_dist Std        0.00195679
expl/env_infos/initial/reward_dist Max        0.00949838
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.704334
expl/env_infos/reward_dist Std                0.658628
expl/env_infos/reward_dist Max                1.5708
expl/env_infos/reward_dist Min                0
eval/num steps total                     116800
eval/num paths total                       2920
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.842209
eval/Rewards Std                              0.643528
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            33.6884
eval/Returns Std                             11.1623
eval/Returns Max                             41.5814
eval/Returns Min                              0.690023
eval/Actions Mean                             0.342096
eval/Actions Std                              0.777732
eval/Actions Max                              1
eval/Actions Min                             -0.999995
eval/Num Paths                               10
eval/Average Returns                         33.6884
eval/env_infos/final/reward_dist Mean         1.41229
eval/env_infos/final/reward_dist Std          0.470769
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.842209
eval/env_infos/reward_dist Std                0.643528
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00576548
time/evaluation sampling (s)                  3.48983
time/exploration sampling (s)                17.4364
time/logging (s)                              0.00534652
time/saving (s)                               0.00233774
time/training (s)                             4.39831
time/epoch (s)                               25.338
time/total (s)                             7500.85
Epoch                                       291
---------------------------------------  ----------------
2023-08-05 02:26:39.456555 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 292 finished
---------------------------------------  ----------------
epoch                                       292
replay_buffer/size                       586000
trainer/QF1 Loss                              3.85168
trainer/QF2 Loss                              3.74716
trainer/Policy Loss                         -12.6213
trainer/Q1 Predictions Mean                  11.0297
trainer/Q1 Predictions Std                   16.213
trainer/Q1 Predictions Max                   59.5972
trainer/Q1 Predictions Min                 -237.458
trainer/Q2 Predictions Mean                  10.9967
trainer/Q2 Predictions Std                   16.1945
trainer/Q2 Predictions Max                   60.7039
trainer/Q2 Predictions Min                 -237.349
trainer/Q Targets Mean                       10.9723
trainer/Q Targets Std                        16.2974
trainer/Q Targets Max                        60.4819
trainer/Q Targets Min                      -222.559
trainer/Bellman Errors 1 Mean                 3.85168
trainer/Bellman Errors 1 Std                 39.595
trainer/Bellman Errors 1 Max               1811.54
trainer/Bellman Errors 1 Min                  4.64533e-08
trainer/Bellman Errors 2 Mean                 3.74716
trainer/Bellman Errors 2 Std                 39.7716
trainer/Bellman Errors 2 Max               1838.83
trainer/Bellman Errors 2 Min                  2.55477e-09
trainer/Policy Action Mean                    0.229427
trainer/Policy Action Std                     0.835769
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     586000
expl/num paths total                      14650
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.796912
expl/Rewards Std                              0.655627
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            31.8765
expl/Returns Std                             13.6382
expl/Returns Max                             40.5779
expl/Returns Min                              0.636942
expl/Actions Mean                             0.301717
expl/Actions Std                              0.767991
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         31.8765
expl/env_infos/final/reward_dist Mean         1.3178
expl/env_infos/final/reward_dist Std          0.575139
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00119414
expl/env_infos/initial/reward_dist Std        0.00286061
expl/env_infos/initial/reward_dist Max        0.0114035
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.796912
expl/env_infos/reward_dist Std                0.655627
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     117200
eval/num paths total                       2930
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.774457
eval/Rewards Std                              0.660222
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            30.9783
eval/Returns Std                             15.0096
eval/Returns Max                             40.1535
eval/Returns Min                              1.07584
eval/Actions Mean                             0.289078
eval/Actions Std                              0.789933
eval/Actions Max                              1
eval/Actions Min                             -0.999981
eval/Num Paths                               10
eval/Average Returns                         30.9783
eval/env_infos/final/reward_dist Mean         1.25571
eval/env_infos/final/reward_dist Std          0.627856
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.0018929
eval/env_infos/initial/reward_dist Std        0.00325254
eval/env_infos/initial/reward_dist Max        0.0107046
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.774457
eval/env_infos/reward_dist Std                0.660222
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00568475
time/evaluation sampling (s)                  3.43498
time/exploration sampling (s)                18.0953
time/logging (s)                              0.00535711
time/saving (s)                               0.00235331
time/training (s)                             4.72449
time/epoch (s)                               26.2682
time/total (s)                             7527.12
Epoch                                       292
---------------------------------------  ----------------
2023-08-05 02:27:05.717716 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 293 finished
---------------------------------------  ----------------
epoch                                       293
replay_buffer/size                       588000
trainer/QF1 Loss                              4.8558
trainer/QF2 Loss                              4.86372
trainer/Policy Loss                         -11.9104
trainer/Q1 Predictions Mean                  10.4102
trainer/Q1 Predictions Std                   16.705
trainer/Q1 Predictions Max                   55.0439
trainer/Q1 Predictions Min                 -170.223
trainer/Q2 Predictions Mean                  10.3398
trainer/Q2 Predictions Std                   16.6704
trainer/Q2 Predictions Max                   55.3131
trainer/Q2 Predictions Min                 -170.106
trainer/Q Targets Mean                       10.4
trainer/Q Targets Std                        16.9273
trainer/Q Targets Max                        55.1262
trainer/Q Targets Min                      -167.531
trainer/Bellman Errors 1 Mean                 4.8558
trainer/Bellman Errors 1 Std                 49.3227
trainer/Bellman Errors 1 Max               1721.63
trainer/Bellman Errors 1 Min                  3.60169e-08
trainer/Bellman Errors 2 Mean                 4.86372
trainer/Bellman Errors 2 Std                 50.6183
trainer/Bellman Errors 2 Max               1865.67
trainer/Bellman Errors 2 Min                  2.59761e-08
trainer/Policy Action Mean                    0.240757
trainer/Policy Action Std                     0.834662
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     588000
expl/num paths total                      14700
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.809801
expl/Rewards Std                              0.649995
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            32.392
expl/Returns Std                             12.894
expl/Returns Max                             41.6884
expl/Returns Min                              0.634238
expl/Actions Mean                             0.30182
expl/Actions Std                              0.771314
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         32.392
expl/env_infos/final/reward_dist Mean         1.34942
expl/env_infos/final/reward_dist Std          0.544458
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.00119389
expl/env_infos/initial/reward_dist Std        0.00269454
expl/env_infos/initial/reward_dist Max        0.0102229
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.809801
expl/env_infos/reward_dist Std                0.649995
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     117600
eval/num paths total                       2940
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.846482
eval/Rewards Std                              0.643603
eval/Rewards Max                              1.57064
eval/Rewards Min                              0
eval/Returns Mean                            33.8593
eval/Returns Std                             11.1225
eval/Returns Max                             40.1905
eval/Returns Min                              0.704668
eval/Actions Mean                             0.333187
eval/Actions Std                              0.782149
eval/Actions Max                              1
eval/Actions Min                             -0.999967
eval/Num Paths                               10
eval/Average Returns                         33.8593
eval/env_infos/final/reward_dist Mean         1.41185
eval/env_infos/final/reward_dist Std          0.470619
eval/env_infos/final/reward_dist Max          1.57064
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.846482
eval/env_infos/reward_dist Std                0.643603
eval/env_infos/reward_dist Max                1.57064
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00580792
time/evaluation sampling (s)                  3.45742
time/exploration sampling (s)                18.0743
time/logging (s)                              0.00531602
time/saving (s)                               0.0024279
time/training (s)                             4.7125
time/epoch (s)                               26.2578
time/total (s)                             7553.38
Epoch                                       293
---------------------------------------  ----------------
2023-08-05 02:27:31.766775 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 294 finished
---------------------------------------  ----------------
epoch                                       294
replay_buffer/size                       590000
trainer/QF1 Loss                              6.70007
trainer/QF2 Loss                              6.37494
trainer/Policy Loss                         -12.2994
trainer/Q1 Predictions Mean                  10.7943
trainer/Q1 Predictions Std                   16.8742
trainer/Q1 Predictions Max                   56.1199
trainer/Q1 Predictions Min                 -224.539
trainer/Q2 Predictions Mean                  10.7807
trainer/Q2 Predictions Std                   16.9173
trainer/Q2 Predictions Max                   56.5089
trainer/Q2 Predictions Min                 -229.85
trainer/Q Targets Mean                       10.6274
trainer/Q Targets Std                        17.4645
trainer/Q Targets Max                        55.7771
trainer/Q Targets Min                      -313.474
trainer/Bellman Errors 1 Mean                 6.70007
trainer/Bellman Errors 1 Std                131.744
trainer/Bellman Errors 1 Max               7909.37
trainer/Bellman Errors 1 Min                  9.66575e-08
trainer/Bellman Errors 2 Mean                 6.37494
trainer/Bellman Errors 2 Std                118.574
trainer/Bellman Errors 2 Max               6992.85
trainer/Bellman Errors 2 Min                  9.93191e-09
trainer/Policy Action Mean                    0.244467
trainer/Policy Action Std                     0.834783
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     590000
expl/num paths total                      14750
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.753773
expl/Rewards Std                              0.658825
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            30.1509
expl/Returns Std                             14.7817
expl/Returns Max                             39.8613
expl/Returns Min                              0.622935
expl/Actions Mean                             0.280293
expl/Actions Std                              0.774712
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.1509
expl/env_infos/final/reward_dist Mean         1.25478
expl/env_infos/final/reward_dist Std          0.627396
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000690668
expl/env_infos/initial/reward_dist Std        0.00169275
expl/env_infos/initial/reward_dist Max        0.0065153
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.753773
expl/env_infos/reward_dist Std                0.658825
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     118000
eval/num paths total                       2950
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.85842
eval/Rewards Std                              0.645328
eval/Rewards Max                              1.5707
eval/Rewards Min                              0
eval/Returns Mean                            34.3368
eval/Returns Std                             11.304
eval/Returns Max                             40.0401
eval/Returns Min                              0.691759
eval/Actions Mean                             0.326113
eval/Actions Std                              0.789762
eval/Actions Max                              1
eval/Actions Min                             -0.999973
eval/Num Paths                               10
eval/Average Returns                         34.3368
eval/env_infos/final/reward_dist Mean         1.41231
eval/env_infos/final/reward_dist Std          0.470771
eval/env_infos/final/reward_dist Max          1.5707
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0.000732625
eval/env_infos/initial/reward_dist Std        0.00219787
eval/env_infos/initial/reward_dist Max        0.00732625
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.85842
eval/env_infos/reward_dist Std                0.645328
eval/env_infos/reward_dist Max                1.5707
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00589339
time/evaluation sampling (s)                  3.52837
time/exploration sampling (s)                17.8105
time/logging (s)                              0.00531342
time/saving (s)                               0.00235942
time/training (s)                             4.69329
time/epoch (s)                               26.0458
time/total (s)                             7579.43
Epoch                                       294
---------------------------------------  ----------------
2023-08-05 02:27:57.598243 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 295 finished
---------------------------------------  ----------------
epoch                                       295
replay_buffer/size                       592000
trainer/QF1 Loss                              4.68554
trainer/QF2 Loss                              4.59412
trainer/Policy Loss                         -11.9165
trainer/Q1 Predictions Mean                  10.3344
trainer/Q1 Predictions Std                   17.2472
trainer/Q1 Predictions Max                   55.0213
trainer/Q1 Predictions Min                 -175.698
trainer/Q2 Predictions Mean                  10.2532
trainer/Q2 Predictions Std                   17.1741
trainer/Q2 Predictions Max                   55.2782
trainer/Q2 Predictions Min                 -175.958
trainer/Q Targets Mean                       10.3263
trainer/Q Targets Std                        17.3317
trainer/Q Targets Max                        55.6978
trainer/Q Targets Min                      -198.806
trainer/Bellman Errors 1 Mean                 4.68554
trainer/Bellman Errors 1 Std                 38.0868
trainer/Bellman Errors 1 Max               1005.27
trainer/Bellman Errors 1 Min                  2.1013e-08
trainer/Bellman Errors 2 Mean                 4.59412
trainer/Bellman Errors 2 Std                 37.6883
trainer/Bellman Errors 2 Max                993.824
trainer/Bellman Errors 2 Min                  6.63022e-08
trainer/Policy Action Mean                    0.229418
trainer/Policy Action Std                     0.842417
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     592000
expl/num paths total                      14800
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.760265
expl/Rewards Std                              0.654884
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            30.4106
expl/Returns Std                             13.9685
expl/Returns Max                             40.1542
expl/Returns Min                              0.630078
expl/Actions Mean                             0.280775
expl/Actions Std                              0.777393
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.4106
expl/env_infos/final/reward_dist Mean         1.2866
expl/env_infos/final/reward_dist Std          0.602803
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000794559
expl/env_infos/initial/reward_dist Std        0.00227587
expl/env_infos/initial/reward_dist Max        0.00821571
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.760265
expl/env_infos/reward_dist Std                0.654884
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     118400
eval/num paths total                       2960
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.947806
eval/Rewards Std                              0.609235
eval/Rewards Max                              1.57019
eval/Rewards Min                              0
eval/Returns Mean                            37.9123
eval/Returns Std                              1.52476
eval/Returns Max                             39.518
eval/Returns Min                             35.0972
eval/Actions Mean                             0.35573
eval/Actions Std                              0.789556
eval/Actions Max                              1
eval/Actions Min                             -0.999956
eval/Num Paths                               10
eval/Average Returns                         37.9123
eval/env_infos/final/reward_dist Mean         1.56891
eval/env_infos/final/reward_dist Std          0.00109852
eval/env_infos/final/reward_dist Max          1.57019
eval/env_infos/final/reward_dist Min          1.56673
eval/env_infos/initial/reward_dist Mean       0.00117795
eval/env_infos/initial/reward_dist Std        0.00198394
eval/env_infos/initial/reward_dist Max        0.00606543
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.947806
eval/env_infos/reward_dist Std                0.609235
eval/env_infos/reward_dist Max                1.57019
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.0059138
time/evaluation sampling (s)                  3.61687
time/exploration sampling (s)                17.6384
time/logging (s)                              0.00529824
time/saving (s)                               0.00238936
time/training (s)                             4.55937
time/epoch (s)                               25.8282
time/total (s)                             7605.26
Epoch                                       295
---------------------------------------  ----------------
2023-08-05 02:28:24.242193 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 296 finished
---------------------------------------  ----------------
epoch                                       296
replay_buffer/size                       594000
trainer/QF1 Loss                              5.63805
trainer/QF2 Loss                              5.47472
trainer/Policy Loss                         -11.8926
trainer/Q1 Predictions Mean                  10.2303
trainer/Q1 Predictions Std                   16.9739
trainer/Q1 Predictions Max                   56.7648
trainer/Q1 Predictions Min                 -237.639
trainer/Q2 Predictions Mean                  10.2276
trainer/Q2 Predictions Std                   16.9872
trainer/Q2 Predictions Max                   57.1833
trainer/Q2 Predictions Min                 -237.316
trainer/Q Targets Mean                       10.1857
trainer/Q Targets Std                        17.3891
trainer/Q Targets Max                        56.7232
trainer/Q Targets Min                      -245.958
trainer/Bellman Errors 1 Mean                 5.63805
trainer/Bellman Errors 1 Std                 62.0998
trainer/Bellman Errors 1 Max               2515.16
trainer/Bellman Errors 1 Min                  2.45927e-09
trainer/Bellman Errors 2 Mean                 5.47472
trainer/Bellman Errors 2 Std                 60.5839
trainer/Bellman Errors 2 Max               2538.77
trainer/Bellman Errors 2 Min                  7.36691e-09
trainer/Policy Action Mean                    0.220777
trainer/Policy Action Std                     0.841421
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     594000
expl/num paths total                      14850
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.708692
expl/Rewards Std                              0.651888
expl/Rewards Max                              1.57079
expl/Rewards Min                              0
expl/Returns Mean                            28.3477
expl/Returns Std                             14.779
expl/Returns Max                             41.6138
expl/Returns Min                              0.63187
expl/Actions Mean                             0.256225
expl/Actions Std                              0.778892
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         28.3477
expl/env_infos/final/reward_dist Mean         1.22393
expl/env_infos/final/reward_dist Std          0.650011
expl/env_infos/final/reward_dist Max          1.57079
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000759934
expl/env_infos/initial/reward_dist Std        0.00218215
expl/env_infos/initial/reward_dist Max        0.00870415
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.708692
expl/env_infos/reward_dist Std                0.651888
expl/env_infos/reward_dist Max                1.57079
expl/env_infos/reward_dist Min                0
eval/num steps total                     118800
eval/num paths total                       2970
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.891472
eval/Rewards Std                              0.614669
eval/Rewards Max                              1.57075
eval/Rewards Min                              0
eval/Returns Mean                            35.6589
eval/Returns Std                              1.79237
eval/Returns Max                             38.9339
eval/Returns Min                             32.8786
eval/Actions Mean                             0.347441
eval/Actions Std                              0.789421
eval/Actions Max                              1
eval/Actions Min                             -0.999941
eval/Num Paths                               10
eval/Average Returns                         35.6589
eval/env_infos/final/reward_dist Mean         1.56943
eval/env_infos/final/reward_dist Std          0.00123994
eval/env_infos/final/reward_dist Max          1.57075
eval/env_infos/final/reward_dist Min          1.56712
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.891472
eval/env_infos/reward_dist Std                0.614669
eval/env_infos/reward_dist Max                1.57075
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00587242
time/evaluation sampling (s)                  3.76407
time/exploration sampling (s)                18.2595
time/logging (s)                              0.00531401
time/saving (s)                               0.00231284
time/training (s)                             4.60349
time/epoch (s)                               26.6406
time/total (s)                             7631.9
Epoch                                       296
---------------------------------------  ----------------
2023-08-05 02:28:49.302152 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 297 finished
---------------------------------------  ----------------
epoch                                       297
replay_buffer/size                       596000
trainer/QF1 Loss                              5.17659
trainer/QF2 Loss                              4.88951
trainer/Policy Loss                         -11.9016
trainer/Q1 Predictions Mean                  10.3218
trainer/Q1 Predictions Std                   17.7571
trainer/Q1 Predictions Max                   55.6225
trainer/Q1 Predictions Min                 -205.629
trainer/Q2 Predictions Mean                  10.3132
trainer/Q2 Predictions Std                   17.8239
trainer/Q2 Predictions Max                   55.3913
trainer/Q2 Predictions Min                 -211.668
trainer/Q Targets Mean                       10.2929
trainer/Q Targets Std                        17.9289
trainer/Q Targets Max                        55.9394
trainer/Q Targets Min                      -239.654
trainer/Bellman Errors 1 Mean                 5.17659
trainer/Bellman Errors 1 Std                 49.7177
trainer/Bellman Errors 1 Max               1487.19
trainer/Bellman Errors 1 Min                  1.26638e-06
trainer/Bellman Errors 2 Mean                 4.88951
trainer/Bellman Errors 2 Std                 44.6795
trainer/Bellman Errors 2 Max               1429.31
trainer/Bellman Errors 2 Min                  1.97502e-07
trainer/Policy Action Mean                    0.174646
trainer/Policy Action Std                     0.83738
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     596000
expl/num paths total                      14900
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.600979
expl/Rewards Std                              0.609834
expl/Rewards Max                              1.57072
expl/Rewards Min                              0
expl/Returns Mean                            24.0391
expl/Returns Std                             13.9684
expl/Returns Max                             39.3929
expl/Returns Min                              0.61138
expl/Actions Mean                             0.141575
expl/Actions Std                              0.768215
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         24.0391
expl/env_infos/final/reward_dist Mean         1.16036
expl/env_infos/final/reward_dist Std          0.687807
expl/env_infos/final/reward_dist Max          1.57072
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000765995
expl/env_infos/initial/reward_dist Std        0.00214714
expl/env_infos/initial/reward_dist Max        0.0101099
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.600979
expl/env_infos/reward_dist Std                0.609834
expl/env_infos/reward_dist Max                1.57072
expl/env_infos/reward_dist Min                0
eval/num steps total                     119200
eval/num paths total                       2980
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.67908
eval/Rewards Std                              0.629683
eval/Rewards Max                              1.57074
eval/Rewards Min                              0
eval/Returns Mean                            27.1632
eval/Returns Std                             13.3371
eval/Returns Max                             36.7142
eval/Returns Min                              0.694634
eval/Actions Mean                             0.196081
eval/Actions Std                              0.781712
eval/Actions Max                              1
eval/Actions Min                             -0.999882
eval/Num Paths                               10
eval/Average Returns                         27.1632
eval/env_infos/final/reward_dist Mean         1.2536
eval/env_infos/final/reward_dist Std          0.626804
eval/env_infos/final/reward_dist Max          1.57074
eval/env_infos/final/reward_dist Min          0
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.67908
eval/env_infos/reward_dist Std                0.629683
eval/env_infos/reward_dist Max                1.57074
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00575152
time/evaluation sampling (s)                  3.58592
time/exploration sampling (s)                17.0774
time/logging (s)                              0.00538038
time/saving (s)                               0.00243886
time/training (s)                             4.37972
time/epoch (s)                               25.0567
time/total (s)                             7656.96
Epoch                                       297
---------------------------------------  ----------------
2023-08-05 02:29:13.897467 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 298 finished
---------------------------------------  ----------------
epoch                                       298
replay_buffer/size                       598000
trainer/QF1 Loss                              6.84431
trainer/QF2 Loss                              6.75407
trainer/Policy Loss                         -12.1751
trainer/Q1 Predictions Mean                  10.4828
trainer/Q1 Predictions Std                   17.0598
trainer/Q1 Predictions Max                   56.7288
trainer/Q1 Predictions Min                 -168.764
trainer/Q2 Predictions Mean                  10.4391
trainer/Q2 Predictions Std                   17.0432
trainer/Q2 Predictions Max                   56.6301
trainer/Q2 Predictions Min                 -168.237
trainer/Q Targets Mean                       10.3901
trainer/Q Targets Std                        17.4016
trainer/Q Targets Max                        56.4594
trainer/Q Targets Min                      -159.977
trainer/Bellman Errors 1 Mean                 6.84431
trainer/Bellman Errors 1 Std                 65.2965
trainer/Bellman Errors 1 Max               2085.03
trainer/Bellman Errors 1 Min                  2.31378e-08
trainer/Bellman Errors 2 Mean                 6.75407
trainer/Bellman Errors 2 Std                 64.2189
trainer/Bellman Errors 2 Max               2030.6
trainer/Bellman Errors 2 Min                  1.30967e-10
trainer/Policy Action Mean                    0.15849
trainer/Policy Action Std                     0.832094
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     598000
expl/num paths total                      14950
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.677164
expl/Rewards Std                              0.59989
expl/Rewards Max                              1.57078
expl/Rewards Min                              0
expl/Returns Mean                            27.0866
expl/Returns Std                             10.9955
expl/Returns Max                             38.0775
expl/Returns Min                              0.643323
expl/Actions Mean                             0.14984
expl/Actions Std                              0.759882
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         27.0866
expl/env_infos/final/reward_dist Mean         1.34872
expl/env_infos/final/reward_dist Std          0.544178
expl/env_infos/final/reward_dist Max          1.57078
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000559882
expl/env_infos/initial/reward_dist Std        0.00211829
expl/env_infos/initial/reward_dist Max        0.0113351
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.677164
expl/env_infos/reward_dist Std                0.59989
expl/env_infos/reward_dist Max                1.57078
expl/env_infos/reward_dist Min                0
eval/num steps total                     119600
eval/num paths total                       2990
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.806547
eval/Rewards Std                              0.583685
eval/Rewards Max                              1.57079
eval/Rewards Min                              0
eval/Returns Mean                            32.2619
eval/Returns Std                              3.05431
eval/Returns Max                             38.7322
eval/Returns Min                             28.5301
eval/Actions Mean                             0.210569
eval/Actions Std                              0.777902
eval/Actions Max                              1
eval/Actions Min                             -0.999737
eval/Num Paths                               10
eval/Average Returns                         32.2619
eval/env_infos/final/reward_dist Mean         1.56795
eval/env_infos/final/reward_dist Std          0.00349241
eval/env_infos/final/reward_dist Max          1.57079
eval/env_infos/final/reward_dist Min          1.56187
eval/env_infos/initial/reward_dist Mean       0.0010955
eval/env_infos/initial/reward_dist Std        0.0025127
eval/env_infos/initial/reward_dist Max        0.00822813
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.806547
eval/env_infos/reward_dist Std                0.583685
eval/env_infos/reward_dist Max                1.57079
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00581186
time/evaluation sampling (s)                  3.53242
time/exploration sampling (s)                17.0882
time/logging (s)                              0.00394426
time/saving (s)                               0.00185275
time/training (s)                             3.95831
time/epoch (s)                               24.5906
time/total (s)                             7681.55
Epoch                                       298
---------------------------------------  ----------------
2023-08-05 02:29:38.172941 PDT | [Fanuc_pivoting_td3_2023_08_05_00_21_12_0000--s-0] Epoch 299 finished
---------------------------------------  ----------------
epoch                                       299
replay_buffer/size                       600000
trainer/QF1 Loss                              5.21435
trainer/QF2 Loss                              5.09603
trainer/Policy Loss                         -12.2797
trainer/Q1 Predictions Mean                  10.6632
trainer/Q1 Predictions Std                   17.4622
trainer/Q1 Predictions Max                   58.0774
trainer/Q1 Predictions Min                 -140.078
trainer/Q2 Predictions Mean                  10.667
trainer/Q2 Predictions Std                   17.4956
trainer/Q2 Predictions Max                   57.8567
trainer/Q2 Predictions Min                 -143.638
trainer/Q Targets Mean                       10.603
trainer/Q Targets Std                        17.7035
trainer/Q Targets Max                        58.1379
trainer/Q Targets Min                      -150.721
trainer/Bellman Errors 1 Mean                 5.21435
trainer/Bellman Errors 1 Std                 53.1867
trainer/Bellman Errors 1 Max               1979.17
trainer/Bellman Errors 1 Min                  1.06083e-08
trainer/Bellman Errors 2 Mean                 5.09603
trainer/Bellman Errors 2 Std                 52.314
trainer/Bellman Errors 2 Max               1897.78
trainer/Bellman Errors 2 Min                  9.31323e-10
trainer/Policy Action Mean                    0.165228
trainer/Policy Action Std                     0.832028
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                     600000
expl/num paths total                      15000
expl/path length Mean                        40
expl/path length Std                          0
expl/path length Max                         40
expl/path length Min                         40
expl/Rewards Mean                             0.768546
expl/Rewards Std                              0.617716
expl/Rewards Max                              1.57077
expl/Rewards Min                              0
expl/Returns Mean                            30.7418
expl/Returns Std                             10.1872
expl/Returns Max                             39.7426
expl/Returns Min                              0.854076
expl/Actions Mean                             0.200437
expl/Actions Std                              0.760632
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               50
expl/Average Returns                         30.7418
expl/env_infos/final/reward_dist Mean         1.41159
expl/env_infos/final/reward_dist Std          0.470535
expl/env_infos/final/reward_dist Max          1.57077
expl/env_infos/final/reward_dist Min          0
expl/env_infos/initial/reward_dist Mean       0.000898968
expl/env_infos/initial/reward_dist Std        0.00221675
expl/env_infos/initial/reward_dist Max        0.0102251
expl/env_infos/initial/reward_dist Min        0
expl/env_infos/reward_dist Mean               0.768546
expl/env_infos/reward_dist Std                0.617716
expl/env_infos/reward_dist Max                1.57077
expl/env_infos/reward_dist Min                0
eval/num steps total                     120000
eval/num paths total                       3000
eval/path length Mean                        40
eval/path length Std                          0
eval/path length Max                         40
eval/path length Min                         40
eval/Rewards Mean                             0.816621
eval/Rewards Std                              0.593841
eval/Rewards Max                              1.57073
eval/Rewards Min                              0
eval/Returns Mean                            32.6649
eval/Returns Std                              1.99721
eval/Returns Max                             36.4425
eval/Returns Min                             29.5884
eval/Actions Mean                             0.240662
eval/Actions Std                              0.770292
eval/Actions Max                              1
eval/Actions Min                             -0.999602
eval/Num Paths                               10
eval/Average Returns                         32.6649
eval/env_infos/final/reward_dist Mean         1.56784
eval/env_infos/final/reward_dist Std          0.00248243
eval/env_infos/final/reward_dist Max          1.57073
eval/env_infos/final/reward_dist Min          1.56269
eval/env_infos/initial/reward_dist Mean       0
eval/env_infos/initial/reward_dist Std        0
eval/env_infos/initial/reward_dist Max        0
eval/env_infos/initial/reward_dist Min        0
eval/env_infos/reward_dist Mean               0.816621
eval/env_infos/reward_dist Std                0.593841
eval/env_infos/reward_dist Max                1.57073
eval/env_infos/reward_dist Min                0
time/data storing (s)                         0.00588104
time/evaluation sampling (s)                  3.49378
time/exploration sampling (s)                16.9917
time/logging (s)                              0.00395431
time/saving (s)                               0.010474
time/training (s)                             3.76639
time/epoch (s)                               24.2722
time/total (s)                             7705.82
Epoch                                       299
---------------------------------------  ----------------
