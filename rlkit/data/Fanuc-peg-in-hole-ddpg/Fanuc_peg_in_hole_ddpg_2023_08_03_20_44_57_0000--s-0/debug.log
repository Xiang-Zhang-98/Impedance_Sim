2023-08-03 20:46:59.971728 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 0 finished
---------------------------------------  ---------------
epoch                                        0
replay_buffer/size                       10500
trainer/QF Loss                              0.577262
trainer/Policy Loss                         -0.00130695
trainer/Raw Policy Loss                     -0.00130695
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                   0.00136195
trainer/Q Predictions Std                    0.00128183
trainer/Q Predictions Max                    0.00644368
trainer/Q Predictions Min                   -0.00239599
trainer/Q Targets Mean                       0.083963
trainer/Q Targets Std                        0.755181
trainer/Q Targets Max                       10.0003
trainer/Q Targets Min                       -0.00185079
trainer/Bellman Errors Mean                  0.577262
trainer/Bellman Errors Std                   7.32707
trainer/Bellman Errors Max                 100.014
trainer/Bellman Errors Min                   7.10863e-14
trainer/Policy Action Mean                  -0.00030505
trainer/Policy Action Std                    0.00179589
trainer/Policy Action Max                    0.00768846
trainer/Policy Action Min                   -0.0140437
expl/num steps total                     10500
expl/num paths total                       525
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0341493
expl/Rewards Std                             0.278755
expl/Rewards Max                             3.61424
expl/Rewards Min                             1.77718e-15
expl/Returns Mean                            0.682985
expl/Returns Std                             2.74485
expl/Returns Max                            14.1181
expl/Returns Min                             0.015497
expl/Actions Mean                           -0.019021
expl/Actions Std                             0.491811
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.682985
expl/env_infos/final/reward_dist Mean        0.0558896
expl/env_infos/final/reward_dist Std         0.208406
expl/env_infos/final/reward_dist Max         1.0569
expl/env_infos/final/reward_dist Min         1.77718e-15
expl/env_infos/initial/reward_dist Mean      0.0108735
expl/env_infos/initial/reward_dist Std       0.0168211
expl/env_infos/initial/reward_dist Max       0.0536478
expl/env_infos/initial/reward_dist Min       8.51579e-05
expl/env_infos/reward_dist Mean              0.0341493
expl/env_infos/reward_dist Std               0.278755
expl/env_infos/reward_dist Max               3.61424
expl/env_infos/reward_dist Min               1.77718e-15
eval/num steps total                       100
eval/num paths total                         5
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00383892
eval/Rewards Std                             0.00591899
eval/Rewards Max                             0.0376128
eval/Rewards Min                             8.35234e-05
eval/Returns Mean                            0.0767784
eval/Returns Std                             0.0588705
eval/Returns Max                             0.183892
eval/Returns Min                             0.0177562
eval/Actions Mean                           -0.000358363
eval/Actions Std                             0.0015282
eval/Actions Max                             0.00473921
eval/Actions Min                            -0.0112325
eval/Num Paths                               5
eval/Average Returns                         0.0767784
eval/env_infos/final/reward_dist Mean        0.00240915
eval/env_infos/final/reward_dist Std         0.00155862
eval/env_infos/final/reward_dist Max         0.0050353
eval/env_infos/final/reward_dist Min         0.000167439
eval/env_infos/initial/reward_dist Mean      0.0121009
eval/env_infos/initial/reward_dist Std       0.0132061
eval/env_infos/initial/reward_dist Max       0.0376128
eval/env_infos/initial/reward_dist Min       0.00255163
eval/env_infos/reward_dist Mean              0.00383892
eval/env_infos/reward_dist Std               0.00591899
eval/env_infos/reward_dist Max               0.0376128
eval/env_infos/reward_dist Min               8.35234e-05
time/data storing (s)                        0.00152033
time/evaluation sampling (s)               109.123
time/exploration sampling (s)                5.32043
time/logging (s)                             0.00177841
time/saving (s)                              0.0138764
time/training (s)                            4.58822
time/epoch (s)                             119.049
time/total (s)                             122.219
Epoch                                        0
---------------------------------------  ---------------
2023-08-03 20:47:09.572014 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 1 finished
---------------------------------------  ---------------
epoch                                        1
replay_buffer/size                       11000
trainer/QF Loss                             38.6732
trainer/Policy Loss                        -27.3686
trainer/Raw Policy Loss                    -27.3686
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  19.3136
trainer/Q Predictions Std                   12.8997
trainer/Q Predictions Max                   94.5558
trainer/Q Predictions Min                   -8.8888
trainer/Q Targets Mean                      19.2957
trainer/Q Targets Std                       14.2098
trainer/Q Targets Max                      106.338
trainer/Q Targets Min                       -9.3064
trainer/Bellman Errors Mean                 38.6732
trainer/Bellman Errors Std                 135.374
trainer/Bellman Errors Max                2969.98
trainer/Bellman Errors Min                   1.04713e-06
trainer/Policy Action Mean                  -0.409751
trainer/Policy Action Std                    0.867787
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     11000
expl/num paths total                       550
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0116314
expl/Rewards Std                             0.13213
expl/Rewards Max                             2.88832
expl/Rewards Min                             6.64883e-19
expl/Returns Mean                            0.232628
expl/Returns Std                             0.606858
expl/Returns Max                             3.0863
expl/Returns Min                             0.00661879
expl/Actions Mean                           -0.274426
expl/Actions Std                             0.775168
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.232628
expl/env_infos/final/reward_dist Mean        1.86541e-07
expl/env_infos/final/reward_dist Std         9.08157e-07
expl/env_infos/final/reward_dist Max         4.63555e-06
expl/env_infos/final/reward_dist Min         6.64883e-19
expl/env_infos/initial/reward_dist Mean      0.0131449
expl/env_infos/initial/reward_dist Std       0.0182777
expl/env_infos/initial/reward_dist Max       0.0778406
expl/env_infos/initial/reward_dist Min       1.23996e-05
expl/env_infos/reward_dist Mean              0.0116314
expl/env_infos/reward_dist Std               0.13213
expl/env_infos/reward_dist Max               2.88832
expl/env_infos/reward_dist Min               6.64883e-19
eval/num steps total                       200
eval/num paths total                        10
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00196157
eval/Rewards Std                             0.00645588
eval/Rewards Max                             0.0387092
eval/Rewards Min                             4.76319e-16
eval/Returns Mean                            0.0392313
eval/Returns Std                             0.0216298
eval/Returns Max                             0.0741814
eval/Returns Min                             0.0150541
eval/Actions Mean                           -0.341688
eval/Actions Std                             0.893609
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0392313
eval/env_infos/final/reward_dist Mean        1.86929e-14
eval/env_infos/final/reward_dist Std         2.68557e-14
eval/env_infos/final/reward_dist Max         7.16789e-14
eval/env_infos/final/reward_dist Min         4.76319e-16
eval/env_infos/initial/reward_dist Mean      0.0109652
eval/env_infos/initial/reward_dist Std       0.0138793
eval/env_infos/initial/reward_dist Max       0.0364528
eval/env_infos/initial/reward_dist Min       0.000290056
eval/env_infos/reward_dist Mean              0.00196157
eval/env_infos/reward_dist Std               0.00645588
eval/env_infos/reward_dist Max               0.0387092
eval/env_infos/reward_dist Min               4.76319e-16
time/data storing (s)                        0.0015413
time/evaluation sampling (s)                 0.993558
time/exploration sampling (s)                4.54913
time/logging (s)                             0.00225173
time/saving (s)                              0.00102434
time/training (s)                            4.05142
time/epoch (s)                               9.59893
time/total (s)                             131.819
Epoch                                        1
---------------------------------------  ---------------
2023-08-03 20:47:19.095750 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 2 finished
---------------------------------------  ---------------
epoch                                        2
replay_buffer/size                       11500
trainer/QF Loss                            131.014
trainer/Policy Loss                        -83.0451
trainer/Raw Policy Loss                    -83.0451
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  64.4843
trainer/Q Predictions Std                   24.3898
trainer/Q Predictions Max                  196.08
trainer/Q Predictions Min                   -9.52325
trainer/Q Targets Mean                      63.0265
trainer/Q Targets Std                       27.3095
trainer/Q Targets Max                      200.819
trainer/Q Targets Min                       -8.73473
trainer/Bellman Errors Mean                131.014
trainer/Bellman Errors Std                 254.16
trainer/Bellman Errors Max                3444.42
trainer/Bellman Errors Min                   0.000534222
trainer/Policy Action Mean                  -0.548241
trainer/Policy Action Std                    0.735051
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     11500
expl/num paths total                       575
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0167676
expl/Rewards Std                             0.0600064
expl/Rewards Max                             0.446373
expl/Rewards Min                             1.61482e-11
expl/Returns Mean                            0.335352
expl/Returns Std                             0.996469
expl/Returns Max                             4.57349
expl/Returns Min                             0.0134551
expl/Actions Mean                           -0.465595
expl/Actions Std                             0.652446
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.335352
expl/env_infos/final/reward_dist Mean        0.00951916
expl/env_infos/final/reward_dist Std         0.0448122
expl/env_infos/final/reward_dist Max         0.229005
expl/env_infos/final/reward_dist Min         1.61482e-11
expl/env_infos/initial/reward_dist Mean      0.0058896
expl/env_infos/initial/reward_dist Std       0.00809968
expl/env_infos/initial/reward_dist Max       0.0307204
expl/env_infos/initial/reward_dist Min       0.000116535
expl/env_infos/reward_dist Mean              0.0167676
expl/env_infos/reward_dist Std               0.0600064
expl/env_infos/reward_dist Max               0.446373
expl/env_infos/reward_dist Min               1.61482e-11
eval/num steps total                       300
eval/num paths total                        15
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00201351
eval/Rewards Std                             0.00672587
eval/Rewards Max                             0.0434151
eval/Rewards Min                             2.64778e-08
eval/Returns Mean                            0.0402701
eval/Returns Std                             0.0164253
eval/Returns Max                             0.0681316
eval/Returns Min                             0.0230312
eval/Actions Mean                           -0.590676
eval/Actions Std                             0.735267
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0402701
eval/env_infos/final/reward_dist Mean        1.35922e-05
eval/env_infos/final/reward_dist Std         1.77764e-05
eval/env_infos/final/reward_dist Max         4.643e-05
eval/env_infos/final/reward_dist Min         2.97767e-08
eval/env_infos/initial/reward_dist Mean      0.00897843
eval/env_infos/initial/reward_dist Std       0.00610698
eval/env_infos/initial/reward_dist Max       0.0189542
eval/env_infos/initial/reward_dist Min       1.46329e-05
eval/env_infos/reward_dist Mean              0.00201351
eval/env_infos/reward_dist Std               0.00672587
eval/env_infos/reward_dist Max               0.0434151
eval/env_infos/reward_dist Min               2.64778e-08
time/data storing (s)                        0.00150862
time/evaluation sampling (s)                 0.724015
time/exploration sampling (s)                3.88746
time/logging (s)                             0.00318061
time/saving (s)                              0.00128522
time/training (s)                            4.90487
time/epoch (s)                               9.52231
time/total (s)                             141.343
Epoch                                        2
---------------------------------------  ---------------
2023-08-03 20:47:27.072454 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 3 finished
---------------------------------------  ---------------
epoch                                        3
replay_buffer/size                       12000
trainer/QF Loss                            287.384
trainer/Policy Loss                       -187.853
trainer/Raw Policy Loss                   -187.853
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 160.148
trainer/Q Predictions Std                   47.5684
trainer/Q Predictions Max                  388.256
trainer/Q Predictions Min                   -1.1016
trainer/Q Targets Mean                     159.955
trainer/Q Targets Std                       50.4799
trainer/Q Targets Max                      395.462
trainer/Q Targets Min                      -18.224
trainer/Bellman Errors Mean                287.384
trainer/Bellman Errors Std                 556.547
trainer/Bellman Errors Max                8542.66
trainer/Bellman Errors Min                   5.73904e-06
trainer/Policy Action Mean                  -0.193754
trainer/Policy Action Std                    0.910297
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     12000
expl/num paths total                       600
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00266553
expl/Rewards Std                             0.00916649
expl/Rewards Max                             0.117157
expl/Rewards Min                             3.4091e-11
expl/Returns Mean                            0.0533107
expl/Returns Std                             0.0453545
expl/Returns Max                             0.166509
expl/Returns Min                             0.00816571
expl/Actions Mean                           -0.11222
expl/Actions Std                             0.807854
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0533107
expl/env_infos/final/reward_dist Mean        0.00978055
expl/env_infos/final/reward_dist Std         0.0243896
expl/env_infos/final/reward_dist Max         0.117157
expl/env_infos/final/reward_dist Min         1.11496e-10
expl/env_infos/initial/reward_dist Mean      0.00306407
expl/env_infos/initial/reward_dist Std       0.00473742
expl/env_infos/initial/reward_dist Max       0.0178525
expl/env_infos/initial/reward_dist Min       4.3876e-06
expl/env_infos/reward_dist Mean              0.00266553
expl/env_infos/reward_dist Std               0.00916649
expl/env_infos/reward_dist Max               0.117157
expl/env_infos/reward_dist Min               3.4091e-11
eval/num steps total                       400
eval/num paths total                        20
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00218462
eval/Rewards Std                             0.0044985
eval/Rewards Max                             0.0245834
eval/Rewards Min                             1.10513e-09
eval/Returns Mean                            0.0436924
eval/Returns Std                             0.0199546
eval/Returns Max                             0.0802197
eval/Returns Min                             0.0253582
eval/Actions Mean                           -0.148152
eval/Actions Std                             0.936603
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0436924
eval/env_infos/final/reward_dist Mean        0.00365354
eval/env_infos/final/reward_dist Std         0.0054966
eval/env_infos/final/reward_dist Max         0.0145684
eval/env_infos/final/reward_dist Min         2.03813e-05
eval/env_infos/initial/reward_dist Mean      0.00708202
eval/env_infos/initial/reward_dist Std       0.00636869
eval/env_infos/initial/reward_dist Max       0.0145323
eval/env_infos/initial/reward_dist Min       1.33486e-05
eval/env_infos/reward_dist Mean              0.00218462
eval/env_infos/reward_dist Std               0.0044985
eval/env_infos/reward_dist Max               0.0245834
eval/env_infos/reward_dist Min               1.10513e-09
time/data storing (s)                        0.0015588
time/evaluation sampling (s)                 0.552636
time/exploration sampling (s)                3.41687
time/logging (s)                             0.00226287
time/saving (s)                              0.00103335
time/training (s)                            3.99837
time/epoch (s)                               7.97272
time/total (s)                             149.319
Epoch                                        3
---------------------------------------  ---------------
2023-08-03 20:47:35.941139 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 4 finished
---------------------------------------  ----------------
epoch                                         4
replay_buffer/size                        12500
trainer/QF Loss                            1651.61
trainer/Policy Loss                        -529.604
trainer/Raw Policy Loss                    -529.604
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  439.038
trainer/Q Predictions Std                    85.2106
trainer/Q Predictions Max                   793.269
trainer/Q Predictions Min                   208.926
trainer/Q Targets Mean                      442.035
trainer/Q Targets Std                        95.3444
trainer/Q Targets Max                       778.846
trainer/Q Targets Min                       210.727
trainer/Bellman Errors Mean                1651.61
trainer/Bellman Errors Std                 3788.25
trainer/Bellman Errors Max               107183
trainer/Bellman Errors Min                    4.10713e-05
trainer/Policy Action Mean                   -0.00728495
trainer/Policy Action Std                     0.963913
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      12500
expl/num paths total                        625
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0111786
expl/Rewards Std                              0.053176
expl/Rewards Max                              0.684149
expl/Rewards Min                              2.66928e-22
expl/Returns Mean                             0.223572
expl/Returns Std                              0.441241
expl/Returns Max                              1.73616
expl/Returns Min                              0.00990016
expl/Actions Mean                            -0.063923
expl/Actions Std                              0.818578
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.223572
expl/env_infos/final/reward_dist Mean         0.0275352
expl/env_infos/final/reward_dist Std          0.134032
expl/env_infos/final/reward_dist Max          0.684149
expl/env_infos/final/reward_dist Min          2.66928e-22
expl/env_infos/initial/reward_dist Mean       0.0101894
expl/env_infos/initial/reward_dist Std        0.0140683
expl/env_infos/initial/reward_dist Max        0.0484056
expl/env_infos/initial/reward_dist Min        5.78624e-05
expl/env_infos/reward_dist Mean               0.0111786
expl/env_infos/reward_dist Std                0.053176
expl/env_infos/reward_dist Max                0.684149
expl/env_infos/reward_dist Min                2.66928e-22
eval/num steps total                        500
eval/num paths total                         25
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.00203872
eval/Rewards Std                              0.00544444
eval/Rewards Max                              0.0302106
eval/Rewards Min                              2.97315e-17
eval/Returns Mean                             0.0407744
eval/Returns Std                              0.0188427
eval/Returns Max                              0.0634192
eval/Returns Min                              0.0185167
eval/Actions Mean                            -0.123455
eval/Actions Std                              0.968735
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.0407744
eval/env_infos/final/reward_dist Mean         1.14244e-15
eval/env_infos/final/reward_dist Std          1.26171e-15
eval/env_infos/final/reward_dist Max          3.45041e-15
eval/env_infos/final/reward_dist Min          2.97315e-17
eval/env_infos/initial/reward_dist Mean       0.0124393
eval/env_infos/initial/reward_dist Std        0.0109728
eval/env_infos/initial/reward_dist Max        0.0302106
eval/env_infos/initial/reward_dist Min        0.000672836
eval/env_infos/reward_dist Mean               0.00203872
eval/env_infos/reward_dist Std                0.00544444
eval/env_infos/reward_dist Max                0.0302106
eval/env_infos/reward_dist Min                2.97315e-17
time/data storing (s)                         0.00150845
time/evaluation sampling (s)                  0.72281
time/exploration sampling (s)                 3.95684
time/logging (s)                              0.00223752
time/saving (s)                               0.00101812
time/training (s)                             4.18189
time/epoch (s)                                8.8663
time/total (s)                              158.187
Epoch                                         4
---------------------------------------  ----------------
2023-08-03 20:47:45.069581 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 5 finished
---------------------------------------  ---------------
epoch                                        5
replay_buffer/size                       13000
trainer/QF Loss                           1007.02
trainer/Policy Loss                       -656.412
trainer/Raw Policy Loss                   -656.412
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 609.463
trainer/Q Predictions Std                   67.8332
trainer/Q Predictions Max                  934.915
trainer/Q Predictions Min                  335.562
trainer/Q Targets Mean                     609.089
trainer/Q Targets Std                       71.6708
trainer/Q Targets Max                      960.023
trainer/Q Targets Min                      346.021
trainer/Bellman Errors Mean               1007.02
trainer/Bellman Errors Std                1972.54
trainer/Bellman Errors Max               31995
trainer/Bellman Errors Min                   0.000555053
trainer/Policy Action Mean                  -0.1689
trainer/Policy Action Std                    0.964182
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     13000
expl/num paths total                       650
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0237788
expl/Rewards Std                             0.148285
expl/Rewards Max                             2.4006
expl/Rewards Min                             1.50343e-10
expl/Returns Mean                            0.475576
expl/Returns Std                             0.628164
expl/Returns Max                             2.5577
expl/Returns Min                             0.0161252
expl/Actions Mean                           -0.166525
expl/Actions Std                             0.82063
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.475576
expl/env_infos/final/reward_dist Mean        0.0296695
expl/env_infos/final/reward_dist Std         0.0810563
expl/env_infos/final/reward_dist Max         0.403428
expl/env_infos/final/reward_dist Min         1.20711e-09
expl/env_infos/initial/reward_dist Mean      0.0098861
expl/env_infos/initial/reward_dist Std       0.0138413
expl/env_infos/initial/reward_dist Max       0.0506922
expl/env_infos/initial/reward_dist Min       0.000240328
expl/env_infos/reward_dist Mean              0.0237788
expl/env_infos/reward_dist Std               0.148285
expl/env_infos/reward_dist Max               2.4006
expl/env_infos/reward_dist Min               1.50343e-10
eval/num steps total                       600
eval/num paths total                        30
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.154956
eval/Rewards Std                             1.01283
eval/Rewards Max                            10
eval/Rewards Min                             1.15593e-06
eval/Returns Mean                            3.09911
eval/Returns Std                             4.13143
eval/Returns Max                            11.1075
eval/Returns Min                             0.256072
eval/Actions Mean                           -0.181043
eval/Actions Std                             0.955267
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         3.09911
eval/env_infos/final/reward_dist Mean        0.0294666
eval/env_infos/final/reward_dist Std         0.0187682
eval/env_infos/final/reward_dist Max         0.0624518
eval/env_infos/final/reward_dist Min         0.00908654
eval/env_infos/initial/reward_dist Mean      0.00505343
eval/env_infos/initial/reward_dist Std       0.00665837
eval/env_infos/initial/reward_dist Max       0.0179813
eval/env_infos/initial/reward_dist Min       0.000348768
eval/env_infos/reward_dist Mean              0.154956
eval/env_infos/reward_dist Std               1.01283
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               1.15593e-06
time/data storing (s)                        0.00149353
time/evaluation sampling (s)                 0.675507
time/exploration sampling (s)                4.05114
time/logging (s)                             0.00222649
time/saving (s)                              0.00101707
time/training (s)                            4.39466
time/epoch (s)                               9.12605
time/total (s)                             167.315
Epoch                                        5
---------------------------------------  ---------------
2023-08-03 20:47:53.213230 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 6 finished
---------------------------------------  ---------------
epoch                                        6
replay_buffer/size                       13500
trainer/QF Loss                            646.484
trainer/Policy Loss                       -598.606
trainer/Raw Policy Loss                   -598.606
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 573.859
trainer/Q Predictions Std                   74.1494
trainer/Q Predictions Max                  918.53
trainer/Q Predictions Min                  376.871
trainer/Q Targets Mean                     573.033
trainer/Q Targets Std                       77.791
trainer/Q Targets Max                      941.16
trainer/Q Targets Min                      369.173
trainer/Bellman Errors Mean                646.483
trainer/Bellman Errors Std                2573.47
trainer/Bellman Errors Max               58162.4
trainer/Bellman Errors Min                   6.78934e-05
trainer/Policy Action Mean                  -0.522356
trainer/Policy Action Std                    0.837858
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     13500
expl/num paths total                       675
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00864363
expl/Rewards Std                             0.0304185
expl/Rewards Max                             0.321995
expl/Rewards Min                             2.26207e-12
expl/Returns Mean                            0.172873
expl/Returns Std                             0.136798
expl/Returns Max                             0.489829
expl/Returns Min                             0.0168922
expl/Actions Mean                           -0.356804
expl/Actions Std                             0.74746
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.172873
expl/env_infos/final/reward_dist Mean        0.0247933
expl/env_infos/final/reward_dist Std         0.0833841
expl/env_infos/final/reward_dist Max         0.321995
expl/env_infos/final/reward_dist Min         2.26207e-12
expl/env_infos/initial/reward_dist Mean      0.00847791
expl/env_infos/initial/reward_dist Std       0.0131754
expl/env_infos/initial/reward_dist Max       0.0632896
expl/env_infos/initial/reward_dist Min       0.000270978
expl/env_infos/reward_dist Mean              0.00864363
expl/env_infos/reward_dist Std               0.0304185
expl/env_infos/reward_dist Max               0.321995
expl/env_infos/reward_dist Min               2.26207e-12
eval/num steps total                       700
eval/num paths total                        35
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00596854
eval/Rewards Std                             0.023001
eval/Rewards Max                             0.21562
eval/Rewards Min                             1.63338e-09
eval/Returns Mean                            0.119371
eval/Returns Std                             0.105021
eval/Returns Max                             0.303392
eval/Returns Min                             0.0236387
eval/Actions Mean                           -0.476148
eval/Actions Std                             0.851173
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.119371
eval/env_infos/final/reward_dist Mean        2.2218e-06
eval/env_infos/final/reward_dist Std         3.8529e-06
eval/env_infos/final/reward_dist Max         9.89969e-06
eval/env_infos/final/reward_dist Min         1.63338e-09
eval/env_infos/initial/reward_dist Mean      0.0115575
eval/env_infos/initial/reward_dist Std       0.0120527
eval/env_infos/initial/reward_dist Max       0.0333606
eval/env_infos/initial/reward_dist Min       0.000182334
eval/env_infos/reward_dist Mean              0.00596854
eval/env_infos/reward_dist Std               0.023001
eval/env_infos/reward_dist Max               0.21562
eval/env_infos/reward_dist Min               1.63338e-09
time/data storing (s)                        0.00149034
time/evaluation sampling (s)                 0.826573
time/exploration sampling (s)                4.29858
time/logging (s)                             0.00173279
time/saving (s)                              0.000803892
time/training (s)                            3.01165
time/epoch (s)                               8.14083
time/total (s)                             175.458
Epoch                                        6
---------------------------------------  ---------------
2023-08-03 20:48:03.264120 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 7 finished
---------------------------------------  ---------------
epoch                                        7
replay_buffer/size                       14000
trainer/QF Loss                            434.594
trainer/Policy Loss                       -613.764
trainer/Raw Policy Loss                   -613.764
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 570.48
trainer/Q Predictions Std                   63.4934
trainer/Q Predictions Max                  887.632
trainer/Q Predictions Min                  362.592
trainer/Q Targets Mean                     571.301
trainer/Q Targets Std                       65.4318
trainer/Q Targets Max                      864.357
trainer/Q Targets Min                      320.31
trainer/Bellman Errors Mean                434.594
trainer/Bellman Errors Std                1213.75
trainer/Bellman Errors Max               22555.9
trainer/Bellman Errors Min                   7.83242e-05
trainer/Policy Action Mean                  -0.357283
trainer/Policy Action Std                    0.915477
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     14000
expl/num paths total                       700
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00327799
expl/Rewards Std                             0.0104144
expl/Rewards Max                             0.116766
expl/Rewards Min                             1.12792e-17
expl/Returns Mean                            0.0655598
expl/Returns Std                             0.0618406
expl/Returns Max                             0.225259
expl/Returns Min                             0.00606444
expl/Actions Mean                           -0.303024
expl/Actions Std                             0.793239
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0655598
expl/env_infos/final/reward_dist Mean        2.05666e-09
expl/env_infos/final/reward_dist Std         5.21174e-09
expl/env_infos/final/reward_dist Max         2.45403e-08
expl/env_infos/final/reward_dist Min         1.12792e-17
expl/env_infos/initial/reward_dist Mean      0.00922087
expl/env_infos/initial/reward_dist Std       0.0149126
expl/env_infos/initial/reward_dist Max       0.0480175
expl/env_infos/initial/reward_dist Min       3.36166e-05
expl/env_infos/reward_dist Mean              0.00327799
expl/env_infos/reward_dist Std               0.0104144
expl/env_infos/reward_dist Max               0.116766
expl/env_infos/reward_dist Min               1.12792e-17
eval/num steps total                       800
eval/num paths total                        40
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00192698
eval/Rewards Std                             0.00776062
eval/Rewards Max                             0.061627
eval/Rewards Min                             6.9622e-13
eval/Returns Mean                            0.0385396
eval/Returns Std                             0.0186297
eval/Returns Max                             0.0730536
eval/Returns Min                             0.0190779
eval/Actions Mean                           -0.359043
eval/Actions Std                             0.919631
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0385396
eval/env_infos/final/reward_dist Mean        2.06435e-11
eval/env_infos/final/reward_dist Std         1.62304e-11
eval/env_infos/final/reward_dist Max         4.20906e-11
eval/env_infos/final/reward_dist Min         6.9622e-13
eval/env_infos/initial/reward_dist Mean      0.0181919
eval/env_infos/initial/reward_dist Std       0.0239239
eval/env_infos/initial/reward_dist Max       0.061627
eval/env_infos/initial/reward_dist Min       0.000168304
eval/env_infos/reward_dist Mean              0.00192698
eval/env_infos/reward_dist Std               0.00776062
eval/env_infos/reward_dist Max               0.061627
eval/env_infos/reward_dist Min               6.9622e-13
time/data storing (s)                        0.00147645
time/evaluation sampling (s)                 0.882327
time/exploration sampling (s)                4.3747
time/logging (s)                             0.00322226
time/saving (s)                              0.0012913
time/training (s)                            4.78757
time/epoch (s)                              10.0506
time/total (s)                             185.51
Epoch                                        7
---------------------------------------  ---------------
2023-08-03 20:48:13.304989 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 8 finished
---------------------------------------  ---------------
epoch                                        8
replay_buffer/size                       14500
trainer/QF Loss                            252.299
trainer/Policy Loss                       -580.886
trainer/Raw Policy Loss                   -580.886
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 558.74
trainer/Q Predictions Std                   44.1331
trainer/Q Predictions Max                  778.942
trainer/Q Predictions Min                  254.669
trainer/Q Targets Mean                     559.211
trainer/Q Targets Std                       46.4731
trainer/Q Targets Max                      777.633
trainer/Q Targets Min                      256.987
trainer/Bellman Errors Mean                252.299
trainer/Bellman Errors Std                 592.433
trainer/Bellman Errors Max               14596
trainer/Bellman Errors Min                   2.71574e-06
trainer/Policy Action Mean                  -0.342884
trainer/Policy Action Std                    0.915834
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     14500
expl/num paths total                       725
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00672879
expl/Rewards Std                             0.0528286
expl/Rewards Max                             1.13852
expl/Rewards Min                             5.47161e-13
expl/Returns Mean                            0.134576
expl/Returns Std                             0.238417
expl/Returns Max                             1.2118
expl/Returns Min                             0.003988
expl/Actions Mean                           -0.151978
expl/Actions Std                             0.813157
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.134576
expl/env_infos/final/reward_dist Mean        3.43227e-05
expl/env_infos/final/reward_dist Std         0.000151608
expl/env_infos/final/reward_dist Max         0.000773192
expl/env_infos/final/reward_dist Min         5.47161e-13
expl/env_infos/initial/reward_dist Mean      0.00943089
expl/env_infos/initial/reward_dist Std       0.0175823
expl/env_infos/initial/reward_dist Max       0.0647185
expl/env_infos/initial/reward_dist Min       4.19397e-05
expl/env_infos/reward_dist Mean              0.00672879
expl/env_infos/reward_dist Std               0.0528286
expl/env_infos/reward_dist Max               1.13852
expl/env_infos/reward_dist Min               5.47161e-13
eval/num steps total                       900
eval/num paths total                        45
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.000848158
eval/Rewards Std                             0.00217024
eval/Rewards Max                             0.0133544
eval/Rewards Min                             8.88014e-13
eval/Returns Mean                            0.0169632
eval/Returns Std                             0.0082392
eval/Returns Max                             0.031428
eval/Returns Min                             0.00845916
eval/Actions Mean                           -0.212663
eval/Actions Std                             0.970019
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0169632
eval/env_infos/final/reward_dist Mean        6.18618e-11
eval/env_infos/final/reward_dist Std         1.12933e-10
eval/env_infos/final/reward_dist Max         2.87386e-10
eval/env_infos/final/reward_dist Min         8.88014e-13
eval/env_infos/initial/reward_dist Mean      0.00573424
eval/env_infos/initial/reward_dist Std       0.00502645
eval/env_infos/initial/reward_dist Max       0.0133544
eval/env_infos/initial/reward_dist Min       2.93029e-05
eval/env_infos/reward_dist Mean              0.000848158
eval/env_infos/reward_dist Std               0.00217024
eval/env_infos/reward_dist Max               0.0133544
eval/env_infos/reward_dist Min               8.88014e-13
time/data storing (s)                        0.00145973
time/evaluation sampling (s)                 1.40539
time/exploration sampling (s)                4.65297
time/logging (s)                             0.00225646
time/saving (s)                              0.00105605
time/training (s)                            3.97368
time/epoch (s)                              10.0368
time/total (s)                             195.549
Epoch                                        8
---------------------------------------  ---------------
2023-08-03 20:48:22.777176 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 9 finished
---------------------------------------  ---------------
epoch                                        9
replay_buffer/size                       15000
trainer/QF Loss                            146.693
trainer/Policy Loss                       -486.796
trainer/Raw Policy Loss                   -486.796
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 473.484
trainer/Q Predictions Std                   32.3652
trainer/Q Predictions Max                  626.73
trainer/Q Predictions Min                  287.055
trainer/Q Targets Mean                     472.89
trainer/Q Targets Std                       33.8187
trainer/Q Targets Max                      631.625
trainer/Q Targets Min                      282.123
trainer/Bellman Errors Mean                146.693
trainer/Bellman Errors Std                 338.263
trainer/Bellman Errors Max                5286.28
trainer/Bellman Errors Min                   1.85156e-05
trainer/Policy Action Mean                  -0.426544
trainer/Policy Action Std                    0.867954
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     15000
expl/num paths total                       750
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00198115
expl/Rewards Std                             0.00673073
expl/Rewards Max                             0.0649267
expl/Rewards Min                             9.62544e-13
expl/Returns Mean                            0.0396231
expl/Returns Std                             0.0273389
expl/Returns Max                             0.126889
expl/Returns Min                             0.00804028
expl/Actions Mean                           -0.303635
expl/Actions Std                             0.781081
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0396231
expl/env_infos/final/reward_dist Mean        1.33019e-07
expl/env_infos/final/reward_dist Std         4.32911e-07
expl/env_infos/final/reward_dist Max         1.62292e-06
expl/env_infos/final/reward_dist Min         9.62544e-13
expl/env_infos/initial/reward_dist Mean      0.0154702
expl/env_infos/initial/reward_dist Std       0.0205308
expl/env_infos/initial/reward_dist Max       0.0649267
expl/env_infos/initial/reward_dist Min       3.79526e-05
expl/env_infos/reward_dist Mean              0.00198115
expl/env_infos/reward_dist Std               0.00673073
expl/env_infos/reward_dist Max               0.0649267
expl/env_infos/reward_dist Min               9.62544e-13
eval/num steps total                      1000
eval/num paths total                        50
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00112851
eval/Rewards Std                             0.00409924
eval/Rewards Max                             0.0312988
eval/Rewards Min                             8.61712e-11
eval/Returns Mean                            0.0225702
eval/Returns Std                             0.0118386
eval/Returns Max                             0.0383042
eval/Returns Min                             0.0107857
eval/Actions Mean                           -0.348978
eval/Actions Std                             0.930945
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0225702
eval/env_infos/final/reward_dist Mean        1.33663e-09
eval/env_infos/final/reward_dist Std         1.93085e-09
eval/env_infos/final/reward_dist Max         5.16105e-09
eval/env_infos/final/reward_dist Min         8.61712e-11
eval/env_infos/initial/reward_dist Mean      0.00689844
eval/env_infos/initial/reward_dist Std       0.00937115
eval/env_infos/initial/reward_dist Max       0.0252606
eval/env_infos/initial/reward_dist Min       0.000269443
eval/env_infos/reward_dist Mean              0.00112851
eval/env_infos/reward_dist Std               0.00409924
eval/env_infos/reward_dist Max               0.0312988
eval/env_infos/reward_dist Min               8.61712e-11
time/data storing (s)                        0.00147751
time/evaluation sampling (s)                 0.916112
time/exploration sampling (s)                4.76619
time/logging (s)                             0.00221741
time/saving (s)                              0.00100531
time/training (s)                            3.78279
time/epoch (s)                               9.46979
time/total (s)                             205.021
Epoch                                        9
---------------------------------------  ---------------
2023-08-03 20:48:32.213202 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 10 finished
---------------------------------------  ---------------
epoch                                       10
replay_buffer/size                       15500
trainer/QF Loss                            123.598
trainer/Policy Loss                       -373.826
trainer/Raw Policy Loss                   -373.826
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 363.86
trainer/Q Predictions Std                   22.6925
trainer/Q Predictions Max                  506.892
trainer/Q Predictions Min                  232.125
trainer/Q Targets Mean                     363.296
trainer/Q Targets Std                       24.7579
trainer/Q Targets Max                      531.419
trainer/Q Targets Min                      222.75
trainer/Bellman Errors Mean                123.598
trainer/Bellman Errors Std                 267.242
trainer/Bellman Errors Max                5516.27
trainer/Bellman Errors Min                   2.92063e-06
trainer/Policy Action Mean                  -0.312614
trainer/Policy Action Std                    0.909418
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     15500
expl/num paths total                       775
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00628756
expl/Rewards Std                             0.0678168
expl/Rewards Max                             1.49686
expl/Rewards Min                             1.66719e-14
expl/Returns Mean                            0.125751
expl/Returns Std                             0.300441
expl/Returns Max                             1.5737
expl/Returns Min                             0.00750221
expl/Actions Mean                           -0.209199
expl/Actions Std                             0.802609
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.125751
expl/env_infos/final/reward_dist Mean        5.16481e-06
expl/env_infos/final/reward_dist Std         2.46719e-05
expl/env_infos/final/reward_dist Max         0.000125995
expl/env_infos/final/reward_dist Min         1.66719e-14
expl/env_infos/initial/reward_dist Mean      0.00869371
expl/env_infos/initial/reward_dist Std       0.0128722
expl/env_infos/initial/reward_dist Max       0.0574009
expl/env_infos/initial/reward_dist Min       5.30818e-05
expl/env_infos/reward_dist Mean              0.00628756
expl/env_infos/reward_dist Std               0.0678168
expl/env_infos/reward_dist Max               1.49686
expl/env_infos/reward_dist Min               1.66719e-14
eval/num steps total                      1100
eval/num paths total                        55
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00139814
eval/Rewards Std                             0.00511355
eval/Rewards Max                             0.0400252
eval/Rewards Min                             5.2101e-15
eval/Returns Mean                            0.0279627
eval/Returns Std                             0.0160653
eval/Returns Max                             0.0556809
eval/Returns Min                             0.00842958
eval/Actions Mean                           -0.235754
eval/Actions Std                             0.943469
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0279627
eval/env_infos/final/reward_dist Mean        7.88632e-11
eval/env_infos/final/reward_dist Std         1.57029e-10
eval/env_infos/final/reward_dist Max         3.9292e-10
eval/env_infos/final/reward_dist Min         5.2101e-15
eval/env_infos/initial/reward_dist Mean      0.00593976
eval/env_infos/initial/reward_dist Std       0.00628884
eval/env_infos/initial/reward_dist Max       0.0174043
eval/env_infos/initial/reward_dist Min       0.000466868
eval/env_infos/reward_dist Mean              0.00139814
eval/env_infos/reward_dist Std               0.00511355
eval/env_infos/reward_dist Max               0.0400252
eval/env_infos/reward_dist Min               5.2101e-15
time/data storing (s)                        0.00149963
time/evaluation sampling (s)                 0.994189
time/exploration sampling (s)                4.69977
time/logging (s)                             0.0022213
time/saving (s)                              0.00102727
time/training (s)                            3.73497
time/epoch (s)                               9.43368
time/total (s)                             214.457
Epoch                                       10
---------------------------------------  ---------------
2023-08-03 20:48:41.201735 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 11 finished
---------------------------------------  ---------------
epoch                                       11
replay_buffer/size                       16000
trainer/QF Loss                            124.161
trainer/Policy Loss                       -338.248
trainer/Raw Policy Loss                   -338.248
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 326.029
trainer/Q Predictions Std                   45.9808
trainer/Q Predictions Max                  501.983
trainer/Q Predictions Min                  252.272
trainer/Q Targets Mean                     326.405
trainer/Q Targets Std                       46.4645
trainer/Q Targets Max                      501.594
trainer/Q Targets Min                      250.67
trainer/Bellman Errors Mean                124.161
trainer/Bellman Errors Std                 307.763
trainer/Bellman Errors Max                6136.87
trainer/Bellman Errors Min                   1.82539e-07
trainer/Policy Action Mean                  -0.232754
trainer/Policy Action Std                    0.94975
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     16000
expl/num paths total                       800
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00653894
expl/Rewards Std                             0.0287245
expl/Rewards Max                             0.525704
expl/Rewards Min                             1.18103e-07
expl/Returns Mean                            0.130779
expl/Returns Std                             0.128125
expl/Returns Max                             0.60325
expl/Returns Min                             0.0159069
expl/Actions Mean                           -0.150929
expl/Actions Std                             0.80584
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.130779
expl/env_infos/final/reward_dist Mean        0.0255123
expl/env_infos/final/reward_dist Std         0.102915
expl/env_infos/final/reward_dist Max         0.525704
expl/env_infos/final/reward_dist Min         1.26806e-07
expl/env_infos/initial/reward_dist Mean      0.0160842
expl/env_infos/initial/reward_dist Std       0.0181743
expl/env_infos/initial/reward_dist Max       0.0493844
expl/env_infos/initial/reward_dist Min       4.57369e-05
expl/env_infos/reward_dist Mean              0.00653894
expl/env_infos/reward_dist Std               0.0287245
expl/env_infos/reward_dist Max               0.525704
expl/env_infos/reward_dist Min               1.18103e-07
eval/num steps total                      1200
eval/num paths total                        60
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00491017
eval/Rewards Std                             0.0145948
eval/Rewards Max                             0.0983943
eval/Rewards Min                             4.34606e-06
eval/Returns Mean                            0.0982035
eval/Returns Std                             0.0359968
eval/Returns Max                             0.146437
eval/Returns Min                             0.045679
eval/Actions Mean                           -0.210714
eval/Actions Std                             0.936731
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0982035
eval/env_infos/final/reward_dist Mean        0.0265662
eval/env_infos/final/reward_dist Std         0.0372495
eval/env_infos/final/reward_dist Max         0.0983943
eval/env_infos/final/reward_dist Min         0.000525093
eval/env_infos/initial/reward_dist Mean      0.0070326
eval/env_infos/initial/reward_dist Std       0.0117464
eval/env_infos/initial/reward_dist Max       0.0304704
eval/env_infos/initial/reward_dist Min       0.000487263
eval/env_infos/reward_dist Mean              0.00491017
eval/env_infos/reward_dist Std               0.0145948
eval/env_infos/reward_dist Max               0.0983943
eval/env_infos/reward_dist Min               4.34606e-06
time/data storing (s)                        0.0014715
time/evaluation sampling (s)                 0.716079
time/exploration sampling (s)                4.28332
time/logging (s)                             0.00224153
time/saving (s)                              0.00101309
time/training (s)                            3.98206
time/epoch (s)                               8.98619
time/total (s)                             223.445
Epoch                                       11
---------------------------------------  ---------------
2023-08-03 20:48:49.775990 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 12 finished
---------------------------------------  ---------------
epoch                                       12
replay_buffer/size                       16500
trainer/QF Loss                            583.579
trainer/Policy Loss                       -501.069
trainer/Raw Policy Loss                   -501.069
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 444.726
trainer/Q Predictions Std                   95.7524
trainer/Q Predictions Max                  809.005
trainer/Q Predictions Min                  161.836
trainer/Q Targets Mean                     445.192
trainer/Q Targets Std                       97.4587
trainer/Q Targets Max                      805.548
trainer/Q Targets Min                      140.609
trainer/Bellman Errors Mean                583.579
trainer/Bellman Errors Std                1623.59
trainer/Bellman Errors Max               33835.3
trainer/Bellman Errors Min                   0.000152007
trainer/Policy Action Mean                  -0.135947
trainer/Policy Action Std                    0.968273
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     16500
expl/num paths total                       825
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00720097
expl/Rewards Std                             0.0288926
expl/Rewards Max                             0.2842
expl/Rewards Min                             7.9004e-19
expl/Returns Mean                            0.144019
expl/Returns Std                             0.128722
expl/Returns Max                             0.381629
expl/Returns Min                             0.00943985
expl/Actions Mean                           -0.0578158
expl/Actions Std                             0.832687
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.144019
expl/env_infos/final/reward_dist Mean        4.12273e-07
expl/env_infos/final/reward_dist Std         9.52938e-07
expl/env_infos/final/reward_dist Max         3.29144e-06
expl/env_infos/final/reward_dist Min         7.9004e-19
expl/env_infos/initial/reward_dist Mean      0.0161439
expl/env_infos/initial/reward_dist Std       0.0183341
expl/env_infos/initial/reward_dist Max       0.0551476
expl/env_infos/initial/reward_dist Min       5.33514e-05
expl/env_infos/reward_dist Mean              0.00720097
expl/env_infos/reward_dist Std               0.0288926
expl/env_infos/reward_dist Max               0.2842
expl/env_infos/reward_dist Min               7.9004e-19
eval/num steps total                      1300
eval/num paths total                        65
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00186562
eval/Rewards Std                             0.00564318
eval/Rewards Max                             0.0394749
eval/Rewards Min                             6.23435e-11
eval/Returns Mean                            0.0373124
eval/Returns Std                             0.00610492
eval/Returns Max                             0.0463713
eval/Returns Min                             0.0283154
eval/Actions Mean                           -0.0512161
eval/Actions Std                             0.9649
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0373124
eval/env_infos/final/reward_dist Mean        2.03338e-05
eval/env_infos/final/reward_dist Std         4.06643e-05
eval/env_infos/final/reward_dist Max         0.000101662
eval/env_infos/final/reward_dist Min         7.30414e-11
eval/env_infos/initial/reward_dist Mean      0.00190546
eval/env_infos/initial/reward_dist Std       0.00188306
eval/env_infos/initial/reward_dist Max       0.00560084
eval/env_infos/initial/reward_dist Min       0.000546298
eval/env_infos/reward_dist Mean              0.00186562
eval/env_infos/reward_dist Std               0.00564318
eval/env_infos/reward_dist Max               0.0394749
eval/env_infos/reward_dist Min               6.23435e-11
time/data storing (s)                        0.00146964
time/evaluation sampling (s)                 0.684697
time/exploration sampling (s)                3.89319
time/logging (s)                             0.00222385
time/saving (s)                              0.00103543
time/training (s)                            3.98924
time/epoch (s)                               8.57186
time/total (s)                             232.019
Epoch                                       12
---------------------------------------  ---------------
2023-08-03 20:48:59.017903 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 13 finished
---------------------------------------  ---------------
epoch                                       13
replay_buffer/size                       17000
trainer/QF Loss                           1121.95
trainer/Policy Loss                       -635.336
trainer/Raw Policy Loss                   -635.336
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 590.946
trainer/Q Predictions Std                   88.5555
trainer/Q Predictions Max                  904.359
trainer/Q Predictions Min                  166.048
trainer/Q Targets Mean                     591.137
trainer/Q Targets Std                       93.4305
trainer/Q Targets Max                      929.702
trainer/Q Targets Min                      161.018
trainer/Bellman Errors Mean               1121.95
trainer/Bellman Errors Std                3038.84
trainer/Bellman Errors Max               91412.3
trainer/Bellman Errors Min                   0.000976562
trainer/Policy Action Mean                  -0.243779
trainer/Policy Action Std                    0.932888
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     17000
expl/num paths total                       850
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.013116
expl/Rewards Std                             0.0526433
expl/Rewards Max                             0.718109
expl/Rewards Min                             1.92354e-20
expl/Returns Mean                            0.26232
expl/Returns Std                             0.197544
expl/Returns Max                             0.791691
expl/Returns Min                             0.0779934
expl/Actions Mean                           -0.238575
expl/Actions Std                             0.803375
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.26232
expl/env_infos/final/reward_dist Mean        5.11689e-05
expl/env_infos/final/reward_dist Std         0.000213435
expl/env_infos/final/reward_dist Max         0.00108961
expl/env_infos/final/reward_dist Min         1.92354e-20
expl/env_infos/initial/reward_dist Mean      0.0134418
expl/env_infos/initial/reward_dist Std       0.0174735
expl/env_infos/initial/reward_dist Max       0.0688679
expl/env_infos/initial/reward_dist Min       4.22003e-05
expl/env_infos/reward_dist Mean              0.013116
expl/env_infos/reward_dist Std               0.0526433
expl/env_infos/reward_dist Max               0.718109
expl/env_infos/reward_dist Min               1.92354e-20
eval/num steps total                      1400
eval/num paths total                        70
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0122244
eval/Rewards Std                             0.0405957
eval/Rewards Max                             0.294623
eval/Rewards Min                             1.0375e-11
eval/Returns Mean                            0.244488
eval/Returns Std                             0.13117
eval/Returns Max                             0.495933
eval/Returns Min                             0.140058
eval/Actions Mean                           -0.22232
eval/Actions Std                             0.936244
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.244488
eval/env_infos/final/reward_dist Mean        3.10038e-11
eval/env_infos/final/reward_dist Std         2.20761e-11
eval/env_infos/final/reward_dist Max         6.78831e-11
eval/env_infos/final/reward_dist Min         1.0375e-11
eval/env_infos/initial/reward_dist Mean      0.000230679
eval/env_infos/initial/reward_dist Std       0.000158936
eval/env_infos/initial/reward_dist Max       0.000509539
eval/env_infos/initial/reward_dist Min       2.41461e-05
eval/env_infos/reward_dist Mean              0.0122244
eval/env_infos/reward_dist Std               0.0405957
eval/env_infos/reward_dist Max               0.294623
eval/env_infos/reward_dist Min               1.0375e-11
time/data storing (s)                        0.00151188
time/evaluation sampling (s)                 0.862207
time/exploration sampling (s)                4.37672
time/logging (s)                             0.00221966
time/saving (s)                              0.00102955
time/training (s)                            3.99585
time/epoch (s)                               9.23953
time/total (s)                             241.26
Epoch                                       13
---------------------------------------  ---------------
2023-08-03 20:49:08.909489 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 14 finished
---------------------------------------  ---------------
epoch                                       14
replay_buffer/size                       17500
trainer/QF Loss                            681.838
trainer/Policy Loss                       -693.983
trainer/Raw Policy Loss                   -693.983
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 648.55
trainer/Q Predictions Std                   59.0609
trainer/Q Predictions Max                  842.378
trainer/Q Predictions Min                  190.991
trainer/Q Targets Mean                     647.916
trainer/Q Targets Std                       64.0388
trainer/Q Targets Max                      864.281
trainer/Q Targets Min                      141.953
trainer/Bellman Errors Mean                681.838
trainer/Bellman Errors Std                1301.53
trainer/Bellman Errors Max               20776.8
trainer/Bellman Errors Min                   4.82798e-06
trainer/Policy Action Mean                  -0.233676
trainer/Policy Action Std                    0.869647
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     17500
expl/num paths total                       875
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.011006
expl/Rewards Std                             0.0491677
expl/Rewards Max                             0.705418
expl/Rewards Min                             2.84956e-13
expl/Returns Mean                            0.22012
expl/Returns Std                             0.256963
expl/Returns Max                             0.956217
expl/Returns Min                             0.00888277
expl/Actions Mean                           -0.135657
expl/Actions Std                             0.79061
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.22012
expl/env_infos/final/reward_dist Mean        0.0070149
expl/env_infos/final/reward_dist Std         0.0342872
expl/env_infos/final/reward_dist Max         0.174987
expl/env_infos/final/reward_dist Min         2.84956e-13
expl/env_infos/initial/reward_dist Mean      0.0180376
expl/env_infos/initial/reward_dist Std       0.0170804
expl/env_infos/initial/reward_dist Max       0.0664157
expl/env_infos/initial/reward_dist Min       6.77645e-05
expl/env_infos/reward_dist Mean              0.011006
expl/env_infos/reward_dist Std               0.0491677
expl/env_infos/reward_dist Max               0.705418
expl/env_infos/reward_dist Min               2.84956e-13
eval/num steps total                      1500
eval/num paths total                        75
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00494737
eval/Rewards Std                             0.0162006
eval/Rewards Max                             0.114055
eval/Rewards Min                             4.89801e-10
eval/Returns Mean                            0.0989474
eval/Returns Std                             0.0734129
eval/Returns Max                             0.233662
eval/Returns Min                             0.026344
eval/Actions Mean                           -0.17352
eval/Actions Std                             0.902877
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0989474
eval/env_infos/final/reward_dist Mean        6.14264e-06
eval/env_infos/final/reward_dist Std         1.22272e-05
eval/env_infos/final/reward_dist Max         3.05969e-05
eval/env_infos/final/reward_dist Min         4.89801e-10
eval/env_infos/initial/reward_dist Mean      0.0353868
eval/env_infos/initial/reward_dist Std       0.0400996
eval/env_infos/initial/reward_dist Max       0.114055
eval/env_infos/initial/reward_dist Min       0.00415706
eval/env_infos/reward_dist Mean              0.00494737
eval/env_infos/reward_dist Std               0.0162006
eval/env_infos/reward_dist Max               0.114055
eval/env_infos/reward_dist Min               4.89801e-10
time/data storing (s)                        0.00150091
time/evaluation sampling (s)                 1.06101
time/exploration sampling (s)                4.8275
time/logging (s)                             0.00222174
time/saving (s)                              0.000985746
time/training (s)                            3.99599
time/epoch (s)                               9.88921
time/total (s)                             251.152
Epoch                                       14
---------------------------------------  ---------------
2023-08-03 20:49:18.316853 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 15 finished
---------------------------------------  ---------------
epoch                                       15
replay_buffer/size                       18000
trainer/QF Loss                            259.698
trainer/Policy Loss                       -561.36
trainer/Raw Policy Loss                   -561.36
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 545.772
trainer/Q Predictions Std                   32.3918
trainer/Q Predictions Max                  645.774
trainer/Q Predictions Min                  113.031
trainer/Q Targets Mean                     545.626
trainer/Q Targets Std                       35.584
trainer/Q Targets Max                      770.692
trainer/Q Targets Min                      118.096
trainer/Bellman Errors Mean                259.698
trainer/Bellman Errors Std                 739.891
trainer/Bellman Errors Max               29799.3
trainer/Bellman Errors Min                   2.38419e-07
trainer/Policy Action Mean                  -0.187793
trainer/Policy Action Std                    0.946285
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     18000
expl/num paths total                       900
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.202642
expl/Rewards Std                             1.26443
expl/Rewards Max                            10
expl/Rewards Min                             3.64062e-11
expl/Returns Mean                            4.05285
expl/Returns Std                            15.693
expl/Returns Max                            80.5826
expl/Returns Min                             0.0328076
expl/Actions Mean                           -0.114501
expl/Actions Std                             0.801697
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         4.05285
expl/env_infos/final/reward_dist Mean        0.414261
expl/env_infos/final/reward_dist Std         1.95708
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         3.64062e-11
expl/env_infos/initial/reward_dist Mean      0.00878736
expl/env_infos/initial/reward_dist Std       0.0127123
expl/env_infos/initial/reward_dist Max       0.0395719
expl/env_infos/initial/reward_dist Min       0.000162692
expl/env_infos/reward_dist Mean              0.202642
expl/env_infos/reward_dist Std               1.26443
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               3.64062e-11
eval/num steps total                      1600
eval/num paths total                        80
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.032616
eval/Rewards Std                             0.134179
eval/Rewards Max                             1.15581
eval/Rewards Min                             1.11028e-11
eval/Returns Mean                            0.652319
eval/Returns Std                             0.692111
eval/Returns Max                             1.83443
eval/Returns Min                             0.0695254
eval/Actions Mean                           -0.149062
eval/Actions Std                             0.934339
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.652319
eval/env_infos/final/reward_dist Mean        8.35192e-08
eval/env_infos/final/reward_dist Std         1.46935e-07
eval/env_infos/final/reward_dist Max         3.76447e-07
eval/env_infos/final/reward_dist Min         1.11028e-11
eval/env_infos/initial/reward_dist Mean      0.0167977
eval/env_infos/initial/reward_dist Std       0.0205514
eval/env_infos/initial/reward_dist Max       0.0559947
eval/env_infos/initial/reward_dist Min       0.000495439
eval/env_infos/reward_dist Mean              0.032616
eval/env_infos/reward_dist Std               0.134179
eval/env_infos/reward_dist Max               1.15581
eval/env_infos/reward_dist Min               1.11028e-11
time/data storing (s)                        0.00167989
time/evaluation sampling (s)                 0.7775
time/exploration sampling (s)                4.40398
time/logging (s)                             0.00224947
time/saving (s)                              0.00100599
time/training (s)                            4.21859
time/epoch (s)                               9.40501
time/total (s)                             260.559
Epoch                                       15
---------------------------------------  ---------------
2023-08-03 20:49:27.554603 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 16 finished
---------------------------------------  ---------------
epoch                                       16
replay_buffer/size                       18500
trainer/QF Loss                            208.388
trainer/Policy Loss                       -481.612
trainer/Raw Policy Loss                   -481.612
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 461.5
trainer/Q Predictions Std                   45.9731
trainer/Q Predictions Max                  699.265
trainer/Q Predictions Min                  234.201
trainer/Q Targets Mean                     461.161
trainer/Q Targets Std                       46.8951
trainer/Q Targets Max                      657.851
trainer/Q Targets Min                      242.392
trainer/Bellman Errors Mean                208.388
trainer/Bellman Errors Std                 539.606
trainer/Bellman Errors Max               12553.3
trainer/Bellman Errors Min                   5.52181e-06
trainer/Policy Action Mean                  -0.222226
trainer/Policy Action Std                    0.951867
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     18500
expl/num paths total                       925
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.000683625
expl/Rewards Std                             0.00438424
expl/Rewards Max                             0.0546012
expl/Rewards Min                             1.86369e-12
expl/Returns Mean                            0.0136725
expl/Returns Std                             0.0234765
expl/Returns Max                             0.113809
expl/Returns Min                             0.000524824
expl/Actions Mean                           -0.00801882
expl/Actions Std                             0.838494
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0136725
expl/env_infos/final/reward_dist Mean        6.93995e-07
expl/env_infos/final/reward_dist Std         2.73019e-06
expl/env_infos/final/reward_dist Max         1.37562e-05
expl/env_infos/final/reward_dist Min         1.86369e-12
expl/env_infos/initial/reward_dist Mean      0.00840346
expl/env_infos/initial/reward_dist Std       0.0135108
expl/env_infos/initial/reward_dist Max       0.0546012
expl/env_infos/initial/reward_dist Min       3.20038e-06
expl/env_infos/reward_dist Mean              0.000683625
expl/env_infos/reward_dist Std               0.00438424
expl/env_infos/reward_dist Max               0.0546012
expl/env_infos/reward_dist Min               1.86369e-12
eval/num steps total                      1700
eval/num paths total                        85
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.000433991
eval/Rewards Std                             0.00188467
eval/Rewards Max                             0.0132026
eval/Rewards Min                             8.03222e-10
eval/Returns Mean                            0.00867982
eval/Returns Std                             0.00824844
eval/Returns Max                             0.0193523
eval/Returns Min                             0.000787644
eval/Actions Mean                           -0.0115788
eval/Actions Std                             0.972963
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.00867982
eval/env_infos/final/reward_dist Mean        8.34618e-08
eval/env_infos/final/reward_dist Std         1.51937e-07
eval/env_infos/final/reward_dist Max         3.86729e-07
eval/env_infos/final/reward_dist Min         8.03222e-10
eval/env_infos/initial/reward_dist Mean      0.00350833
eval/env_infos/initial/reward_dist Std       0.00409105
eval/env_infos/initial/reward_dist Max       0.011244
eval/env_infos/initial/reward_dist Min       7.51654e-05
eval/env_infos/reward_dist Mean              0.000433991
eval/env_infos/reward_dist Std               0.00188467
eval/env_infos/reward_dist Max               0.0132026
eval/env_infos/reward_dist Min               8.03222e-10
time/data storing (s)                        0.00155037
time/evaluation sampling (s)                 0.686137
time/exploration sampling (s)                4.11155
time/logging (s)                             0.00229463
time/saving (s)                              0.00104384
time/training (s)                            4.43281
time/epoch (s)                               9.23539
time/total (s)                             269.796
Epoch                                       16
---------------------------------------  ---------------
2023-08-03 20:49:37.199392 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 17 finished
---------------------------------------  ---------------
epoch                                       17
replay_buffer/size                       19000
trainer/QF Loss                            174.807
trainer/Policy Loss                       -421.261
trainer/Raw Policy Loss                   -421.261
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 404.666
trainer/Q Predictions Std                   52.3036
trainer/Q Predictions Max                  627.309
trainer/Q Predictions Min                   15.4251
trainer/Q Targets Mean                     404.562
trainer/Q Targets Std                       53.7344
trainer/Q Targets Max                      664.564
trainer/Q Targets Min                      -18.0444
trainer/Bellman Errors Mean                174.807
trainer/Bellman Errors Std                 382.963
trainer/Bellman Errors Max                6828.14
trainer/Bellman Errors Min                   1.1065e-05
trainer/Policy Action Mean                  -0.199731
trainer/Policy Action Std                    0.933816
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     19000
expl/num paths total                       950
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00528257
expl/Rewards Std                             0.0519448
expl/Rewards Max                             1.05621
expl/Rewards Min                             1.13117e-10
expl/Returns Mean                            0.105651
expl/Returns Std                             0.227668
expl/Returns Max                             1.09219
expl/Returns Min                             0.000474476
expl/Actions Mean                           -0.00732263
expl/Actions Std                             0.808785
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.105651
expl/env_infos/final/reward_dist Mean        0.000279302
expl/env_infos/final/reward_dist Std         0.00119976
expl/env_infos/final/reward_dist Max         0.0061338
expl/env_infos/final/reward_dist Min         1.13117e-10
expl/env_infos/initial/reward_dist Mean      0.010125
expl/env_infos/initial/reward_dist Std       0.0151327
expl/env_infos/initial/reward_dist Max       0.0504015
expl/env_infos/initial/reward_dist Min       8.3495e-06
expl/env_infos/reward_dist Mean              0.00528257
expl/env_infos/reward_dist Std               0.0519448
expl/env_infos/reward_dist Max               1.05621
expl/env_infos/reward_dist Min               1.13117e-10
eval/num steps total                      1800
eval/num paths total                        90
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.000967825
eval/Rewards Std                             0.00387327
eval/Rewards Max                             0.0286809
eval/Rewards Min                             5.91809e-09
eval/Returns Mean                            0.0193565
eval/Returns Std                             0.0152922
eval/Returns Max                             0.0398827
eval/Returns Min                             0.00261252
eval/Actions Mean                           -0.0116334
eval/Actions Std                             0.92491
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0193565
eval/env_infos/final/reward_dist Mean        4.18494e-07
eval/env_infos/final/reward_dist Std         6.88947e-07
eval/env_infos/final/reward_dist Max         1.78129e-06
eval/env_infos/final/reward_dist Min         5.91809e-09
eval/env_infos/initial/reward_dist Mean      0.00598588
eval/env_infos/initial/reward_dist Std       0.00718404
eval/env_infos/initial/reward_dist Max       0.0157478
eval/env_infos/initial/reward_dist Min       7.65296e-05
eval/env_infos/reward_dist Mean              0.000967825
eval/env_infos/reward_dist Std               0.00387327
eval/env_infos/reward_dist Max               0.0286809
eval/env_infos/reward_dist Min               5.91809e-09
time/data storing (s)                        0.00152426
time/evaluation sampling (s)                 0.915504
time/exploration sampling (s)                4.14087
time/logging (s)                             0.00336194
time/saving (s)                              0.00141566
time/training (s)                            4.58065
time/epoch (s)                               9.64333
time/total (s)                             279.441
Epoch                                       17
---------------------------------------  ---------------
2023-08-03 20:49:47.233307 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 18 finished
---------------------------------------  ---------------
epoch                                       18
replay_buffer/size                       19500
trainer/QF Loss                            527.288
trainer/Policy Loss                       -440.704
trainer/Raw Policy Loss                   -440.704
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 411.793
trainer/Q Predictions Std                   46.4259
trainer/Q Predictions Max                  633.861
trainer/Q Predictions Min                  134.678
trainer/Q Targets Mean                     411.856
trainer/Q Targets Std                       51.3051
trainer/Q Targets Max                      663.084
trainer/Q Targets Min                      127.893
trainer/Bellman Errors Mean                527.288
trainer/Bellman Errors Std                1184.24
trainer/Bellman Errors Max               33926.5
trainer/Bellman Errors Min                   0.000223611
trainer/Policy Action Mean                   0.136958
trainer/Policy Action Std                    0.935644
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     19500
expl/num paths total                       975
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00894304
expl/Rewards Std                             0.0342708
expl/Rewards Max                             0.41803
expl/Rewards Min                             2.5385e-07
expl/Returns Mean                            0.178861
expl/Returns Std                             0.135575
expl/Returns Max                             0.527745
expl/Returns Min                             0.0352259
expl/Actions Mean                            0.00339929
expl/Actions Std                             0.82127
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.178861
expl/env_infos/final/reward_dist Mean        0.00828628
expl/env_infos/final/reward_dist Std         0.0218161
expl/env_infos/final/reward_dist Max         0.102861
expl/env_infos/final/reward_dist Min         3.17614e-07
expl/env_infos/initial/reward_dist Mean      0.00591003
expl/env_infos/initial/reward_dist Std       0.00914569
expl/env_infos/initial/reward_dist Max       0.0263059
expl/env_infos/initial/reward_dist Min       2.17971e-05
expl/env_infos/reward_dist Mean              0.00894304
expl/env_infos/reward_dist Std               0.0342708
expl/env_infos/reward_dist Max               0.41803
expl/env_infos/reward_dist Min               2.5385e-07
eval/num steps total                      1900
eval/num paths total                        95
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0105962
eval/Rewards Std                             0.030319
eval/Rewards Max                             0.226034
eval/Rewards Min                             4.32845e-13
eval/Returns Mean                            0.211923
eval/Returns Std                             0.0909193
eval/Returns Max                             0.292312
eval/Returns Min                             0.0407981
eval/Actions Mean                           -0.00249678
eval/Actions Std                             0.954611
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.211923
eval/env_infos/final/reward_dist Mean        0.00929195
eval/env_infos/final/reward_dist Std         0.0140675
eval/env_infos/final/reward_dist Max         0.0370808
eval/env_infos/final/reward_dist Min         4.32845e-13
eval/env_infos/initial/reward_dist Mean      0.0158271
eval/env_infos/initial/reward_dist Std       0.0162825
eval/env_infos/initial/reward_dist Max       0.0375317
eval/env_infos/initial/reward_dist Min       0.00015691
eval/env_infos/reward_dist Mean              0.0105962
eval/env_infos/reward_dist Std               0.030319
eval/env_infos/reward_dist Max               0.226034
eval/env_infos/reward_dist Min               4.32845e-13
time/data storing (s)                        0.0015358
time/evaluation sampling (s)                 0.661898
time/exploration sampling (s)                3.61954
time/logging (s)                             0.0025292
time/saving (s)                              0.0103088
time/training (s)                            5.73379
time/epoch (s)                              10.0296
time/total (s)                             289.474
Epoch                                       18
---------------------------------------  ---------------
2023-08-03 20:49:56.183363 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 19 finished
---------------------------------------  ---------------
epoch                                       19
replay_buffer/size                       20000
trainer/QF Loss                            250.431
trainer/Policy Loss                       -445.497
trainer/Raw Policy Loss                   -445.497
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 425.421
trainer/Q Predictions Std                   30.5944
trainer/Q Predictions Max                  646.037
trainer/Q Predictions Min                   84.8829
trainer/Q Targets Mean                     424.676
trainer/Q Targets Std                       33.0075
trainer/Q Targets Max                      637.647
trainer/Q Targets Min                       88.1
trainer/Bellman Errors Mean                250.431
trainer/Bellman Errors Std                 672.318
trainer/Bellman Errors Max               19598.4
trainer/Bellman Errors Min                   7.71228e-06
trainer/Policy Action Mean                   0.0880601
trainer/Policy Action Std                    0.944363
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     20000
expl/num paths total                      1000
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00666587
expl/Rewards Std                             0.0350348
expl/Rewards Max                             0.653206
expl/Rewards Min                             2.63468e-13
expl/Returns Mean                            0.133317
expl/Returns Std                             0.165152
expl/Returns Max                             0.810428
expl/Returns Min                             0.000961291
expl/Actions Mean                           -0.143097
expl/Actions Std                             0.792236
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.133317
expl/env_infos/final/reward_dist Mean        0.00831001
expl/env_infos/final/reward_dist Std         0.0243921
expl/env_infos/final/reward_dist Max         0.111293
expl/env_infos/final/reward_dist Min         5.18127e-13
expl/env_infos/initial/reward_dist Mean      0.0137022
expl/env_infos/initial/reward_dist Std       0.0221376
expl/env_infos/initial/reward_dist Max       0.0980337
expl/env_infos/initial/reward_dist Min       3.36389e-05
expl/env_infos/reward_dist Mean              0.00666587
expl/env_infos/reward_dist Std               0.0350348
expl/env_infos/reward_dist Max               0.653206
expl/env_infos/reward_dist Min               2.63468e-13
eval/num steps total                      2000
eval/num paths total                       100
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00456681
eval/Rewards Std                             0.0130598
eval/Rewards Max                             0.0906937
eval/Rewards Min                             1.57178e-08
eval/Returns Mean                            0.0913362
eval/Returns Std                             0.0300828
eval/Returns Max                             0.147131
eval/Returns Min                             0.0644568
eval/Actions Mean                           -0.245692
eval/Actions Std                             0.915389
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0913362
eval/env_infos/final/reward_dist Mean        0.0155862
eval/env_infos/final/reward_dist Std         0.021136
eval/env_infos/final/reward_dist Max         0.0573576
eval/env_infos/final/reward_dist Min         1.61177e-05
eval/env_infos/initial/reward_dist Mean      0.016625
eval/env_infos/initial/reward_dist Std       0.0180535
eval/env_infos/initial/reward_dist Max       0.0390652
eval/env_infos/initial/reward_dist Min       0.000492243
eval/env_infos/reward_dist Mean              0.00456681
eval/env_infos/reward_dist Std               0.0130598
eval/env_infos/reward_dist Max               0.0906937
eval/env_infos/reward_dist Min               1.57178e-08
time/data storing (s)                        0.0021368
time/evaluation sampling (s)                 0.638065
time/exploration sampling (s)                4.04251
time/logging (s)                             0.00222809
time/saving (s)                              0.00103351
time/training (s)                            4.25902
time/epoch (s)                               8.94499
time/total (s)                             298.423
Epoch                                       19
---------------------------------------  ---------------
2023-08-03 20:50:05.463471 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 20 finished
---------------------------------------  ---------------
epoch                                       20
replay_buffer/size                       20500
trainer/QF Loss                            113.977
trainer/Policy Loss                       -376.166
trainer/Raw Policy Loss                   -376.166
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 363.85
trainer/Q Predictions Std                   25.2204
trainer/Q Predictions Max                  512.153
trainer/Q Predictions Min                   16.4241
trainer/Q Targets Mean                     363.687
trainer/Q Targets Std                       26.9336
trainer/Q Targets Max                      494.396
trainer/Q Targets Min                       -4.06492
trainer/Bellman Errors Mean                113.977
trainer/Bellman Errors Std                 279.013
trainer/Bellman Errors Max                7299.6
trainer/Bellman Errors Min                   1.34483e-06
trainer/Policy Action Mean                   0.168951
trainer/Policy Action Std                    0.933707
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     20500
expl/num paths total                      1025
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00931505
expl/Rewards Std                             0.0348366
expl/Rewards Max                             0.515531
expl/Rewards Min                             2.29896e-09
expl/Returns Mean                            0.186301
expl/Returns Std                             0.178406
expl/Returns Max                             0.763451
expl/Returns Min                             0.0412737
expl/Actions Mean                            0.0340773
expl/Actions Std                             0.82574
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.186301
expl/env_infos/final/reward_dist Mean        0.0255055
expl/env_infos/final/reward_dist Std         0.0653493
expl/env_infos/final/reward_dist Max         0.255717
expl/env_infos/final/reward_dist Min         2.29896e-09
expl/env_infos/initial/reward_dist Mean      0.0104335
expl/env_infos/initial/reward_dist Std       0.016679
expl/env_infos/initial/reward_dist Max       0.0598
expl/env_infos/initial/reward_dist Min       7.53654e-06
expl/env_infos/reward_dist Mean              0.00931505
expl/env_infos/reward_dist Std               0.0348366
expl/env_infos/reward_dist Max               0.515531
expl/env_infos/reward_dist Min               2.29896e-09
eval/num steps total                      2100
eval/num paths total                       105
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00980795
eval/Rewards Std                             0.0265705
eval/Rewards Max                             0.205224
eval/Rewards Min                             6.20021e-08
eval/Returns Mean                            0.196159
eval/Returns Std                             0.133693
eval/Returns Max                             0.411613
eval/Returns Min                             0.0574527
eval/Actions Mean                            0.00843682
eval/Actions Std                             0.958348
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.196159
eval/env_infos/final/reward_dist Mean        0.00524794
eval/env_infos/final/reward_dist Std         0.00867183
eval/env_infos/final/reward_dist Max         0.0225388
eval/env_infos/final/reward_dist Min         1.78029e-05
eval/env_infos/initial/reward_dist Mean      0.00791011
eval/env_infos/initial/reward_dist Std       0.00889316
eval/env_infos/initial/reward_dist Max       0.0218251
eval/env_infos/initial/reward_dist Min       0.000144665
eval/env_infos/reward_dist Mean              0.00980795
eval/env_infos/reward_dist Std               0.0265705
eval/env_infos/reward_dist Max               0.205224
eval/env_infos/reward_dist Min               6.20021e-08
time/data storing (s)                        0.00214023
time/evaluation sampling (s)                 0.609099
time/exploration sampling (s)                4.11884
time/logging (s)                             0.00297883
time/saving (s)                              0.0011929
time/training (s)                            4.54417
time/epoch (s)                               9.27842
time/total (s)                             307.703
Epoch                                       20
---------------------------------------  ---------------
2023-08-03 20:50:13.964656 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 21 finished
---------------------------------------  ---------------
epoch                                       21
replay_buffer/size                       21000
trainer/QF Loss                            154.095
trainer/Policy Loss                       -328.785
trainer/Raw Policy Loss                   -328.785
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 315.354
trainer/Q Predictions Std                   29.3416
trainer/Q Predictions Max                  461.535
trainer/Q Predictions Min                  150.468
trainer/Q Targets Mean                     315.73
trainer/Q Targets Std                       31.8403
trainer/Q Targets Max                      478.847
trainer/Q Targets Min                      165.233
trainer/Bellman Errors Mean                154.095
trainer/Bellman Errors Std                 357.171
trainer/Bellman Errors Max                6726.31
trainer/Bellman Errors Min                   4.18071e-06
trainer/Policy Action Mean                   0.0361273
trainer/Policy Action Std                    0.952992
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     21000
expl/num paths total                      1050
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00279323
expl/Rewards Std                             0.0137916
expl/Rewards Max                             0.161597
expl/Rewards Min                             5.94523e-10
expl/Returns Mean                            0.0558645
expl/Returns Std                             0.131543
expl/Returns Max                             0.690629
expl/Returns Min                             0.0023041
expl/Actions Mean                           -0.0747748
expl/Actions Std                             0.818604
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0558645
expl/env_infos/final/reward_dist Mean        3.51008e-05
expl/env_infos/final/reward_dist Std         6.63352e-05
expl/env_infos/final/reward_dist Max         0.000273525
expl/env_infos/final/reward_dist Min         9.47563e-10
expl/env_infos/initial/reward_dist Mean      0.0208123
expl/env_infos/initial/reward_dist Std       0.0246765
expl/env_infos/initial/reward_dist Max       0.102099
expl/env_infos/initial/reward_dist Min       7.82995e-05
expl/env_infos/reward_dist Mean              0.00279323
expl/env_infos/reward_dist Std               0.0137916
expl/env_infos/reward_dist Max               0.161597
expl/env_infos/reward_dist Min               5.94523e-10
eval/num steps total                      2200
eval/num paths total                       110
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00117921
eval/Rewards Std                             0.0037546
eval/Rewards Max                             0.0245471
eval/Rewards Min                             1.70359e-07
eval/Returns Mean                            0.0235842
eval/Returns Std                             0.019911
eval/Returns Max                             0.0626885
eval/Returns Min                             0.00846924
eval/Actions Mean                           -0.0576491
eval/Actions Std                             0.942865
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0235842
eval/env_infos/final/reward_dist Mean        7.19835e-05
eval/env_infos/final/reward_dist Std         0.000135366
eval/env_infos/final/reward_dist Max         0.000342622
eval/env_infos/final/reward_dist Min         3.7619e-07
eval/env_infos/initial/reward_dist Mean      0.00862151
eval/env_infos/initial/reward_dist Std       0.00851994
eval/env_infos/initial/reward_dist Max       0.0237702
eval/env_infos/initial/reward_dist Min       0.000101019
eval/env_infos/reward_dist Mean              0.00117921
eval/env_infos/reward_dist Std               0.0037546
eval/env_infos/reward_dist Max               0.0245471
eval/env_infos/reward_dist Min               1.70359e-07
time/data storing (s)                        0.0015716
time/evaluation sampling (s)                 0.639766
time/exploration sampling (s)                3.78659
time/logging (s)                             0.0028574
time/saving (s)                              0.00112952
time/training (s)                            4.06528
time/epoch (s)                               8.4972
time/total (s)                             316.204
Epoch                                       21
---------------------------------------  ---------------
2023-08-03 20:50:24.200126 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 22 finished
---------------------------------------  ---------------
epoch                                       22
replay_buffer/size                       21500
trainer/QF Loss                            151.905
trainer/Policy Loss                       -312.287
trainer/Raw Policy Loss                   -312.287
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 296.666
trainer/Q Predictions Std                   20.1688
trainer/Q Predictions Max                  418.74
trainer/Q Predictions Min                  150.099
trainer/Q Targets Mean                     296.196
trainer/Q Targets Std                       23.2516
trainer/Q Targets Max                      433.134
trainer/Q Targets Min                      148.569
trainer/Bellman Errors Mean                151.905
trainer/Bellman Errors Std                 336.178
trainer/Bellman Errors Max                6154.31
trainer/Bellman Errors Min                   3.72529e-07
trainer/Policy Action Mean                  -0.0038729
trainer/Policy Action Std                    0.959225
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     21500
expl/num paths total                      1075
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0388313
expl/Rewards Std                             0.157494
expl/Rewards Max                             1.46165
expl/Rewards Min                             1.7875e-13
expl/Returns Mean                            0.776626
expl/Returns Std                             2.55123
expl/Returns Max                            13.2413
expl/Returns Min                             0.0665949
expl/Actions Mean                            0.066856
expl/Actions Std                             0.810769
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.776626
expl/env_infos/final/reward_dist Mean        0.017468
expl/env_infos/final/reward_dist Std         0.0605111
expl/env_infos/final/reward_dist Max         0.275773
expl/env_infos/final/reward_dist Min         1.7875e-13
expl/env_infos/initial/reward_dist Mean      0.0217105
expl/env_infos/initial/reward_dist Std       0.0214588
expl/env_infos/initial/reward_dist Max       0.0814838
expl/env_infos/initial/reward_dist Min       0.000110139
expl/env_infos/reward_dist Mean              0.0388313
expl/env_infos/reward_dist Std               0.157494
expl/env_infos/reward_dist Max               1.46165
expl/env_infos/reward_dist Min               1.7875e-13
eval/num steps total                      2300
eval/num paths total                       115
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0139393
eval/Rewards Std                             0.0263061
eval/Rewards Max                             0.177765
eval/Rewards Min                             1.48708e-06
eval/Returns Mean                            0.278786
eval/Returns Std                             0.108073
eval/Returns Max                             0.491996
eval/Returns Min                             0.203934
eval/Actions Mean                            0.138335
eval/Actions Std                             0.935415
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.278786
eval/env_infos/final/reward_dist Mean        1.30039e-05
eval/env_infos/final/reward_dist Std         1.25826e-05
eval/env_infos/final/reward_dist Max         3.68932e-05
eval/env_infos/final/reward_dist Min         1.48708e-06
eval/env_infos/initial/reward_dist Mean      0.0121052
eval/env_infos/initial/reward_dist Std       0.00913506
eval/env_infos/initial/reward_dist Max       0.0267971
eval/env_infos/initial/reward_dist Min       0.000259621
eval/env_infos/reward_dist Mean              0.0139393
eval/env_infos/reward_dist Std               0.0263061
eval/env_infos/reward_dist Max               0.177765
eval/env_infos/reward_dist Min               1.48708e-06
time/data storing (s)                        0.00153016
time/evaluation sampling (s)                 0.814846
time/exploration sampling (s)                5.08033
time/logging (s)                             0.00235199
time/saving (s)                              0.00101069
time/training (s)                            4.33174
time/epoch (s)                              10.2318
time/total (s)                             326.438
Epoch                                       22
---------------------------------------  ---------------
2023-08-03 20:50:33.061513 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 23 finished
---------------------------------------  ---------------
epoch                                       23
replay_buffer/size                       22000
trainer/QF Loss                             44.1811
trainer/Policy Loss                       -253.918
trainer/Raw Policy Loss                   -253.918
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 245.008
trainer/Q Predictions Std                   10.4242
trainer/Q Predictions Max                  314.813
trainer/Q Predictions Min                  138.678
trainer/Q Targets Mean                     244.435
trainer/Q Targets Std                       12.1359
trainer/Q Targets Max                      318.952
trainer/Q Targets Min                      126.576
trainer/Bellman Errors Mean                 44.1811
trainer/Bellman Errors Std                  92.0996
trainer/Bellman Errors Max                2100.36
trainer/Bellman Errors Min                   3.01749e-07
trainer/Policy Action Mean                   0.00471213
trainer/Policy Action Std                    0.959883
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     22000
expl/num paths total                      1100
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00418092
expl/Rewards Std                             0.0146658
expl/Rewards Max                             0.217225
expl/Rewards Min                             3.16788e-13
expl/Returns Mean                            0.0836184
expl/Returns Std                             0.0666291
expl/Returns Max                             0.252178
expl/Returns Min                             0.00708231
expl/Actions Mean                            0.0523534
expl/Actions Std                             0.830269
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0836184
expl/env_infos/final/reward_dist Mean        0.00580158
expl/env_infos/final/reward_dist Std         0.0222744
expl/env_infos/final/reward_dist Max         0.114132
expl/env_infos/final/reward_dist Min         3.16788e-13
expl/env_infos/initial/reward_dist Mean      0.00341181
expl/env_infos/initial/reward_dist Std       0.0044264
expl/env_infos/initial/reward_dist Max       0.0197492
expl/env_infos/initial/reward_dist Min       3.49813e-05
expl/env_infos/reward_dist Mean              0.00418092
expl/env_infos/reward_dist Std               0.0146658
expl/env_infos/reward_dist Max               0.217225
expl/env_infos/reward_dist Min               3.16788e-13
eval/num steps total                      2400
eval/num paths total                       120
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00199793
eval/Rewards Std                             0.00677215
eval/Rewards Max                             0.0543099
eval/Rewards Min                             2.64444e-10
eval/Returns Mean                            0.0399587
eval/Returns Std                             0.0277197
eval/Returns Max                             0.0804484
eval/Returns Min                             0.00732605
eval/Actions Mean                           -0.0396764
eval/Actions Std                             0.972523
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0399587
eval/env_infos/final/reward_dist Mean        0.00130163
eval/env_infos/final/reward_dist Std         0.00260325
eval/env_infos/final/reward_dist Max         0.00650812
eval/env_infos/final/reward_dist Min         6.02607e-10
eval/env_infos/initial/reward_dist Mean      0.00463094
eval/env_infos/initial/reward_dist Std       0.00557632
eval/env_infos/initial/reward_dist Max       0.0137999
eval/env_infos/initial/reward_dist Min       0.000191361
eval/env_infos/reward_dist Mean              0.00199793
eval/env_infos/reward_dist Std               0.00677215
eval/env_infos/reward_dist Max               0.0543099
eval/env_infos/reward_dist Min               2.64444e-10
time/data storing (s)                        0.00153999
time/evaluation sampling (s)                 0.705545
time/exploration sampling (s)                3.98398
time/logging (s)                             0.00228411
time/saving (s)                              0.00101389
time/training (s)                            4.16276
time/epoch (s)                               8.85712
time/total (s)                             335.299
Epoch                                       23
---------------------------------------  ---------------
2023-08-03 20:50:41.727171 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 24 finished
---------------------------------------  ---------------
epoch                                       24
replay_buffer/size                       22500
trainer/QF Loss                             28.4509
trainer/Policy Loss                       -184.492
trainer/Raw Policy Loss                   -184.492
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 181.159
trainer/Q Predictions Std                    9.78521
trainer/Q Predictions Max                  271.019
trainer/Q Predictions Min                  107.284
trainer/Q Targets Mean                     181.415
trainer/Q Targets Std                       11.1426
trainer/Q Targets Max                      290.428
trainer/Q Targets Min                      102.133
trainer/Bellman Errors Mean                 28.4509
trainer/Bellman Errors Std                  97.5128
trainer/Bellman Errors Max                2239.75
trainer/Bellman Errors Min                   8.67271e-06
trainer/Policy Action Mean                  -0.129736
trainer/Policy Action Std                    0.966626
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     22500
expl/num paths total                      1125
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0164514
expl/Rewards Std                             0.104827
expl/Rewards Max                             2.21908
expl/Rewards Min                             9.40637e-12
expl/Returns Mean                            0.329029
expl/Returns Std                             0.579703
expl/Returns Max                             2.42085
expl/Returns Min                             0.0284968
expl/Actions Mean                           -0.0767556
expl/Actions Std                             0.825403
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.329029
expl/env_infos/final/reward_dist Mean        0.110164
expl/env_infos/final/reward_dist Std         0.43414
expl/env_infos/final/reward_dist Max         2.21908
expl/env_infos/final/reward_dist Min         9.40637e-12
expl/env_infos/initial/reward_dist Mean      0.0113387
expl/env_infos/initial/reward_dist Std       0.0172712
expl/env_infos/initial/reward_dist Max       0.0838056
expl/env_infos/initial/reward_dist Min       4.13044e-05
expl/env_infos/reward_dist Mean              0.0164514
expl/env_infos/reward_dist Std               0.104827
expl/env_infos/reward_dist Max               2.21908
expl/env_infos/reward_dist Min               9.40637e-12
eval/num steps total                      2500
eval/num paths total                       125
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.002328
eval/Rewards Std                             0.00610134
eval/Rewards Max                             0.0549099
eval/Rewards Min                             5.94908e-05
eval/Returns Mean                            0.04656
eval/Returns Std                             0.0253105
eval/Returns Max                             0.0856814
eval/Returns Min                             0.0218884
eval/Actions Mean                           -0.0701489
eval/Actions Std                             0.967459
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.04656
eval/env_infos/final/reward_dist Mean        0.000355939
eval/env_infos/final/reward_dist Std         0.000355811
eval/env_infos/final/reward_dist Max         0.00105595
eval/env_infos/final/reward_dist Min         8.25746e-05
eval/env_infos/initial/reward_dist Mean      0.0124327
eval/env_infos/initial/reward_dist Std       0.0213064
eval/env_infos/initial/reward_dist Max       0.0549099
eval/env_infos/initial/reward_dist Min       0.000167915
eval/env_infos/reward_dist Mean              0.002328
eval/env_infos/reward_dist Std               0.00610134
eval/env_infos/reward_dist Max               0.0549099
eval/env_infos/reward_dist Min               5.94908e-05
time/data storing (s)                        0.00150224
time/evaluation sampling (s)                 0.594156
time/exploration sampling (s)                3.93392
time/logging (s)                             0.00225395
time/saving (s)                              0.00101197
time/training (s)                            4.13018
time/epoch (s)                               8.66303
time/total (s)                             343.964
Epoch                                       24
---------------------------------------  ---------------
2023-08-03 20:50:50.430987 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 25 finished
---------------------------------------  ---------------
epoch                                       25
replay_buffer/size                       23000
trainer/QF Loss                             30.8168
trainer/Policy Loss                       -143.034
trainer/Raw Policy Loss                   -143.034
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 137.872
trainer/Q Predictions Std                   15.304
trainer/Q Predictions Max                  391.408
trainer/Q Predictions Min                   97.2636
trainer/Q Targets Mean                     138.454
trainer/Q Targets Std                       16.0383
trainer/Q Targets Max                      386.087
trainer/Q Targets Min                      100.488
trainer/Bellman Errors Mean                 30.8168
trainer/Bellman Errors Std                 123.428
trainer/Bellman Errors Max                3526.98
trainer/Bellman Errors Min                   6.29574e-07
trainer/Policy Action Mean                  -0.035856
trainer/Policy Action Std                    0.977165
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     23000
expl/num paths total                      1150
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00306358
expl/Rewards Std                             0.00895667
expl/Rewards Max                             0.105347
expl/Rewards Min                             5.25536e-10
expl/Returns Mean                            0.0612717
expl/Returns Std                             0.0540917
expl/Returns Max                             0.205699
expl/Returns Min                             0.00849084
expl/Actions Mean                            0.0396406
expl/Actions Std                             0.839295
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0612717
expl/env_infos/final/reward_dist Mean        0.00204749
expl/env_infos/final/reward_dist Std         0.00468345
expl/env_infos/final/reward_dist Max         0.0223963
expl/env_infos/final/reward_dist Min         5.25536e-10
expl/env_infos/initial/reward_dist Mean      0.013338
expl/env_infos/initial/reward_dist Std       0.0161016
expl/env_infos/initial/reward_dist Max       0.0575737
expl/env_infos/initial/reward_dist Min       2.05114e-05
expl/env_infos/reward_dist Mean              0.00306358
expl/env_infos/reward_dist Std               0.00895667
expl/env_infos/reward_dist Max               0.105347
expl/env_infos/reward_dist Min               5.25536e-10
eval/num steps total                      2600
eval/num paths total                       130
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00116131
eval/Rewards Std                             0.00367759
eval/Rewards Max                             0.0237486
eval/Rewards Min                             5.21501e-06
eval/Returns Mean                            0.0232261
eval/Returns Std                             0.0228245
eval/Returns Max                             0.0661582
eval/Returns Min                             0.00155188
eval/Actions Mean                            0.0242582
eval/Actions Std                             0.979242
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0232261
eval/env_infos/final/reward_dist Mean        9.97117e-05
eval/env_infos/final/reward_dist Std         3.69092e-05
eval/env_infos/final/reward_dist Max         0.00014295
eval/env_infos/final/reward_dist Min         4.16595e-05
eval/env_infos/initial/reward_dist Mean      0.00749645
eval/env_infos/initial/reward_dist Std       0.00876803
eval/env_infos/initial/reward_dist Max       0.0237486
eval/env_infos/initial/reward_dist Min       6.24392e-06
eval/env_infos/reward_dist Mean              0.00116131
eval/env_infos/reward_dist Std               0.00367759
eval/env_infos/reward_dist Max               0.0237486
eval/env_infos/reward_dist Min               5.21501e-06
time/data storing (s)                        0.00152011
time/evaluation sampling (s)                 0.579191
time/exploration sampling (s)                4.09926
time/logging (s)                             0.00231539
time/saving (s)                              0.00108012
time/training (s)                            4.01792
time/epoch (s)                               8.70129
time/total (s)                             352.668
Epoch                                       25
---------------------------------------  ---------------
2023-08-03 20:50:59.484803 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 26 finished
---------------------------------------  ---------------
epoch                                       26
replay_buffer/size                       23500
trainer/QF Loss                            133.313
trainer/Policy Loss                       -128.023
trainer/Raw Policy Loss                   -128.023
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 121.055
trainer/Q Predictions Std                   39.0416
trainer/Q Predictions Max                  612.381
trainer/Q Predictions Min                   81.019
trainer/Q Targets Mean                     119.776
trainer/Q Targets Std                       40.4313
trainer/Q Targets Max                      582.551
trainer/Q Targets Min                       76.0703
trainer/Bellman Errors Mean                133.313
trainer/Bellman Errors Std                 305.521
trainer/Bellman Errors Max                4125.59
trainer/Bellman Errors Min                   5.96046e-08
trainer/Policy Action Mean                  -0.205259
trainer/Policy Action Std                    0.959842
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     23500
expl/num paths total                      1175
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0146698
expl/Rewards Std                             0.0462828
expl/Rewards Max                             0.719026
expl/Rewards Min                             9.99598e-15
expl/Returns Mean                            0.293396
expl/Returns Std                             0.607059
expl/Returns Max                             2.72318
expl/Returns Min                             0.00787793
expl/Actions Mean                           -0.159653
expl/Actions Std                             0.811903
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.293396
expl/env_infos/final/reward_dist Mean        0.0069199
expl/env_infos/final/reward_dist Std         0.0273062
expl/env_infos/final/reward_dist Max         0.138716
expl/env_infos/final/reward_dist Min         9.99598e-15
expl/env_infos/initial/reward_dist Mean      0.0130627
expl/env_infos/initial/reward_dist Std       0.0155889
expl/env_infos/initial/reward_dist Max       0.0560446
expl/env_infos/initial/reward_dist Min       2.81874e-05
expl/env_infos/reward_dist Mean              0.0146698
expl/env_infos/reward_dist Std               0.0462828
expl/env_infos/reward_dist Max               0.719026
expl/env_infos/reward_dist Min               9.99598e-15
eval/num steps total                      2700
eval/num paths total                       135
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0146835
eval/Rewards Std                             0.0270598
eval/Rewards Max                             0.0751588
eval/Rewards Min                             8.01731e-12
eval/Returns Mean                            0.29367
eval/Returns Std                             0.51506
eval/Returns Max                             1.32327
eval/Returns Min                             0.0165655
eval/Actions Mean                           -0.224311
eval/Actions Std                             0.949384
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.29367
eval/env_infos/final/reward_dist Mean        0.0145
eval/env_infos/final/reward_dist Std         0.029
eval/env_infos/final/reward_dist Max         0.0725
eval/env_infos/final/reward_dist Min         8.01731e-12
eval/env_infos/initial/reward_dist Mean      0.00682667
eval/env_infos/initial/reward_dist Std       0.00579364
eval/env_infos/initial/reward_dist Max       0.0165097
eval/env_infos/initial/reward_dist Min       5.27041e-05
eval/env_infos/reward_dist Mean              0.0146835
eval/env_infos/reward_dist Std               0.0270598
eval/env_infos/reward_dist Max               0.0751588
eval/env_infos/reward_dist Min               8.01731e-12
time/data storing (s)                        0.00151107
time/evaluation sampling (s)                 0.610788
time/exploration sampling (s)                4.15801
time/logging (s)                             0.00233428
time/saving (s)                              0.00118933
time/training (s)                            4.27705
time/epoch (s)                               9.05089
time/total (s)                             361.721
Epoch                                       26
---------------------------------------  ---------------
2023-08-03 20:51:08.482818 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 27 finished
---------------------------------------  ---------------
epoch                                       27
replay_buffer/size                       24000
trainer/QF Loss                            628.83
trainer/Policy Loss                       -283.512
trainer/Raw Policy Loss                   -283.512
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 248.026
trainer/Q Predictions Std                   95.6186
trainer/Q Predictions Max                 1065.93
trainer/Q Predictions Min                  136.717
trainer/Q Targets Mean                     246.821
trainer/Q Targets Std                       99.4511
trainer/Q Targets Max                     1156.35
trainer/Q Targets Min                      130.895
trainer/Bellman Errors Mean                628.83
trainer/Bellman Errors Std                2015.98
trainer/Bellman Errors Max               51186.6
trainer/Bellman Errors Min                   7.37701e-06
trainer/Policy Action Mean                  -0.309836
trainer/Policy Action Std                    0.925467
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     24000
expl/num paths total                      1200
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00465686
expl/Rewards Std                             0.0302994
expl/Rewards Max                             0.507972
expl/Rewards Min                             9.04999e-16
expl/Returns Mean                            0.0931372
expl/Returns Std                             0.17308
expl/Returns Max                             0.729588
expl/Returns Min                             0.00334393
expl/Actions Mean                           -0.3133
expl/Actions Std                             0.767962
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0931372
expl/env_infos/final/reward_dist Mean        0.000650058
expl/env_infos/final/reward_dist Std         0.00189227
expl/env_infos/final/reward_dist Max         0.00754158
expl/env_infos/final/reward_dist Min         9.04999e-16
expl/env_infos/initial/reward_dist Mean      0.0102882
expl/env_infos/initial/reward_dist Std       0.0134248
expl/env_infos/initial/reward_dist Max       0.0520597
expl/env_infos/initial/reward_dist Min       1.41234e-05
expl/env_infos/reward_dist Mean              0.00465686
expl/env_infos/reward_dist Std               0.0302994
expl/env_infos/reward_dist Max               0.507972
expl/env_infos/reward_dist Min               9.04999e-16
eval/num steps total                      2800
eval/num paths total                       140
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00136513
eval/Rewards Std                             0.00362095
eval/Rewards Max                             0.0196759
eval/Rewards Min                             8.65157e-17
eval/Returns Mean                            0.0273026
eval/Returns Std                             0.0131671
eval/Returns Max                             0.038995
eval/Returns Min                             0.00446959
eval/Actions Mean                           -0.458936
eval/Actions Std                             0.861714
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0273026
eval/env_infos/final/reward_dist Mean        3.96182e-10
eval/env_infos/final/reward_dist Std         7.91079e-10
eval/env_infos/final/reward_dist Max         1.97834e-09
eval/env_infos/final/reward_dist Min         8.65157e-17
eval/env_infos/initial/reward_dist Mean      0.00524679
eval/env_infos/initial/reward_dist Std       0.00630073
eval/env_infos/initial/reward_dist Max       0.0169154
eval/env_infos/initial/reward_dist Min       0.000144903
eval/env_infos/reward_dist Mean              0.00136513
eval/env_infos/reward_dist Std               0.00362095
eval/env_infos/reward_dist Max               0.0196759
eval/env_infos/reward_dist Min               8.65157e-17
time/data storing (s)                        0.00149435
time/evaluation sampling (s)                 0.764132
time/exploration sampling (s)                4.12836
time/logging (s)                             0.00230677
time/saving (s)                              0.00111055
time/training (s)                            4.0979
time/epoch (s)                               8.99531
time/total (s)                             370.718
Epoch                                       27
---------------------------------------  ---------------
2023-08-03 20:51:18.591858 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 28 finished
---------------------------------------  ----------------
epoch                                        28
replay_buffer/size                        24500
trainer/QF Loss                            2596.97
trainer/Policy Loss                        -544.818
trainer/Raw Policy Loss                    -544.818
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  505.532
trainer/Q Predictions Std                   170.352
trainer/Q Predictions Max                  1536.78
trainer/Q Predictions Min                   244.813
trainer/Q Targets Mean                      503.666
trainer/Q Targets Std                       178.124
trainer/Q Targets Max                      1592.36
trainer/Q Targets Min                       262.422
trainer/Bellman Errors Mean                2596.97
trainer/Bellman Errors Std                 8355.02
trainer/Bellman Errors Max               294542
trainer/Bellman Errors Min                    8.3819e-07
trainer/Policy Action Mean                    0.0169891
trainer/Policy Action Std                     0.983389
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      24500
expl/num paths total                       1225
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0018497
expl/Rewards Std                              0.00687217
expl/Rewards Max                              0.0760301
expl/Rewards Min                              1.25962e-13
expl/Returns Mean                             0.036994
expl/Returns Std                              0.028328
expl/Returns Max                              0.109174
expl/Returns Min                              0.00483839
expl/Actions Mean                            -0.0348571
expl/Actions Std                              0.837717
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.036994
expl/env_infos/final/reward_dist Mean         6.81857e-05
expl/env_infos/final/reward_dist Std          0.000214915
expl/env_infos/final/reward_dist Max          0.00105098
expl/env_infos/final/reward_dist Min          1.25962e-13
expl/env_infos/initial/reward_dist Mean       0.0110769
expl/env_infos/initial/reward_dist Std        0.0183536
expl/env_infos/initial/reward_dist Max        0.066196
expl/env_infos/initial/reward_dist Min        8.99988e-06
expl/env_infos/reward_dist Mean               0.0018497
expl/env_infos/reward_dist Std                0.00687217
expl/env_infos/reward_dist Max                0.0760301
expl/env_infos/reward_dist Min                1.25962e-13
eval/num steps total                       2900
eval/num paths total                        145
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.00166362
eval/Rewards Std                              0.00544267
eval/Rewards Max                              0.0431414
eval/Rewards Min                              3.38228e-11
eval/Returns Mean                             0.0332724
eval/Returns Std                              0.0204983
eval/Returns Max                              0.0723086
eval/Returns Min                              0.0131325
eval/Actions Mean                            -0.0543
eval/Actions Std                              0.980991
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.0332724
eval/env_infos/final/reward_dist Mean         1.50766e-10
eval/env_infos/final/reward_dist Std          1.1343e-10
eval/env_infos/final/reward_dist Max          3.16291e-10
eval/env_infos/final/reward_dist Min          3.38228e-11
eval/env_infos/initial/reward_dist Mean       0.0102812
eval/env_infos/initial/reward_dist Std        0.00842962
eval/env_infos/initial/reward_dist Max        0.020572
eval/env_infos/initial/reward_dist Min        0.000115301
eval/env_infos/reward_dist Mean               0.00166362
eval/env_infos/reward_dist Std                0.00544267
eval/env_infos/reward_dist Max                0.0431414
eval/env_infos/reward_dist Min                3.38228e-11
time/data storing (s)                         0.00153846
time/evaluation sampling (s)                  1.18606
time/exploration sampling (s)                 4.67539
time/logging (s)                              0.00229116
time/saving (s)                               0.00113012
time/training (s)                             4.23957
time/epoch (s)                               10.106
time/total (s)                              380.827
Epoch                                        28
---------------------------------------  ----------------
2023-08-03 20:51:28.400545 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 29 finished
---------------------------------------  ----------------
epoch                                        29
replay_buffer/size                        25000
trainer/QF Loss                            1347.81
trainer/Policy Loss                        -594.105
trainer/Raw Policy Loss                    -594.105
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  570.015
trainer/Q Predictions Std                   119.939
trainer/Q Predictions Max                  1928.47
trainer/Q Predictions Min                   405.125
trainer/Q Targets Mean                      570.985
trainer/Q Targets Std                       124.856
trainer/Q Targets Max                      1959.65
trainer/Q Targets Min                       388.036
trainer/Bellman Errors Mean                1347.81
trainer/Bellman Errors Std                 4054.29
trainer/Bellman Errors Max               142264
trainer/Bellman Errors Min                    1.64285e-06
trainer/Policy Action Mean                    0.131525
trainer/Policy Action Std                     0.962688
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      25000
expl/num paths total                       1250
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.00188375
expl/Rewards Std                              0.00682719
expl/Rewards Max                              0.07574
expl/Rewards Min                              3.34495e-11
expl/Returns Mean                             0.037675
expl/Returns Std                              0.030758
expl/Returns Max                              0.112711
expl/Returns Min                              0.00584972
expl/Actions Mean                             0.115098
expl/Actions Std                              0.828511
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.037675
expl/env_infos/final/reward_dist Mean         0.000355455
expl/env_infos/final/reward_dist Std          0.00171289
expl/env_infos/final/reward_dist Max          0.0087463
expl/env_infos/final/reward_dist Min          3.34495e-11
expl/env_infos/initial/reward_dist Mean       0.00527767
expl/env_infos/initial/reward_dist Std        0.0104353
expl/env_infos/initial/reward_dist Max        0.0530115
expl/env_infos/initial/reward_dist Min        6.56816e-06
expl/env_infos/reward_dist Mean               0.00188375
expl/env_infos/reward_dist Std                0.00682719
expl/env_infos/reward_dist Max                0.07574
expl/env_infos/reward_dist Min                3.34495e-11
eval/num steps total                       3000
eval/num paths total                        150
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.000975734
eval/Rewards Std                              0.00337531
eval/Rewards Max                              0.0226991
eval/Rewards Min                              3.75704e-11
eval/Returns Mean                             0.0195147
eval/Returns Std                              0.0111268
eval/Returns Max                              0.0353321
eval/Returns Min                              0.0041464
eval/Actions Mean                             0.0835944
eval/Actions Std                              0.972429
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.0195147
eval/env_infos/final/reward_dist Mean         1.02909e-10
eval/env_infos/final/reward_dist Std          6.5096e-11
eval/env_infos/final/reward_dist Max          2.30587e-10
eval/env_infos/final/reward_dist Min          5.53427e-11
eval/env_infos/initial/reward_dist Mean       0.0111235
eval/env_infos/initial/reward_dist Std        0.00883819
eval/env_infos/initial/reward_dist Max        0.0226991
eval/env_infos/initial/reward_dist Min        0.000649049
eval/env_infos/reward_dist Mean               0.000975734
eval/env_infos/reward_dist Std                0.00337531
eval/env_infos/reward_dist Max                0.0226991
eval/env_infos/reward_dist Min                3.75704e-11
time/data storing (s)                         0.00153982
time/evaluation sampling (s)                  1.19345
time/exploration sampling (s)                 4.43633
time/logging (s)                              0.00229052
time/saving (s)                               0.00105104
time/training (s)                             4.17142
time/epoch (s)                                9.80607
time/total (s)                              390.635
Epoch                                        29
---------------------------------------  ----------------
2023-08-03 20:51:37.605237 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 30 finished
---------------------------------------  ----------------
epoch                                        30
replay_buffer/size                        25500
trainer/QF Loss                            1322.7
trainer/Policy Loss                        -653.846
trainer/Raw Policy Loss                    -653.846
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  620.476
trainer/Q Predictions Std                   124.666
trainer/Q Predictions Max                  1778.74
trainer/Q Predictions Min                   467.283
trainer/Q Targets Mean                      620.019
trainer/Q Targets Std                       129.699
trainer/Q Targets Max                      1808.58
trainer/Q Targets Min                       423.44
trainer/Bellman Errors Mean                1322.7
trainer/Bellman Errors Std                 5412.26
trainer/Bellman Errors Max               121612
trainer/Bellman Errors Min                    0.000115395
trainer/Policy Action Mean                   -0.010263
trainer/Policy Action Std                     0.9513
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      25500
expl/num paths total                       1275
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.00203573
expl/Rewards Std                              0.00631393
expl/Rewards Max                              0.0596765
expl/Rewards Min                              3.56099e-15
expl/Returns Mean                             0.0407147
expl/Returns Std                              0.024338
expl/Returns Max                              0.0879357
expl/Returns Min                              0.00829013
expl/Actions Mean                            -0.0253673
expl/Actions Std                              0.833063
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.0407147
expl/env_infos/final/reward_dist Mean         1.69252e-05
expl/env_infos/final/reward_dist Std          8.26794e-05
expl/env_infos/final/reward_dist Max          0.000421968
expl/env_infos/final/reward_dist Min          3.56099e-15
expl/env_infos/initial/reward_dist Mean       0.0115587
expl/env_infos/initial/reward_dist Std        0.0143251
expl/env_infos/initial/reward_dist Max        0.0596765
expl/env_infos/initial/reward_dist Min        0.00028029
expl/env_infos/reward_dist Mean               0.00203573
expl/env_infos/reward_dist Std                0.00631393
expl/env_infos/reward_dist Max                0.0596765
expl/env_infos/reward_dist Min                3.56099e-15
eval/num steps total                       3100
eval/num paths total                        155
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.00140542
eval/Rewards Std                              0.00414142
eval/Rewards Max                              0.0256972
eval/Rewards Min                              1.901e-11
eval/Returns Mean                             0.0281083
eval/Returns Std                              0.010272
eval/Returns Max                              0.0401487
eval/Returns Min                              0.0111639
eval/Actions Mean                            -0.00906568
eval/Actions Std                              0.960452
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.0281083
eval/env_infos/final/reward_dist Mean         5.87497e-05
eval/env_infos/final/reward_dist Std          0.000117499
eval/env_infos/final/reward_dist Max          0.000293748
eval/env_infos/final/reward_dist Min          1.901e-11
eval/env_infos/initial/reward_dist Mean       0.0127062
eval/env_infos/initial/reward_dist Std        0.0103595
eval/env_infos/initial/reward_dist Max        0.0256972
eval/env_infos/initial/reward_dist Min        0.00023606
eval/env_infos/reward_dist Mean               0.00140542
eval/env_infos/reward_dist Std                0.00414142
eval/env_infos/reward_dist Max                0.0256972
eval/env_infos/reward_dist Min                1.901e-11
time/data storing (s)                         0.0014912
time/evaluation sampling (s)                  0.69445
time/exploration sampling (s)                 4.18009
time/logging (s)                              0.00229125
time/saving (s)                               0.00103259
time/training (s)                             4.32272
time/epoch (s)                                9.20208
time/total (s)                              399.839
Epoch                                        30
---------------------------------------  ----------------
2023-08-03 20:51:47.665987 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 31 finished
---------------------------------------  ----------------
epoch                                        31
replay_buffer/size                        26000
trainer/QF Loss                            2810.56
trainer/Policy Loss                        -785.029
trainer/Raw Policy Loss                    -785.029
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  730.207
trainer/Q Predictions Std                   136.127
trainer/Q Predictions Max                  2137.37
trainer/Q Predictions Min                   517.615
trainer/Q Targets Mean                      730.424
trainer/Q Targets Std                       144.999
trainer/Q Targets Max                      2070.93
trainer/Q Targets Min                       487.117
trainer/Bellman Errors Mean                2810.56
trainer/Bellman Errors Std                11043
trainer/Bellman Errors Max               259160
trainer/Bellman Errors Min                    2.20872e-05
trainer/Policy Action Mean                   -0.172784
trainer/Policy Action Std                     0.937446
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      26000
expl/num paths total                       1300
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.269589
expl/Rewards Std                              1.59065
expl/Rewards Max                             10
expl/Rewards Min                              1.35766e-10
expl/Returns Mean                             5.39177
expl/Returns Std                             25.6504
expl/Returns Max                            131.05
expl/Returns Min                              0.0151859
expl/Actions Mean                            -0.125302
expl/Actions Std                              0.822852
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          5.39177
expl/env_infos/final/reward_dist Mean         0.400689
expl/env_infos/final/reward_dist Std          1.95945
expl/env_infos/final/reward_dist Max         10
expl/env_infos/final/reward_dist Min          1.51527e-10
expl/env_infos/initial/reward_dist Mean       0.0141238
expl/env_infos/initial/reward_dist Std        0.0189653
expl/env_infos/initial/reward_dist Max        0.0625613
expl/env_infos/initial/reward_dist Min        1.38882e-05
expl/env_infos/reward_dist Mean               0.269589
expl/env_infos/reward_dist Std                1.59065
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                1.35766e-10
eval/num steps total                       3200
eval/num paths total                        160
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0129478
eval/Rewards Std                              0.0404551
eval/Rewards Max                              0.251507
eval/Rewards Min                              7.85827e-10
eval/Returns Mean                             0.258955
eval/Returns Std                              0.198622
eval/Returns Max                              0.534036
eval/Returns Min                              0.0164491
eval/Actions Mean                            -0.182618
eval/Actions Std                              0.946151
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.258955
eval/env_infos/final/reward_dist Mean         2.38984e-07
eval/env_infos/final/reward_dist Std          3.12496e-07
eval/env_infos/final/reward_dist Max          7.74933e-07
eval/env_infos/final/reward_dist Min          7.85827e-10
eval/env_infos/initial/reward_dist Mean       0.0225156
eval/env_infos/initial/reward_dist Std        0.0312591
eval/env_infos/initial/reward_dist Max        0.082941
eval/env_infos/initial/reward_dist Min        4.15568e-05
eval/env_infos/reward_dist Mean               0.0129478
eval/env_infos/reward_dist Std                0.0404551
eval/env_infos/reward_dist Max                0.251507
eval/env_infos/reward_dist Min                7.85827e-10
time/data storing (s)                         0.00215901
time/evaluation sampling (s)                  0.887556
time/exploration sampling (s)                 4.84729
time/logging (s)                              0.00226795
time/saving (s)                               0.000995454
time/training (s)                             4.31781
time/epoch (s)                               10.0581
time/total (s)                              409.9
Epoch                                        31
---------------------------------------  ----------------
2023-08-03 20:51:58.157349 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 32 finished
---------------------------------------  ----------------
epoch                                        32
replay_buffer/size                        26500
trainer/QF Loss                            2531.09
trainer/Policy Loss                        -963.854
trainer/Raw Policy Loss                    -963.854
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  907.924
trainer/Q Predictions Std                    99.6048
trainer/Q Predictions Max                  2146.03
trainer/Q Predictions Min                   694.686
trainer/Q Targets Mean                      910.907
trainer/Q Targets Std                       112.997
trainer/Q Targets Max                      2229.47
trainer/Q Targets Min                       699.02
trainer/Bellman Errors Mean                2531.09
trainer/Bellman Errors Std                 9173.66
trainer/Bellman Errors Max               290663
trainer/Bellman Errors Min                    8.60691e-05
trainer/Policy Action Mean                   -0.0755488
trainer/Policy Action Std                     0.953562
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      26500
expl/num paths total                       1325
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0211265
expl/Rewards Std                              0.121328
expl/Rewards Max                              2.27826
expl/Rewards Min                              1.16986e-11
expl/Returns Mean                             0.42253
expl/Returns Std                              0.625404
expl/Returns Max                              2.76747
expl/Returns Min                              0.024257
expl/Actions Mean                            -0.0927691
expl/Actions Std                              0.804242
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.42253
expl/env_infos/final/reward_dist Mean         0.000589996
expl/env_infos/final/reward_dist Std          0.00156343
expl/env_infos/final/reward_dist Max          0.00635094
expl/env_infos/final/reward_dist Min          1.16986e-11
expl/env_infos/initial/reward_dist Mean       0.0105731
expl/env_infos/initial/reward_dist Std        0.0125802
expl/env_infos/initial/reward_dist Max        0.0367615
expl/env_infos/initial/reward_dist Min        3.16911e-05
expl/env_infos/reward_dist Mean               0.0211265
expl/env_infos/reward_dist Std                0.121328
expl/env_infos/reward_dist Max                2.27826
expl/env_infos/reward_dist Min                1.16986e-11
eval/num steps total                       3300
eval/num paths total                        165
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0344305
eval/Rewards Std                              0.186427
eval/Rewards Max                              1.63551
eval/Rewards Min                              2.03874e-10
eval/Returns Mean                             0.688611
eval/Returns Std                              0.786273
eval/Returns Max                              2.11635
eval/Returns Min                              0.042771
eval/Actions Mean                            -0.169311
eval/Actions Std                              0.924311
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.688611
eval/env_infos/final/reward_dist Mean         5.31909e-10
eval/env_infos/final/reward_dist Std          2.96696e-10
eval/env_infos/final/reward_dist Max          9.43083e-10
eval/env_infos/final/reward_dist Min          2.03874e-10
eval/env_infos/initial/reward_dist Mean       0.0117185
eval/env_infos/initial/reward_dist Std        0.0220102
eval/env_infos/initial/reward_dist Max        0.0556923
eval/env_infos/initial/reward_dist Min        1.99453e-05
eval/env_infos/reward_dist Mean               0.0344305
eval/env_infos/reward_dist Std                0.186427
eval/env_infos/reward_dist Max                1.63551
eval/env_infos/reward_dist Min                2.03874e-10
time/data storing (s)                         0.00183371
time/evaluation sampling (s)                  0.972252
time/exploration sampling (s)                 5.25094
time/logging (s)                              0.00283253
time/saving (s)                               0.00110897
time/training (s)                             4.26037
time/epoch (s)                               10.4893
time/total (s)                              420.391
Epoch                                        32
---------------------------------------  ----------------
2023-08-03 20:52:08.284083 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 33 finished
---------------------------------------  ----------------
epoch                                        33
replay_buffer/size                        27000
trainer/QF Loss                            2167.06
trainer/Policy Loss                       -1008.24
trainer/Raw Policy Loss                   -1008.24
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  954.077
trainer/Q Predictions Std                   113.426
trainer/Q Predictions Max                  2465.32
trainer/Q Predictions Min                   702.267
trainer/Q Targets Mean                      951.352
trainer/Q Targets Std                       121.895
trainer/Q Targets Max                      2553.61
trainer/Q Targets Min                       689.264
trainer/Bellman Errors Mean                2167.06
trainer/Bellman Errors Std                 9618.59
trainer/Bellman Errors Max               267725
trainer/Bellman Errors Min                    5.09992e-06
trainer/Policy Action Mean                   -0.218755
trainer/Policy Action Std                     0.929956
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      27000
expl/num paths total                       1350
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.037898
expl/Rewards Std                              0.150632
expl/Rewards Max                              1.68506
expl/Rewards Min                              3.56381e-11
expl/Returns Mean                             0.75796
expl/Returns Std                              0.897684
expl/Returns Max                              3.63455
expl/Returns Min                              0.0593039
expl/Actions Mean                            -0.1729
expl/Actions Std                              0.794851
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.75796
expl/env_infos/final/reward_dist Mean         0.00517358
expl/env_infos/final/reward_dist Std          0.0132791
expl/env_infos/final/reward_dist Max          0.0615426
expl/env_infos/final/reward_dist Min          3.56381e-11
expl/env_infos/initial/reward_dist Mean       0.0140355
expl/env_infos/initial/reward_dist Std        0.0182529
expl/env_infos/initial/reward_dist Max        0.07268
expl/env_infos/initial/reward_dist Min        0.000102708
expl/env_infos/reward_dist Mean               0.037898
expl/env_infos/reward_dist Std                0.150632
expl/env_infos/reward_dist Max                1.68506
expl/env_infos/reward_dist Min                3.56381e-11
eval/num steps total                       3400
eval/num paths total                        170
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0630742
eval/Rewards Std                              0.240264
eval/Rewards Max                              1.8246
eval/Rewards Min                              4.17654e-11
eval/Returns Mean                             1.26148
eval/Returns Std                              0.564213
eval/Returns Max                              1.96734
eval/Returns Min                              0.276153
eval/Actions Mean                            -0.17877
eval/Actions Std                              0.922112
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          1.26148
eval/env_infos/final/reward_dist Mean         0.00013058
eval/env_infos/final/reward_dist Std          0.000246013
eval/env_infos/final/reward_dist Max          0.000622319
eval/env_infos/final/reward_dist Min          2.23123e-08
eval/env_infos/initial/reward_dist Mean       0.0118471
eval/env_infos/initial/reward_dist Std        0.0192791
eval/env_infos/initial/reward_dist Max        0.0498984
eval/env_infos/initial/reward_dist Min        0.000262991
eval/env_infos/reward_dist Mean               0.0630742
eval/env_infos/reward_dist Std                0.240264
eval/env_infos/reward_dist Max                1.8246
eval/env_infos/reward_dist Min                4.17654e-11
time/data storing (s)                         0.00183075
time/evaluation sampling (s)                  0.994406
time/exploration sampling (s)                 5.18717
time/logging (s)                              0.00225099
time/saving (s)                               0.00100054
time/training (s)                             3.93618
time/epoch (s)                               10.1228
time/total (s)                              430.516
Epoch                                        33
---------------------------------------  ----------------
2023-08-03 20:52:18.503705 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 34 finished
---------------------------------------  ----------------
epoch                                        34
replay_buffer/size                        27500
trainer/QF Loss                            1220.04
trainer/Policy Loss                        -891.591
trainer/Raw Policy Loss                    -891.591
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  861.733
trainer/Q Predictions Std                    95.2737
trainer/Q Predictions Max                  3093.15
trainer/Q Predictions Min                   593.408
trainer/Q Targets Mean                      860.367
trainer/Q Targets Std                       103.586
trainer/Q Targets Max                      3061.08
trainer/Q Targets Min                       647.659
trainer/Bellman Errors Mean                1220.04
trainer/Bellman Errors Std                 5979.24
trainer/Bellman Errors Max               176067
trainer/Bellman Errors Min                    3.35276e-06
trainer/Policy Action Mean                   -0.173164
trainer/Policy Action Std                     0.946674
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      27500
expl/num paths total                       1375
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0167923
expl/Rewards Std                              0.105289
expl/Rewards Max                              1.97555
expl/Rewards Min                              9.48353e-13
expl/Returns Mean                             0.335845
expl/Returns Std                              0.448306
expl/Returns Max                              2.17552
expl/Returns Min                              0.0340061
expl/Actions Mean                            -0.193122
expl/Actions Std                              0.805358
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.335845
expl/env_infos/final/reward_dist Mean         0.000333949
expl/env_infos/final/reward_dist Std          0.00163
expl/env_infos/final/reward_dist Max          0.00831929
expl/env_infos/final/reward_dist Min          9.48353e-13
expl/env_infos/initial/reward_dist Mean       0.0104544
expl/env_infos/initial/reward_dist Std        0.013445
expl/env_infos/initial/reward_dist Max        0.0636135
expl/env_infos/initial/reward_dist Min        0.000168097
expl/env_infos/reward_dist Mean               0.0167923
expl/env_infos/reward_dist Std                0.105289
expl/env_infos/reward_dist Max                1.97555
expl/env_infos/reward_dist Min                9.48353e-13
eval/num steps total                       3500
eval/num paths total                        175
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0116967
eval/Rewards Std                              0.0565861
eval/Rewards Max                              0.527722
eval/Rewards Min                              5.74856e-10
eval/Returns Mean                             0.233934
eval/Returns Std                              0.204329
eval/Returns Max                              0.62454
eval/Returns Min                              0.0435947
eval/Actions Mean                            -0.259242
eval/Actions Std                              0.915493
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.233934
eval/env_infos/final/reward_dist Mean         3.40799e-05
eval/env_infos/final/reward_dist Std          4.5311e-05
eval/env_infos/final/reward_dist Max          0.000118422
eval/env_infos/final/reward_dist Min          9.68911e-10
eval/env_infos/initial/reward_dist Mean       0.00292624
eval/env_infos/initial/reward_dist Std        0.00214068
eval/env_infos/initial/reward_dist Max        0.00586433
eval/env_infos/initial/reward_dist Min        0.00083755
eval/env_infos/reward_dist Mean               0.0116967
eval/env_infos/reward_dist Std                0.0565861
eval/env_infos/reward_dist Max                0.527722
eval/env_infos/reward_dist Min                5.74856e-10
time/data storing (s)                         0.00149282
time/evaluation sampling (s)                  0.834493
time/exploration sampling (s)                 5.13957
time/logging (s)                              0.00235926
time/saving (s)                               0.00109006
time/training (s)                             4.23825
time/epoch (s)                               10.2173
time/total (s)                              440.736
Epoch                                        34
---------------------------------------  ----------------
2023-08-03 20:52:28.100562 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 35 finished
---------------------------------------  ---------------
epoch                                       35
replay_buffer/size                       28000
trainer/QF Loss                           3676.64
trainer/Policy Loss                       -748.404
trainer/Raw Policy Loss                   -748.404
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 710.117
trainer/Q Predictions Std                  136.759
trainer/Q Predictions Max                 2818.7
trainer/Q Predictions Min                  547.019
trainer/Q Targets Mean                     714.225
trainer/Q Targets Std                      155.427
trainer/Q Targets Max                     2805.51
trainer/Q Targets Min                      557.794
trainer/Bellman Errors Mean               3676.64
trainer/Bellman Errors Std               27072.4
trainer/Bellman Errors Max                   1.35236e+06
trainer/Bellman Errors Min                   0.000190273
trainer/Policy Action Mean                  -0.0765436
trainer/Policy Action Std                    0.953086
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     28000
expl/num paths total                      1400
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00642107
expl/Rewards Std                             0.0296835
expl/Rewards Max                             0.369636
expl/Rewards Min                             3.62265e-11
expl/Returns Mean                            0.128421
expl/Returns Std                             0.225698
expl/Returns Max                             1.1207
expl/Returns Min                             0.00208962
expl/Actions Mean                           -0.0217072
expl/Actions Std                             0.81557
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.128421
expl/env_infos/final/reward_dist Mean        0.0116746
expl/env_infos/final/reward_dist Std         0.054882
expl/env_infos/final/reward_dist Max         0.280483
expl/env_infos/final/reward_dist Min         3.62265e-11
expl/env_infos/initial/reward_dist Mean      0.0109654
expl/env_infos/initial/reward_dist Std       0.0186674
expl/env_infos/initial/reward_dist Max       0.067277
expl/env_infos/initial/reward_dist Min       1.07489e-05
expl/env_infos/reward_dist Mean              0.00642107
expl/env_infos/reward_dist Std               0.0296835
expl/env_infos/reward_dist Max               0.369636
expl/env_infos/reward_dist Min               3.62265e-11
eval/num steps total                      3600
eval/num paths total                       180
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00399093
eval/Rewards Std                             0.0129776
eval/Rewards Max                             0.106474
eval/Rewards Min                             7.55002e-11
eval/Returns Mean                            0.0798185
eval/Returns Std                             0.0646496
eval/Returns Max                             0.182229
eval/Returns Min                             0.0196736
eval/Actions Mean                           -0.0851953
eval/Actions Std                             0.949857
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0798185
eval/env_infos/final/reward_dist Mean        1.26287e-08
eval/env_infos/final/reward_dist Std         2.19859e-08
eval/env_infos/final/reward_dist Max         5.63693e-08
eval/env_infos/final/reward_dist Min         7.55002e-11
eval/env_infos/initial/reward_dist Mean      0.00275197
eval/env_infos/initial/reward_dist Std       0.00218309
eval/env_infos/initial/reward_dist Max       0.00518799
eval/env_infos/initial/reward_dist Min       2.60533e-05
eval/env_infos/reward_dist Mean              0.00399093
eval/env_infos/reward_dist Std               0.0129776
eval/env_infos/reward_dist Max               0.106474
eval/env_infos/reward_dist Min               7.55002e-11
time/data storing (s)                        0.0015151
time/evaluation sampling (s)                 0.940475
time/exploration sampling (s)                4.51798
time/logging (s)                             0.00226742
time/saving (s)                              0.00107286
time/training (s)                            4.13056
time/epoch (s)                               9.59386
time/total (s)                             450.332
Epoch                                       35
---------------------------------------  ---------------
2023-08-03 20:52:37.778287 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 36 finished
---------------------------------------  ----------------
epoch                                        36
replay_buffer/size                        28500
trainer/QF Loss                            4939.9
trainer/Policy Loss                        -903.687
trainer/Raw Policy Loss                    -903.687
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  853.545
trainer/Q Predictions Std                   145.866
trainer/Q Predictions Max                  1445.27
trainer/Q Predictions Min                  -100.853
trainer/Q Targets Mean                      853.764
trainer/Q Targets Std                       164.046
trainer/Q Targets Max                      1517.3
trainer/Q Targets Min                      -110.411
trainer/Bellman Errors Mean                4939.9
trainer/Bellman Errors Std                15007.6
trainer/Bellman Errors Max               260596
trainer/Bellman Errors Min                    0.000144575
trainer/Policy Action Mean                    0.101924
trainer/Policy Action Std                     0.973824
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      28500
expl/num paths total                       1425
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.00406348
expl/Rewards Std                              0.0185571
expl/Rewards Max                              0.291992
expl/Rewards Min                              7.43488e-10
expl/Returns Mean                             0.0812695
expl/Returns Std                              0.103638
expl/Returns Max                              0.418576
expl/Returns Min                              0.0124792
expl/Actions Mean                            -0.00372878
expl/Actions Std                              0.833909
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.0812695
expl/env_infos/final/reward_dist Mean         0.00404387
expl/env_infos/final/reward_dist Std          0.0097214
expl/env_infos/final/reward_dist Max          0.0459016
expl/env_infos/final/reward_dist Min          1.97076e-09
expl/env_infos/initial/reward_dist Mean       0.0114431
expl/env_infos/initial/reward_dist Std        0.0288267
expl/env_infos/initial/reward_dist Max        0.147833
expl/env_infos/initial/reward_dist Min        6.59712e-05
expl/env_infos/reward_dist Mean               0.00406348
expl/env_infos/reward_dist Std                0.0185571
expl/env_infos/reward_dist Max                0.291992
expl/env_infos/reward_dist Min                7.43488e-10
eval/num steps total                       3700
eval/num paths total                        185
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.00186705
eval/Rewards Std                              0.00517085
eval/Rewards Max                              0.0406953
eval/Rewards Min                              5.2843e-06
eval/Returns Mean                             0.0373409
eval/Returns Std                              0.0213357
eval/Returns Max                              0.0745753
eval/Returns Min                              0.0153312
eval/Actions Mean                            -0.0406803
eval/Actions Std                              0.976182
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.0373409
eval/env_infos/final/reward_dist Mean         0.00927921
eval/env_infos/final/reward_dist Std          0.015755
eval/env_infos/final/reward_dist Max          0.0406953
eval/env_infos/final/reward_dist Min          1.16171e-05
eval/env_infos/initial/reward_dist Mean       0.00767366
eval/env_infos/initial/reward_dist Std        0.0080296
eval/env_infos/initial/reward_dist Max        0.0220874
eval/env_infos/initial/reward_dist Min        6.05128e-05
eval/env_infos/reward_dist Mean               0.00186705
eval/env_infos/reward_dist Std                0.00517085
eval/env_infos/reward_dist Max                0.0406953
eval/env_infos/reward_dist Min                5.2843e-06
time/data storing (s)                         0.00151971
time/evaluation sampling (s)                  0.957269
time/exploration sampling (s)                 4.51956
time/logging (s)                              0.00231584
time/saving (s)                               0.000999008
time/training (s)                             4.19312
time/epoch (s)                                9.67478
time/total (s)                              460.009
Epoch                                        36
---------------------------------------  ----------------
2023-08-03 20:52:47.878427 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 37 finished
---------------------------------------  ----------------
epoch                                        37
replay_buffer/size                        29000
trainer/QF Loss                            2481.63
trainer/Policy Loss                       -1060.75
trainer/Raw Policy Loss                   -1060.75
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 1001.04
trainer/Q Predictions Std                   109.693
trainer/Q Predictions Max                  1844.15
trainer/Q Predictions Min                   681.532
trainer/Q Targets Mean                     1000.66
trainer/Q Targets Std                       118.469
trainer/Q Targets Max                      1841.86
trainer/Q Targets Min                       679.225
trainer/Bellman Errors Mean                2481.63
trainer/Bellman Errors Std                 7258.36
trainer/Bellman Errors Max               113096
trainer/Bellman Errors Min                    1.3411e-07
trainer/Policy Action Mean                    0.389603
trainer/Policy Action Std                     0.901555
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      29000
expl/num paths total                       1450
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0116899
expl/Rewards Std                              0.0519128
expl/Rewards Max                              0.847718
expl/Rewards Min                              3.25449e-10
expl/Returns Mean                             0.233799
expl/Returns Std                              0.263466
expl/Returns Max                              1.04067
expl/Returns Min                              0.0234249
expl/Actions Mean                             0.321888
expl/Actions Std                              0.773302
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.233799
expl/env_infos/final/reward_dist Mean         0.00832471
expl/env_infos/final/reward_dist Std          0.0201731
expl/env_infos/final/reward_dist Max          0.0946806
expl/env_infos/final/reward_dist Min          1.74114e-09
expl/env_infos/initial/reward_dist Mean       0.0234913
expl/env_infos/initial/reward_dist Std        0.0615605
expl/env_infos/initial/reward_dist Max        0.320102
expl/env_infos/initial/reward_dist Min        3.31071e-05
expl/env_infos/reward_dist Mean               0.0116899
expl/env_infos/reward_dist Std                0.0519128
expl/env_infos/reward_dist Max                0.847718
expl/env_infos/reward_dist Min                3.25449e-10
eval/num steps total                       3800
eval/num paths total                        190
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.00454739
eval/Rewards Std                              0.00870402
eval/Rewards Max                              0.0515069
eval/Rewards Min                              9.61564e-07
eval/Returns Mean                             0.0909478
eval/Returns Std                              0.0414787
eval/Returns Max                              0.140513
eval/Returns Min                              0.0229632
eval/Actions Mean                             0.421687
eval/Actions Std                              0.885159
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.0909478
eval/env_infos/final/reward_dist Mean         0.000299105
eval/env_infos/final/reward_dist Std          0.000515301
eval/env_infos/final/reward_dist Max          0.00132782
eval/env_infos/final/reward_dist Min          2.74267e-06
eval/env_infos/initial/reward_dist Mean       0.0181805
eval/env_infos/initial/reward_dist Std        0.0219547
eval/env_infos/initial/reward_dist Max        0.0515069
eval/env_infos/initial/reward_dist Min        6.6868e-05
eval/env_infos/reward_dist Mean               0.00454739
eval/env_infos/reward_dist Std                0.00870402
eval/env_infos/reward_dist Max                0.0515069
eval/env_infos/reward_dist Min                9.61564e-07
time/data storing (s)                         0.0021599
time/evaluation sampling (s)                  1.14507
time/exploration sampling (s)                 4.82248
time/logging (s)                              0.00173914
time/saving (s)                               0.000800148
time/training (s)                             4.12463
time/epoch (s)                               10.0969
time/total (s)                              470.108
Epoch                                        37
---------------------------------------  ----------------
2023-08-03 20:52:57.883490 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 38 finished
---------------------------------------  ---------------
epoch                                       38
replay_buffer/size                       29500
trainer/QF Loss                            611.722
trainer/Policy Loss                       -824.09
trainer/Raw Policy Loss                   -824.09
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 806.781
trainer/Q Predictions Std                   57.548
trainer/Q Predictions Max                 1840.96
trainer/Q Predictions Min                  654.849
trainer/Q Targets Mean                     806.176
trainer/Q Targets Std                       61.2593
trainer/Q Targets Max                     1848.72
trainer/Q Targets Min                      627.196
trainer/Bellman Errors Mean                611.722
trainer/Bellman Errors Std                2666.43
trainer/Bellman Errors Max               82792.4
trainer/Bellman Errors Min                   1.04643e-05
trainer/Policy Action Mean                   0.244274
trainer/Policy Action Std                    0.950295
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     29500
expl/num paths total                      1475
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00719117
expl/Rewards Std                             0.0366992
expl/Rewards Max                             0.516028
expl/Rewards Min                             8.73154e-08
expl/Returns Mean                            0.143823
expl/Returns Std                             0.169333
expl/Returns Max                             0.67461
expl/Returns Min                             0.0131411
expl/Actions Mean                            0.199321
expl/Actions Std                             0.811102
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.143823
expl/env_infos/final/reward_dist Mean        0.0137979
expl/env_infos/final/reward_dist Std         0.0297359
expl/env_infos/final/reward_dist Max         0.114021
expl/env_infos/final/reward_dist Min         8.73154e-08
expl/env_infos/initial/reward_dist Mean      0.00881759
expl/env_infos/initial/reward_dist Std       0.013285
expl/env_infos/initial/reward_dist Max       0.0505757
expl/env_infos/initial/reward_dist Min       5.84866e-05
expl/env_infos/reward_dist Mean              0.00719117
expl/env_infos/reward_dist Std               0.0366992
expl/env_infos/reward_dist Max               0.516028
expl/env_infos/reward_dist Min               8.73154e-08
eval/num steps total                      3900
eval/num paths total                       195
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0144576
eval/Rewards Std                             0.073825
eval/Rewards Max                             0.665569
eval/Rewards Min                             3.83744e-06
eval/Returns Mean                            0.289151
eval/Returns Std                             0.257585
eval/Returns Max                             0.695426
eval/Returns Min                             0.0234984
eval/Actions Mean                            0.239448
eval/Actions Std                             0.930665
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.289151
eval/env_infos/final/reward_dist Mean        0.00786066
eval/env_infos/final/reward_dist Std         0.0123639
eval/env_infos/final/reward_dist Max         0.0324664
eval/env_infos/final/reward_dist Min         0.000142532
eval/env_infos/initial/reward_dist Mean      0.00404741
eval/env_infos/initial/reward_dist Std       0.00406722
eval/env_infos/initial/reward_dist Max       0.0109713
eval/env_infos/initial/reward_dist Min       0.000174176
eval/env_infos/reward_dist Mean              0.0144576
eval/env_infos/reward_dist Std               0.073825
eval/env_infos/reward_dist Max               0.665569
eval/env_infos/reward_dist Min               3.83744e-06
time/data storing (s)                        0.00214707
time/evaluation sampling (s)                 0.719207
time/exploration sampling (s)                4.66488
time/logging (s)                             0.00224922
time/saving (s)                              0.00103832
time/training (s)                            4.61408
time/epoch (s)                              10.0036
time/total (s)                             480.113
Epoch                                       38
---------------------------------------  ---------------
2023-08-03 20:53:07.036769 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 39 finished
---------------------------------------  ---------------
epoch                                       39
replay_buffer/size                       30000
trainer/QF Loss                            358.527
trainer/Policy Loss                       -590.797
trainer/Raw Policy Loss                   -590.797
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 583.155
trainer/Q Predictions Std                   63.1915
trainer/Q Predictions Max                 1469.03
trainer/Q Predictions Min                  472.501
trainer/Q Targets Mean                     583.663
trainer/Q Targets Std                       65.3215
trainer/Q Targets Max                     1505.59
trainer/Q Targets Min                      451.036
trainer/Bellman Errors Mean                358.527
trainer/Bellman Errors Std                1342.45
trainer/Bellman Errors Max               62276.4
trainer/Bellman Errors Min                   1.97068e-06
trainer/Policy Action Mean                   0.188321
trainer/Policy Action Std                    0.95167
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     30000
expl/num paths total                      1500
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0125577
expl/Rewards Std                             0.0747776
expl/Rewards Max                             1.2225
expl/Rewards Min                             1.81124e-09
expl/Returns Mean                            0.251154
expl/Returns Std                             0.319789
expl/Returns Max                             1.30748
expl/Returns Min                             0.0165249
expl/Actions Mean                            0.149642
expl/Actions Std                             0.803004
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.251154
expl/env_infos/final/reward_dist Mean        0.024422
expl/env_infos/final/reward_dist Std         0.0820484
expl/env_infos/final/reward_dist Max         0.406806
expl/env_infos/final/reward_dist Min         2.23767e-09
expl/env_infos/initial/reward_dist Mean      0.0059614
expl/env_infos/initial/reward_dist Std       0.0090442
expl/env_infos/initial/reward_dist Max       0.0402288
expl/env_infos/initial/reward_dist Min       3.67723e-05
expl/env_infos/reward_dist Mean              0.0125577
expl/env_infos/reward_dist Std               0.0747776
expl/env_infos/reward_dist Max               1.2225
expl/env_infos/reward_dist Min               1.81124e-09
eval/num steps total                      4000
eval/num paths total                       200
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0195104
eval/Rewards Std                             0.0554259
eval/Rewards Max                             0.303994
eval/Rewards Min                             6.46079e-06
eval/Returns Mean                            0.390207
eval/Returns Std                             0.280729
eval/Returns Max                             0.893136
eval/Returns Min                             0.08969
eval/Actions Mean                            0.14591
eval/Actions Std                             0.931704
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.390207
eval/env_infos/final/reward_dist Mean        0.000307019
eval/env_infos/final/reward_dist Std         0.000221043
eval/env_infos/final/reward_dist Max         0.000659891
eval/env_infos/final/reward_dist Min         5.71941e-05
eval/env_infos/initial/reward_dist Mean      0.0155072
eval/env_infos/initial/reward_dist Std       0.0180167
eval/env_infos/initial/reward_dist Max       0.0424175
eval/env_infos/initial/reward_dist Min       1.36808e-05
eval/env_infos/reward_dist Mean              0.0195104
eval/env_infos/reward_dist Std               0.0554259
eval/env_infos/reward_dist Max               0.303994
eval/env_infos/reward_dist Min               6.46079e-06
time/data storing (s)                        0.00154713
time/evaluation sampling (s)                 0.731027
time/exploration sampling (s)                4.17558
time/logging (s)                             0.0022643
time/saving (s)                              0.00101155
time/training (s)                            4.23934
time/epoch (s)                               9.15077
time/total (s)                             489.266
Epoch                                       39
---------------------------------------  ---------------
2023-08-03 20:53:17.289633 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 40 finished
---------------------------------------  ---------------
epoch                                       40
replay_buffer/size                       30500
trainer/QF Loss                            285.489
trainer/Policy Loss                       -444.353
trainer/Raw Policy Loss                   -444.353
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 433.971
trainer/Q Predictions Std                   53.2056
trainer/Q Predictions Max                 1403.11
trainer/Q Predictions Min                  279.918
trainer/Q Targets Mean                     434.028
trainer/Q Targets Std                       56.7212
trainer/Q Targets Max                     1420.78
trainer/Q Targets Min                      294.974
trainer/Bellman Errors Mean                285.489
trainer/Bellman Errors Std                1399
trainer/Bellman Errors Max               38811
trainer/Bellman Errors Min                   1.90446e-05
trainer/Policy Action Mean                   0.134193
trainer/Policy Action Std                    0.938066
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     30500
expl/num paths total                      1525
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00473046
expl/Rewards Std                             0.022753
expl/Rewards Max                             0.4465
expl/Rewards Min                             1.14537e-12
expl/Returns Mean                            0.0946091
expl/Returns Std                             0.11677
expl/Returns Max                             0.488147
expl/Returns Min                             0.0024505
expl/Actions Mean                            0.0344476
expl/Actions Std                             0.816248
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0946091
expl/env_infos/final/reward_dist Mean        0.00320631
expl/env_infos/final/reward_dist Std         0.00892591
expl/env_infos/final/reward_dist Max         0.0330165
expl/env_infos/final/reward_dist Min         1.14537e-12
expl/env_infos/initial/reward_dist Mean      0.00769421
expl/env_infos/initial/reward_dist Std       0.00733924
expl/env_infos/initial/reward_dist Max       0.026536
expl/env_infos/initial/reward_dist Min       0.000124343
expl/env_infos/reward_dist Mean              0.00473046
expl/env_infos/reward_dist Std               0.022753
expl/env_infos/reward_dist Max               0.4465
expl/env_infos/reward_dist Min               1.14537e-12
eval/num steps total                      4100
eval/num paths total                       205
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00520649
eval/Rewards Std                             0.0135324
eval/Rewards Max                             0.103677
eval/Rewards Min                             1.3618e-06
eval/Returns Mean                            0.10413
eval/Returns Std                             0.0619039
eval/Returns Max                             0.221328
eval/Returns Min                             0.0539629
eval/Actions Mean                            0.0280328
eval/Actions Std                             0.930143
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.10413
eval/env_infos/final/reward_dist Mean        0.0342708
eval/env_infos/final/reward_dist Std         0.0395856
eval/env_infos/final/reward_dist Max         0.103677
eval/env_infos/final/reward_dist Min         0.00152356
eval/env_infos/initial/reward_dist Mean      0.0181871
eval/env_infos/initial/reward_dist Std       0.00827449
eval/env_infos/initial/reward_dist Max       0.0280667
eval/env_infos/initial/reward_dist Min       0.00321167
eval/env_infos/reward_dist Mean              0.00520649
eval/env_infos/reward_dist Std               0.0135324
eval/env_infos/reward_dist Max               0.103677
eval/env_infos/reward_dist Min               1.3618e-06
time/data storing (s)                        0.00153997
time/evaluation sampling (s)                 0.893959
time/exploration sampling (s)                5.12807
time/logging (s)                             0.00230521
time/saving (s)                              0.000997428
time/training (s)                            4.22351
time/epoch (s)                              10.2504
time/total (s)                             499.518
Epoch                                       40
---------------------------------------  ---------------
2023-08-03 20:53:25.889520 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 41 finished
---------------------------------------  ---------------
epoch                                       41
replay_buffer/size                       31000
trainer/QF Loss                            914.858
trainer/Policy Loss                       -430.208
trainer/Raw Policy Loss                   -430.208
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 386.306
trainer/Q Predictions Std                  113.489
trainer/Q Predictions Max                 1750.54
trainer/Q Predictions Min                  199.207
trainer/Q Targets Mean                     385.589
trainer/Q Targets Std                      115.002
trainer/Q Targets Max                     1680.27
trainer/Q Targets Min                      213.185
trainer/Bellman Errors Mean                914.858
trainer/Bellman Errors Std                3262.67
trainer/Bellman Errors Max               73348.6
trainer/Bellman Errors Min                   7.83242e-07
trainer/Policy Action Mean                   0.113202
trainer/Policy Action Std                    0.967145
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     31000
expl/num paths total                      1550
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00347422
expl/Rewards Std                             0.0150156
expl/Rewards Max                             0.212692
expl/Rewards Min                             1.16729e-17
expl/Returns Mean                            0.0694844
expl/Returns Std                             0.0890765
expl/Returns Max                             0.377324
expl/Returns Min                             0.00864333
expl/Actions Mean                            0.100289
expl/Actions Std                             0.848253
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0694844
expl/env_infos/final/reward_dist Mean        0.00918948
expl/env_infos/final/reward_dist Std         0.0416117
expl/env_infos/final/reward_dist Max         0.212692
expl/env_infos/final/reward_dist Min         1.16729e-17
expl/env_infos/initial/reward_dist Mean      0.0115445
expl/env_infos/initial/reward_dist Std       0.0128521
expl/env_infos/initial/reward_dist Max       0.0540978
expl/env_infos/initial/reward_dist Min       7.44751e-05
expl/env_infos/reward_dist Mean              0.00347422
expl/env_infos/reward_dist Std               0.0150156
expl/env_infos/reward_dist Max               0.212692
expl/env_infos/reward_dist Min               1.16729e-17
eval/num steps total                      4200
eval/num paths total                       210
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.000562337
eval/Rewards Std                             0.00246819
eval/Rewards Max                             0.021115
eval/Rewards Min                             2.57102e-17
eval/Returns Mean                            0.0112467
eval/Returns Std                             0.00836506
eval/Returns Max                             0.0221382
eval/Returns Min                             0.00332531
eval/Actions Mean                            0.105251
eval/Actions Std                             0.980361
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0112467
eval/env_infos/final/reward_dist Mean        4.11003e-10
eval/env_infos/final/reward_dist Std         8.22002e-10
eval/env_infos/final/reward_dist Max         2.05501e-09
eval/env_infos/final/reward_dist Min         2.57102e-17
eval/env_infos/initial/reward_dist Mean      0.00699768
eval/env_infos/initial/reward_dist Std       0.00816146
eval/env_infos/initial/reward_dist Max       0.021115
eval/env_infos/initial/reward_dist Min       0.000226466
eval/env_infos/reward_dist Mean              0.000562337
eval/env_infos/reward_dist Std               0.00246819
eval/env_infos/reward_dist Max               0.021115
eval/env_infos/reward_dist Min               2.57102e-17
time/data storing (s)                        0.00148677
time/evaluation sampling (s)                 0.879068
time/exploration sampling (s)                4.07229
time/logging (s)                             0.00311661
time/saving (s)                              0.01197
time/training (s)                            3.62967
time/epoch (s)                               8.59761
time/total (s)                             508.119
Epoch                                       41
---------------------------------------  ---------------
2023-08-03 20:53:35.769555 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 42 finished
---------------------------------------  ---------------
epoch                                       42
replay_buffer/size                       31500
trainer/QF Loss                           2441.04
trainer/Policy Loss                       -965.781
trainer/Raw Policy Loss                   -965.781
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 872.219
trainer/Q Predictions Std                  165.327
trainer/Q Predictions Max                 1784.37
trainer/Q Predictions Min                  582.926
trainer/Q Targets Mean                     869.714
trainer/Q Targets Std                      172.193
trainer/Q Targets Max                     1827.96
trainer/Q Targets Min                      534.413
trainer/Bellman Errors Mean               2441.04
trainer/Bellman Errors Std                5426.08
trainer/Bellman Errors Max               88201.8
trainer/Bellman Errors Min                   1.08629e-05
trainer/Policy Action Mean                   0.0175189
trainer/Policy Action Std                    0.951505
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     31500
expl/num paths total                      1575
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0104209
expl/Rewards Std                             0.0391831
expl/Rewards Max                             0.251003
expl/Rewards Min                             2.42908e-22
expl/Returns Mean                            0.208418
expl/Returns Std                             0.578254
expl/Returns Max                             2.35291
expl/Returns Min                             0.00161068
expl/Actions Mean                            0.0165537
expl/Actions Std                             0.826025
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.208418
expl/env_infos/final/reward_dist Mean        0.0110043
expl/env_infos/final/reward_dist Std         0.0373306
expl/env_infos/final/reward_dist Max         0.141068
expl/env_infos/final/reward_dist Min         2.42908e-22
expl/env_infos/initial/reward_dist Mean      0.0103327
expl/env_infos/initial/reward_dist Std       0.0132226
expl/env_infos/initial/reward_dist Max       0.0485857
expl/env_infos/initial/reward_dist Min       3.1659e-05
expl/env_infos/reward_dist Mean              0.0104209
expl/env_infos/reward_dist Std               0.0391831
expl/env_infos/reward_dist Max               0.251003
expl/env_infos/reward_dist Min               2.42908e-22
eval/num steps total                      4300
eval/num paths total                       215
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00134516
eval/Rewards Std                             0.00405913
eval/Rewards Max                             0.0219685
eval/Rewards Min                             2.15252e-21
eval/Returns Mean                            0.0269033
eval/Returns Std                             0.00447937
eval/Returns Max                             0.0310071
eval/Returns Min                             0.018594
eval/Actions Mean                           -0.0149924
eval/Actions Std                             0.951777
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0269033
eval/env_infos/final/reward_dist Mean        2.18162e-19
eval/env_infos/final/reward_dist Std         2.26465e-19
eval/env_infos/final/reward_dist Max         6.10757e-19
eval/env_infos/final/reward_dist Min         2.15252e-21
eval/env_infos/initial/reward_dist Mean      0.00414056
eval/env_infos/initial/reward_dist Std       0.0051289
eval/env_infos/initial/reward_dist Max       0.014278
eval/env_infos/initial/reward_dist Min       0.000327728
eval/env_infos/reward_dist Mean              0.00134516
eval/env_infos/reward_dist Std               0.00405913
eval/env_infos/reward_dist Max               0.0219685
eval/env_infos/reward_dist Min               2.15252e-21
time/data storing (s)                        0.00148123
time/evaluation sampling (s)                 1.07969
time/exploration sampling (s)                4.50291
time/logging (s)                             0.0023152
time/saving (s)                              0.00102629
time/training (s)                            4.28846
time/epoch (s)                               9.87588
time/total (s)                             517.997
Epoch                                       42
---------------------------------------  ---------------
2023-08-03 20:53:44.954742 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 43 finished
---------------------------------------  ----------------
epoch                                        43
replay_buffer/size                        32000
trainer/QF Loss                            5380.27
trainer/Policy Loss                       -1215.53
trainer/Raw Policy Loss                   -1215.53
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 1145.23
trainer/Q Predictions Std                   274.834
trainer/Q Predictions Max                  2294.03
trainer/Q Predictions Min                   849.92
trainer/Q Targets Mean                     1147.52
trainer/Q Targets Std                       284.234
trainer/Q Targets Max                      2187.9
trainer/Q Targets Min                       844.789
trainer/Bellman Errors Mean                5380.27
trainer/Bellman Errors Std                14990.9
trainer/Bellman Errors Max               218028
trainer/Bellman Errors Min                    0.00148797
trainer/Policy Action Mean                    0.0334147
trainer/Policy Action Std                     0.971843
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      32000
expl/num paths total                       1600
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.000369344
expl/Rewards Std                              0.00198421
expl/Rewards Max                              0.026208
expl/Rewards Min                              6.53139e-18
expl/Returns Mean                             0.00738687
expl/Returns Std                              0.00902694
expl/Returns Max                              0.0363605
expl/Returns Min                              0.000346293
expl/Actions Mean                            -0.0596924
expl/Actions Std                              0.821923
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.00738687
expl/env_infos/final/reward_dist Mean         2.05088e-07
expl/env_infos/final/reward_dist Std          8.0908e-07
expl/env_infos/final/reward_dist Max          4.02889e-06
expl/env_infos/final/reward_dist Min          6.53139e-18
expl/env_infos/initial/reward_dist Mean       0.00400368
expl/env_infos/initial/reward_dist Std        0.0066735
expl/env_infos/initial/reward_dist Max        0.026208
expl/env_infos/initial/reward_dist Min        1.36544e-05
expl/env_infos/reward_dist Mean               0.000369344
expl/env_infos/reward_dist Std                0.00198421
expl/env_infos/reward_dist Max                0.026208
expl/env_infos/reward_dist Min                6.53139e-18
eval/num steps total                       4400
eval/num paths total                        220
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.000372294
eval/Rewards Std                              0.00249243
eval/Rewards Max                              0.0248064
eval/Rewards Min                              5.06226e-17
eval/Returns Mean                             0.00744587
eval/Returns Std                              0.010135
eval/Returns Max                              0.0275871
eval/Returns Min                              0.000988179
eval/Actions Mean                            -0.0446326
eval/Actions Std                              0.985458
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.00744587
eval/env_infos/final/reward_dist Mean         2.11295e-12
eval/env_infos/final/reward_dist Std          2.59581e-12
eval/env_infos/final/reward_dist Max          6.87738e-12
eval/env_infos/final/reward_dist Min          5.06226e-17
eval/env_infos/initial/reward_dist Mean       0.00600685
eval/env_infos/initial/reward_dist Std        0.0094713
eval/env_infos/initial/reward_dist Max        0.0248064
eval/env_infos/initial/reward_dist Min        1.32784e-05
eval/env_infos/reward_dist Mean               0.000372294
eval/env_infos/reward_dist Std                0.00249243
eval/env_infos/reward_dist Max                0.0248064
eval/env_infos/reward_dist Min                5.06226e-17
time/data storing (s)                         0.00148417
time/evaluation sampling (s)                  1.09536
time/exploration sampling (s)                 3.94817
time/logging (s)                              0.00226617
time/saving (s)                               0.00102705
time/training (s)                             4.13418
time/epoch (s)                                9.18249
time/total (s)                              527.182
Epoch                                        43
---------------------------------------  ----------------
2023-08-03 20:53:53.843226 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 44 finished
---------------------------------------  ----------------
epoch                                        44
replay_buffer/size                        32500
trainer/QF Loss                           11129.3
trainer/Policy Loss                       -1758.69
trainer/Raw Policy Loss                   -1758.69
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 1633.56
trainer/Q Predictions Std                   316.422
trainer/Q Predictions Max                  2795.81
trainer/Q Predictions Min                  1175.01
trainer/Q Targets Mean                     1633.77
trainer/Q Targets Std                       329.904
trainer/Q Targets Max                      2863.7
trainer/Q Targets Min                      1154.6
trainer/Bellman Errors Mean               11129.3
trainer/Bellman Errors Std                30074.1
trainer/Bellman Errors Max               738306
trainer/Bellman Errors Min                    0.000152007
trainer/Policy Action Mean                    0.151275
trainer/Policy Action Std                     0.971337
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      32500
expl/num paths total                       1625
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.00157785
expl/Rewards Std                              0.00593933
expl/Rewards Max                              0.0816031
expl/Rewards Min                              2.11404e-12
expl/Returns Mean                             0.031557
expl/Returns Std                              0.0238987
expl/Returns Max                              0.0929232
expl/Returns Min                              0.00266625
expl/Actions Mean                             0.291771
expl/Actions Std                              0.785312
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.031557
expl/env_infos/final/reward_dist Mean         5.1815e-08
expl/env_infos/final/reward_dist Std          2.16526e-07
expl/env_infos/final/reward_dist Max          1.11088e-06
expl/env_infos/final/reward_dist Min          2.11404e-12
expl/env_infos/initial/reward_dist Mean       0.0115326
expl/env_infos/initial/reward_dist Std        0.0201272
expl/env_infos/initial/reward_dist Max        0.0816031
expl/env_infos/initial/reward_dist Min        1.06586e-05
expl/env_infos/reward_dist Mean               0.00157785
expl/env_infos/reward_dist Std                0.00593933
expl/env_infos/reward_dist Max                0.0816031
expl/env_infos/reward_dist Min                2.11404e-12
eval/num steps total                       4500
eval/num paths total                        225
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.00115524
eval/Rewards Std                              0.00403113
eval/Rewards Max                              0.0294955
eval/Rewards Min                              3.22166e-09
eval/Returns Mean                             0.0231049
eval/Returns Std                              0.0208665
eval/Returns Max                              0.0630778
eval/Returns Min                              0.00470493
eval/Actions Mean                             0.39224
eval/Actions Std                              0.902489
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.0231049
eval/env_infos/final/reward_dist Mean         2.90918e-07
eval/env_infos/final/reward_dist Std          3.06247e-07
eval/env_infos/final/reward_dist Max          8.34607e-07
eval/env_infos/final/reward_dist Min          7.47211e-09
eval/env_infos/initial/reward_dist Mean       0.0037217
eval/env_infos/initial/reward_dist Std        0.00330084
eval/env_infos/initial/reward_dist Max        0.00850332
eval/env_infos/initial/reward_dist Min        0.000154794
eval/env_infos/reward_dist Mean               0.00115524
eval/env_infos/reward_dist Std                0.00403113
eval/env_infos/reward_dist Max                0.0294955
eval/env_infos/reward_dist Min                3.22166e-09
time/data storing (s)                         0.00215433
time/evaluation sampling (s)                  0.690488
time/exploration sampling (s)                 3.95849
time/logging (s)                              0.00229796
time/saving (s)                               0.00102534
time/training (s)                             4.23139
time/epoch (s)                                8.88584
time/total (s)                              536.07
Epoch                                        44
---------------------------------------  ----------------
2023-08-03 20:54:04.065821 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 45 finished
---------------------------------------  ---------------
epoch                                       45
replay_buffer/size                       33000
trainer/QF Loss                           3389.09
trainer/Policy Loss                      -1800.25
trainer/Raw Policy Loss                  -1800.25
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                1727.31
trainer/Q Predictions Std                  156.799
trainer/Q Predictions Max                 4053.36
trainer/Q Predictions Min                 1082.93
trainer/Q Targets Mean                    1728.01
trainer/Q Targets Std                      166.209
trainer/Q Targets Max                     3915.47
trainer/Q Targets Min                     1096.68
trainer/Bellman Errors Mean               3389.09
trainer/Bellman Errors Std               23610.8
trainer/Bellman Errors Max                   1.44988e+06
trainer/Bellman Errors Min                   2.92063e-06
trainer/Policy Action Mean                   0.255996
trainer/Policy Action Std                    0.935877
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     33000
expl/num paths total                      1650
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0015925
expl/Rewards Std                             0.00681538
expl/Rewards Max                             0.093509
expl/Rewards Min                             1.7637e-11
expl/Returns Mean                            0.0318501
expl/Returns Std                             0.031975
expl/Returns Max                             0.101267
expl/Returns Min                             0.000877245
expl/Actions Mean                            0.261477
expl/Actions Std                             0.798851
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0318501
expl/env_infos/final/reward_dist Mean        2.33624e-07
expl/env_infos/final/reward_dist Std         1.00474e-06
expl/env_infos/final/reward_dist Max         5.14284e-06
expl/env_infos/final/reward_dist Min         1.7637e-11
expl/env_infos/initial/reward_dist Mean      0.00787688
expl/env_infos/initial/reward_dist Std       0.0127355
expl/env_infos/initial/reward_dist Max       0.0403403
expl/env_infos/initial/reward_dist Min       1.72726e-05
expl/env_infos/reward_dist Mean              0.0015925
expl/env_infos/reward_dist Std               0.00681538
expl/env_infos/reward_dist Max               0.093509
expl/env_infos/reward_dist Min               1.7637e-11
eval/num steps total                      4600
eval/num paths total                       230
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00689314
eval/Rewards Std                             0.0460097
eval/Rewards Max                             0.447272
eval/Rewards Min                             1.29587e-10
eval/Returns Mean                            0.137863
eval/Returns Std                             0.182032
eval/Returns Max                             0.494202
eval/Returns Min                             0.00448216
eval/Actions Mean                            0.349453
eval/Actions Std                             0.90933
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.137863
eval/env_infos/final/reward_dist Mean        5.94583e-08
eval/env_infos/final/reward_dist Std         1.15797e-07
eval/env_infos/final/reward_dist Max         2.91021e-07
eval/env_infos/final/reward_dist Min         1.3712e-10
eval/env_infos/initial/reward_dist Mean      0.017889
eval/env_infos/initial/reward_dist Std       0.0210095
eval/env_infos/initial/reward_dist Max       0.0467709
eval/env_infos/initial/reward_dist Min       9.0311e-06
eval/env_infos/reward_dist Mean              0.00689314
eval/env_infos/reward_dist Std               0.0460097
eval/env_infos/reward_dist Max               0.447272
eval/env_infos/reward_dist Min               1.29587e-10
time/data storing (s)                        0.00188907
time/evaluation sampling (s)                 0.726786
time/exploration sampling (s)                4.1513
time/logging (s)                             0.00225182
time/saving (s)                              0.00103596
time/training (s)                            5.33662
time/epoch (s)                              10.2199
time/total (s)                             546.292
Epoch                                       45
---------------------------------------  ---------------
2023-08-03 20:54:12.831685 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 46 finished
---------------------------------------  ---------------
epoch                                       46
replay_buffer/size                       33500
trainer/QF Loss                            925.476
trainer/Policy Loss                      -1399.57
trainer/Raw Policy Loss                  -1399.57
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                1370.32
trainer/Q Predictions Std                   91.7296
trainer/Q Predictions Max                 3121.71
trainer/Q Predictions Min                  675.929
trainer/Q Targets Mean                    1371.44
trainer/Q Targets Std                       95.5828
trainer/Q Targets Max                     3162.72
trainer/Q Targets Min                      659.736
trainer/Bellman Errors Mean                925.476
trainer/Bellman Errors Std                2812.97
trainer/Bellman Errors Max               84175.1
trainer/Bellman Errors Min                   2.92063e-06
trainer/Policy Action Mean                   0.142738
trainer/Policy Action Std                    0.961039
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     33500
expl/num paths total                      1675
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0062451
expl/Rewards Std                             0.0303823
expl/Rewards Max                             0.382551
expl/Rewards Min                             1.06534e-10
expl/Returns Mean                            0.124902
expl/Returns Std                             0.474802
expl/Returns Max                             2.44015
expl/Returns Min                             0.00132938
expl/Actions Mean                            0.182993
expl/Actions Std                             0.81613
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.124902
expl/env_infos/final/reward_dist Mean        2.40967e-05
expl/env_infos/final/reward_dist Std         5.73002e-05
expl/env_infos/final/reward_dist Max         0.000181509
expl/env_infos/final/reward_dist Min         1.16204e-10
expl/env_infos/initial/reward_dist Mean      0.00759911
expl/env_infos/initial/reward_dist Std       0.0153288
expl/env_infos/initial/reward_dist Max       0.0655104
expl/env_infos/initial/reward_dist Min       1.75228e-05
expl/env_infos/reward_dist Mean              0.0062451
expl/env_infos/reward_dist Std               0.0303823
expl/env_infos/reward_dist Max               0.382551
expl/env_infos/reward_dist Min               1.06534e-10
eval/num steps total                      4700
eval/num paths total                       235
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.000762723
eval/Rewards Std                             0.003387
eval/Rewards Max                             0.0312606
eval/Rewards Min                             4.32229e-10
eval/Returns Mean                            0.0152545
eval/Returns Std                             0.0125043
eval/Returns Max                             0.0387777
eval/Returns Min                             0.00237157
eval/Actions Mean                            0.151913
eval/Actions Std                             0.958909
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0152545
eval/env_infos/final/reward_dist Mean        5.09868e-09
eval/env_infos/final/reward_dist Std         7.41397e-09
eval/env_infos/final/reward_dist Max         1.98415e-08
eval/env_infos/final/reward_dist Min         4.32229e-10
eval/env_infos/initial/reward_dist Mean      0.00930018
eval/env_infos/initial/reward_dist Std       0.0118516
eval/env_infos/initial/reward_dist Max       0.0312606
eval/env_infos/initial/reward_dist Min       1.95714e-05
eval/env_infos/reward_dist Mean              0.000762723
eval/env_infos/reward_dist Std               0.003387
eval/env_infos/reward_dist Max               0.0312606
eval/env_infos/reward_dist Min               4.32229e-10
time/data storing (s)                        0.00154495
time/evaluation sampling (s)                 0.689952
time/exploration sampling (s)                3.80891
time/logging (s)                             0.00225407
time/saving (s)                              0.00102594
time/training (s)                            4.25958
time/epoch (s)                               8.76326
time/total (s)                             555.057
Epoch                                       46
---------------------------------------  ---------------
2023-08-03 20:54:22.333811 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 47 finished
---------------------------------------  ---------------
epoch                                       47
replay_buffer/size                       34000
trainer/QF Loss                            627.305
trainer/Policy Loss                      -1035.4
trainer/Raw Policy Loss                  -1035.4
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                1017.38
trainer/Q Predictions Std                   65.4699
trainer/Q Predictions Max                 2211.98
trainer/Q Predictions Min                  712.418
trainer/Q Targets Mean                    1016.92
trainer/Q Targets Std                       70.3824
trainer/Q Targets Max                     2311.4
trainer/Q Targets Min                      681.804
trainer/Bellman Errors Mean                627.305
trainer/Bellman Errors Std                1528.67
trainer/Bellman Errors Max               36882.5
trainer/Bellman Errors Min                   0.000212792
trainer/Policy Action Mean                   0.196659
trainer/Policy Action Std                    0.960523
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     34000
expl/num paths total                      1700
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00178272
expl/Rewards Std                             0.00548505
expl/Rewards Max                             0.0827213
expl/Rewards Min                             2.83828e-12
expl/Returns Mean                            0.0356543
expl/Returns Std                             0.0279455
expl/Returns Max                             0.141852
expl/Returns Min                             0.00891479
expl/Actions Mean                            0.131663
expl/Actions Std                             0.837863
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0356543
expl/env_infos/final/reward_dist Mean        2.58534e-06
expl/env_infos/final/reward_dist Std         1.22782e-05
expl/env_infos/final/reward_dist Max         6.27225e-05
expl/env_infos/final/reward_dist Min         2.83828e-12
expl/env_infos/initial/reward_dist Mean      0.00721985
expl/env_infos/initial/reward_dist Std       0.0103514
expl/env_infos/initial/reward_dist Max       0.0361907
expl/env_infos/initial/reward_dist Min       2.34749e-05
expl/env_infos/reward_dist Mean              0.00178272
expl/env_infos/reward_dist Std               0.00548505
expl/env_infos/reward_dist Max               0.0827213
expl/env_infos/reward_dist Min               2.83828e-12
eval/num steps total                      4800
eval/num paths total                       240
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00119511
eval/Rewards Std                             0.00317343
eval/Rewards Max                             0.0198229
eval/Rewards Min                             4.14255e-10
eval/Returns Mean                            0.0239022
eval/Returns Std                             0.0097184
eval/Returns Max                             0.0396342
eval/Returns Min                             0.0128367
eval/Actions Mean                            0.13721
eval/Actions Std                             0.968833
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0239022
eval/env_infos/final/reward_dist Mean        4.92187e-08
eval/env_infos/final/reward_dist Std         9.66363e-08
eval/env_infos/final/reward_dist Max         2.4249e-07
eval/env_infos/final/reward_dist Min         4.14255e-10
eval/env_infos/initial/reward_dist Mean      0.00652043
eval/env_infos/initial/reward_dist Std       0.00771662
eval/env_infos/initial/reward_dist Max       0.0198229
eval/env_infos/initial/reward_dist Min       0.000111931
eval/env_infos/reward_dist Mean              0.00119511
eval/env_infos/reward_dist Std               0.00317343
eval/env_infos/reward_dist Max               0.0198229
eval/env_infos/reward_dist Min               4.14255e-10
time/data storing (s)                        0.00215045
time/evaluation sampling (s)                 0.701213
time/exploration sampling (s)                4.06636
time/logging (s)                             0.00328363
time/saving (s)                              0.0012793
time/training (s)                            4.72631
time/epoch (s)                               9.50059
time/total (s)                             564.559
Epoch                                       47
---------------------------------------  ---------------
2023-08-03 20:54:31.488818 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 48 finished
---------------------------------------  ---------------
epoch                                       48
replay_buffer/size                       34500
trainer/QF Loss                            645.771
trainer/Policy Loss                       -738.206
trainer/Raw Policy Loss                   -738.206
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 727.484
trainer/Q Predictions Std                   60.0917
trainer/Q Predictions Max                 1475.73
trainer/Q Predictions Min                  411.027
trainer/Q Targets Mean                     728.067
trainer/Q Targets Std                       65.9159
trainer/Q Targets Max                     1506
trainer/Q Targets Min                      407.744
trainer/Bellman Errors Mean                645.771
trainer/Bellman Errors Std                2229.03
trainer/Bellman Errors Max               59601.9
trainer/Bellman Errors Min                   2.14577e-06
trainer/Policy Action Mean                   0.303088
trainer/Policy Action Std                    0.930977
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     34500
expl/num paths total                      1725
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00228432
expl/Rewards Std                             0.00705739
expl/Rewards Max                             0.0679847
expl/Rewards Min                             7.51857e-11
expl/Returns Mean                            0.0456865
expl/Returns Std                             0.0314923
expl/Returns Max                             0.12418
expl/Returns Min                             0.00289463
expl/Actions Mean                            0.338752
expl/Actions Std                             0.764955
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0456865
expl/env_infos/final/reward_dist Mean        1.04599e-07
expl/env_infos/final/reward_dist Std         4.3809e-07
expl/env_infos/final/reward_dist Max         2.24673e-06
expl/env_infos/final/reward_dist Min         5.26143e-10
expl/env_infos/initial/reward_dist Mean      0.00848783
expl/env_infos/initial/reward_dist Std       0.0140919
expl/env_infos/initial/reward_dist Max       0.0541426
expl/env_infos/initial/reward_dist Min       3.58785e-05
expl/env_infos/reward_dist Mean              0.00228432
expl/env_infos/reward_dist Std               0.00705739
expl/env_infos/reward_dist Max               0.0679847
expl/env_infos/reward_dist Min               7.51857e-11
eval/num steps total                      4900
eval/num paths total                       245
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00112055
eval/Rewards Std                             0.00345938
eval/Rewards Max                             0.0190571
eval/Rewards Min                             1.66263e-10
eval/Returns Mean                            0.0224111
eval/Returns Std                             0.0121527
eval/Returns Max                             0.0403155
eval/Returns Min                             0.00686385
eval/Actions Mean                            0.406508
eval/Actions Std                             0.880147
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0224111
eval/env_infos/final/reward_dist Mean        3.10304e-09
eval/env_infos/final/reward_dist Std         1.89693e-09
eval/env_infos/final/reward_dist Max         5.4198e-09
eval/env_infos/final/reward_dist Min         1.66263e-10
eval/env_infos/initial/reward_dist Mean      0.00577307
eval/env_infos/initial/reward_dist Std       0.00693579
eval/env_infos/initial/reward_dist Max       0.0190571
eval/env_infos/initial/reward_dist Min       3.28467e-05
eval/env_infos/reward_dist Mean              0.00112055
eval/env_infos/reward_dist Std               0.00345938
eval/env_infos/reward_dist Max               0.0190571
eval/env_infos/reward_dist Min               1.66263e-10
time/data storing (s)                        0.00215858
time/evaluation sampling (s)                 0.717435
time/exploration sampling (s)                4.1092
time/logging (s)                             0.00223618
time/saving (s)                              0.00100576
time/training (s)                            4.31848
time/epoch (s)                               9.15051
time/total (s)                             573.713
Epoch                                       48
---------------------------------------  ---------------
2023-08-03 20:54:40.827990 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 49 finished
---------------------------------------  ---------------
epoch                                       49
replay_buffer/size                       35000
trainer/QF Loss                            410.844
trainer/Policy Loss                       -515.585
trainer/Raw Policy Loss                   -515.585
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 510.352
trainer/Q Predictions Std                   49.409
trainer/Q Predictions Max                 1028.62
trainer/Q Predictions Min                  393.498
trainer/Q Targets Mean                     510.852
trainer/Q Targets Std                       52.931
trainer/Q Targets Max                     1012.54
trainer/Q Targets Min                      261.676
trainer/Bellman Errors Mean                410.844
trainer/Bellman Errors Std                1906.63
trainer/Bellman Errors Max               68895.6
trainer/Bellman Errors Min                   0.000217267
trainer/Policy Action Mean                   0.291937
trainer/Policy Action Std                    0.934678
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     35000
expl/num paths total                      1750
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00250856
expl/Rewards Std                             0.0076815
expl/Rewards Max                             0.0899711
expl/Rewards Min                             1.93486e-10
expl/Returns Mean                            0.0501712
expl/Returns Std                             0.0368754
expl/Returns Max                             0.178717
expl/Returns Min                             0.0130072
expl/Actions Mean                            0.35333
expl/Actions Std                             0.755678
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0501712
expl/env_infos/final/reward_dist Mean        0.000373943
expl/env_infos/final/reward_dist Std         0.00183163
expl/env_infos/final/reward_dist Max         0.00934705
expl/env_infos/final/reward_dist Min         8.55421e-10
expl/env_infos/initial/reward_dist Mean      0.00922718
expl/env_infos/initial/reward_dist Std       0.0121441
expl/env_infos/initial/reward_dist Max       0.0487328
expl/env_infos/initial/reward_dist Min       3.17213e-05
expl/env_infos/reward_dist Mean              0.00250856
expl/env_infos/reward_dist Std               0.0076815
expl/env_infos/reward_dist Max               0.0899711
expl/env_infos/reward_dist Min               1.93486e-10
eval/num steps total                      5000
eval/num paths total                       250
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00149216
eval/Rewards Std                             0.00401452
eval/Rewards Max                             0.0258201
eval/Rewards Min                             3.54965e-10
eval/Returns Mean                            0.0298432
eval/Returns Std                             0.0107646
eval/Returns Max                             0.0435478
eval/Returns Min                             0.0144457
eval/Actions Mean                            0.460773
eval/Actions Std                             0.855182
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0298432
eval/env_infos/final/reward_dist Mean        3.21984e-09
eval/env_infos/final/reward_dist Std         1.82996e-09
eval/env_infos/final/reward_dist Max         5.83863e-09
eval/env_infos/final/reward_dist Min         3.54965e-10
eval/env_infos/initial/reward_dist Mean      0.00241469
eval/env_infos/initial/reward_dist Std       0.00222507
eval/env_infos/initial/reward_dist Max       0.00668181
eval/env_infos/initial/reward_dist Min       0.000201594
eval/env_infos/reward_dist Mean              0.00149216
eval/env_infos/reward_dist Std               0.00401452
eval/env_infos/reward_dist Max               0.0258201
eval/env_infos/reward_dist Min               3.54965e-10
time/data storing (s)                        0.0021628
time/evaluation sampling (s)                 0.68687
time/exploration sampling (s)                4.27029
time/logging (s)                             0.0023037
time/saving (s)                              0.00106965
time/training (s)                            4.37393
time/epoch (s)                               9.33663
time/total (s)                             583.051
Epoch                                       49
---------------------------------------  ---------------
2023-08-03 20:54:49.934014 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 50 finished
---------------------------------------  ---------------
epoch                                       50
replay_buffer/size                       35500
trainer/QF Loss                            341.901
trainer/Policy Loss                       -383.533
trainer/Raw Policy Loss                   -383.533
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 376.177
trainer/Q Predictions Std                   49.688
trainer/Q Predictions Max                  941.37
trainer/Q Predictions Min                  175.329
trainer/Q Targets Mean                     376.715
trainer/Q Targets Std                       52.7926
trainer/Q Targets Max                      886.013
trainer/Q Targets Min                       97.0855
trainer/Bellman Errors Mean                341.901
trainer/Bellman Errors Std                1264.93
trainer/Bellman Errors Max               29669.5
trainer/Bellman Errors Min                   1.748e-05
trainer/Policy Action Mean                   0.252457
trainer/Policy Action Std                    0.933114
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     35500
expl/num paths total                      1775
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0142468
expl/Rewards Std                             0.0926346
expl/Rewards Max                             1.30425
expl/Rewards Min                             5.7446e-13
expl/Returns Mean                            0.284936
expl/Returns Std                             0.978122
expl/Returns Max                             4.95143
expl/Returns Min                             0.00483929
expl/Actions Mean                            0.31794
expl/Actions Std                             0.769695
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.284936
expl/env_infos/final/reward_dist Mean        0.000978178
expl/env_infos/final/reward_dist Std         0.00456605
expl/env_infos/final/reward_dist Max         0.0233348
expl/env_infos/final/reward_dist Min         8.37491e-13
expl/env_infos/initial/reward_dist Mean      0.0102418
expl/env_infos/initial/reward_dist Std       0.0127666
expl/env_infos/initial/reward_dist Max       0.0472886
expl/env_infos/initial/reward_dist Min       6.70858e-05
expl/env_infos/reward_dist Mean              0.0142468
expl/env_infos/reward_dist Std               0.0926346
expl/env_infos/reward_dist Max               1.30425
expl/env_infos/reward_dist Min               5.7446e-13
eval/num steps total                      5100
eval/num paths total                       255
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00145267
eval/Rewards Std                             0.0040551
eval/Rewards Max                             0.024564
eval/Rewards Min                             1.51762e-08
eval/Returns Mean                            0.0290534
eval/Returns Std                             0.0142975
eval/Returns Max                             0.0495337
eval/Returns Min                             0.0135182
eval/Actions Mean                            0.499236
eval/Actions Std                             0.822206
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0290534
eval/env_infos/final/reward_dist Mean        9.81614e-07
eval/env_infos/final/reward_dist Std         1.41933e-06
eval/env_infos/final/reward_dist Max         3.76038e-06
eval/env_infos/final/reward_dist Min         1.51762e-08
eval/env_infos/initial/reward_dist Mean      0.00910285
eval/env_infos/initial/reward_dist Std       0.010861
eval/env_infos/initial/reward_dist Max       0.024564
eval/env_infos/initial/reward_dist Min       8.33776e-05
eval/env_infos/reward_dist Mean              0.00145267
eval/env_infos/reward_dist Std               0.0040551
eval/env_infos/reward_dist Max               0.024564
eval/env_infos/reward_dist Min               1.51762e-08
time/data storing (s)                        0.00157004
time/evaluation sampling (s)                 0.62864
time/exploration sampling (s)                4.12177
time/logging (s)                             0.00223743
time/saving (s)                              0.00101273
time/training (s)                            4.34812
time/epoch (s)                               9.10336
time/total (s)                             592.156
Epoch                                       50
---------------------------------------  ---------------
2023-08-03 20:55:00.620658 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 51 finished
---------------------------------------  ---------------
epoch                                       51
replay_buffer/size                       36000
trainer/QF Loss                            325.49
trainer/Policy Loss                       -338.121
trainer/Raw Policy Loss                   -338.121
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 324.454
trainer/Q Predictions Std                   45.7259
trainer/Q Predictions Max                  499.96
trainer/Q Predictions Min                 -168.578
trainer/Q Targets Mean                     323.157
trainer/Q Targets Std                       48.6188
trainer/Q Targets Max                      500.676
trainer/Q Targets Min                     -194.524
trainer/Bellman Errors Mean                325.49
trainer/Bellman Errors Std                 808.645
trainer/Bellman Errors Max               19060.4
trainer/Bellman Errors Min                   6.68913e-05
trainer/Policy Action Mean                   0.242709
trainer/Policy Action Std                    0.919362
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     36000
expl/num paths total                      1800
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.020581
expl/Rewards Std                             0.126942
expl/Rewards Max                             2.68964
expl/Rewards Min                             1.64814e-11
expl/Returns Mean                            0.411619
expl/Returns Std                             0.596943
expl/Returns Max                             2.94277
expl/Returns Min                             0.0114412
expl/Actions Mean                            0.237851
expl/Actions Std                             0.782409
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.411619
expl/env_infos/final/reward_dist Mean        0.00621018
expl/env_infos/final/reward_dist Std         0.0150628
expl/env_infos/final/reward_dist Max         0.0598762
expl/env_infos/final/reward_dist Min         1.64814e-11
expl/env_infos/initial/reward_dist Mean      0.0135651
expl/env_infos/initial/reward_dist Std       0.0150834
expl/env_infos/initial/reward_dist Max       0.0522965
expl/env_infos/initial/reward_dist Min       0.000125141
expl/env_infos/reward_dist Mean              0.020581
expl/env_infos/reward_dist Std               0.126942
expl/env_infos/reward_dist Max               2.68964
expl/env_infos/reward_dist Min               1.64814e-11
eval/num steps total                      5200
eval/num paths total                       260
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0201657
eval/Rewards Std                             0.0607208
eval/Rewards Max                             0.510994
eval/Rewards Min                             3.10966e-11
eval/Returns Mean                            0.403313
eval/Returns Std                             0.343753
eval/Returns Max                             0.947805
eval/Returns Min                             0.0755966
eval/Actions Mean                            0.287638
eval/Actions Std                             0.907359
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.403313
eval/env_infos/final/reward_dist Mean        0.0154651
eval/env_infos/final/reward_dist Std         0.0308503
eval/env_infos/final/reward_dist Max         0.0771657
eval/env_infos/final/reward_dist Min         3.10966e-11
eval/env_infos/initial/reward_dist Mean      0.0176613
eval/env_infos/initial/reward_dist Std       0.0146592
eval/env_infos/initial/reward_dist Max       0.0457134
eval/env_infos/initial/reward_dist Min       0.00533807
eval/env_infos/reward_dist Mean              0.0201657
eval/env_infos/reward_dist Std               0.0607208
eval/env_infos/reward_dist Max               0.510994
eval/env_infos/reward_dist Min               3.10966e-11
time/data storing (s)                        0.00216285
time/evaluation sampling (s)                 0.858973
time/exploration sampling (s)                5.38838
time/logging (s)                             0.00227124
time/saving (s)                              0.00103288
time/training (s)                            4.43127
time/epoch (s)                              10.6841
time/total (s)                             602.843
Epoch                                       51
---------------------------------------  ---------------
2023-08-03 20:55:11.395931 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 52 finished
---------------------------------------  ---------------
epoch                                       52
replay_buffer/size                       36500
trainer/QF Loss                            199.277
trainer/Policy Loss                       -281.871
trainer/Raw Policy Loss                   -281.871
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 272.953
trainer/Q Predictions Std                   40.5862
trainer/Q Predictions Max                  418.778
trainer/Q Predictions Min                 -196.507
trainer/Q Targets Mean                     271.734
trainer/Q Targets Std                       43.2441
trainer/Q Targets Max                      420.085
trainer/Q Targets Min                     -224.67
trainer/Bellman Errors Mean                199.277
trainer/Bellman Errors Std                 419.075
trainer/Bellman Errors Max                8695.14
trainer/Bellman Errors Min                   3.54135e-05
trainer/Policy Action Mean                   0.337337
trainer/Policy Action Std                    0.884806
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     36500
expl/num paths total                      1825
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0161749
expl/Rewards Std                             0.116235
expl/Rewards Max                             1.62532
expl/Rewards Min                             5.36822e-12
expl/Returns Mean                            0.323498
expl/Returns Std                             0.653908
expl/Returns Max                             2.87798
expl/Returns Min                             0.0144624
expl/Actions Mean                            0.287754
expl/Actions Std                             0.763741
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.323498
expl/env_infos/final/reward_dist Mean        0.00129269
expl/env_infos/final/reward_dist Std         0.00373807
expl/env_infos/final/reward_dist Max         0.0188983
expl/env_infos/final/reward_dist Min         5.36822e-12
expl/env_infos/initial/reward_dist Mean      0.006233
expl/env_infos/initial/reward_dist Std       0.00928144
expl/env_infos/initial/reward_dist Max       0.033864
expl/env_infos/initial/reward_dist Min       0.000142874
expl/env_infos/reward_dist Mean              0.0161749
expl/env_infos/reward_dist Std               0.116235
expl/env_infos/reward_dist Max               1.62532
expl/env_infos/reward_dist Min               5.36822e-12
eval/num steps total                      5300
eval/num paths total                       265
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0211035
eval/Rewards Std                             0.0957078
eval/Rewards Max                             0.902452
eval/Rewards Min                             1.73248e-10
eval/Returns Mean                            0.422069
eval/Returns Std                             0.432749
eval/Returns Max                             1.19974
eval/Returns Min                             0.0161035
eval/Actions Mean                            0.380718
eval/Actions Std                             0.854213
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.422069
eval/env_infos/final/reward_dist Mean        0.000629898
eval/env_infos/final/reward_dist Std         0.000342943
eval/env_infos/final/reward_dist Max         0.00103433
eval/env_infos/final/reward_dist Min         2.98181e-09
eval/env_infos/initial/reward_dist Mean      0.0176609
eval/env_infos/initial/reward_dist Std       0.0186257
eval/env_infos/initial/reward_dist Max       0.0417939
eval/env_infos/initial/reward_dist Min       4.45046e-05
eval/env_infos/reward_dist Mean              0.0211035
eval/env_infos/reward_dist Std               0.0957078
eval/env_infos/reward_dist Max               0.902452
eval/env_infos/reward_dist Min               1.73248e-10
time/data storing (s)                        0.00167255
time/evaluation sampling (s)                 0.872567
time/exploration sampling (s)                5.5256
time/logging (s)                             0.00235234
time/saving (s)                              0.001035
time/training (s)                            4.36951
time/epoch (s)                              10.7727
time/total (s)                             613.617
Epoch                                       52
---------------------------------------  ---------------
2023-08-03 20:55:21.806730 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 53 finished
---------------------------------------  ---------------
epoch                                       53
replay_buffer/size                       37000
trainer/QF Loss                            114.294
trainer/Policy Loss                       -191.98
trainer/Raw Policy Loss                   -191.98
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 186.378
trainer/Q Predictions Std                   26.7299
trainer/Q Predictions Max                  457.935
trainer/Q Predictions Min                 -108.669
trainer/Q Targets Mean                     186.092
trainer/Q Targets Std                       28.8335
trainer/Q Targets Max                      450.856
trainer/Q Targets Min                     -140.914
trainer/Bellman Errors Mean                114.294
trainer/Bellman Errors Std                 306.173
trainer/Bellman Errors Max                9678.25
trainer/Bellman Errors Min                   3.93484e-08
trainer/Policy Action Mean                   0.177998
trainer/Policy Action Std                    0.938514
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     37000
expl/num paths total                      1850
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.237794
expl/Rewards Std                             1.29063
expl/Rewards Max                            10
expl/Rewards Min                             1.21797e-11
expl/Returns Mean                            4.75589
expl/Returns Std                            13.9458
expl/Returns Max                            70.762
expl/Returns Min                             0.0488173
expl/Actions Mean                            0.0860798
expl/Actions Std                             0.81752
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         4.75589
expl/env_infos/final/reward_dist Mean        0.419463
expl/env_infos/final/reward_dist Std         1.95622
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         6.02251e-11
expl/env_infos/initial/reward_dist Mean      0.0220993
expl/env_infos/initial/reward_dist Std       0.020042
expl/env_infos/initial/reward_dist Max       0.064424
expl/env_infos/initial/reward_dist Min       0.000121869
expl/env_infos/reward_dist Mean              0.237794
expl/env_infos/reward_dist Std               1.29063
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.21797e-11
eval/num steps total                      5400
eval/num paths total                       270
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.923394
eval/Rewards Std                             2.85642
eval/Rewards Max                            10
eval/Rewards Min                             3.9235e-07
eval/Returns Mean                           18.4679
eval/Returns Std                            35.9733
eval/Returns Max                            90.4091
eval/Returns Min                             0.113688
eval/Actions Mean                            0.133113
eval/Actions Std                             0.929147
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                        18.4679
eval/env_infos/final/reward_dist Mean        2.04402
eval/env_infos/final/reward_dist Std         3.97801
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.030222
eval/env_infos/initial/reward_dist Mean      0.0169042
eval/env_infos/initial/reward_dist Std       0.0137201
eval/env_infos/initial/reward_dist Max       0.0354686
eval/env_infos/initial/reward_dist Min       0.000189672
eval/env_infos/reward_dist Mean              0.923394
eval/env_infos/reward_dist Std               2.85642
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               3.9235e-07
time/data storing (s)                        0.00157369
time/evaluation sampling (s)                 0.895494
time/exploration sampling (s)                4.8101
time/logging (s)                             0.0023046
time/saving (s)                              0.00100102
time/training (s)                            4.69688
time/epoch (s)                              10.4074
time/total (s)                             624.027
Epoch                                       53
---------------------------------------  ---------------
2023-08-03 20:55:31.217173 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 54 finished
---------------------------------------  ---------------
epoch                                       54
replay_buffer/size                       37500
trainer/QF Loss                             93.3314
trainer/Policy Loss                       -158.213
trainer/Raw Policy Loss                   -158.213
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 153.425
trainer/Q Predictions Std                   32.6873
trainer/Q Predictions Max                  618.599
trainer/Q Predictions Min                 -155.669
trainer/Q Targets Mean                     153.154
trainer/Q Targets Std                       33.2101
trainer/Q Targets Max                      552.994
trainer/Q Targets Min                     -165.551
trainer/Bellman Errors Mean                 93.3314
trainer/Bellman Errors Std                 325.648
trainer/Bellman Errors Max                6130.39
trainer/Bellman Errors Min                   1.01703e-05
trainer/Policy Action Mean                   0.247977
trainer/Policy Action Std                    0.931588
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     37500
expl/num paths total                      1875
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00995612
expl/Rewards Std                             0.0483042
expl/Rewards Max                             0.550826
expl/Rewards Min                             7.33411e-14
expl/Returns Mean                            0.199122
expl/Returns Std                             0.245476
expl/Returns Max                             0.944184
expl/Returns Min                             0.0073044
expl/Actions Mean                            0.0571971
expl/Actions Std                             0.823586
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.199122
expl/env_infos/final/reward_dist Mean        3.15397e-05
expl/env_infos/final/reward_dist Std         0.000153503
expl/env_infos/final/reward_dist Max         0.000783531
expl/env_infos/final/reward_dist Min         7.32474e-13
expl/env_infos/initial/reward_dist Mean      0.0219272
expl/env_infos/initial/reward_dist Std       0.0226566
expl/env_infos/initial/reward_dist Max       0.0843453
expl/env_infos/initial/reward_dist Min       2.37221e-05
expl/env_infos/reward_dist Mean              0.00995612
expl/env_infos/reward_dist Std               0.0483042
expl/env_infos/reward_dist Max               0.550826
expl/env_infos/reward_dist Min               7.33411e-14
eval/num steps total                      5500
eval/num paths total                       275
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0100108
eval/Rewards Std                             0.0349735
eval/Rewards Max                             0.228201
eval/Rewards Min                             7.78186e-12
eval/Returns Mean                            0.200217
eval/Returns Std                             0.170045
eval/Returns Max                             0.503216
eval/Returns Min                             0.0509075
eval/Actions Mean                            0.1226
eval/Actions Std                             0.95665
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.200217
eval/env_infos/final/reward_dist Mean        0.000963963
eval/env_infos/final/reward_dist Std         0.00192792
eval/env_infos/final/reward_dist Max         0.00481981
eval/env_infos/final/reward_dist Min         7.78186e-12
eval/env_infos/initial/reward_dist Mean      0.0153716
eval/env_infos/initial/reward_dist Std       0.0125759
eval/env_infos/initial/reward_dist Max       0.0302137
eval/env_infos/initial/reward_dist Min       0.00021067
eval/env_infos/reward_dist Mean              0.0100108
eval/env_infos/reward_dist Std               0.0349735
eval/env_infos/reward_dist Max               0.228201
eval/env_infos/reward_dist Min               7.78186e-12
time/data storing (s)                        0.00149621
time/evaluation sampling (s)                 1.05638
time/exploration sampling (s)                4.11318
time/logging (s)                             0.00229316
time/saving (s)                              0.00102268
time/training (s)                            4.23339
time/epoch (s)                               9.40777
time/total (s)                             633.437
Epoch                                       54
---------------------------------------  ---------------
2023-08-03 20:55:40.743137 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 55 finished
---------------------------------------  ---------------
epoch                                       55
replay_buffer/size                       38000
trainer/QF Loss                            480.267
trainer/Policy Loss                       -189.554
trainer/Raw Policy Loss                   -189.554
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 166.348
trainer/Q Predictions Std                   58.3146
trainer/Q Predictions Max                  731.863
trainer/Q Predictions Min                 -192.518
trainer/Q Targets Mean                     166.539
trainer/Q Targets Std                       61.936
trainer/Q Targets Max                      741.371
trainer/Q Targets Min                     -190.728
trainer/Bellman Errors Mean                480.267
trainer/Bellman Errors Std                1690.26
trainer/Bellman Errors Max               43597.6
trainer/Bellman Errors Min                   0.000125097
trainer/Policy Action Mean                   0.0437718
trainer/Policy Action Std                    0.975267
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     38000
expl/num paths total                      1900
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0777983
expl/Rewards Std                             0.259154
expl/Rewards Max                             3.53217
expl/Rewards Min                             5.14188e-11
expl/Returns Mean                            1.55597
expl/Returns Std                             1.67157
expl/Returns Max                             7.61584
expl/Returns Min                             0.0911531
expl/Actions Mean                            0.0476782
expl/Actions Std                             0.81564
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         1.55597
expl/env_infos/final/reward_dist Mean        0.0434302
expl/env_infos/final/reward_dist Std         0.111521
expl/env_infos/final/reward_dist Max         0.51841
expl/env_infos/final/reward_dist Min         5.14188e-11
expl/env_infos/initial/reward_dist Mean      0.0247194
expl/env_infos/initial/reward_dist Std       0.0317569
expl/env_infos/initial/reward_dist Max       0.142227
expl/env_infos/initial/reward_dist Min       4.96021e-05
expl/env_infos/reward_dist Mean              0.0777983
expl/env_infos/reward_dist Std               0.259154
expl/env_infos/reward_dist Max               3.53217
expl/env_infos/reward_dist Min               5.14188e-11
eval/num steps total                      5600
eval/num paths total                       280
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.853765
eval/Rewards Std                             2.70217
eval/Rewards Max                            10
eval/Rewards Min                             7.98551e-07
eval/Returns Mean                           17.0753
eval/Returns Std                            31.9672
eval/Returns Max                            81.0005
eval/Returns Min                             0.516354
eval/Actions Mean                            0.0886074
eval/Actions Std                             0.954045
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                        17.0753
eval/env_infos/final/reward_dist Mean        2.03317
eval/env_infos/final/reward_dist Std         3.98391
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.62016e-06
eval/env_infos/initial/reward_dist Mean      0.00380935
eval/env_infos/initial/reward_dist Std       0.0037244
eval/env_infos/initial/reward_dist Max       0.0100223
eval/env_infos/initial/reward_dist Min       4.10997e-05
eval/env_infos/reward_dist Mean              0.853765
eval/env_infos/reward_dist Std               2.70217
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               7.98551e-07
time/data storing (s)                        0.00154797
time/evaluation sampling (s)                 0.919147
time/exploration sampling (s)                4.33085
time/logging (s)                             0.00227491
time/saving (s)                              0.00101801
time/training (s)                            4.26835
time/epoch (s)                               9.52319
time/total (s)                             642.963
Epoch                                       55
---------------------------------------  ---------------
2023-08-03 20:55:51.186004 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 56 finished
---------------------------------------  ---------------
epoch                                       56
replay_buffer/size                       38500
trainer/QF Loss                            462.229
trainer/Policy Loss                       -230.576
trainer/Raw Policy Loss                   -230.576
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 207.619
trainer/Q Predictions Std                   71.0832
trainer/Q Predictions Max                  895.112
trainer/Q Predictions Min                  -80.6964
trainer/Q Targets Mean                     209.26
trainer/Q Targets Std                       74.8493
trainer/Q Targets Max                      884.593
trainer/Q Targets Min                      -81.1803
trainer/Bellman Errors Mean                462.229
trainer/Bellman Errors Std                1173.17
trainer/Bellman Errors Max               19928.2
trainer/Bellman Errors Min                   4.84139e-05
trainer/Policy Action Mean                  -0.0876457
trainer/Policy Action Std                    0.963627
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     38500
expl/num paths total                      1925
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0534165
expl/Rewards Std                             0.232177
expl/Rewards Max                             2.98478
expl/Rewards Min                             1.25398e-18
expl/Returns Mean                            1.06833
expl/Returns Std                             1.5686
expl/Returns Max                             6.40278
expl/Returns Min                             0.00680865
expl/Actions Mean                           -0.0944654
expl/Actions Std                             0.802907
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         1.06833
expl/env_infos/final/reward_dist Mean        0.0391146
expl/env_infos/final/reward_dist Std         0.0867492
expl/env_infos/final/reward_dist Max         0.318707
expl/env_infos/final/reward_dist Min         1.25398e-18
expl/env_infos/initial/reward_dist Mean      0.0112189
expl/env_infos/initial/reward_dist Std       0.0148982
expl/env_infos/initial/reward_dist Max       0.0524053
expl/env_infos/initial/reward_dist Min       2.01577e-05
expl/env_infos/reward_dist Mean              0.0534165
expl/env_infos/reward_dist Std               0.232177
expl/env_infos/reward_dist Max               2.98478
expl/env_infos/reward_dist Min               1.25398e-18
eval/num steps total                      5700
eval/num paths total                       285
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.138386
eval/Rewards Std                             1.03759
eval/Rewards Max                            10
eval/Rewards Min                             1.44723e-14
eval/Returns Mean                            2.76773
eval/Returns Std                             5.46224
eval/Returns Max                            13.692
eval/Returns Min                             0.00712961
eval/Actions Mean                           -0.132391
eval/Actions Std                             0.949869
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         2.76773
eval/env_infos/final/reward_dist Mean        2
eval/env_infos/final/reward_dist Std         4
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.44723e-14
eval/env_infos/initial/reward_dist Mean      0.00386989
eval/env_infos/initial/reward_dist Std       0.00281827
eval/env_infos/initial/reward_dist Max       0.007604
eval/env_infos/initial/reward_dist Min       0.000133668
eval/env_infos/reward_dist Mean              0.138386
eval/env_infos/reward_dist Std               1.03759
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               1.44723e-14
time/data storing (s)                        0.00169648
time/evaluation sampling (s)                 0.751842
time/exploration sampling (s)                4.49099
time/logging (s)                             0.00286721
time/saving (s)                              0.00112415
time/training (s)                            5.1922
time/epoch (s)                              10.4407
time/total (s)                             653.406
Epoch                                       56
---------------------------------------  ---------------
2023-08-03 20:56:00.365887 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 57 finished
---------------------------------------  ---------------
epoch                                       57
replay_buffer/size                       39000
trainer/QF Loss                            462.383
trainer/Policy Loss                       -283.503
trainer/Raw Policy Loss                   -283.503
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 262.333
trainer/Q Predictions Std                   79.1768
trainer/Q Predictions Max                  922.078
trainer/Q Predictions Min                   15.7071
trainer/Q Targets Mean                     260.761
trainer/Q Targets Std                       81.6948
trainer/Q Targets Max                      929.615
trainer/Q Targets Min                       17.5936
trainer/Bellman Errors Mean                462.383
trainer/Bellman Errors Std                1673.54
trainer/Bellman Errors Max               35466.4
trainer/Bellman Errors Min                   4.56348e-06
trainer/Policy Action Mean                  -0.0610897
trainer/Policy Action Std                    0.967208
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     39000
expl/num paths total                      1950
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00894366
expl/Rewards Std                             0.0227978
expl/Rewards Max                             0.241237
expl/Rewards Min                             3.75448e-10
expl/Returns Mean                            0.178873
expl/Returns Std                             0.234445
expl/Returns Max                             1.04315
expl/Returns Min                             0.0201678
expl/Actions Mean                           -0.0600243
expl/Actions Std                             0.817366
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.178873
expl/env_infos/final/reward_dist Mean        0.0232167
expl/env_infos/final/reward_dist Std         0.058987
expl/env_infos/final/reward_dist Max         0.241237
expl/env_infos/final/reward_dist Min         3.75448e-10
expl/env_infos/initial/reward_dist Mean      0.0128989
expl/env_infos/initial/reward_dist Std       0.0151052
expl/env_infos/initial/reward_dist Max       0.0634451
expl/env_infos/initial/reward_dist Min       6.89327e-05
expl/env_infos/reward_dist Mean              0.00894366
expl/env_infos/reward_dist Std               0.0227978
expl/env_infos/reward_dist Max               0.241237
expl/env_infos/reward_dist Min               3.75448e-10
eval/num steps total                      5800
eval/num paths total                       290
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0118902
eval/Rewards Std                             0.0585277
eval/Rewards Max                             0.585001
eval/Rewards Min                             2.04385e-05
eval/Returns Mean                            0.237805
eval/Returns Std                             0.26433
eval/Returns Max                             0.762114
eval/Returns Min                             0.0733017
eval/Actions Mean                           -0.0867364
eval/Actions Std                             0.937326
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.237805
eval/env_infos/final/reward_dist Mean        0.122835
eval/env_infos/final/reward_dist Std         0.231184
eval/env_infos/final/reward_dist Max         0.585001
eval/env_infos/final/reward_dist Min         8.556e-05
eval/env_infos/initial/reward_dist Mean      0.0203847
eval/env_infos/initial/reward_dist Std       0.025054
eval/env_infos/initial/reward_dist Max       0.0624269
eval/env_infos/initial/reward_dist Min       4.04894e-05
eval/env_infos/reward_dist Mean              0.0118902
eval/env_infos/reward_dist Std               0.0585277
eval/env_infos/reward_dist Max               0.585001
eval/env_infos/reward_dist Min               2.04385e-05
time/data storing (s)                        0.00157296
time/evaluation sampling (s)                 0.712495
time/exploration sampling (s)                3.98223
time/logging (s)                             0.0028666
time/saving (s)                              0.00116077
time/training (s)                            4.47606
time/epoch (s)                               9.17639
time/total (s)                             662.584
Epoch                                       57
---------------------------------------  ---------------
2023-08-03 20:56:09.554453 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 58 finished
---------------------------------------  ---------------
epoch                                       58
replay_buffer/size                       39500
trainer/QF Loss                            539.809
trainer/Policy Loss                       -324.253
trainer/Raw Policy Loss                   -324.253
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 298.643
trainer/Q Predictions Std                   71.7325
trainer/Q Predictions Max                  905.782
trainer/Q Predictions Min                  -67.2053
trainer/Q Targets Mean                     297.987
trainer/Q Targets Std                       74.8799
trainer/Q Targets Max                      940.722
trainer/Q Targets Min                      -78.6864
trainer/Bellman Errors Mean                539.809
trainer/Bellman Errors Std                1641.96
trainer/Bellman Errors Max               41569.9
trainer/Bellman Errors Min                   6.992e-05
trainer/Policy Action Mean                  -0.0957585
trainer/Policy Action Std                    0.974233
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     39500
expl/num paths total                      1975
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0121734
expl/Rewards Std                             0.044075
expl/Rewards Max                             0.515384
expl/Rewards Min                             4.94873e-11
expl/Returns Mean                            0.243468
expl/Returns Std                             0.560589
expl/Returns Max                             2.36911
expl/Returns Min                             0.0168776
expl/Actions Mean                           -0.0921884
expl/Actions Std                             0.826561
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.243468
expl/env_infos/final/reward_dist Mean        0.023803
expl/env_infos/final/reward_dist Std         0.0654324
expl/env_infos/final/reward_dist Max         0.301899
expl/env_infos/final/reward_dist Min         3.91329e-10
expl/env_infos/initial/reward_dist Mean      0.00559677
expl/env_infos/initial/reward_dist Std       0.00859605
expl/env_infos/initial/reward_dist Max       0.0341521
expl/env_infos/initial/reward_dist Min       2.3343e-05
expl/env_infos/reward_dist Mean              0.0121734
expl/env_infos/reward_dist Std               0.044075
expl/env_infos/reward_dist Max               0.515384
expl/env_infos/reward_dist Min               4.94873e-11
eval/num steps total                      5900
eval/num paths total                       295
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0374039
eval/Rewards Std                             0.148571
eval/Rewards Max                             0.965275
eval/Rewards Min                             7.04081e-07
eval/Returns Mean                            0.748078
eval/Returns Std                             0.894101
eval/Returns Max                             2.21064
eval/Returns Min                             0.0201576
eval/Actions Mean                           -0.104719
eval/Actions Std                             0.958034
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.748078
eval/env_infos/final/reward_dist Mean        0.0485389
eval/env_infos/final/reward_dist Std         0.0704247
eval/env_infos/final/reward_dist Max         0.187729
eval/env_infos/final/reward_dist Min         3.10011e-06
eval/env_infos/initial/reward_dist Mean      0.00320311
eval/env_infos/initial/reward_dist Std       0.00263353
eval/env_infos/initial/reward_dist Max       0.00726951
eval/env_infos/initial/reward_dist Min       0.000274149
eval/env_infos/reward_dist Mean              0.0374039
eval/env_infos/reward_dist Std               0.148571
eval/env_infos/reward_dist Max               0.965275
eval/env_infos/reward_dist Min               7.04081e-07
time/data storing (s)                        0.0029153
time/evaluation sampling (s)                 0.754086
time/exploration sampling (s)                4.04887
time/logging (s)                             0.00224343
time/saving (s)                              0.00100924
time/training (s)                            4.37532
time/epoch (s)                               9.18444
time/total (s)                             671.771
Epoch                                       58
---------------------------------------  ---------------
2023-08-03 20:56:19.737963 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 59 finished
---------------------------------------  ----------------
epoch                                        59
replay_buffer/size                        40000
trainer/QF Loss                            4907.78
trainer/Policy Loss                        -643.676
trainer/Raw Policy Loss                    -643.676
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                  551.151
trainer/Q Predictions Std                   187.537
trainer/Q Predictions Max                  2354.59
trainer/Q Predictions Min                   -59.6504
trainer/Q Targets Mean                      548.757
trainer/Q Targets Std                       204.017
trainer/Q Targets Max                      2417.16
trainer/Q Targets Min                       -58.7679
trainer/Bellman Errors Mean                4907.78
trainer/Bellman Errors Std                18449.2
trainer/Bellman Errors Max               548937
trainer/Bellman Errors Min                    8.3819e-07
trainer/Policy Action Mean                   -0.214427
trainer/Policy Action Std                     0.949699
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      40000
expl/num paths total                       2000
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.128155
expl/Rewards Std                              0.54473
expl/Rewards Max                              3.74603
expl/Rewards Min                              1.482e-06
expl/Returns Mean                             2.5631
expl/Returns Std                              9.17296
expl/Returns Max                             46.4464
expl/Returns Min                              0.0138471
expl/Actions Mean                            -0.244528
expl/Actions Std                              0.772029
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          2.5631
expl/env_infos/final/reward_dist Mean         0.121897
expl/env_infos/final/reward_dist Std          0.376484
expl/env_infos/final/reward_dist Max          1.78506
expl/env_infos/final/reward_dist Min          9.96394e-06
expl/env_infos/initial/reward_dist Mean       0.0124731
expl/env_infos/initial/reward_dist Std        0.0189691
expl/env_infos/initial/reward_dist Max        0.0626971
expl/env_infos/initial/reward_dist Min        2.13234e-05
expl/env_infos/reward_dist Mean               0.128155
expl/env_infos/reward_dist Std                0.54473
expl/env_infos/reward_dist Max                3.74603
expl/env_infos/reward_dist Min                1.482e-06
eval/num steps total                       6000
eval/num paths total                        300
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.00991812
eval/Rewards Std                              0.0216079
eval/Rewards Max                              0.113104
eval/Rewards Min                              9.40287e-06
eval/Returns Mean                             0.198362
eval/Returns Std                              0.0578019
eval/Returns Max                              0.279173
eval/Returns Min                              0.102148
eval/Actions Mean                            -0.321535
eval/Actions Std                              0.895857
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.198362
eval/env_infos/final/reward_dist Mean         0.0246014
eval/env_infos/final/reward_dist Std          0.035283
eval/env_infos/final/reward_dist Max          0.091838
eval/env_infos/final/reward_dist Min          0.000163586
eval/env_infos/initial/reward_dist Mean       0.0210715
eval/env_infos/initial/reward_dist Std        0.0256787
eval/env_infos/initial/reward_dist Max        0.0526137
eval/env_infos/initial/reward_dist Min        1.59573e-05
eval/env_infos/reward_dist Mean               0.00991812
eval/env_infos/reward_dist Std                0.0216079
eval/env_infos/reward_dist Max                0.113104
eval/env_infos/reward_dist Min                9.40287e-06
time/data storing (s)                         0.00215215
time/evaluation sampling (s)                  0.731994
time/exploration sampling (s)                 4.44078
time/logging (s)                              0.00221226
time/saving (s)                               0.00102071
time/training (s)                             5.0027
time/epoch (s)                               10.1809
time/total (s)                              681.954
Epoch                                        59
---------------------------------------  ----------------
2023-08-03 20:56:29.954921 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 60 finished
---------------------------------------  ---------------
epoch                                       60
replay_buffer/size                       40500
trainer/QF Loss                          19720.3
trainer/Policy Loss                      -1120.44
trainer/Raw Policy Loss                  -1120.44
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 977.533
trainer/Q Predictions Std                  449.368
trainer/Q Predictions Max                 7934.31
trainer/Q Predictions Min                 -225.352
trainer/Q Targets Mean                     972.071
trainer/Q Targets Std                      468.97
trainer/Q Targets Max                     7941.98
trainer/Q Targets Min                     -205.735
trainer/Bellman Errors Mean              19720.3
trainer/Bellman Errors Std               85871.9
trainer/Bellman Errors Max                   1.83032e+06
trainer/Bellman Errors Min                   6.19926e-05
trainer/Policy Action Mean                  -0.287863
trainer/Policy Action Std                    0.937619
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     40500
expl/num paths total                      2025
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0345459
expl/Rewards Std                             0.194052
expl/Rewards Max                             3.4383
expl/Rewards Min                             1.10709e-09
expl/Returns Mean                            0.690918
expl/Returns Std                             0.850951
expl/Returns Max                             3.91185
expl/Returns Min                             0.0797711
expl/Actions Mean                           -0.174007
expl/Actions Std                             0.808772
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.690918
expl/env_infos/final/reward_dist Mean        0.0166864
expl/env_infos/final/reward_dist Std         0.0378697
expl/env_infos/final/reward_dist Max         0.133913
expl/env_infos/final/reward_dist Min         1.10709e-09
expl/env_infos/initial/reward_dist Mean      0.0144563
expl/env_infos/initial/reward_dist Std       0.0151496
expl/env_infos/initial/reward_dist Max       0.0529823
expl/env_infos/initial/reward_dist Min       0.000127159
expl/env_infos/reward_dist Mean              0.0345459
expl/env_infos/reward_dist Std               0.194052
expl/env_infos/reward_dist Max               3.4383
expl/env_infos/reward_dist Min               1.10709e-09
eval/num steps total                      6100
eval/num paths total                       305
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0224875
eval/Rewards Std                             0.0705107
eval/Rewards Max                             0.633863
eval/Rewards Min                             6.25568e-06
eval/Returns Mean                            0.449751
eval/Returns Std                             0.320701
eval/Returns Max                             0.867611
eval/Returns Min                             0.117459
eval/Actions Mean                           -0.199138
eval/Actions Std                             0.954227
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.449751
eval/env_infos/final/reward_dist Mean        0.00532199
eval/env_infos/final/reward_dist Std         0.00961175
eval/env_infos/final/reward_dist Max         0.0245294
eval/env_infos/final/reward_dist Min         6.25568e-06
eval/env_infos/initial/reward_dist Mean      0.0253233
eval/env_infos/initial/reward_dist Std       0.0429233
eval/env_infos/initial/reward_dist Max       0.110971
eval/env_infos/initial/reward_dist Min       0.000421851
eval/env_infos/reward_dist Mean              0.0224875
eval/env_infos/reward_dist Std               0.0705107
eval/env_infos/reward_dist Max               0.633863
eval/env_infos/reward_dist Min               6.25568e-06
time/data storing (s)                        0.00214884
time/evaluation sampling (s)                 0.691822
time/exploration sampling (s)                5.19115
time/logging (s)                             0.00224251
time/saving (s)                              0.00103583
time/training (s)                            4.32596
time/epoch (s)                              10.2144
time/total (s)                             692.171
Epoch                                       60
---------------------------------------  ---------------
2023-08-03 20:56:40.135646 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 61 finished
---------------------------------------  ----------------
epoch                                        61
replay_buffer/size                        41000
trainer/QF Loss                           58362.7
trainer/Policy Loss                       -1930.77
trainer/Raw Policy Loss                   -1930.77
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 1699.48
trainer/Q Predictions Std                   862.347
trainer/Q Predictions Max                 15814.2
trainer/Q Predictions Min                   270.92
trainer/Q Targets Mean                     1711.59
trainer/Q Targets Std                       910.749
trainer/Q Targets Max                     15494.2
trainer/Q Targets Min                       352.693
trainer/Bellman Errors Mean               58362.7
trainer/Bellman Errors Std               266893
trainer/Bellman Errors Max                    7.72837e+06
trainer/Bellman Errors Min                    0.0034118
trainer/Policy Action Mean                   -0.445758
trainer/Policy Action Std                     0.870207
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      41000
expl/num paths total                       2050
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0512238
expl/Rewards Std                              0.15979
expl/Rewards Max                              2.10136
expl/Rewards Min                              2.44837e-07
expl/Returns Mean                             1.02448
expl/Returns Std                              1.91524
expl/Returns Max                              7.97701
expl/Returns Min                              0.0133843
expl/Actions Mean                            -0.241233
expl/Actions Std                              0.793884
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          1.02448
expl/env_infos/final/reward_dist Mean         0.0564866
expl/env_infos/final/reward_dist Std          0.096707
expl/env_infos/final/reward_dist Max          0.415329
expl/env_infos/final/reward_dist Min          2.44837e-07
expl/env_infos/initial/reward_dist Mean       0.00969269
expl/env_infos/initial/reward_dist Std        0.0167062
expl/env_infos/initial/reward_dist Max        0.0712674
expl/env_infos/initial/reward_dist Min        6.29459e-05
expl/env_infos/reward_dist Mean               0.0512238
expl/env_infos/reward_dist Std                0.15979
expl/env_infos/reward_dist Max                2.10136
expl/env_infos/reward_dist Min                2.44837e-07
eval/num steps total                       6200
eval/num paths total                        310
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0472359
eval/Rewards Std                              0.0772111
eval/Rewards Max                              0.431591
eval/Rewards Min                              5.16613e-05
eval/Returns Mean                             0.944718
eval/Returns Std                              0.444635
eval/Returns Max                              1.51724
eval/Returns Min                              0.229268
eval/Actions Mean                            -0.368876
eval/Actions Std                              0.881246
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.944718
eval/env_infos/final/reward_dist Mean         0.00578498
eval/env_infos/final/reward_dist Std          0.00627834
eval/env_infos/final/reward_dist Max          0.0179856
eval/env_infos/final/reward_dist Min          0.000140721
eval/env_infos/initial/reward_dist Mean       0.00513448
eval/env_infos/initial/reward_dist Std        0.00772888
eval/env_infos/initial/reward_dist Max        0.0204629
eval/env_infos/initial/reward_dist Min        0.000317669
eval/env_infos/reward_dist Mean               0.0472359
eval/env_infos/reward_dist Std                0.0772111
eval/env_infos/reward_dist Max                0.431591
eval/env_infos/reward_dist Min                5.16613e-05
time/data storing (s)                         0.00214381
time/evaluation sampling (s)                  0.75233
time/exploration sampling (s)                 4.80116
time/logging (s)                              0.00228943
time/saving (s)                               0.00100608
time/training (s)                             4.6192
time/epoch (s)                               10.1781
time/total (s)                              702.351
Epoch                                        61
---------------------------------------  ----------------
2023-08-03 20:56:49.018104 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 62 finished
---------------------------------------  ----------------
epoch                                        62
replay_buffer/size                        41500
trainer/QF Loss                           49199.2
trainer/Policy Loss                       -2827.25
trainer/Raw Policy Loss                   -2827.25
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 2611.64
trainer/Q Predictions Std                   778.044
trainer/Q Predictions Max                 13364.6
trainer/Q Predictions Min                  1118.39
trainer/Q Targets Mean                     2610.23
trainer/Q Targets Std                       818.465
trainer/Q Targets Max                     13815.9
trainer/Q Targets Min                      1089.08
trainer/Bellman Errors Mean               49199.2
trainer/Bellman Errors Std               234547
trainer/Bellman Errors Max                    6.66259e+06
trainer/Bellman Errors Min                    0.000120699
trainer/Policy Action Mean                   -0.412336
trainer/Policy Action Std                     0.871932
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      41500
expl/num paths total                       2075
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.119845
expl/Rewards Std                              0.277964
expl/Rewards Max                              2.94399
expl/Rewards Min                              4.74479e-06
expl/Returns Mean                             2.3969
expl/Returns Std                              2.92682
expl/Returns Max                             10.459
expl/Returns Min                              0.0440647
expl/Actions Mean                            -0.29721
expl/Actions Std                              0.760611
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          2.3969
expl/env_infos/final/reward_dist Mean         0.0851896
expl/env_infos/final/reward_dist Std          0.153554
expl/env_infos/final/reward_dist Max          0.626452
expl/env_infos/final/reward_dist Min          6.45898e-05
expl/env_infos/initial/reward_dist Mean       0.0269847
expl/env_infos/initial/reward_dist Std        0.0242026
expl/env_infos/initial/reward_dist Max        0.0777988
expl/env_infos/initial/reward_dist Min        4.33792e-05
expl/env_infos/reward_dist Mean               0.119845
expl/env_infos/reward_dist Std                0.277964
expl/env_infos/reward_dist Max                2.94399
expl/env_infos/reward_dist Min                4.74479e-06
eval/num steps total                       6300
eval/num paths total                        315
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0596946
eval/Rewards Std                              0.119908
eval/Rewards Max                              0.868761
eval/Rewards Min                              1.99056e-05
eval/Returns Mean                             1.19389
eval/Returns Std                              0.668255
eval/Returns Max                              2.16162
eval/Returns Min                              0.382269
eval/Actions Mean                            -0.323049
eval/Actions Std                              0.906292
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          1.19389
eval/env_infos/final/reward_dist Mean         0.0158125
eval/env_infos/final/reward_dist Std          0.0214102
eval/env_infos/final/reward_dist Max          0.0573834
eval/env_infos/final/reward_dist Min          0.000271788
eval/env_infos/initial/reward_dist Mean       0.0228579
eval/env_infos/initial/reward_dist Std        0.0208669
eval/env_infos/initial/reward_dist Max        0.0540526
eval/env_infos/initial/reward_dist Min        0.000425958
eval/env_infos/reward_dist Mean               0.0596946
eval/env_infos/reward_dist Std                0.119908
eval/env_infos/reward_dist Max                0.868761
eval/env_infos/reward_dist Min                1.99056e-05
time/data storing (s)                         0.00152118
time/evaluation sampling (s)                  0.680077
time/exploration sampling (s)                 4.58721
time/logging (s)                              0.00226257
time/saving (s)                               0.000982973
time/training (s)                             3.60766
time/epoch (s)                                8.87972
time/total (s)                              711.232
Epoch                                        62
---------------------------------------  ----------------
2023-08-03 20:56:59.052124 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 63 finished
---------------------------------------  ----------------
epoch                                        63
replay_buffer/size                        42000
trainer/QF Loss                          108537
trainer/Policy Loss                       -3970.11
trainer/Raw Policy Loss                   -3970.11
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 3529.23
trainer/Q Predictions Std                   866.899
trainer/Q Predictions Max                  8583.38
trainer/Q Predictions Min                  1248.42
trainer/Q Targets Mean                     3529.21
trainer/Q Targets Std                       929.833
trainer/Q Targets Max                      8162.87
trainer/Q Targets Min                      1005.3
trainer/Bellman Errors Mean              108537
trainer/Bellman Errors Std               426534
trainer/Bellman Errors Max                    1.1086e+07
trainer/Bellman Errors Min                    0.000391066
trainer/Policy Action Mean                   -0.173293
trainer/Policy Action Std                     0.953247
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      42000
expl/num paths total                       2100
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0720746
expl/Rewards Std                              0.204196
expl/Rewards Max                              2.29312
expl/Rewards Min                              1.60329e-05
expl/Returns Mean                             1.44149
expl/Returns Std                              1.96768
expl/Returns Max                              6.58789
expl/Returns Min                              0.0532561
expl/Actions Mean                            -0.121847
expl/Actions Std                              0.796256
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          1.44149
expl/env_infos/final/reward_dist Mean         0.180258
expl/env_infos/final/reward_dist Std          0.45133
expl/env_infos/final/reward_dist Max          2.29312
expl/env_infos/final/reward_dist Min          8.54242e-05
expl/env_infos/initial/reward_dist Mean       0.0131938
expl/env_infos/initial/reward_dist Std        0.0161311
expl/env_infos/initial/reward_dist Max        0.0625792
expl/env_infos/initial/reward_dist Min        0.000161611
expl/env_infos/reward_dist Mean               0.0720746
expl/env_infos/reward_dist Std                0.204196
expl/env_infos/reward_dist Max                2.29312
expl/env_infos/reward_dist Min                1.60329e-05
eval/num steps total                       6400
eval/num paths total                        320
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0921354
eval/Rewards Std                              0.0919418
eval/Rewards Max                              0.34879
eval/Rewards Min                              0.000144634
eval/Returns Mean                             1.84271
eval/Returns Std                              1.15891
eval/Returns Max                              3.26717
eval/Returns Min                              0.194182
eval/Actions Mean                            -0.0884922
eval/Actions Std                              0.941681
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          1.84271
eval/env_infos/final/reward_dist Mean         0.0995777
eval/env_infos/final/reward_dist Std          0.0694659
eval/env_infos/final/reward_dist Max          0.213279
eval/env_infos/final/reward_dist Min          0.0011818
eval/env_infos/initial/reward_dist Mean       0.0177651
eval/env_infos/initial/reward_dist Std        0.0154383
eval/env_infos/initial/reward_dist Max        0.0408427
eval/env_infos/initial/reward_dist Min        0.000162641
eval/env_infos/reward_dist Mean               0.0921354
eval/env_infos/reward_dist Std                0.0919418
eval/env_infos/reward_dist Max                0.34879
eval/env_infos/reward_dist Min                0.000144634
time/data storing (s)                         0.00153994
time/evaluation sampling (s)                  0.889145
time/exploration sampling (s)                 4.88445
time/logging (s)                              0.00227332
time/saving (s)                               0.00100293
time/training (s)                             4.25299
time/epoch (s)                               10.0314
time/total (s)                              721.266
Epoch                                        63
---------------------------------------  ----------------
2023-08-03 20:57:10.069852 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 64 finished
---------------------------------------  ----------------
epoch                                        64
replay_buffer/size                        42500
trainer/QF Loss                           95530.4
trainer/Policy Loss                       -5314
trainer/Raw Policy Loss                   -5314
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 4884.26
trainer/Q Predictions Std                   894.732
trainer/Q Predictions Max                  9269.74
trainer/Q Predictions Min                  2900.57
trainer/Q Targets Mean                     4885.95
trainer/Q Targets Std                       947.128
trainer/Q Targets Max                      8779.92
trainer/Q Targets Min                      2919.15
trainer/Bellman Errors Mean               95530.4
trainer/Bellman Errors Std               274267
trainer/Bellman Errors Max                    5.62085e+06
trainer/Bellman Errors Min                    0.0297933
trainer/Policy Action Mean                   -0.295475
trainer/Policy Action Std                     0.895961
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      42500
expl/num paths total                       2125
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.259021
expl/Rewards Std                              1.02372
expl/Rewards Max                             10
expl/Rewards Min                              5.90486e-11
expl/Returns Mean                             5.18042
expl/Returns Std                             10.1444
expl/Returns Max                             51.3372
expl/Returns Min                              0.0982243
expl/Actions Mean                            -0.200108
expl/Actions Std                              0.757809
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          5.18042
expl/env_infos/final/reward_dist Mean         0.686114
expl/env_infos/final/reward_dist Std          1.9634
expl/env_infos/final/reward_dist Max         10
expl/env_infos/final/reward_dist Min          5.90486e-11
expl/env_infos/initial/reward_dist Mean       0.0494024
expl/env_infos/initial/reward_dist Std        0.111929
expl/env_infos/initial/reward_dist Max        0.588895
expl/env_infos/initial/reward_dist Min        0.000645397
expl/env_infos/reward_dist Mean               0.259021
expl/env_infos/reward_dist Std                1.02372
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                5.90486e-11
eval/num steps total                       6500
eval/num paths total                        325
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.232179
eval/Rewards Std                              0.278789
eval/Rewards Max                              1.17102
eval/Rewards Min                              9.62996e-05
eval/Returns Mean                             4.64358
eval/Returns Std                              3.63998
eval/Returns Max                             11.7754
eval/Returns Min                              2.131
eval/Actions Mean                            -0.275915
eval/Actions Std                              0.833208
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          4.64358
eval/env_infos/final/reward_dist Mean         0.286457
eval/env_infos/final/reward_dist Std          0.314345
eval/env_infos/final/reward_dist Max          0.714762
eval/env_infos/final/reward_dist Min          0.00415879
eval/env_infos/initial/reward_dist Mean       0.0418824
eval/env_infos/initial/reward_dist Std        0.0376746
eval/env_infos/initial/reward_dist Max        0.0955473
eval/env_infos/initial/reward_dist Min        0.00238834
eval/env_infos/reward_dist Mean               0.232179
eval/env_infos/reward_dist Std                0.278789
eval/env_infos/reward_dist Max                1.17102
eval/env_infos/reward_dist Min                9.62996e-05
time/data storing (s)                         0.00152826
time/evaluation sampling (s)                  1.13625
time/exploration sampling (s)                 5.54378
time/logging (s)                              0.00232017
time/saving (s)                               0.0010244
time/training (s)                             4.33012
time/epoch (s)                               11.015
time/total (s)                              732.283
Epoch                                        64
---------------------------------------  ----------------
2023-08-03 20:57:21.557100 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 65 finished
---------------------------------------  ----------------
epoch                                        65
replay_buffer/size                        43000
trainer/QF Loss                           46070.9
trainer/Policy Loss                       -5663.69
trainer/Raw Policy Loss                   -5663.69
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 5383.86
trainer/Q Predictions Std                   605.919
trainer/Q Predictions Max                  8381.89
trainer/Q Predictions Min                  3885.97
trainer/Q Targets Mean                     5383.95
trainer/Q Targets Std                       633.674
trainer/Q Targets Max                      8315.85
trainer/Q Targets Min                      3837.7
trainer/Bellman Errors Mean               46070.9
trainer/Bellman Errors Std               129255
trainer/Bellman Errors Max                    2.71249e+06
trainer/Bellman Errors Min                    0.0375769
trainer/Policy Action Mean                   -0.29922
trainer/Policy Action Std                     0.88644
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      43000
expl/num paths total                       2150
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.111764
expl/Rewards Std                              0.302106
expl/Rewards Max                              3.01602
expl/Rewards Min                              1.20675e-08
expl/Returns Mean                             2.23527
expl/Returns Std                              3.01288
expl/Returns Max                             12.7282
expl/Returns Min                              0.156006
expl/Actions Mean                            -0.163197
expl/Actions Std                              0.767978
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          2.23527
expl/env_infos/final/reward_dist Mean         0.048468
expl/env_infos/final/reward_dist Std          0.0868821
expl/env_infos/final/reward_dist Max          0.288719
expl/env_infos/final/reward_dist Min          1.20675e-08
expl/env_infos/initial/reward_dist Mean       0.0245776
expl/env_infos/initial/reward_dist Std        0.0263985
expl/env_infos/initial/reward_dist Max        0.10862
expl/env_infos/initial/reward_dist Min        0.000272917
expl/env_infos/reward_dist Mean               0.111764
expl/env_infos/reward_dist Std                0.302106
expl/env_infos/reward_dist Max                3.01602
expl/env_infos/reward_dist Min                1.20675e-08
eval/num steps total                       6600
eval/num paths total                        330
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0540438
eval/Rewards Std                              0.222662
eval/Rewards Max                              2.02093
eval/Rewards Min                              1.82537e-05
eval/Returns Mean                             1.08088
eval/Returns Std                              0.876837
eval/Returns Max                              2.67925
eval/Returns Min                              0.219066
eval/Actions Mean                            -0.228424
eval/Actions Std                              0.879058
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          1.08088
eval/env_infos/final/reward_dist Mean         0.164027
eval/env_infos/final/reward_dist Std          0.325315
eval/env_infos/final/reward_dist Max          0.814653
eval/env_infos/final/reward_dist Min          0.000110859
eval/env_infos/initial/reward_dist Mean       0.0112582
eval/env_infos/initial/reward_dist Std        0.0122555
eval/env_infos/initial/reward_dist Max        0.0337988
eval/env_infos/initial/reward_dist Min        0.000229825
eval/env_infos/reward_dist Mean               0.0540438
eval/env_infos/reward_dist Std                0.222662
eval/env_infos/reward_dist Max                2.02093
eval/env_infos/reward_dist Min                1.82537e-05
time/data storing (s)                         0.00214726
time/evaluation sampling (s)                  1.59105
time/exploration sampling (s)                 5.67659
time/logging (s)                              0.00234788
time/saving (s)                               0.00109194
time/training (s)                             4.21078
time/epoch (s)                               11.484
time/total (s)                              743.77
Epoch                                        65
---------------------------------------  ----------------
2023-08-03 20:57:32.749112 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 66 finished
---------------------------------------  ----------------
epoch                                        66
replay_buffer/size                        43500
trainer/QF Loss                           19266.7
trainer/Policy Loss                       -4998.77
trainer/Raw Policy Loss                   -4998.77
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 4819.52
trainer/Q Predictions Std                   283.576
trainer/Q Predictions Max                  7025.3
trainer/Q Predictions Min                  4022.45
trainer/Q Targets Mean                     4818.76
trainer/Q Targets Std                       314.118
trainer/Q Targets Max                      7185.79
trainer/Q Targets Min                      4000.06
trainer/Bellman Errors Mean               19266.7
trainer/Bellman Errors Std                48314.7
trainer/Bellman Errors Max               965632
trainer/Bellman Errors Min                    0.00515199
trainer/Policy Action Mean                   -0.301036
trainer/Policy Action Std                     0.896499
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      43500
expl/num paths total                       2175
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0303169
expl/Rewards Std                              0.179393
expl/Rewards Max                              3.79075
expl/Rewards Min                              2.72209e-07
expl/Returns Mean                             0.606338
expl/Returns Std                              1.3235
expl/Returns Max                              6.89685
expl/Returns Min                              0.0216937
expl/Actions Mean                            -0.19449
expl/Actions Std                              0.780945
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.606338
expl/env_infos/final/reward_dist Mean         0.0382392
expl/env_infos/final/reward_dist Std          0.101331
expl/env_infos/final/reward_dist Max          0.507123
expl/env_infos/final/reward_dist Min          3.55402e-05
expl/env_infos/initial/reward_dist Mean       0.00719938
expl/env_infos/initial/reward_dist Std        0.00829164
expl/env_infos/initial/reward_dist Max        0.0355619
expl/env_infos/initial/reward_dist Min        0.000251622
expl/env_infos/reward_dist Mean               0.0303169
expl/env_infos/reward_dist Std                0.179393
expl/env_infos/reward_dist Max                3.79075
expl/env_infos/reward_dist Min                2.72209e-07
eval/num steps total                       6700
eval/num paths total                        335
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.063642
eval/Rewards Std                              0.226273
eval/Rewards Max                              1.81858
eval/Rewards Min                              8.75758e-06
eval/Returns Mean                             1.27284
eval/Returns Std                              1.52333
eval/Returns Max                              4.1198
eval/Returns Min                              0.106056
eval/Actions Mean                            -0.260872
eval/Actions Std                              0.884143
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          1.27284
eval/env_infos/final/reward_dist Mean         0.154793
eval/env_infos/final/reward_dist Std          0.304666
eval/env_infos/final/reward_dist Max          0.76409
eval/env_infos/final/reward_dist Min          0.000214819
eval/env_infos/initial/reward_dist Mean       0.00228917
eval/env_infos/initial/reward_dist Std        0.00339935
eval/env_infos/initial/reward_dist Max        0.00907951
eval/env_infos/initial/reward_dist Min        0.000313667
eval/env_infos/reward_dist Mean               0.063642
eval/env_infos/reward_dist Std                0.226273
eval/env_infos/reward_dist Max                1.81858
eval/env_infos/reward_dist Min                8.75758e-06
time/data storing (s)                         0.00217433
time/evaluation sampling (s)                  0.978546
time/exploration sampling (s)                 5.53571
time/logging (s)                              0.00295394
time/saving (s)                               0.00121854
time/training (s)                             4.66886
time/epoch (s)                               11.1895
time/total (s)                              754.962
Epoch                                        66
---------------------------------------  ----------------
2023-08-03 20:57:43.012313 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 67 finished
---------------------------------------  ---------------
epoch                                       67
replay_buffer/size                       44000
trainer/QF Loss                          13546.3
trainer/Policy Loss                      -4250.43
trainer/Raw Policy Loss                  -4250.43
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                4089.76
trainer/Q Predictions Std                  261.883
trainer/Q Predictions Max                 7321.09
trainer/Q Predictions Min                 3514.46
trainer/Q Targets Mean                    4088.62
trainer/Q Targets Std                      286.605
trainer/Q Targets Max                     7405.62
trainer/Q Targets Min                     3474.32
trainer/Bellman Errors Mean              13546.3
trainer/Bellman Errors Std               34623.2
trainer/Bellman Errors Max                   1.02684e+06
trainer/Bellman Errors Min                   0.000105143
trainer/Policy Action Mean                  -0.20039
trainer/Policy Action Std                    0.936043
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     44000
expl/num paths total                      2200
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.145209
expl/Rewards Std                             0.492695
expl/Rewards Max                             3.55722
expl/Rewards Min                             7.4586e-11
expl/Returns Mean                            2.90418
expl/Returns Std                             7.19727
expl/Returns Max                            26.4061
expl/Returns Min                             0.00298653
expl/Actions Mean                           -0.111098
expl/Actions Std                             0.82461
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         2.90418
expl/env_infos/final/reward_dist Mean        0.134864
expl/env_infos/final/reward_dist Std         0.359346
expl/env_infos/final/reward_dist Max         1.43816
expl/env_infos/final/reward_dist Min         1.94587e-10
expl/env_infos/initial/reward_dist Mean      0.0212737
expl/env_infos/initial/reward_dist Std       0.0208777
expl/env_infos/initial/reward_dist Max       0.0683495
expl/env_infos/initial/reward_dist Min       8.43456e-05
expl/env_infos/reward_dist Mean              0.145209
expl/env_infos/reward_dist Std               0.492695
expl/env_infos/reward_dist Max               3.55722
expl/env_infos/reward_dist Min               7.4586e-11
eval/num steps total                      6800
eval/num paths total                       340
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00126125
eval/Rewards Std                             0.00569452
eval/Rewards Max                             0.0525143
eval/Rewards Min                             3.17211e-06
eval/Returns Mean                            0.0252249
eval/Returns Std                             0.0272773
eval/Returns Max                             0.0753615
eval/Returns Min                             0.00373052
eval/Actions Mean                           -0.142208
eval/Actions Std                             0.958518
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0252249
eval/env_infos/final/reward_dist Mean        2.71635e-05
eval/env_infos/final/reward_dist Std         3.13508e-05
eval/env_infos/final/reward_dist Max         8.72587e-05
eval/env_infos/final/reward_dist Min         4.40021e-06
eval/env_infos/initial/reward_dist Mean      0.0140804
eval/env_infos/initial/reward_dist Std       0.0196029
eval/env_infos/initial/reward_dist Max       0.0525143
eval/env_infos/initial/reward_dist Min       1.17727e-05
eval/env_infos/reward_dist Mean              0.00126125
eval/env_infos/reward_dist Std               0.00569452
eval/env_infos/reward_dist Max               0.0525143
eval/env_infos/reward_dist Min               3.17211e-06
time/data storing (s)                        0.00150214
time/evaluation sampling (s)                 0.902633
time/exploration sampling (s)                5.41809
time/logging (s)                             0.00226997
time/saving (s)                              0.00113822
time/training (s)                            3.93266
time/epoch (s)                              10.2583
time/total (s)                             765.223
Epoch                                       67
---------------------------------------  ---------------
2023-08-03 20:57:54.443784 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 68 finished
---------------------------------------  ----------------
epoch                                        68
replay_buffer/size                        44500
trainer/QF Loss                           35089.7
trainer/Policy Loss                       -3731.43
trainer/Raw Policy Loss                   -3731.43
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 3558.8
trainer/Q Predictions Std                   526.232
trainer/Q Predictions Max                 11730
trainer/Q Predictions Min                  2757.62
trainer/Q Targets Mean                     3559.96
trainer/Q Targets Std                       540.575
trainer/Q Targets Max                     11314.3
trainer/Q Targets Min                      2811.51
trainer/Bellman Errors Mean               35089.7
trainer/Bellman Errors Std               225389
trainer/Bellman Errors Max                    9.97977e+06
trainer/Bellman Errors Min                    0.0083819
trainer/Policy Action Mean                   -0.183854
trainer/Policy Action Std                     0.934341
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      44500
expl/num paths total                       2225
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0850687
expl/Rewards Std                              0.203211
expl/Rewards Max                              1.96114
expl/Rewards Min                              1.492e-07
expl/Returns Mean                             1.70137
expl/Returns Std                              2.30713
expl/Returns Max                             10.6616
expl/Returns Min                              0.0460578
expl/Actions Mean                            -0.0784837
expl/Actions Std                              0.797018
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          1.70137
expl/env_infos/final/reward_dist Mean         0.0836407
expl/env_infos/final/reward_dist Std          0.162647
expl/env_infos/final/reward_dist Max          0.587569
expl/env_infos/final/reward_dist Min          3.95319e-07
expl/env_infos/initial/reward_dist Mean       0.0183428
expl/env_infos/initial/reward_dist Std        0.0185639
expl/env_infos/initial/reward_dist Max        0.0633363
expl/env_infos/initial/reward_dist Min        0.000705231
expl/env_infos/reward_dist Mean               0.0850687
expl/env_infos/reward_dist Std                0.203211
expl/env_infos/reward_dist Max                1.96114
expl/env_infos/reward_dist Min                1.492e-07
eval/num steps total                       6900
eval/num paths total                        345
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0577372
eval/Rewards Std                              0.111021
eval/Rewards Max                              0.749216
eval/Rewards Min                              8.36453e-05
eval/Returns Mean                             1.15474
eval/Returns Std                              1.204
eval/Returns Max                              3.45653
eval/Returns Min                              0.157936
eval/Actions Mean                            -0.0889702
eval/Actions Std                              0.919955
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          1.15474
eval/env_infos/final/reward_dist Mean         0.0391174
eval/env_infos/final/reward_dist Std          0.0755825
eval/env_infos/final/reward_dist Max          0.190271
eval/env_infos/final/reward_dist Min          0.000487765
eval/env_infos/initial/reward_dist Mean       0.0164602
eval/env_infos/initial/reward_dist Std        0.01022
eval/env_infos/initial/reward_dist Max        0.0283802
eval/env_infos/initial/reward_dist Min        0.000307253
eval/env_infos/reward_dist Mean               0.0577372
eval/env_infos/reward_dist Std                0.111021
eval/env_infos/reward_dist Max                0.749216
eval/env_infos/reward_dist Min                8.36453e-05
time/data storing (s)                         0.00149904
time/evaluation sampling (s)                  1.29128
time/exploration sampling (s)                 5.30136
time/logging (s)                              0.00234897
time/saving (s)                               0.000996454
time/training (s)                             4.83101
time/epoch (s)                               11.4285
time/total (s)                              776.654
Epoch                                        68
---------------------------------------  ----------------
2023-08-03 20:58:06.636196 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 69 finished
---------------------------------------  ----------------
epoch                                        69
replay_buffer/size                        45000
trainer/QF Loss                          114105
trainer/Policy Loss                       -5268.47
trainer/Raw Policy Loss                   -5268.47
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 4727.88
trainer/Q Predictions Std                  1067.74
trainer/Q Predictions Max                 12487.9
trainer/Q Predictions Min                  2383.61
trainer/Q Targets Mean                     4747.13
trainer/Q Targets Std                      1133.12
trainer/Q Targets Max                     12959.6
trainer/Q Targets Min                      2378.19
trainer/Bellman Errors Mean              114105
trainer/Bellman Errors Std               302715
trainer/Bellman Errors Max                    7.05772e+06
trainer/Bellman Errors Min                    0.0402739
trainer/Policy Action Mean                   -0.0539752
trainer/Policy Action Std                     0.925804
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      45000
expl/num paths total                       2250
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.169677
expl/Rewards Std                              0.356856
expl/Rewards Max                              1.95325
expl/Rewards Min                              5.72909e-06
expl/Returns Mean                             3.39354
expl/Returns Std                              4.6481
expl/Returns Max                             13.0199
expl/Returns Min                              0.0373965
expl/Actions Mean                            -0.00894651
expl/Actions Std                              0.788798
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          3.39354
expl/env_infos/final/reward_dist Mean         0.137407
expl/env_infos/final/reward_dist Std          0.194617
expl/env_infos/final/reward_dist Max          0.716897
expl/env_infos/final/reward_dist Min          5.72909e-06
expl/env_infos/initial/reward_dist Mean       0.0134871
expl/env_infos/initial/reward_dist Std        0.0104358
expl/env_infos/initial/reward_dist Max        0.0383611
expl/env_infos/initial/reward_dist Min        0.000545417
expl/env_infos/reward_dist Mean               0.169677
expl/env_infos/reward_dist Std                0.356856
expl/env_infos/reward_dist Max                1.95325
expl/env_infos/reward_dist Min                5.72909e-06
eval/num steps total                       7000
eval/num paths total                        350
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0724281
eval/Rewards Std                              0.157735
eval/Rewards Max                              1.14145
eval/Rewards Min                              5.52013e-05
eval/Returns Mean                             1.44856
eval/Returns Std                              1.178
eval/Returns Max                              3.24358
eval/Returns Min                              0.14815
eval/Actions Mean                            -0.0215909
eval/Actions Std                              0.891565
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          1.44856
eval/env_infos/final/reward_dist Mean         0.0442531
eval/env_infos/final/reward_dist Std          0.0485064
eval/env_infos/final/reward_dist Max          0.134615
eval/env_infos/final/reward_dist Min          6.79573e-05
eval/env_infos/initial/reward_dist Mean       0.019195
eval/env_infos/initial/reward_dist Std        0.00924998
eval/env_infos/initial/reward_dist Max        0.0358617
eval/env_infos/initial/reward_dist Min        0.0087717
eval/env_infos/reward_dist Mean               0.0724281
eval/env_infos/reward_dist Std                0.157735
eval/env_infos/reward_dist Max                1.14145
eval/env_infos/reward_dist Min                5.52013e-05
time/data storing (s)                         0.00264675
time/evaluation sampling (s)                  1.2671
time/exploration sampling (s)                 6.39846
time/logging (s)                              0.00227011
time/saving (s)                               0.00101934
time/training (s)                             4.51618
time/epoch (s)                               12.1877
time/total (s)                              788.845
Epoch                                        69
---------------------------------------  ----------------
2023-08-03 20:58:19.036206 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 70 finished
---------------------------------------  ----------------
epoch                                        70
replay_buffer/size                        45500
trainer/QF Loss                          122388
trainer/Policy Loss                       -6853.99
trainer/Raw Policy Loss                   -6853.99
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 6285.49
trainer/Q Predictions Std                  1568.03
trainer/Q Predictions Max                 16558.3
trainer/Q Predictions Min                  2828.75
trainer/Q Targets Mean                     6280.22
trainer/Q Targets Std                      1605.15
trainer/Q Targets Max                     17103.2
trainer/Q Targets Min                      2770.29
trainer/Bellman Errors Mean              122388
trainer/Bellman Errors Std               394597
trainer/Bellman Errors Max                    7.94854e+06
trainer/Bellman Errors Min                    0.0017429
trainer/Policy Action Mean                   -0.0771619
trainer/Policy Action Std                     0.916316
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      45500
expl/num paths total                       2275
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.27407
expl/Rewards Std                              0.486611
expl/Rewards Max                              3.622
expl/Rewards Min                              2.44637e-06
expl/Returns Mean                             5.48141
expl/Returns Std                              5.25378
expl/Returns Max                             18.2445
expl/Returns Min                              0.213295
expl/Actions Mean                            -0.0662397
expl/Actions Std                              0.775453
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          5.48141
expl/env_infos/final/reward_dist Mean         0.129074
expl/env_infos/final/reward_dist Std          0.221243
expl/env_infos/final/reward_dist Max          0.928997
expl/env_infos/final/reward_dist Min          2.44637e-06
expl/env_infos/initial/reward_dist Mean       0.0319195
expl/env_infos/initial/reward_dist Std        0.0214592
expl/env_infos/initial/reward_dist Max        0.0662645
expl/env_infos/initial/reward_dist Min        0.00364277
expl/env_infos/reward_dist Mean               0.27407
expl/env_infos/reward_dist Std                0.486611
expl/env_infos/reward_dist Max                3.622
expl/env_infos/reward_dist Min                2.44637e-06
eval/num steps total                       7100
eval/num paths total                        355
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.127352
eval/Rewards Std                              0.280585
eval/Rewards Max                              1.72413
eval/Rewards Min                              0.000629364
eval/Returns Mean                             2.54704
eval/Returns Std                              0.78025
eval/Returns Max                              3.72054
eval/Returns Min                              1.57292
eval/Actions Mean                            -0.12595
eval/Actions Std                              0.878577
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          2.54704
eval/env_infos/final/reward_dist Mean         0.0157199
eval/env_infos/final/reward_dist Std          0.0103341
eval/env_infos/final/reward_dist Max          0.0325704
eval/env_infos/final/reward_dist Min          0.000689965
eval/env_infos/initial/reward_dist Mean       0.036965
eval/env_infos/initial/reward_dist Std        0.0169885
eval/env_infos/initial/reward_dist Max        0.0542347
eval/env_infos/initial/reward_dist Min        0.0123244
eval/env_infos/reward_dist Mean               0.127352
eval/env_infos/reward_dist Std                0.280585
eval/env_infos/reward_dist Max                1.72413
eval/env_infos/reward_dist Min                0.000629364
time/data storing (s)                         0.00152114
time/evaluation sampling (s)                  0.99201
time/exploration sampling (s)                 6.49161
time/logging (s)                              0.00227761
time/saving (s)                               0.000997966
time/training (s)                             4.90879
time/epoch (s)                               12.3972
time/total (s)                              801.245
Epoch                                        70
---------------------------------------  ----------------
2023-08-03 20:58:30.590005 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 71 finished
---------------------------------------  ----------------
epoch                                        71
replay_buffer/size                        46000
trainer/QF Loss                          143981
trainer/Policy Loss                       -8430.86
trainer/Raw Policy Loss                   -8430.86
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 7767.77
trainer/Q Predictions Std                  1822.88
trainer/Q Predictions Max                 18997.4
trainer/Q Predictions Min                  3272.73
trainer/Q Targets Mean                     7769.66
trainer/Q Targets Std                      1869.82
trainer/Q Targets Max                     18324.6
trainer/Q Targets Min                      3189.76
trainer/Bellman Errors Mean              143981
trainer/Bellman Errors Std               421658
trainer/Bellman Errors Max                    8.36231e+06
trainer/Bellman Errors Min                    0.00878906
trainer/Policy Action Mean                    0.00835685
trainer/Policy Action Std                     0.911653
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      46000
expl/num paths total                       2300
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.646059
expl/Rewards Std                              2.15779
expl/Rewards Max                             10
expl/Rewards Min                              9.13892e-06
expl/Returns Mean                            12.9212
expl/Returns Std                             33.8836
expl/Returns Max                            131.63
expl/Returns Min                              0.127467
expl/Actions Mean                            -0.0453149
expl/Actions Std                              0.77341
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                         12.9212
expl/env_infos/final/reward_dist Mean         0.854496
expl/env_infos/final/reward_dist Std          2.6996
expl/env_infos/final/reward_dist Max         10
expl/env_infos/final/reward_dist Min          9.13892e-06
expl/env_infos/initial/reward_dist Mean       0.0521113
expl/env_infos/initial/reward_dist Std        0.0968457
expl/env_infos/initial/reward_dist Max        0.499827
expl/env_infos/initial/reward_dist Min        0.00459699
expl/env_infos/reward_dist Mean               0.646059
expl/env_infos/reward_dist Std                2.15779
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                9.13892e-06
eval/num steps total                       7200
eval/num paths total                        360
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0874047
eval/Rewards Std                              0.219517
eval/Rewards Max                              1.7039
eval/Rewards Min                              0.000710484
eval/Returns Mean                             1.74809
eval/Returns Std                              1.05294
eval/Returns Max                              3.26364
eval/Returns Min                              0.671589
eval/Actions Mean                            -0.0639685
eval/Actions Std                              0.892364
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          1.74809
eval/env_infos/final/reward_dist Mean         0.0115516
eval/env_infos/final/reward_dist Std          0.0191951
eval/env_infos/final/reward_dist Max          0.0498188
eval/env_infos/final/reward_dist Min          0.000909959
eval/env_infos/initial/reward_dist Mean       0.0643063
eval/env_infos/initial/reward_dist Std        0.052979
eval/env_infos/initial/reward_dist Max        0.168663
eval/env_infos/initial/reward_dist Min        0.0283907
eval/env_infos/reward_dist Mean               0.0874047
eval/env_infos/reward_dist Std                0.219517
eval/env_infos/reward_dist Max                1.7039
eval/env_infos/reward_dist Min                0.000710484
time/data storing (s)                         0.0015309
time/evaluation sampling (s)                  1.21722
time/exploration sampling (s)                 5.37279
time/logging (s)                              0.00226953
time/saving (s)                               0.00101106
time/training (s)                             4.9559
time/epoch (s)                               11.5507
time/total (s)                              812.798
Epoch                                        71
---------------------------------------  ----------------
2023-08-03 20:58:43.767517 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 72 finished
---------------------------------------  ----------------
epoch                                        72
replay_buffer/size                        46500
trainer/QF Loss                          173369
trainer/Policy Loss                       -9907.44
trainer/Raw Policy Loss                   -9907.44
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 9192.17
trainer/Q Predictions Std                  1989.99
trainer/Q Predictions Max                 18906.4
trainer/Q Predictions Min                  3833.49
trainer/Q Targets Mean                     9178.2
trainer/Q Targets Std                      2040.61
trainer/Q Targets Max                     19186.1
trainer/Q Targets Min                      3705.29
trainer/Bellman Errors Mean              173369
trainer/Bellman Errors Std               485930
trainer/Bellman Errors Max                    1.27084e+07
trainer/Bellman Errors Min                    0.00309849
trainer/Policy Action Mean                   -0.0453217
trainer/Policy Action Std                     0.906139
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      46500
expl/num paths total                       2325
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.12689
expl/Rewards Std                              0.399115
expl/Rewards Max                              4.77696
expl/Rewards Min                              0.000218413
expl/Returns Mean                             2.5378
expl/Returns Std                              3.01254
expl/Returns Max                             13.8197
expl/Returns Min                              0.129134
expl/Actions Mean                            -0.0731655
expl/Actions Std                              0.794326
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          2.5378
expl/env_infos/final/reward_dist Mean         0.039685
expl/env_infos/final/reward_dist Std          0.0819792
expl/env_infos/final/reward_dist Max          0.365922
expl/env_infos/final/reward_dist Min          0.000218413
expl/env_infos/initial/reward_dist Mean       0.0352387
expl/env_infos/initial/reward_dist Std        0.0290678
expl/env_infos/initial/reward_dist Max        0.126929
expl/env_infos/initial/reward_dist Min        0.00303155
expl/env_infos/reward_dist Mean               0.12689
expl/env_infos/reward_dist Std                0.399115
expl/env_infos/reward_dist Max                4.77696
expl/env_infos/reward_dist Min                0.000218413
eval/num steps total                       7300
eval/num paths total                        365
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0603621
eval/Rewards Std                              0.14559
eval/Rewards Max                              0.965928
eval/Rewards Min                              0.000552057
eval/Returns Mean                             1.20724
eval/Returns Std                              0.552142
eval/Returns Max                              1.96264
eval/Returns Min                              0.413762
eval/Actions Mean                            -0.102945
eval/Actions Std                              0.88902
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          1.20724
eval/env_infos/final/reward_dist Mean         0.00227133
eval/env_infos/final/reward_dist Std          0.00271692
eval/env_infos/final/reward_dist Max          0.0077003
eval/env_infos/final/reward_dist Min          0.000758664
eval/env_infos/initial/reward_dist Mean       0.0159769
eval/env_infos/initial/reward_dist Std        0.0117726
eval/env_infos/initial/reward_dist Max        0.0381843
eval/env_infos/initial/reward_dist Min        0.00317358
eval/env_infos/reward_dist Mean               0.0603621
eval/env_infos/reward_dist Std                0.14559
eval/env_infos/reward_dist Max                0.965928
eval/env_infos/reward_dist Min                0.000552057
time/data storing (s)                         0.00154986
time/evaluation sampling (s)                  1.35668
time/exploration sampling (s)                 6.07324
time/logging (s)                              0.00286959
time/saving (s)                               0.00966541
time/training (s)                             5.73121
time/epoch (s)                               13.1752
time/total (s)                              825.975
Epoch                                        72
---------------------------------------  ----------------
2023-08-03 20:58:55.497801 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 73 finished
---------------------------------------  ----------------
epoch                                        73
replay_buffer/size                        47000
trainer/QF Loss                          120554
trainer/Policy Loss                      -10535.7
trainer/Raw Policy Loss                  -10535.7
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 9946.45
trainer/Q Predictions Std                  1766.89
trainer/Q Predictions Max                 15221.6
trainer/Q Predictions Min                  4932.47
trainer/Q Targets Mean                     9968.26
trainer/Q Targets Std                      1808.9
trainer/Q Targets Max                     15252.9
trainer/Q Targets Min                      4575.33
trainer/Bellman Errors Mean              120554
trainer/Bellman Errors Std               347071
trainer/Bellman Errors Max                    1.01151e+07
trainer/Bellman Errors Min                    0.01896
trainer/Policy Action Mean                   -0.0242969
trainer/Policy Action Std                     0.910751
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      47000
expl/num paths total                       2350
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.342778
expl/Rewards Std                              0.816731
expl/Rewards Max                             10
expl/Rewards Min                              6.05583e-05
expl/Returns Mean                             6.85556
expl/Returns Std                              8.11914
expl/Returns Max                             27.4095
expl/Returns Min                              0.188944
expl/Actions Mean                            -0.0327755
expl/Actions Std                              0.774507
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          6.85556
expl/env_infos/final/reward_dist Mean         0.0844306
expl/env_infos/final/reward_dist Std          0.151619
expl/env_infos/final/reward_dist Max          0.534492
expl/env_infos/final/reward_dist Min          6.05583e-05
expl/env_infos/initial/reward_dist Mean       0.0250699
expl/env_infos/initial/reward_dist Std        0.0211414
expl/env_infos/initial/reward_dist Max        0.0727006
expl/env_infos/initial/reward_dist Min        0.00116714
expl/env_infos/reward_dist Mean               0.342778
expl/env_infos/reward_dist Std                0.816731
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                6.05583e-05
eval/num steps total                       7400
eval/num paths total                        370
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.12644
eval/Rewards Std                              0.325603
eval/Rewards Max                              2.09638
eval/Rewards Min                              0.000466828
eval/Returns Mean                             2.52879
eval/Returns Std                              1.02127
eval/Returns Max                              3.59677
eval/Returns Min                              1.09263
eval/Actions Mean                            -0.0575003
eval/Actions Std                              0.864125
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          2.52879
eval/env_infos/final/reward_dist Mean         0.0760543
eval/env_infos/final/reward_dist Std          0.097166
eval/env_infos/final/reward_dist Max          0.25353
eval/env_infos/final/reward_dist Min          0.00113655
eval/env_infos/initial/reward_dist Mean       0.0457662
eval/env_infos/initial/reward_dist Std        0.0112585
eval/env_infos/initial/reward_dist Max        0.0645694
eval/env_infos/initial/reward_dist Min        0.0335168
eval/env_infos/reward_dist Mean               0.12644
eval/env_infos/reward_dist Std                0.325603
eval/env_infos/reward_dist Max                2.09638
eval/env_infos/reward_dist Min                0.000466828
time/data storing (s)                         0.00157155
time/evaluation sampling (s)                  1.07323
time/exploration sampling (s)                 5.69227
time/logging (s)                              0.00224815
time/saving (s)                               0.00104914
time/training (s)                             4.95569
time/epoch (s)                               11.7261
time/total (s)                              837.704
Epoch                                        73
---------------------------------------  ----------------
2023-08-03 20:59:07.533834 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 74 finished
---------------------------------------  ----------------
epoch                                        74
replay_buffer/size                        47500
trainer/QF Loss                          104202
trainer/Policy Loss                       -9824.87
trainer/Raw Policy Loss                   -9824.87
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 9332.75
trainer/Q Predictions Std                  1360.08
trainer/Q Predictions Max                 13420.7
trainer/Q Predictions Min                  4466.05
trainer/Q Targets Mean                     9327.24
trainer/Q Targets Std                      1387.83
trainer/Q Targets Max                     13309
trainer/Q Targets Min                      4260.6
trainer/Bellman Errors Mean              104202
trainer/Bellman Errors Std               287599
trainer/Bellman Errors Max                    5.49615e+06
trainer/Bellman Errors Min                    0.148797
trainer/Policy Action Mean                   -0.0374913
trainer/Policy Action Std                     0.903066
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      47500
expl/num paths total                       2375
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.483874
expl/Rewards Std                              1.3084
expl/Rewards Max                             10
expl/Rewards Min                              2.4029e-06
expl/Returns Mean                             9.67748
expl/Returns Std                             18.0008
expl/Returns Max                             90.5037
expl/Returns Min                              0.273761
expl/Actions Mean                            -0.0585989
expl/Actions Std                              0.754563
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          9.67748
expl/env_infos/final/reward_dist Mean         0.633856
expl/env_infos/final/reward_dist Std          1.96599
expl/env_infos/final/reward_dist Max         10
expl/env_infos/final/reward_dist Min          7.96273e-06
expl/env_infos/initial/reward_dist Mean       0.0393644
expl/env_infos/initial/reward_dist Std        0.0265223
expl/env_infos/initial/reward_dist Max        0.12149
expl/env_infos/initial/reward_dist Min        0.00386218
expl/env_infos/reward_dist Mean               0.483874
expl/env_infos/reward_dist Std                1.3084
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                2.4029e-06
eval/num steps total                       7500
eval/num paths total                        375
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.588958
eval/Rewards Std                              0.959379
eval/Rewards Max                              4.18613
eval/Rewards Min                              0.00485179
eval/Returns Mean                            11.7792
eval/Returns Std                              9.7877
eval/Returns Max                             29.0342
eval/Returns Min                              0.511587
eval/Actions Mean                            -0.0468827
eval/Actions Std                              0.830586
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                         11.7792
eval/env_infos/final/reward_dist Mean         0.268037
eval/env_infos/final/reward_dist Std          0.248032
eval/env_infos/final/reward_dist Max          0.70973
eval/env_infos/final/reward_dist Min          0.0332033
eval/env_infos/initial/reward_dist Mean       0.0285849
eval/env_infos/initial/reward_dist Std        0.00903923
eval/env_infos/initial/reward_dist Max        0.0414436
eval/env_infos/initial/reward_dist Min        0.016959
eval/env_infos/reward_dist Mean               0.588958
eval/env_infos/reward_dist Std                0.959379
eval/env_infos/reward_dist Max                4.18613
eval/env_infos/reward_dist Min                0.00485179
time/data storing (s)                         0.00158572
time/evaluation sampling (s)                  1.24316
time/exploration sampling (s)                 6.04572
time/logging (s)                              0.00227349
time/saving (s)                               0.000993429
time/training (s)                             4.73955
time/epoch (s)                               12.0333
time/total (s)                              849.739
Epoch                                        74
---------------------------------------  ----------------
2023-08-03 20:59:22.122323 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 75 finished
---------------------------------------  ----------------
epoch                                        75
replay_buffer/size                        48000
trainer/QF Loss                           89406.5
trainer/Policy Loss                       -9007.37
trainer/Raw Policy Loss                   -9007.37
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 8573.83
trainer/Q Predictions Std                  1187.87
trainer/Q Predictions Max                 12115.3
trainer/Q Predictions Min                  4399.97
trainer/Q Targets Mean                     8572.67
trainer/Q Targets Std                      1224.87
trainer/Q Targets Max                     12587.4
trainer/Q Targets Min                      4297.09
trainer/Bellman Errors Mean               89406.5
trainer/Bellman Errors Std               295941
trainer/Bellman Errors Max                    7.65328e+06
trainer/Bellman Errors Min                    0.00038147
trainer/Policy Action Mean                   -0.066225
trainer/Policy Action Std                     0.895153
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      48000
expl/num paths total                       2400
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.725116
expl/Rewards Std                              1.98663
expl/Rewards Max                             10
expl/Rewards Min                              1.81161e-06
expl/Returns Mean                            14.5023
expl/Returns Std                             31.0233
expl/Returns Max                            140.667
expl/Returns Min                              0.217206
expl/Actions Mean                            -0.0682312
expl/Actions Std                              0.747005
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                         14.5023
expl/env_infos/final/reward_dist Mean         1.02637
expl/env_infos/final/reward_dist Std          2.68867
expl/env_infos/final/reward_dist Max         10
expl/env_infos/final/reward_dist Min          6.74534e-06
expl/env_infos/initial/reward_dist Mean       0.0891903
expl/env_infos/initial/reward_dist Std        0.170331
expl/env_infos/initial/reward_dist Max        0.744163
expl/env_infos/initial/reward_dist Min        0.00347967
expl/env_infos/reward_dist Mean               0.725116
expl/env_infos/reward_dist Std                1.98663
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                1.81161e-06
eval/num steps total                       7600
eval/num paths total                        380
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.656176
eval/Rewards Std                              0.777188
eval/Rewards Max                              3.76592
eval/Rewards Min                              0.0156056
eval/Returns Mean                            13.1235
eval/Returns Std                              3.36556
eval/Returns Max                             17.2965
eval/Returns Min                              7.86524
eval/Actions Mean                            -0.0361596
eval/Actions Std                              0.834708
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                         13.1235
eval/env_infos/final/reward_dist Mean         0.163924
eval/env_infos/final/reward_dist Std          0.0982574
eval/env_infos/final/reward_dist Max          0.312861
eval/env_infos/final/reward_dist Min          0.0617727
eval/env_infos/initial/reward_dist Mean       0.113496
eval/env_infos/initial/reward_dist Std        0.160422
eval/env_infos/initial/reward_dist Max        0.433201
eval/env_infos/initial/reward_dist Min        0.017004
eval/env_infos/reward_dist Mean               0.656176
eval/env_infos/reward_dist Std                0.777188
eval/env_infos/reward_dist Max                3.76592
eval/env_infos/reward_dist Min                0.0156056
time/data storing (s)                         0.00174711
time/evaluation sampling (s)                  1.90307
time/exploration sampling (s)                 6.6219
time/logging (s)                              0.00227205
time/saving (s)                               0.00104464
time/training (s)                             6.05549
time/epoch (s)                               14.5855
time/total (s)                              864.327
Epoch                                        75
---------------------------------------  ----------------
2023-08-03 20:59:35.077788 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 76 finished
---------------------------------------  ----------------
epoch                                        76
replay_buffer/size                        48500
trainer/QF Loss                           73389.2
trainer/Policy Loss                       -8262.95
trainer/Raw Policy Loss                   -8262.95
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 7870.15
trainer/Q Predictions Std                  1034.87
trainer/Q Predictions Max                 11445.1
trainer/Q Predictions Min                  4167.26
trainer/Q Targets Mean                     7862.29
trainer/Q Targets Std                      1070.76
trainer/Q Targets Max                     11465.9
trainer/Q Targets Min                      4038.25
trainer/Bellman Errors Mean               73389.2
trainer/Bellman Errors Std               206469
trainer/Bellman Errors Max                    3.79333e+06
trainer/Bellman Errors Min                    0.0302162
trainer/Policy Action Mean                   -0.0665168
trainer/Policy Action Std                     0.891365
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      48500
expl/num paths total                       2425
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             1.53148
expl/Rewards Std                              3.20413
expl/Rewards Max                             10
expl/Rewards Min                              0.000131625
expl/Returns Mean                            30.6297
expl/Returns Std                             55.3419
expl/Returns Max                            173.964
expl/Returns Min                              0.243387
expl/Actions Mean                            -0.0355871
expl/Actions Std                              0.761052
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                         30.6297
expl/env_infos/final/reward_dist Mean         1.79809
expl/env_infos/final/reward_dist Std          3.60316
expl/env_infos/final/reward_dist Max         10
expl/env_infos/final/reward_dist Min          0.000779203
expl/env_infos/initial/reward_dist Mean       0.0292178
expl/env_infos/initial/reward_dist Std        0.0189594
expl/env_infos/initial/reward_dist Max        0.0650684
expl/env_infos/initial/reward_dist Min        0.00331324
expl/env_infos/reward_dist Mean               1.53148
expl/env_infos/reward_dist Std                3.20413
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                0.000131625
eval/num steps total                       7700
eval/num paths total                        385
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.540402
eval/Rewards Std                              0.873285
eval/Rewards Max                              4.26718
eval/Rewards Min                              0.00288855
eval/Returns Mean                            10.808
eval/Returns Std                              8.21536
eval/Returns Max                             25.5493
eval/Returns Min                              3.06987
eval/Actions Mean                            -0.0494924
eval/Actions Std                              0.816206
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                         10.808
eval/env_infos/final/reward_dist Mean         0.141304
eval/env_infos/final/reward_dist Std          0.0707661
eval/env_infos/final/reward_dist Max          0.234261
eval/env_infos/final/reward_dist Min          0.0257433
eval/env_infos/initial/reward_dist Mean       0.0284151
eval/env_infos/initial/reward_dist Std        0.0112824
eval/env_infos/initial/reward_dist Max        0.0503154
eval/env_infos/initial/reward_dist Min        0.0191356
eval/env_infos/reward_dist Mean               0.540402
eval/env_infos/reward_dist Std                0.873285
eval/env_infos/reward_dist Max                4.26718
eval/env_infos/reward_dist Min                0.00288855
time/data storing (s)                         0.00151684
time/evaluation sampling (s)                  1.2912
time/exploration sampling (s)                 7.10683
time/logging (s)                              0.0023785
time/saving (s)                               0.00100277
time/training (s)                             4.54989
time/epoch (s)                               12.9528
time/total (s)                              877.282
Epoch                                        76
---------------------------------------  ----------------
2023-08-03 20:59:48.586524 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 77 finished
---------------------------------------  ----------------
epoch                                        77
replay_buffer/size                        49000
trainer/QF Loss                           44866
trainer/Policy Loss                       -7501.25
trainer/Raw Policy Loss                   -7501.25
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 7177.45
trainer/Q Predictions Std                   775.006
trainer/Q Predictions Max                 10593.4
trainer/Q Predictions Min                  4415.59
trainer/Q Targets Mean                     7185.83
trainer/Q Targets Std                       803.385
trainer/Q Targets Max                     10674.2
trainer/Q Targets Min                      4285.09
trainer/Bellman Errors Mean               44866
trainer/Bellman Errors Std               140479
trainer/Bellman Errors Max                    4.58897e+06
trainer/Bellman Errors Min                    0.00842667
trainer/Policy Action Mean                   -0.0773828
trainer/Policy Action Std                     0.890944
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      49000
expl/num paths total                       2450
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             1.03649
expl/Rewards Std                              2.6345
expl/Rewards Max                             10
expl/Rewards Min                              2.35437e-07
expl/Returns Mean                            20.7298
expl/Returns Std                             50.413
expl/Returns Max                            190.387
expl/Returns Min                              0.300471
expl/Actions Mean                            -0.0199995
expl/Actions Std                              0.752626
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                         20.7298
expl/env_infos/final/reward_dist Mean         0.940222
expl/env_infos/final/reward_dist Std          2.68196
expl/env_infos/final/reward_dist Max         10
expl/env_infos/final/reward_dist Min          2.35437e-07
expl/env_infos/initial/reward_dist Mean       0.051634
expl/env_infos/initial/reward_dist Std        0.0982093
expl/env_infos/initial/reward_dist Max        0.386656
expl/env_infos/initial/reward_dist Min        0.000193339
expl/env_infos/reward_dist Mean               1.03649
expl/env_infos/reward_dist Std                2.6345
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                2.35437e-07
eval/num steps total                       7800
eval/num paths total                        390
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.247109
eval/Rewards Std                              0.290728
eval/Rewards Max                              1.40328
eval/Rewards Min                              0.00155584
eval/Returns Mean                             4.94218
eval/Returns Std                              2.77972
eval/Returns Max                              9.68802
eval/Returns Min                              1.58247
eval/Actions Mean                            -0.0295546
eval/Actions Std                              0.794909
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          4.94218
eval/env_infos/final/reward_dist Mean         0.201594
eval/env_infos/final/reward_dist Std          0.211983
eval/env_infos/final/reward_dist Max          0.571799
eval/env_infos/final/reward_dist Min          0.0237079
eval/env_infos/initial/reward_dist Mean       0.0257519
eval/env_infos/initial/reward_dist Std        0.0119926
eval/env_infos/initial/reward_dist Max        0.0450491
eval/env_infos/initial/reward_dist Min        0.00761774
eval/env_infos/reward_dist Mean               0.247109
eval/env_infos/reward_dist Std                0.290728
eval/env_infos/reward_dist Max                1.40328
eval/env_infos/reward_dist Min                0.00155584
time/data storing (s)                         0.00149114
time/evaluation sampling (s)                  2.10447
time/exploration sampling (s)                 7.11894
time/logging (s)                              0.00231173
time/saving (s)                               0.00107555
time/training (s)                             4.27711
time/epoch (s)                               13.5054
time/total (s)                              890.79
Epoch                                        77
---------------------------------------  ----------------
2023-08-03 21:00:01.097287 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 78 finished
---------------------------------------  ---------------
epoch                                       78
replay_buffer/size                       49500
trainer/QF Loss                          29845.7
trainer/Policy Loss                      -6367.64
trainer/Raw Policy Loss                  -6367.64
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                6109.45
trainer/Q Predictions Std                  578.144
trainer/Q Predictions Max                11863.4
trainer/Q Predictions Min                 4066.21
trainer/Q Targets Mean                    6103.6
trainer/Q Targets Std                      614.214
trainer/Q Targets Max                    11732.1
trainer/Q Targets Min                     3826.54
trainer/Bellman Errors Mean              29845.7
trainer/Bellman Errors Std               75609.3
trainer/Bellman Errors Max                   1.91113e+06
trainer/Bellman Errors Min                   0.000161171
trainer/Policy Action Mean                  -0.0293827
trainer/Policy Action Std                    0.884921
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     49500
expl/num paths total                      2475
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            1.44155
expl/Rewards Std                             3.06107
expl/Rewards Max                            10
expl/Rewards Min                             6.64756e-07
expl/Returns Mean                           28.831
expl/Returns Std                            50.3367
expl/Returns Max                           181.828
expl/Returns Min                             0.208348
expl/Actions Mean                            0.0214574
expl/Actions Std                             0.736522
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        28.831
expl/env_infos/final/reward_dist Mean        2.26563
expl/env_infos/final/reward_dist Std         3.89907
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         7.67648e-07
expl/env_infos/initial/reward_dist Mean      0.0329119
expl/env_infos/initial/reward_dist Std       0.0198484
expl/env_infos/initial/reward_dist Max       0.0767045
expl/env_infos/initial/reward_dist Min       0.00570074
expl/env_infos/reward_dist Mean              1.44155
expl/env_infos/reward_dist Std               3.06107
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.64756e-07
eval/num steps total                      7900
eval/num paths total                       395
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.640242
eval/Rewards Std                             0.847089
eval/Rewards Max                             3.43757
eval/Rewards Min                             0.0074847
eval/Returns Mean                           12.8048
eval/Returns Std                             9.71809
eval/Returns Max                            29.8959
eval/Returns Min                             0.496249
eval/Actions Mean                            0.0575574
eval/Actions Std                             0.768568
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                        12.8048
eval/env_infos/final/reward_dist Mean        0.7114
eval/env_infos/final/reward_dist Std         1.00548
eval/env_infos/final/reward_dist Max         2.68901
eval/env_infos/final/reward_dist Min         0.0335121
eval/env_infos/initial/reward_dist Mean      0.0302192
eval/env_infos/initial/reward_dist Std       0.00631019
eval/env_infos/initial/reward_dist Max       0.0405627
eval/env_infos/initial/reward_dist Min       0.0234546
eval/env_infos/reward_dist Mean              0.640242
eval/env_infos/reward_dist Std               0.847089
eval/env_infos/reward_dist Max               3.43757
eval/env_infos/reward_dist Min               0.0074847
time/data storing (s)                        0.00155516
time/evaluation sampling (s)                 1.44586
time/exploration sampling (s)                6.46726
time/logging (s)                             0.00294991
time/saving (s)                              0.00117481
time/training (s)                            4.58898
time/epoch (s)                              12.5078
time/total (s)                             903.301
Epoch                                       78
---------------------------------------  ---------------
2023-08-03 21:00:13.979730 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 79 finished
---------------------------------------  ----------------
epoch                                        79
replay_buffer/size                        50000
trainer/QF Loss                           36036.2
trainer/Policy Loss                       -5895.12
trainer/Raw Policy Loss                   -5895.12
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 5615.35
trainer/Q Predictions Std                   686.268
trainer/Q Predictions Max                 12255.5
trainer/Q Predictions Min                  3612.08
trainer/Q Targets Mean                     5618.2
trainer/Q Targets Std                       710.32
trainer/Q Targets Max                     12214.2
trainer/Q Targets Min                      3574.07
trainer/Bellman Errors Mean               36036.2
trainer/Bellman Errors Std               126344
trainer/Bellman Errors Max                    3.29054e+06
trainer/Bellman Errors Min                    0.00802809
trainer/Policy Action Mean                    0.00276225
trainer/Policy Action Std                     0.886735
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      50000
expl/num paths total                       2500
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.992854
expl/Rewards Std                              2.18529
expl/Rewards Max                             10
expl/Rewards Min                              0.000137756
expl/Returns Mean                            19.8571
expl/Returns Std                             34.3478
expl/Returns Max                            161.199
expl/Returns Min                              0.270069
expl/Actions Mean                             0.0198791
expl/Actions Std                              0.735909
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                         19.8571
expl/env_infos/final/reward_dist Mean         1.2225
expl/env_infos/final/reward_dist Std          2.66394
expl/env_infos/final/reward_dist Max         10
expl/env_infos/final/reward_dist Min          0.000940984
expl/env_infos/initial/reward_dist Mean       0.0337079
expl/env_infos/initial/reward_dist Std        0.0200978
expl/env_infos/initial/reward_dist Max        0.0832759
expl/env_infos/initial/reward_dist Min        0.00189226
expl/env_infos/reward_dist Mean               0.992854
expl/env_infos/reward_dist Std                2.18529
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                0.000137756
eval/num steps total                       8000
eval/num paths total                        400
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             2.65462
eval/Rewards Std                              3.61234
eval/Rewards Max                             10
eval/Rewards Min                              0.00446912
eval/Returns Mean                            53.0923
eval/Returns Std                             66.9053
eval/Returns Max                            184.398
eval/Returns Min                              0.618312
eval/Actions Mean                             0.094955
eval/Actions Std                              0.730678
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                         53.0923
eval/env_infos/final/reward_dist Mean         2.5103
eval/env_infos/final/reward_dist Std          3.75974
eval/env_infos/final/reward_dist Max         10
eval/env_infos/final/reward_dist Min          0.0126871
eval/env_infos/initial/reward_dist Mean       0.0445054
eval/env_infos/initial/reward_dist Std        0.0388521
eval/env_infos/initial/reward_dist Max        0.120826
eval/env_infos/initial/reward_dist Min        0.0159388
eval/env_infos/reward_dist Mean               2.65462
eval/env_infos/reward_dist Std                3.61234
eval/env_infos/reward_dist Max               10
eval/env_infos/reward_dist Min                0.00446912
time/data storing (s)                         0.00149509
time/evaluation sampling (s)                  1.3322
time/exploration sampling (s)                 7.23398
time/logging (s)                              0.00286975
time/saving (s)                               0.00112014
time/training (s)                             4.30698
time/epoch (s)                               12.8786
time/total (s)                              916.182
Epoch                                        79
---------------------------------------  ----------------
2023-08-03 21:00:26.772378 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 80 finished
---------------------------------------  ----------------
epoch                                        80
replay_buffer/size                        50500
trainer/QF Loss                           38271.8
trainer/Policy Loss                       -5526.56
trainer/Raw Policy Loss                   -5526.56
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 5257.29
trainer/Q Predictions Std                   702.613
trainer/Q Predictions Max                 12961.9
trainer/Q Predictions Min                  3205.74
trainer/Q Targets Mean                     5259.18
trainer/Q Targets Std                       735.912
trainer/Q Targets Max                     12958
trainer/Q Targets Min                      3122.76
trainer/Bellman Errors Mean               38271.8
trainer/Bellman Errors Std               106028
trainer/Bellman Errors Max                    2.14514e+06
trainer/Bellman Errors Min                    0.000620127
trainer/Policy Action Mean                   -0.000510458
trainer/Policy Action Std                     0.891733
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      50500
expl/num paths total                       2525
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.679096
expl/Rewards Std                              2.07613
expl/Rewards Max                             10
expl/Rewards Min                              9.34322e-05
expl/Returns Mean                            13.5819
expl/Returns Std                             31.6382
expl/Returns Max                            134.213
expl/Returns Min                              0.227302
expl/Actions Mean                            -0.0649791
expl/Actions Std                              0.760825
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                         13.5819
expl/env_infos/final/reward_dist Mean         1.04991
expl/env_infos/final/reward_dist Std          2.7385
expl/env_infos/final/reward_dist Max         10
expl/env_infos/final/reward_dist Min          0.000617147
expl/env_infos/initial/reward_dist Mean       0.0331081
expl/env_infos/initial/reward_dist Std        0.0317395
expl/env_infos/initial/reward_dist Max        0.172254
expl/env_infos/initial/reward_dist Min        0.00653593
expl/env_infos/reward_dist Mean               0.679096
expl/env_infos/reward_dist Std                2.07613
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                9.34322e-05
eval/num steps total                       8100
eval/num paths total                        405
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.330368
eval/Rewards Std                              1.10823
eval/Rewards Max                             10
eval/Rewards Min                              0.00270932
eval/Returns Mean                             6.60737
eval/Returns Std                              6.63611
eval/Returns Max                             19.4871
eval/Returns Min                              0.365365
eval/Actions Mean                            -0.0432252
eval/Actions Std                              0.858556
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          6.60737
eval/env_infos/final/reward_dist Mean         0.0979205
eval/env_infos/final/reward_dist Std          0.117848
eval/env_infos/final/reward_dist Max          0.298477
eval/env_infos/final/reward_dist Min          0.00275884
eval/env_infos/initial/reward_dist Mean       0.0334158
eval/env_infos/initial/reward_dist Std        0.0231366
eval/env_infos/initial/reward_dist Max        0.0720411
eval/env_infos/initial/reward_dist Min        0.0107792
eval/env_infos/reward_dist Mean               0.330368
eval/env_infos/reward_dist Std                1.10823
eval/env_infos/reward_dist Max               10
eval/env_infos/reward_dist Min                0.00270932
time/data storing (s)                         0.00151986
time/evaluation sampling (s)                  1.53485
time/exploration sampling (s)                 6.7258
time/logging (s)                              0.0023646
time/saving (s)                               0.00114671
time/training (s)                             4.52281
time/epoch (s)                               12.7885
time/total (s)                              928.973
Epoch                                        80
---------------------------------------  ----------------
2023-08-03 21:00:38.855707 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 81 finished
---------------------------------------  ----------------
epoch                                        81
replay_buffer/size                        51000
trainer/QF Loss                           50699.3
trainer/Policy Loss                       -5412.37
trainer/Raw Policy Loss                   -5412.37
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 5162.23
trainer/Q Predictions Std                   742.993
trainer/Q Predictions Max                 12167.7
trainer/Q Predictions Min                  3632.03
trainer/Q Targets Mean                     5168.06
trainer/Q Targets Std                       770.06
trainer/Q Targets Max                     12359.2
trainer/Q Targets Min                      3724.04
trainer/Bellman Errors Mean               50699.3
trainer/Bellman Errors Std               124139
trainer/Bellman Errors Max                    2.02335e+06
trainer/Bellman Errors Min                    0.000572443
trainer/Policy Action Mean                    0.0085953
trainer/Policy Action Std                     0.918635
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      51000
expl/num paths total                       2550
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.470269
expl/Rewards Std                              0.802823
expl/Rewards Max                              4.08322
expl/Rewards Min                              8.85663e-06
expl/Returns Mean                             9.40538
expl/Returns Std                             11.6263
expl/Returns Max                             36.461
expl/Returns Min                              0.206873
expl/Actions Mean                             0.0181579
expl/Actions Std                              0.781474
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          9.40538
expl/env_infos/final/reward_dist Mean         0.48188
expl/env_infos/final/reward_dist Std          0.9058
expl/env_infos/final/reward_dist Max          3.77839
expl/env_infos/final/reward_dist Min          0.000493065
expl/env_infos/initial/reward_dist Mean       0.0323701
expl/env_infos/initial/reward_dist Std        0.0238544
expl/env_infos/initial/reward_dist Max        0.073154
expl/env_infos/initial/reward_dist Min        0.00299444
expl/env_infos/reward_dist Mean               0.470269
expl/env_infos/reward_dist Std                0.802823
expl/env_infos/reward_dist Max                4.08322
expl/env_infos/reward_dist Min                8.85663e-06
eval/num steps total                       8200
eval/num paths total                        410
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.393794
eval/Rewards Std                              0.666759
eval/Rewards Max                              2.67715
eval/Rewards Min                              7.02935e-05
eval/Returns Mean                             7.87589
eval/Returns Std                              9.32205
eval/Returns Max                             25.3286
eval/Returns Min                              0.172878
eval/Actions Mean                             0.118935
eval/Actions Std                              0.891817
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          7.87589
eval/env_infos/final/reward_dist Mean         0.242357
eval/env_infos/final/reward_dist Std          0.482612
eval/env_infos/final/reward_dist Max          1.20758
eval/env_infos/final/reward_dist Min          0.000589888
eval/env_infos/initial/reward_dist Mean       0.0300435
eval/env_infos/initial/reward_dist Std        0.0133441
eval/env_infos/initial/reward_dist Max        0.0499313
eval/env_infos/initial/reward_dist Min        0.012078
eval/env_infos/reward_dist Mean               0.393794
eval/env_infos/reward_dist Std                0.666759
eval/env_infos/reward_dist Max                2.67715
eval/env_infos/reward_dist Min                7.02935e-05
time/data storing (s)                         0.00217585
time/evaluation sampling (s)                  1.45499
time/exploration sampling (s)                 6.32158
time/logging (s)                              0.00226856
time/saving (s)                               0.00100063
time/training (s)                             4.29764
time/epoch (s)                               12.0797
time/total (s)                              941.055
Epoch                                        81
---------------------------------------  ----------------
2023-08-03 21:00:48.114077 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 82 finished
---------------------------------------  ---------------
epoch                                       82
replay_buffer/size                       51500
trainer/QF Loss                          35608.1
trainer/Policy Loss                      -5710.03
trainer/Raw Policy Loss                  -5710.03
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                5403.06
trainer/Q Predictions Std                  847.812
trainer/Q Predictions Max                13234.8
trainer/Q Predictions Min                 4026.19
trainer/Q Targets Mean                    5409.45
trainer/Q Targets Std                      868.673
trainer/Q Targets Max                    13208.8
trainer/Q Targets Min                     4028.42
trainer/Bellman Errors Mean              35608.1
trainer/Bellman Errors Std               80049.4
trainer/Bellman Errors Max                   1.32591e+06
trainer/Bellman Errors Min                   0.000362635
trainer/Policy Action Mean                   0.0574289
trainer/Policy Action Std                    0.932071
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     51500
expl/num paths total                      2575
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0201782
expl/Rewards Std                             0.0704769
expl/Rewards Max                             0.620995
expl/Rewards Min                             5.79842e-15
expl/Returns Mean                            0.403564
expl/Returns Std                             0.902961
expl/Returns Max                             3.30899
expl/Returns Min                             0.0157048
expl/Actions Mean                           -0.0184366
expl/Actions Std                             0.817265
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.403564
expl/env_infos/final/reward_dist Mean        0.0274525
expl/env_infos/final/reward_dist Std         0.071027
expl/env_infos/final/reward_dist Max         0.292196
expl/env_infos/final/reward_dist Min         5.79842e-15
expl/env_infos/initial/reward_dist Mean      0.0118378
expl/env_infos/initial/reward_dist Std       0.011741
expl/env_infos/initial/reward_dist Max       0.0358503
expl/env_infos/initial/reward_dist Min       8.88215e-06
expl/env_infos/reward_dist Mean              0.0201782
expl/env_infos/reward_dist Std               0.0704769
expl/env_infos/reward_dist Max               0.620995
expl/env_infos/reward_dist Min               5.79842e-15
eval/num steps total                      8300
eval/num paths total                       415
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00165792
eval/Rewards Std                             0.00393064
eval/Rewards Max                             0.0267935
eval/Rewards Min                             1.25969e-07
eval/Returns Mean                            0.0331583
eval/Returns Std                             0.0195226
eval/Returns Max                             0.0714821
eval/Returns Min                             0.0177548
eval/Actions Mean                           -0.0166992
eval/Actions Std                             0.952895
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0331583
eval/env_infos/final/reward_dist Mean        0.00148307
eval/env_infos/final/reward_dist Std         0.00201981
eval/env_infos/final/reward_dist Max         0.00540339
eval/env_infos/final/reward_dist Min         5.21738e-05
eval/env_infos/initial/reward_dist Mean      0.00951577
eval/env_infos/initial/reward_dist Std       0.00998339
eval/env_infos/initial/reward_dist Max       0.0267935
eval/env_infos/initial/reward_dist Min       0.00148123
eval/env_infos/reward_dist Mean              0.00165792
eval/env_infos/reward_dist Std               0.00393064
eval/env_infos/reward_dist Max               0.0267935
eval/env_infos/reward_dist Min               1.25969e-07
time/data storing (s)                        0.00152998
time/evaluation sampling (s)                 0.738722
time/exploration sampling (s)                4.1842
time/logging (s)                             0.00225315
time/saving (s)                              0.00101079
time/training (s)                            4.32787
time/epoch (s)                               9.25559
time/total (s)                             950.313
Epoch                                       82
---------------------------------------  ---------------
2023-08-03 21:00:57.027694 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 83 finished
---------------------------------------  ----------------
epoch                                        83
replay_buffer/size                        52000
trainer/QF Loss                           43290.3
trainer/Policy Loss                       -5774.15
trainer/Raw Policy Loss                   -5774.15
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 5430.17
trainer/Q Predictions Std                   773.184
trainer/Q Predictions Max                 11962.6
trainer/Q Predictions Min                  3391.91
trainer/Q Targets Mean                     5424.7
trainer/Q Targets Std                       800.725
trainer/Q Targets Max                     12436.2
trainer/Q Targets Min                      3520.98
trainer/Bellman Errors Mean               43290.3
trainer/Bellman Errors Std               114422
trainer/Bellman Errors Max                    2.53004e+06
trainer/Bellman Errors Min                    0.00366592
trainer/Policy Action Mean                   -0.207949
trainer/Policy Action Std                     0.941477
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      52000
expl/num paths total                       2600
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.00183095
expl/Rewards Std                              0.00595424
expl/Rewards Max                              0.0717633
expl/Rewards Min                              1.93075e-20
expl/Returns Mean                             0.0366189
expl/Returns Std                              0.0274144
expl/Returns Max                              0.12804
expl/Returns Min                              0.00603763
expl/Actions Mean                            -0.245704
expl/Actions Std                              0.818749
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.0366189
expl/env_infos/final/reward_dist Mean         7.80142e-08
expl/env_infos/final/reward_dist Std          3.04405e-07
expl/env_infos/final/reward_dist Max          1.55491e-06
expl/env_infos/final/reward_dist Min          1.93075e-20
expl/env_infos/initial/reward_dist Mean       0.00872344
expl/env_infos/initial/reward_dist Std        0.0136262
expl/env_infos/initial/reward_dist Max        0.0435868
expl/env_infos/initial/reward_dist Min        7.26949e-05
expl/env_infos/reward_dist Mean               0.00183095
expl/env_infos/reward_dist Std                0.00595424
expl/env_infos/reward_dist Max                0.0717633
expl/env_infos/reward_dist Min                1.93075e-20
eval/num steps total                       8400
eval/num paths total                        420
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.00194142
eval/Rewards Std                              0.00442851
eval/Rewards Max                              0.0301406
eval/Rewards Min                              1.45183e-19
eval/Returns Mean                             0.0388284
eval/Returns Std                              0.0162778
eval/Returns Max                              0.069184
eval/Returns Min                              0.0216197
eval/Actions Mean                            -0.317368
eval/Actions Std                              0.937404
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.0388284
eval/env_infos/final/reward_dist Mean         2.10273e-13
eval/env_infos/final/reward_dist Std          4.20535e-13
eval/env_infos/final/reward_dist Max          1.05134e-12
eval/env_infos/final/reward_dist Min          1.45183e-19
eval/env_infos/initial/reward_dist Mean       0.0063624
eval/env_infos/initial/reward_dist Std        0.00509307
eval/env_infos/initial/reward_dist Max        0.0155087
eval/env_infos/initial/reward_dist Min        7.11553e-05
eval/env_infos/reward_dist Mean               0.00194142
eval/env_infos/reward_dist Std                0.00442851
eval/env_infos/reward_dist Max                0.0301406
eval/env_infos/reward_dist Min                1.45183e-19
time/data storing (s)                         0.00215214
time/evaluation sampling (s)                  0.711611
time/exploration sampling (s)                 4.00645
time/logging (s)                              0.00174741
time/saving (s)                               0.000777251
time/training (s)                             4.18763
time/epoch (s)                                8.91037
time/total (s)                              959.225
Epoch                                        83
---------------------------------------  ----------------
2023-08-03 21:01:07.080452 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 84 finished
---------------------------------------  ---------------
epoch                                       84
replay_buffer/size                       52500
trainer/QF Loss                          29868.6
trainer/Policy Loss                      -5701.23
trainer/Raw Policy Loss                  -5701.23
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                5406.57
trainer/Q Predictions Std                  791.906
trainer/Q Predictions Max                11179.8
trainer/Q Predictions Min                 3237.26
trainer/Q Targets Mean                    5391.98
trainer/Q Targets Std                      800.821
trainer/Q Targets Max                    11183.9
trainer/Q Targets Min                     3291.38
trainer/Bellman Errors Mean              29868.6
trainer/Bellman Errors Std               73022.3
trainer/Bellman Errors Max                   1.85157e+06
trainer/Bellman Errors Min                   0.000344276
trainer/Policy Action Mean                   0.0249285
trainer/Policy Action Std                    0.95836
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     52500
expl/num paths total                      2625
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0108633
expl/Rewards Std                             0.0351998
expl/Rewards Max                             0.211121
expl/Rewards Min                             2.82022e-18
expl/Returns Mean                            0.217266
expl/Returns Std                             0.567134
expl/Returns Max                             2.70014
expl/Returns Min                             0.012805
expl/Actions Mean                           -0.0838983
expl/Actions Std                             0.83391
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.217266
expl/env_infos/final/reward_dist Mean        0.00900977
expl/env_infos/final/reward_dist Std         0.0413399
expl/env_infos/final/reward_dist Max         0.211121
expl/env_infos/final/reward_dist Min         2.82022e-18
expl/env_infos/initial/reward_dist Mean      0.0126486
expl/env_infos/initial/reward_dist Std       0.0150224
expl/env_infos/initial/reward_dist Max       0.0572531
expl/env_infos/initial/reward_dist Min       0.000363269
expl/env_infos/reward_dist Mean              0.0108633
expl/env_infos/reward_dist Std               0.0351998
expl/env_infos/reward_dist Max               0.211121
expl/env_infos/reward_dist Min               2.82022e-18
eval/num steps total                      8500
eval/num paths total                       425
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00313208
eval/Rewards Std                             0.0072587
eval/Rewards Max                             0.0392612
eval/Rewards Min                             9.27324e-20
eval/Returns Mean                            0.0626415
eval/Returns Std                             0.00624499
eval/Returns Max                             0.0739779
eval/Returns Min                             0.0562007
eval/Actions Mean                           -0.105574
eval/Actions Std                             0.968459
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0626415
eval/env_infos/final/reward_dist Mean        1.34235e-12
eval/env_infos/final/reward_dist Std         1.74992e-12
eval/env_infos/final/reward_dist Max         4.66125e-12
eval/env_infos/final/reward_dist Min         9.27324e-20
eval/env_infos/initial/reward_dist Mean      0.0151361
eval/env_infos/initial/reward_dist Std       0.0120182
eval/env_infos/initial/reward_dist Max       0.0331205
eval/env_infos/initial/reward_dist Min       0.000560619
eval/env_infos/reward_dist Mean              0.00313208
eval/env_infos/reward_dist Std               0.0072587
eval/env_infos/reward_dist Max               0.0392612
eval/env_infos/reward_dist Min               9.27324e-20
time/data storing (s)                        0.00217766
time/evaluation sampling (s)                 0.715827
time/exploration sampling (s)                4.14212
time/logging (s)                             0.0023054
time/saving (s)                              0.00102251
time/training (s)                            5.18776
time/epoch (s)                              10.0512
time/total (s)                             969.278
Epoch                                       84
---------------------------------------  ---------------
2023-08-03 21:01:16.643156 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 85 finished
---------------------------------------  ----------------
epoch                                        85
replay_buffer/size                        53000
trainer/QF Loss                           18328.6
trainer/Policy Loss                       -5140.62
trainer/Raw Policy Loss                   -5140.62
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 4939.98
trainer/Q Predictions Std                   482.218
trainer/Q Predictions Max                  8762.98
trainer/Q Predictions Min                  3456.08
trainer/Q Targets Mean                     4939.32
trainer/Q Targets Std                       496.214
trainer/Q Targets Max                      8577.97
trainer/Q Targets Min                      3431.12
trainer/Bellman Errors Mean               18328.6
trainer/Bellman Errors Std                46035
trainer/Bellman Errors Max               894085
trainer/Bellman Errors Min                    0.00148797
trainer/Policy Action Mean                    0.0303891
trainer/Policy Action Std                     0.942575
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      53000
expl/num paths total                       2650
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0147562
expl/Rewards Std                              0.0667263
expl/Rewards Max                              0.621959
expl/Rewards Min                              9.05974e-20
expl/Returns Mean                             0.295124
expl/Returns Std                              0.964732
expl/Returns Max                              4.99877
expl/Returns Min                              0.0133368
expl/Actions Mean                            -0.137723
expl/Actions Std                              0.817608
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.295124
expl/env_infos/final/reward_dist Mean         0.000114029
expl/env_infos/final/reward_dist Std          0.000383974
expl/env_infos/final/reward_dist Max          0.00181953
expl/env_infos/final/reward_dist Min          9.05974e-20
expl/env_infos/initial/reward_dist Mean       0.02093
expl/env_infos/initial/reward_dist Std        0.0152838
expl/env_infos/initial/reward_dist Max        0.0562328
expl/env_infos/initial/reward_dist Min        0.000565759
expl/env_infos/reward_dist Mean               0.0147562
expl/env_infos/reward_dist Std                0.0667263
expl/env_infos/reward_dist Max                0.621959
expl/env_infos/reward_dist Min                9.05974e-20
eval/num steps total                       8600
eval/num paths total                        430
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0284558
eval/Rewards Std                              0.0889659
eval/Rewards Max                              0.486272
eval/Rewards Min                              8.09108e-18
eval/Returns Mean                             0.569117
eval/Returns Std                              1.01667
eval/Returns Max                              2.60189
eval/Returns Min                              0.0266133
eval/Actions Mean                            -0.256562
eval/Actions Std                              0.931258
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.569117
eval/env_infos/final/reward_dist Mean         1.25162e-13
eval/env_infos/final/reward_dist Std          1.38124e-13
eval/env_infos/final/reward_dist Max          3.40141e-13
eval/env_infos/final/reward_dist Min          8.09108e-18
eval/env_infos/initial/reward_dist Mean       0.0931128
eval/env_infos/initial/reward_dist Std        0.145718
eval/env_infos/initial/reward_dist Max        0.382554
eval/env_infos/initial/reward_dist Min        0.00543382
eval/env_infos/reward_dist Mean               0.0284558
eval/env_infos/reward_dist Std                0.0889659
eval/env_infos/reward_dist Max                0.486272
eval/env_infos/reward_dist Min                8.09108e-18
time/data storing (s)                         0.00176186
time/evaluation sampling (s)                  0.770525
time/exploration sampling (s)                 4.1141
time/logging (s)                              0.00319545
time/saving (s)                               0.00987657
time/training (s)                             4.66127
time/epoch (s)                                9.56073
time/total (s)                              978.841
Epoch                                        85
---------------------------------------  ----------------
2023-08-03 21:01:27.670831 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 86 finished
---------------------------------------  ----------------
epoch                                        86
replay_buffer/size                        53500
trainer/QF Loss                           11774.2
trainer/Policy Loss                       -4357.59
trainer/Raw Policy Loss                   -4357.59
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 4236
trainer/Q Predictions Std                   293.556
trainer/Q Predictions Max                  8034.15
trainer/Q Predictions Min                  3516.31
trainer/Q Targets Mean                     4233.36
trainer/Q Targets Std                       310.114
trainer/Q Targets Max                      8235.99
trainer/Q Targets Min                      3558.5
trainer/Bellman Errors Mean               11774.2
trainer/Bellman Errors Std                29188.2
trainer/Bellman Errors Max               670776
trainer/Bellman Errors Min                    0.000774622
trainer/Policy Action Mean                   -0.0451956
trainer/Policy Action Std                     0.934763
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      53500
expl/num paths total                       2675
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0503798
expl/Rewards Std                              0.173451
expl/Rewards Max                              2.18504
expl/Rewards Min                              4.10784e-16
expl/Returns Mean                             1.0076
expl/Returns Std                              1.97751
expl/Returns Max                              7.61276
expl/Returns Min                              0.053683
expl/Actions Mean                            -0.0580604
expl/Actions Std                              0.798151
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          1.0076
expl/env_infos/final/reward_dist Mean         0.0489999
expl/env_infos/final/reward_dist Std          0.135387
expl/env_infos/final/reward_dist Max          0.628066
expl/env_infos/final/reward_dist Min          4.10784e-16
expl/env_infos/initial/reward_dist Mean       0.0236749
expl/env_infos/initial/reward_dist Std        0.012746
expl/env_infos/initial/reward_dist Max        0.0489426
expl/env_infos/initial/reward_dist Min        0.00516864
expl/env_infos/reward_dist Mean               0.0503798
expl/env_infos/reward_dist Std                0.173451
expl/env_infos/reward_dist Max                2.18504
expl/env_infos/reward_dist Min                4.10784e-16
eval/num steps total                       8700
eval/num paths total                        435
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.0726815
eval/Rewards Std                              0.256728
eval/Rewards Max                              1.82837
eval/Rewards Min                              1.20095e-13
eval/Returns Mean                             1.45363
eval/Returns Std                              2.6211
eval/Returns Max                              6.69449
eval/Returns Min                              0.0588667
eval/Actions Mean                            -0.117576
eval/Actions Std                              0.907917
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          1.45363
eval/env_infos/final/reward_dist Mean         0.010937
eval/env_infos/final/reward_dist Std          0.021868
eval/env_infos/final/reward_dist Max          0.054673
eval/env_infos/final/reward_dist Min          1.20095e-13
eval/env_infos/initial/reward_dist Mean       0.00933723
eval/env_infos/initial/reward_dist Std        0.00612673
eval/env_infos/initial/reward_dist Max        0.0202499
eval/env_infos/initial/reward_dist Min        0.00272608
eval/env_infos/reward_dist Mean               0.0726815
eval/env_infos/reward_dist Std                0.256728
eval/env_infos/reward_dist Max                1.82837
eval/env_infos/reward_dist Min                1.20095e-13
time/data storing (s)                         0.0021591
time/evaluation sampling (s)                  0.841221
time/exploration sampling (s)                 4.74468
time/logging (s)                              0.00232294
time/saving (s)                               0.00100382
time/training (s)                             5.4317
time/epoch (s)                               11.0231
time/total (s)                              989.866
Epoch                                        86
---------------------------------------  ----------------
2023-08-03 21:01:39.031099 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 87 finished
---------------------------------------  ----------------
epoch                                        87
replay_buffer/size                        54000
trainer/QF Loss                           12909.5
trainer/Policy Loss                       -3669.27
trainer/Raw Policy Loss                   -3669.27
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 3555.89
trainer/Q Predictions Std                   422.718
trainer/Q Predictions Max                  7303.89
trainer/Q Predictions Min                  3062.73
trainer/Q Targets Mean                     3549.49
trainer/Q Targets Std                       436.107
trainer/Q Targets Max                      7611.58
trainer/Q Targets Min                      2935.09
trainer/Bellman Errors Mean               12909.5
trainer/Bellman Errors Std                30696.4
trainer/Bellman Errors Max               507180
trainer/Bellman Errors Min                    0.00056082
trainer/Policy Action Mean                    0.0592378
trainer/Policy Action Std                     0.9242
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      54000
expl/num paths total                       2700
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.606486
expl/Rewards Std                              1.92092
expl/Rewards Max                             10
expl/Rewards Min                              4.37812e-13
expl/Returns Mean                            12.1297
expl/Returns Std                             36.7513
expl/Returns Max                            190.121
expl/Returns Min                              0.0885465
expl/Actions Mean                            -0.0131855
expl/Actions Std                              0.79037
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                         12.1297
expl/env_infos/final/reward_dist Mean         0.707208
expl/env_infos/final/reward_dist Std          1.98283
expl/env_infos/final/reward_dist Max         10
expl/env_infos/final/reward_dist Min          4.37812e-13
expl/env_infos/initial/reward_dist Mean       0.0401878
expl/env_infos/initial/reward_dist Std        0.0299708
expl/env_infos/initial/reward_dist Max        0.124123
expl/env_infos/initial/reward_dist Min        0.00377585
expl/env_infos/reward_dist Mean               0.606486
expl/env_infos/reward_dist Std                1.92092
expl/env_infos/reward_dist Max               10
expl/env_infos/reward_dist Min                4.37812e-13
eval/num steps total                       8800
eval/num paths total                        440
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.277942
eval/Rewards Std                              0.612985
eval/Rewards Max                              3.50656
eval/Rewards Min                              1.94315e-17
eval/Returns Mean                             5.55885
eval/Returns Std                              9.99305
eval/Returns Max                             25.5166
eval/Returns Min                              0.0552509
eval/Actions Mean                            -0.0502846
eval/Actions Std                              0.924958
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          5.55885
eval/env_infos/final/reward_dist Mean         0.326527
eval/env_infos/final/reward_dist Std          0.645852
eval/env_infos/final/reward_dist Max          1.61818
eval/env_infos/final/reward_dist Min          1.94315e-17
eval/env_infos/initial/reward_dist Mean       0.0296026
eval/env_infos/initial/reward_dist Std        0.0269086
eval/env_infos/initial/reward_dist Max        0.08108
eval/env_infos/initial/reward_dist Min        0.00531303
eval/env_infos/reward_dist Mean               0.277942
eval/env_infos/reward_dist Std                0.612985
eval/env_infos/reward_dist Max                3.50656
eval/env_infos/reward_dist Min                1.94315e-17
time/data storing (s)                         0.00154205
time/evaluation sampling (s)                  0.931794
time/exploration sampling (s)                 6.10683
time/logging (s)                              0.00224702
time/saving (s)                               0.00100345
time/training (s)                             4.314
time/epoch (s)                               11.3574
time/total (s)                             1001.23
Epoch                                        87
---------------------------------------  ----------------
2023-08-03 21:01:50.533899 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 88 finished
---------------------------------------  ---------------
epoch                                       88
replay_buffer/size                       54500
trainer/QF Loss                          34182.5
trainer/Policy Loss                      -3735
trainer/Raw Policy Loss                  -3735
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                3503.61
trainer/Q Predictions Std                 1066.49
trainer/Q Predictions Max                10426.5
trainer/Q Predictions Min                 2627.39
trainer/Q Targets Mean                    3504.75
trainer/Q Targets Std                     1072.57
trainer/Q Targets Max                    10293.9
trainer/Q Targets Min                     2579.13
trainer/Bellman Errors Mean              34182.5
trainer/Bellman Errors Std               88527.1
trainer/Bellman Errors Max                   1.78592e+06
trainer/Bellman Errors Min                   0.00543618
trainer/Policy Action Mean                   0.121304
trainer/Policy Action Std                    0.928853
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     54500
expl/num paths total                      2725
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0292841
expl/Rewards Std                             0.114921
expl/Rewards Max                             1.23189
expl/Rewards Min                             2.68207e-23
expl/Returns Mean                            0.585682
expl/Returns Std                             1.25554
expl/Returns Max                             5.65019
expl/Returns Min                             0.009241
expl/Actions Mean                            0.121975
expl/Actions Std                             0.815779
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.585682
expl/env_infos/final/reward_dist Mean        0.00174972
expl/env_infos/final/reward_dist Std         0.00763017
expl/env_infos/final/reward_dist Max         0.0388332
expl/env_infos/final/reward_dist Min         2.68207e-23
expl/env_infos/initial/reward_dist Mean      0.0657335
expl/env_infos/initial/reward_dist Std       0.149548
expl/env_infos/initial/reward_dist Max       0.759716
expl/env_infos/initial/reward_dist Min       0.00247599
expl/env_infos/reward_dist Mean              0.0292841
expl/env_infos/reward_dist Std               0.114921
expl/env_infos/reward_dist Max               1.23189
expl/env_infos/reward_dist Min               2.68207e-23
eval/num steps total                      8900
eval/num paths total                       445
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0315739
eval/Rewards Std                             0.135593
eval/Rewards Max                             1.23825
eval/Rewards Min                             1.18447e-16
eval/Returns Mean                            0.631478
eval/Returns Std                             0.958114
eval/Returns Max                             2.53368
eval/Returns Min                             0.0297658
eval/Actions Mean                            0.096687
eval/Actions Std                             0.943127
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.631478
eval/env_infos/final/reward_dist Mean        2.95719e-05
eval/env_infos/final/reward_dist Std         5.91169e-05
eval/env_infos/final/reward_dist Max         0.000147806
eval/env_infos/final/reward_dist Min         1.18447e-16
eval/env_infos/initial/reward_dist Mean      0.0451225
eval/env_infos/initial/reward_dist Std       0.015515
eval/env_infos/initial/reward_dist Max       0.0702921
eval/env_infos/initial/reward_dist Min       0.0257717
eval/env_infos/reward_dist Mean              0.0315739
eval/env_infos/reward_dist Std               0.135593
eval/env_infos/reward_dist Max               1.23825
eval/env_infos/reward_dist Min               1.18447e-16
time/data storing (s)                        0.00215945
time/evaluation sampling (s)                 0.975286
time/exploration sampling (s)                5.34337
time/logging (s)                             0.00288803
time/saving (s)                              0.00112043
time/training (s)                            5.17586
time/epoch (s)                              11.5007
time/total (s)                            1012.73
Epoch                                       88
---------------------------------------  ---------------
2023-08-03 21:02:00.864011 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 89 finished
---------------------------------------  ----------------
epoch                                        89
replay_buffer/size                        55000
trainer/QF Loss                           54880.2
trainer/Policy Loss                       -5969.63
trainer/Raw Policy Loss                   -5969.63
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 5603.86
trainer/Q Predictions Std                  1103.68
trainer/Q Predictions Max                 10230.2
trainer/Q Predictions Min                  3867.47
trainer/Q Targets Mean                     5617.16
trainer/Q Targets Std                      1129.6
trainer/Q Targets Max                     10157.9
trainer/Q Targets Min                      3698.98
trainer/Bellman Errors Mean               54880.2
trainer/Bellman Errors Std               138902
trainer/Bellman Errors Max                    3.23639e+06
trainer/Bellman Errors Min                    0.000620127
trainer/Policy Action Mean                    0.101682
trainer/Policy Action Std                     0.970623
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      55000
expl/num paths total                       2750
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.00250264
expl/Rewards Std                              0.00989777
expl/Rewards Max                              0.143147
expl/Rewards Min                              4.95911e-22
expl/Returns Mean                             0.0500528
expl/Returns Std                              0.105245
expl/Returns Max                              0.549852
expl/Returns Min                              0.00222019
expl/Actions Mean                             0.04866
expl/Actions Std                              0.827839
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.0500528
expl/env_infos/final/reward_dist Mean         1.20517e-05
expl/env_infos/final/reward_dist Std          5.90387e-05
expl/env_infos/final/reward_dist Max          0.000301281
expl/env_infos/final/reward_dist Min          4.95911e-22
expl/env_infos/initial/reward_dist Mean       0.00616475
expl/env_infos/initial/reward_dist Std        0.0100304
expl/env_infos/initial/reward_dist Max        0.0468266
expl/env_infos/initial/reward_dist Min        6.74355e-05
expl/env_infos/reward_dist Mean               0.00250264
expl/env_infos/reward_dist Std                0.00989777
expl/env_infos/reward_dist Max                0.143147
expl/env_infos/reward_dist Min                4.95911e-22
eval/num steps total                       9000
eval/num paths total                        450
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.000705221
eval/Rewards Std                              0.00353089
eval/Rewards Max                              0.0332264
eval/Rewards Min                              2.06043e-20
eval/Returns Mean                             0.0141044
eval/Returns Std                              0.0206627
eval/Returns Max                              0.0554154
eval/Returns Min                              0.00312902
eval/Actions Mean                             0.0339828
eval/Actions Std                              0.967109
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.0141044
eval/env_infos/final/reward_dist Mean         4.37854e-14
eval/env_infos/final/reward_dist Std          8.28578e-14
eval/env_infos/final/reward_dist Max          2.09409e-13
eval/env_infos/final/reward_dist Min          2.06043e-20
eval/env_infos/initial/reward_dist Mean       0.00327096
eval/env_infos/initial/reward_dist Std        0.00421416
eval/env_infos/initial/reward_dist Max        0.0116663
eval/env_infos/initial/reward_dist Min        0.000704383
eval/env_infos/reward_dist Mean               0.000705221
eval/env_infos/reward_dist Std                0.00353089
eval/env_infos/reward_dist Max                0.0332264
eval/env_infos/reward_dist Min                2.06043e-20
time/data storing (s)                         0.00215437
time/evaluation sampling (s)                  0.766353
time/exploration sampling (s)                 4.96539
time/logging (s)                              0.00226624
time/saving (s)                               0.000963285
time/training (s)                             4.58866
time/epoch (s)                               10.3258
time/total (s)                             1023.06
Epoch                                        89
---------------------------------------  ----------------
2023-08-03 21:02:10.833399 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 90 finished
---------------------------------------  ---------------
epoch                                       90
replay_buffer/size                       55500
trainer/QF Loss                          31497
trainer/Policy Loss                      -6250.19
trainer/Raw Policy Loss                  -6250.19
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                6033.09
trainer/Q Predictions Std                  642.726
trainer/Q Predictions Max                11657.6
trainer/Q Predictions Min                 5027.7
trainer/Q Targets Mean                    6024.34
trainer/Q Targets Std                      661.822
trainer/Q Targets Max                    11748.6
trainer/Q Targets Min                     4901.19
trainer/Bellman Errors Mean              31497
trainer/Bellman Errors Std               86560
trainer/Bellman Errors Max                   1.75204e+06
trainer/Bellman Errors Min                   3.43323e-05
trainer/Policy Action Mean                  -0.019633
trainer/Policy Action Std                    0.957302
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     55500
expl/num paths total                      2775
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.002717
expl/Rewards Std                             0.0139052
expl/Rewards Max                             0.213046
expl/Rewards Min                             7.22256e-20
expl/Returns Mean                            0.05434
expl/Returns Std                             0.133688
expl/Returns Max                             0.693606
expl/Returns Min                             0.00174336
expl/Actions Mean                            0.0225811
expl/Actions Std                             0.826555
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.05434
expl/env_infos/final/reward_dist Mean        3.38218e-06
expl/env_infos/final/reward_dist Std         1.65672e-05
expl/env_infos/final/reward_dist Max         8.45446e-05
expl/env_infos/final/reward_dist Min         7.22256e-20
expl/env_infos/initial/reward_dist Mean      0.0131828
expl/env_infos/initial/reward_dist Std       0.0195061
expl/env_infos/initial/reward_dist Max       0.0570947
expl/env_infos/initial/reward_dist Min       8.952e-05
expl/env_infos/reward_dist Mean              0.002717
expl/env_infos/reward_dist Std               0.0139052
expl/env_infos/reward_dist Max               0.213046
expl/env_infos/reward_dist Min               7.22256e-20
eval/num steps total                      9100
eval/num paths total                       455
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.000614415
eval/Rewards Std                             0.00266371
eval/Rewards Max                             0.0254257
eval/Rewards Min                             3.45067e-16
eval/Returns Mean                            0.0122883
eval/Returns Std                             0.0110932
eval/Returns Max                             0.0338363
eval/Returns Min                             0.00378765
eval/Actions Mean                            0.0176427
eval/Actions Std                             0.981208
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0122883
eval/env_infos/final/reward_dist Mean        4.37928e-15
eval/env_infos/final/reward_dist Std         4.07052e-15
eval/env_infos/final/reward_dist Max         1.08273e-14
eval/env_infos/final/reward_dist Min         3.45067e-16
eval/env_infos/initial/reward_dist Mean      0.00114691
eval/env_infos/initial/reward_dist Std       0.000837847
eval/env_infos/initial/reward_dist Max       0.00218459
eval/env_infos/initial/reward_dist Min       0.000173093
eval/env_infos/reward_dist Mean              0.000614415
eval/env_infos/reward_dist Std               0.00266371
eval/env_infos/reward_dist Max               0.0254257
eval/env_infos/reward_dist Min               3.45067e-16
time/data storing (s)                        0.00149184
time/evaluation sampling (s)                 0.72239
time/exploration sampling (s)                5.28601
time/logging (s)                             0.00233997
time/saving (s)                              0.000993139
time/training (s)                            3.95339
time/epoch (s)                               9.96662
time/total (s)                            1033.03
Epoch                                       90
---------------------------------------  ---------------
2023-08-03 21:02:20.898036 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 91 finished
---------------------------------------  ---------------
epoch                                       91
replay_buffer/size                       56000
trainer/QF Loss                          20487.9
trainer/Policy Loss                      -6008.93
trainer/Raw Policy Loss                  -6008.93
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                5762.35
trainer/Q Predictions Std                  870.813
trainer/Q Predictions Max                10689.1
trainer/Q Predictions Min                 4648.51
trainer/Q Targets Mean                    5749.55
trainer/Q Targets Std                      876.496
trainer/Q Targets Max                    10800.2
trainer/Q Targets Min                     4511.05
trainer/Bellman Errors Mean              20487.9
trainer/Bellman Errors Std               53834.5
trainer/Bellman Errors Max                   1.60902e+06
trainer/Bellman Errors Min                   0.000344276
trainer/Policy Action Mean                   0.0750025
trainer/Policy Action Std                    0.95106
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     56000
expl/num paths total                      2800
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00135575
expl/Rewards Std                             0.00531335
expl/Rewards Max                             0.0685082
expl/Rewards Min                             8.85528e-22
expl/Returns Mean                            0.0271149
expl/Returns Std                             0.0260657
expl/Returns Max                             0.0972444
expl/Returns Min                             0.00359479
expl/Actions Mean                            0.0203692
expl/Actions Std                             0.828434
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0271149
expl/env_infos/final/reward_dist Mean        8.60019e-10
expl/env_infos/final/reward_dist Std         2.89551e-09
expl/env_infos/final/reward_dist Max         1.17214e-08
expl/env_infos/final/reward_dist Min         8.85528e-22
expl/env_infos/initial/reward_dist Mean      0.00713978
expl/env_infos/initial/reward_dist Std       0.0118154
expl/env_infos/initial/reward_dist Max       0.0440015
expl/env_infos/initial/reward_dist Min       1.76793e-05
expl/env_infos/reward_dist Mean              0.00135575
expl/env_infos/reward_dist Std               0.00531335
expl/env_infos/reward_dist Max               0.0685082
expl/env_infos/reward_dist Min               8.85528e-22
eval/num steps total                      9200
eval/num paths total                       460
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.000304386
eval/Rewards Std                             0.00097675
eval/Rewards Max                             0.00718002
eval/Rewards Min                             2.79992e-18
eval/Returns Mean                            0.00608772
eval/Returns Std                             0.00385985
eval/Returns Max                             0.0122734
eval/Returns Min                             0.00171172
eval/Actions Mean                           -0.0388863
eval/Actions Std                             0.972193
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.00608772
eval/env_infos/final/reward_dist Mean        1.04185e-14
eval/env_infos/final/reward_dist Std         2.0823e-14
eval/env_infos/final/reward_dist Max         5.20644e-14
eval/env_infos/final/reward_dist Min         2.79992e-18
eval/env_infos/initial/reward_dist Mean      0.00283989
eval/env_infos/initial/reward_dist Std       0.00309116
eval/env_infos/initial/reward_dist Max       0.00718002
eval/env_infos/initial/reward_dist Min       9.5546e-05
eval/env_infos/reward_dist Mean              0.000304386
eval/env_infos/reward_dist Std               0.00097675
eval/env_infos/reward_dist Max               0.00718002
eval/env_infos/reward_dist Min               2.79992e-18
time/data storing (s)                        0.00377447
time/evaluation sampling (s)                 0.765291
time/exploration sampling (s)                5.27955
time/logging (s)                             0.00879743
time/saving (s)                              0.0245573
time/training (s)                            3.98396
time/epoch (s)                              10.0659
time/total (s)                            1043.09
Epoch                                       91
---------------------------------------  ---------------
2023-08-03 21:02:32.397140 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_20_44_57_0000--s-0] Epoch 92 finished
---------------------------------------  ----------------
epoch                                        92
replay_buffer/size                        56500
trainer/QF Loss                           35971.8
trainer/Policy Loss                       -6411
trainer/Raw Policy Loss                   -6411
trainer/Preactivation Policy Loss             0
trainer/Q Predictions Mean                 6142.95
trainer/Q Predictions Std                  1050.27
trainer/Q Predictions Max                 11873.9
trainer/Q Predictions Min                  4713.88
trainer/Q Targets Mean                     6153.54
trainer/Q Targets Std                      1069.85
trainer/Q Targets Max                     11835.6
trainer/Q Targets Min                      4660.86
trainer/Bellman Errors Mean               35971.8
trainer/Bellman Errors Std               110240
trainer/Bellman Errors Max                    2.20779e+06
trainer/Bellman Errors Min                    0.0013411
trainer/Policy Action Mean                   -0.0357872
trainer/Policy Action Std                     0.950371
trainer/Policy Action Max                     1
trainer/Policy Action Min                    -1
expl/num steps total                      56500
expl/num paths total                       2825
expl/path length Mean                        20
expl/path length Std                          0
expl/path length Max                         20
expl/path length Min                         20
expl/Rewards Mean                             0.0220664
expl/Rewards Std                              0.18917
expl/Rewards Max                              2.71554
expl/Rewards Min                              1.21956e-18
expl/Returns Mean                             0.441327
expl/Returns Std                              2.0349
expl/Returns Max                             10.4093
expl/Returns Min                              0.00217399
expl/Actions Mean                            -0.0698771
expl/Actions Std                              0.810491
expl/Actions Max                              1
expl/Actions Min                             -1
expl/Num Paths                               25
expl/Average Returns                          0.441327
expl/env_infos/final/reward_dist Mean         0.00121333
expl/env_infos/final/reward_dist Std          0.00594408
expl/env_infos/final/reward_dist Max          0.0303333
expl/env_infos/final/reward_dist Min          1.21956e-18
expl/env_infos/initial/reward_dist Mean       0.00666235
expl/env_infos/initial/reward_dist Std        0.0112027
expl/env_infos/initial/reward_dist Max        0.0462536
expl/env_infos/initial/reward_dist Min        1.16496e-05
expl/env_infos/reward_dist Mean               0.0220664
expl/env_infos/reward_dist Std                0.18917
expl/env_infos/reward_dist Max                2.71554
expl/env_infos/reward_dist Min                1.21956e-18
eval/num steps total                       9300
eval/num paths total                        465
eval/path length Mean                        20
eval/path length Std                          0
eval/path length Max                         20
eval/path length Min                         20
eval/Rewards Mean                             0.000530613
eval/Rewards Std                              0.00213711
eval/Rewards Max                              0.0170633
eval/Rewards Min                              4.88142e-19
eval/Returns Mean                             0.0106123
eval/Returns Std                              0.0081403
eval/Returns Max                              0.0212129
eval/Returns Min                              0.00263234
eval/Actions Mean                            -0.110221
eval/Actions Std                              0.961281
eval/Actions Max                              1
eval/Actions Min                             -1
eval/Num Paths                                5
eval/Average Returns                          0.0106123
eval/env_infos/final/reward_dist Mean         9.57148e-18
eval/env_infos/final/reward_dist Std          1.20574e-17
eval/env_infos/final/reward_dist Max          3.24443e-17
eval/env_infos/final/reward_dist Min          4.88142e-19
eval/env_infos/initial/reward_dist Mean       0.00604722
eval/env_infos/initial/reward_dist Std        0.00708826
eval/env_infos/initial/reward_dist Max        0.0170633
eval/env_infos/initial/reward_dist Min        3.49654e-05
eval/env_infos/reward_dist Mean               0.000530613
eval/env_infos/reward_dist Std                0.00213711
eval/env_infos/reward_dist Max                0.0170633
eval/env_infos/reward_dist Min                4.88142e-19
time/data storing (s)                         0.00215689
time/evaluation sampling (s)                  0.776741
time/exploration sampling (s)                 4.99867
time/logging (s)                              0.00183381
time/saving (s)                               0.000857493
time/training (s)                             5.70491
time/epoch (s)                               11.4852
time/total (s)                             1054.59
Epoch                                        92
---------------------------------------  ----------------
