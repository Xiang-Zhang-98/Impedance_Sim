2023-08-03 21:06:05.842856 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 0 finished
---------------------------------------  ---------------
epoch                                        0
replay_buffer/size                       10500
trainer/QF Loss                              0.856961
trainer/Policy Loss                         -0.00102256
trainer/Raw Policy Loss                     -0.00102256
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                   0.0010258
trainer/Q Predictions Std                    0.000922056
trainer/Q Predictions Max                    0.00368083
trainer/Q Predictions Min                   -0.00318497
trainer/Q Targets Mean                       0.112956
trainer/Q Targets Std                        0.91886
trainer/Q Targets Max                       10.0005
trainer/Q Targets Min                       -0.00237888
trainer/Bellman Errors Mean                  0.856961
trainer/Bellman Errors Std                   8.96219
trainer/Bellman Errors Max                 100.017
trainer/Bellman Errors Min                   9.11272e-15
trainer/Policy Action Mean                  -4.01016e-05
trainer/Policy Action Std                    0.00207388
trainer/Policy Action Max                    0.010524
trainer/Policy Action Min                   -0.0168387
expl/num steps total                     10500
expl/num paths total                       525
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0100829
expl/Rewards Std                             0.0540478
expl/Rewards Max                             0.729266
expl/Rewards Min                             4.19871e-08
expl/Returns Mean                            0.201658
expl/Returns Std                             0.487062
expl/Returns Max                             2.55405
expl/Returns Min                             0.00904692
expl/Actions Mean                           -0.0346134
expl/Actions Std                             0.497949
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.201658
expl/env_infos/final/reward_dist Mean        0.0338862
expl/env_infos/final/reward_dist Std         0.130385
expl/env_infos/final/reward_dist Max         0.667046
expl/env_infos/final/reward_dist Min         1.50291e-06
expl/env_infos/initial/reward_dist Mean      0.0133938
expl/env_infos/initial/reward_dist Std       0.0175832
expl/env_infos/initial/reward_dist Max       0.0663252
expl/env_infos/initial/reward_dist Min       3.72629e-05
expl/env_infos/reward_dist Mean              0.0100829
expl/env_infos/reward_dist Std               0.0540478
expl/env_infos/reward_dist Max               0.729266
expl/env_infos/reward_dist Min               4.19871e-08
eval/num steps total                       100
eval/num paths total                         5
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0212282
eval/Rewards Std                             0.0207072
eval/Rewards Max                             0.0648457
eval/Rewards Min                             0.000163267
eval/Returns Mean                            0.424563
eval/Returns Std                             0.363569
eval/Returns Max                             0.999564
eval/Returns Min                             0.0870642
eval/Actions Mean                            1.02211e-05
eval/Actions Std                             0.00146841
eval/Actions Max                             0.00713147
eval/Actions Min                            -0.0100302
eval/Num Paths                               5
eval/Average Returns                         0.424563
eval/env_infos/final/reward_dist Mean        0.0182574
eval/env_infos/final/reward_dist Std         0.0189588
eval/env_infos/final/reward_dist Max         0.0507562
eval/env_infos/final/reward_dist Min         0.000163267
eval/env_infos/initial/reward_dist Mean      0.0257555
eval/env_infos/initial/reward_dist Std       0.0179758
eval/env_infos/initial/reward_dist Max       0.0508204
eval/env_infos/initial/reward_dist Min       0.00269977
eval/env_infos/reward_dist Mean              0.0212282
eval/env_infos/reward_dist Std               0.0207072
eval/env_infos/reward_dist Max               0.0648457
eval/env_infos/reward_dist Min               0.000163267
time/data storing (s)                        0.00215232
time/evaluation sampling (s)               136.261
time/exploration sampling (s)                6.77817
time/logging (s)                             0.00242513
time/saving (s)                              0.00478566
time/training (s)                           20.0747
time/epoch (s)                             163.123
time/total (s)                             167.705
Epoch                                        0
---------------------------------------  ---------------
2023-08-03 21:06:29.120590 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 1 finished
---------------------------------------  ---------------
epoch                                        1
replay_buffer/size                       11000
trainer/QF Loss                              9.75865
trainer/Policy Loss                        -37.9152
trainer/Raw Policy Loss                    -37.9152
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  29.7547
trainer/Q Predictions Std                    4.72346
trainer/Q Predictions Max                   46.7996
trainer/Q Predictions Min                   19.8858
trainer/Q Targets Mean                      29.5724
trainer/Q Targets Std                        5.50518
trainer/Q Targets Max                       51.9324
trainer/Q Targets Min                       17.9555
trainer/Bellman Errors Mean                  9.75865
trainer/Bellman Errors Std                  20.7716
trainer/Bellman Errors Max                 364.373
trainer/Bellman Errors Min                   1.65265e-06
trainer/Policy Action Mean                  -0.267826
trainer/Policy Action Std                    0.942887
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     11000
expl/num paths total                       550
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0106133
expl/Rewards Std                             0.0421175
expl/Rewards Max                             0.287382
expl/Rewards Min                             4.83951e-16
expl/Returns Mean                            0.212267
expl/Returns Std                             0.607655
expl/Returns Max                             3.1075
expl/Returns Min                             0.00956754
expl/Actions Mean                           -0.203699
expl/Actions Std                             0.792149
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.212267
expl/env_infos/final/reward_dist Mean        0.00682709
expl/env_infos/final/reward_dist Std         0.0333358
expl/env_infos/final/reward_dist Max         0.170138
expl/env_infos/final/reward_dist Min         4.83951e-16
expl/env_infos/initial/reward_dist Mean      0.0147645
expl/env_infos/initial/reward_dist Std       0.0180762
expl/env_infos/initial/reward_dist Max       0.0725578
expl/env_infos/initial/reward_dist Min       2.14904e-05
expl/env_infos/reward_dist Mean              0.0106133
expl/env_infos/reward_dist Std               0.0421175
expl/env_infos/reward_dist Max               0.287382
expl/env_infos/reward_dist Min               4.83951e-16
eval/num steps total                       200
eval/num paths total                        10
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00203035
eval/Rewards Std                             0.00578744
eval/Rewards Max                             0.0329513
eval/Rewards Min                             4.26762e-18
eval/Returns Mean                            0.040607
eval/Returns Std                             0.0229036
eval/Returns Max                             0.0808249
eval/Returns Min                             0.0160469
eval/Actions Mean                           -0.252799
eval/Actions Std                             0.936443
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.040607
eval/env_infos/final/reward_dist Mean        0.000159397
eval/env_infos/final/reward_dist Std         0.000318794
eval/env_infos/final/reward_dist Max         0.000796984
eval/env_infos/final/reward_dist Min         4.26762e-18
eval/env_infos/initial/reward_dist Mean      0.0125616
eval/env_infos/initial/reward_dist Std       0.0144991
eval/env_infos/initial/reward_dist Max       0.0317837
eval/env_infos/initial/reward_dist Min       0.000168346
eval/env_infos/reward_dist Mean              0.00203035
eval/env_infos/reward_dist Std               0.00578744
eval/env_infos/reward_dist Max               0.0329513
eval/env_infos/reward_dist Min               4.26762e-18
time/data storing (s)                        0.0016074
time/evaluation sampling (s)                 0.813096
time/exploration sampling (s)                4.53902
time/logging (s)                             0.0101416
time/saving (s)                              0.00144266
time/training (s)                           17.9159
time/epoch (s)                              23.2812
time/total (s)                             190.99
Epoch                                        1
---------------------------------------  ---------------
2023-08-03 21:06:38.795054 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 2 finished
---------------------------------------  ---------------
epoch                                        2
replay_buffer/size                       11500
trainer/QF Loss                              9.80674
trainer/Policy Loss                        -37.3992
trainer/Raw Policy Loss                    -37.3992
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  35.1075
trainer/Q Predictions Std                    6.82594
trainer/Q Predictions Max                   57.2841
trainer/Q Predictions Min                   16.7529
trainer/Q Targets Mean                      35.0474
trainer/Q Targets Std                        7.63675
trainer/Q Targets Max                       64.3263
trainer/Q Targets Min                       15.3193
trainer/Bellman Errors Mean                  9.80674
trainer/Bellman Errors Std                  21.8762
trainer/Bellman Errors Max                 361.025
trainer/Bellman Errors Min                   1.41186e-07
trainer/Policy Action Mean                  -0.134043
trainer/Policy Action Std                    0.988658
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     11500
expl/num paths total                       575
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0511093
expl/Rewards Std                             0.254901
expl/Rewards Max                             2.34888
expl/Rewards Min                             2.50715e-14
expl/Returns Mean                            1.02219
expl/Returns Std                             4.65612
expl/Returns Max                            23.8276
expl/Returns Min                             0.00534402
expl/Actions Mean                           -0.0885039
expl/Actions Std                             0.839133
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         1.02219
expl/env_infos/final/reward_dist Mean        0.0511474
expl/env_infos/final/reward_dist Std         0.249778
expl/env_infos/final/reward_dist Max         1.2748
expl/env_infos/final/reward_dist Min         2.50715e-14
expl/env_infos/initial/reward_dist Mean      0.0176047
expl/env_infos/initial/reward_dist Std       0.0212985
expl/env_infos/initial/reward_dist Max       0.0707901
expl/env_infos/initial/reward_dist Min       7.6222e-05
expl/env_infos/reward_dist Mean              0.0511093
expl/env_infos/reward_dist Std               0.254901
expl/env_infos/reward_dist Max               2.34888
expl/env_infos/reward_dist Min               2.50715e-14
eval/num steps total                       300
eval/num paths total                        15
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0015795
eval/Rewards Std                             0.00632836
eval/Rewards Max                             0.0548225
eval/Rewards Min                             4.19878e-15
eval/Returns Mean                            0.03159
eval/Returns Std                             0.0385803
eval/Returns Max                             0.108565
eval/Returns Min                             0.00913997
eval/Actions Mean                           -0.12031
eval/Actions Std                             0.984276
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.03159
eval/env_infos/final/reward_dist Mean        1.19755e-13
eval/env_infos/final/reward_dist Std         1.33365e-13
eval/env_infos/final/reward_dist Max         3.75571e-13
eval/env_infos/final/reward_dist Min         4.19878e-15
eval/env_infos/initial/reward_dist Mean      0.00566853
eval/env_infos/initial/reward_dist Std       0.00643869
eval/env_infos/initial/reward_dist Max       0.0176894
eval/env_infos/initial/reward_dist Min       4.47044e-05
eval/env_infos/reward_dist Mean              0.0015795
eval/env_infos/reward_dist Std               0.00632836
eval/env_infos/reward_dist Max               0.0548225
eval/env_infos/reward_dist Min               4.19878e-15
time/data storing (s)                        0.00161554
time/evaluation sampling (s)                 0.907744
time/exploration sampling (s)                4.79715
time/logging (s)                             0.00209684
time/saving (s)                              0.0100962
time/training (s)                            3.94474
time/epoch (s)                               9.66344
time/total (s)                             200.656
Epoch                                        2
---------------------------------------  ---------------
2023-08-03 21:07:10.248785 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 3 finished
---------------------------------------  ---------------
epoch                                        3
replay_buffer/size                       12000
trainer/QF Loss                              4.01092
trainer/Policy Loss                        -30.2447
trainer/Raw Policy Loss                    -30.2447
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  29.6365
trainer/Q Predictions Std                    4.80295
trainer/Q Predictions Max                   51.1694
trainer/Q Predictions Min                   14.155
trainer/Q Targets Mean                      29.5789
trainer/Q Targets Std                        5.20438
trainer/Q Targets Max                       54.3302
trainer/Q Targets Min                       12.1803
trainer/Bellman Errors Mean                  4.01092
trainer/Bellman Errors Std                   9.00557
trainer/Bellman Errors Max                 188.817
trainer/Bellman Errors Min                   1.76078e-09
trainer/Policy Action Mean                  -0.132134
trainer/Policy Action Std                    0.989317
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     12000
expl/num paths total                       600
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.134814
expl/Rewards Std                             0.523403
expl/Rewards Max                             4.31485
expl/Rewards Min                             2.91095e-14
expl/Returns Mean                            2.69628
expl/Returns Std                             9.67618
expl/Returns Max                            46.2844
expl/Returns Min                             0.00280303
expl/Actions Mean                           -0.11213
expl/Actions Std                             0.84927
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         2.69628
expl/env_infos/final/reward_dist Mean        0.134042
expl/env_infos/final/reward_dist Std         0.46819
expl/env_infos/final/reward_dist Max         2.12827
expl/env_infos/final/reward_dist Min         2.91095e-14
expl/env_infos/initial/reward_dist Mean      0.0193019
expl/env_infos/initial/reward_dist Std       0.0305563
expl/env_infos/initial/reward_dist Max       0.134683
expl/env_infos/initial/reward_dist Min       5.98254e-05
expl/env_infos/reward_dist Mean              0.134814
expl/env_infos/reward_dist Std               0.523403
expl/env_infos/reward_dist Max               4.31485
expl/env_infos/reward_dist Min               2.91095e-14
eval/num steps total                       400
eval/num paths total                        20
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00114755
eval/Rewards Std                             0.00492971
eval/Rewards Max                             0.0398702
eval/Rewards Min                             3.93362e-13
eval/Returns Mean                            0.022951
eval/Returns Std                             0.0294967
eval/Returns Max                             0.081869
eval/Returns Min                             0.00640878
eval/Actions Mean                           -0.137763
eval/Actions Std                             0.987198
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.022951
eval/env_infos/final/reward_dist Mean        5.51834e-12
eval/env_infos/final/reward_dist Std         1.01864e-11
eval/env_infos/final/reward_dist Max         2.5891e-11
eval/env_infos/final/reward_dist Min         3.93362e-13
eval/env_infos/initial/reward_dist Mean      0.00646299
eval/env_infos/initial/reward_dist Std       0.0106235
eval/env_infos/initial/reward_dist Max       0.0276322
eval/env_infos/initial/reward_dist Min       0.000159593
eval/env_infos/reward_dist Mean              0.00114755
eval/env_infos/reward_dist Std               0.00492971
eval/env_infos/reward_dist Max               0.0398702
eval/env_infos/reward_dist Min               3.93362e-13
time/data storing (s)                        0.00299973
time/evaluation sampling (s)                 0.740482
time/exploration sampling (s)                5.40034
time/logging (s)                             0.00302696
time/saving (s)                              0.00503227
time/training (s)                           25.3009
time/epoch (s)                              31.4527
time/total (s)                             232.111
Epoch                                        3
---------------------------------------  ---------------
2023-08-03 21:07:25.414338 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 4 finished
---------------------------------------  ---------------
epoch                                        4
replay_buffer/size                       12500
trainer/QF Loss                              4.2217
trainer/Policy Loss                        -35.5123
trainer/Raw Policy Loss                    -35.5123
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  34.1334
trainer/Q Predictions Std                    5.49763
trainer/Q Predictions Max                   55.8906
trainer/Q Predictions Min                    5.46987
trainer/Q Targets Mean                      34.1214
trainer/Q Targets Std                        5.75119
trainer/Q Targets Max                       60.0874
trainer/Q Targets Min                        2.53957
trainer/Bellman Errors Mean                  4.2217
trainer/Bellman Errors Std                   7.78601
trainer/Bellman Errors Max                  94.6906
trainer/Bellman Errors Min                   9.09495e-09
trainer/Policy Action Mean                  -0.449823
trainer/Policy Action Std                    0.890645
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     12500
expl/num paths total                       625
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0295014
expl/Rewards Std                             0.170185
expl/Rewards Max                             1.53869
expl/Rewards Min                             3.64479e-14
expl/Returns Mean                            0.590027
expl/Returns Std                             2.50202
expl/Returns Max                            12.8318
expl/Returns Min                             0.00109237
expl/Actions Mean                           -0.376076
expl/Actions Std                             0.754906
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.590027
expl/env_infos/final/reward_dist Mean        0.0407999
expl/env_infos/final/reward_dist Std         0.199861
expl/env_infos/final/reward_dist Max         1.01991
expl/env_infos/final/reward_dist Min         3.64479e-14
expl/env_infos/initial/reward_dist Mean      0.0161437
expl/env_infos/initial/reward_dist Std       0.0164742
expl/env_infos/initial/reward_dist Max       0.0561306
expl/env_infos/initial/reward_dist Min       8.91666e-05
expl/env_infos/reward_dist Mean              0.0295014
expl/env_infos/reward_dist Std               0.170185
expl/env_infos/reward_dist Max               1.53869
expl/env_infos/reward_dist Min               3.64479e-14
eval/num steps total                       500
eval/num paths total                        25
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.348516
eval/Rewards Std                             0.852834
eval/Rewards Max                             3.25564
eval/Rewards Min                             2.46298e-13
eval/Returns Mean                            6.97032
eval/Returns Std                            13.9226
eval/Returns Max                            34.8156
eval/Returns Min                             0.00464934
eval/Actions Mean                           -0.487441
eval/Actions Std                             0.868905
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         6.97032
eval/env_infos/final/reward_dist Mean        0.0750853
eval/env_infos/final/reward_dist Std         0.150171
eval/env_infos/final/reward_dist Max         0.375427
eval/env_infos/final/reward_dist Min         2.46298e-13
eval/env_infos/initial/reward_dist Mean      0.0145619
eval/env_infos/initial/reward_dist Std       0.0164279
eval/env_infos/initial/reward_dist Max       0.0455831
eval/env_infos/initial/reward_dist Min       0.00292881
eval/env_infos/reward_dist Mean              0.348516
eval/env_infos/reward_dist Std               0.852834
eval/env_infos/reward_dist Max               3.25564
eval/env_infos/reward_dist Min               2.46298e-13
time/data storing (s)                        0.00216847
time/evaluation sampling (s)                 1.58965
time/exploration sampling (s)                6.29533
time/logging (s)                             0.00236659
time/saving (s)                              0.000994735
time/training (s)                            7.26975
time/epoch (s)                              15.1603
time/total (s)                             247.275
Epoch                                        4
---------------------------------------  ---------------
2023-08-03 21:07:59.981892 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 5 finished
---------------------------------------  ---------------
epoch                                        5
replay_buffer/size                       13000
trainer/QF Loss                              5.8298
trainer/Policy Loss                        -52.8297
trainer/Raw Policy Loss                    -52.8297
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  48.0535
trainer/Q Predictions Std                    7.75747
trainer/Q Predictions Max                   75.8476
trainer/Q Predictions Min                   19.1976
trainer/Q Targets Mean                      48.0466
trainer/Q Targets Std                        8.15732
trainer/Q Targets Max                       80.3949
trainer/Q Targets Min                       18.1208
trainer/Bellman Errors Mean                  5.8298
trainer/Bellman Errors Std                  14.8382
trainer/Bellman Errors Max                 197.547
trainer/Bellman Errors Min                   1.22382e-08
trainer/Policy Action Mean                  -0.0140559
trainer/Policy Action Std                    0.984266
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     13000
expl/num paths total                       650
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0383625
expl/Rewards Std                             0.114827
expl/Rewards Max                             1.06315
expl/Rewards Min                             1.23543e-12
expl/Returns Mean                            0.767251
expl/Returns Std                             1.13476
expl/Returns Max                             5.76124
expl/Returns Min                             0.0715132
expl/Actions Mean                           -0.022318
expl/Actions Std                             0.820105
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.767251
expl/env_infos/final/reward_dist Mean        0.00262346
expl/env_infos/final/reward_dist Std         0.0125535
expl/env_infos/final/reward_dist Max         0.0641062
expl/env_infos/final/reward_dist Min         1.23543e-12
expl/env_infos/initial/reward_dist Mean      0.0215001
expl/env_infos/initial/reward_dist Std       0.0138256
expl/env_infos/initial/reward_dist Max       0.0446582
expl/env_infos/initial/reward_dist Min       0.000149153
expl/env_infos/reward_dist Mean              0.0383625
expl/env_infos/reward_dist Std               0.114827
expl/env_infos/reward_dist Max               1.06315
expl/env_infos/reward_dist Min               1.23543e-12
eval/num steps total                       600
eval/num paths total                        30
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.026523
eval/Rewards Std                             0.0709492
eval/Rewards Max                             0.614413
eval/Rewards Min                             3.93424e-12
eval/Returns Mean                            0.530459
eval/Returns Std                             0.255725
eval/Returns Max                             1.03313
eval/Returns Min                             0.315105
eval/Actions Mean                           -0.0513294
eval/Actions Std                             0.97529
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.530459
eval/env_infos/final/reward_dist Mean        1.13854e-10
eval/env_infos/final/reward_dist Std         1.22353e-10
eval/env_infos/final/reward_dist Max         3.28648e-10
eval/env_infos/final/reward_dist Min         1.09588e-11
eval/env_infos/initial/reward_dist Mean      0.00774598
eval/env_infos/initial/reward_dist Std       0.00507374
eval/env_infos/initial/reward_dist Max       0.014692
eval/env_infos/initial/reward_dist Min       0.000808333
eval/env_infos/reward_dist Mean              0.026523
eval/env_infos/reward_dist Std               0.0709492
eval/env_infos/reward_dist Max               0.614413
eval/env_infos/reward_dist Min               3.93424e-12
time/data storing (s)                        0.0021792
time/evaluation sampling (s)                 0.975499
time/exploration sampling (s)                6.38294
time/logging (s)                             0.00234729
time/saving (s)                              0.00114758
time/training (s)                           27.1993
time/epoch (s)                              34.5634
time/total (s)                             281.842
Epoch                                        5
---------------------------------------  ---------------
2023-08-03 21:08:36.872392 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 6 finished
---------------------------------------  ---------------
epoch                                        6
replay_buffer/size                       13500
trainer/QF Loss                              3.57138
trainer/Policy Loss                        -39.7481
trainer/Raw Policy Loss                    -39.7481
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  37.8537
trainer/Q Predictions Std                    4.71782
trainer/Q Predictions Max                   58.4531
trainer/Q Predictions Min                   16.4259
trainer/Q Targets Mean                      37.7353
trainer/Q Targets Std                        5.10656
trainer/Q Targets Max                       61.2138
trainer/Q Targets Min                       16.9322
trainer/Bellman Errors Mean                  3.57138
trainer/Bellman Errors Std                  11.2925
trainer/Bellman Errors Max                 314.856
trainer/Bellman Errors Min                   7.75472e-08
trainer/Policy Action Mean                   0.0443231
trainer/Policy Action Std                    0.962645
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     13500
expl/num paths total                       675
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0248288
expl/Rewards Std                             0.190578
expl/Rewards Max                             4.07154
expl/Rewards Min                             4.45436e-14
expl/Returns Mean                            0.496576
expl/Returns Std                             0.849199
expl/Returns Max                             4.34593
expl/Returns Min                             0.0141015
expl/Actions Mean                           -0.00511629
expl/Actions Std                             0.824726
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.496576
expl/env_infos/final/reward_dist Mean        0.0118131
expl/env_infos/final/reward_dist Std         0.0576147
expl/env_infos/final/reward_dist Max         0.294065
expl/env_infos/final/reward_dist Min         4.45436e-14
expl/env_infos/initial/reward_dist Mean      0.0227075
expl/env_infos/initial/reward_dist Std       0.0156861
expl/env_infos/initial/reward_dist Max       0.0643059
expl/env_infos/initial/reward_dist Min       0.00528248
expl/env_infos/reward_dist Mean              0.0248288
expl/env_infos/reward_dist Std               0.190578
expl/env_infos/reward_dist Max               4.07154
expl/env_infos/reward_dist Min               4.45436e-14
eval/num steps total                       700
eval/num paths total                        35
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0240306
eval/Rewards Std                             0.112772
eval/Rewards Max                             1.08564
eval/Rewards Min                             2.22975e-09
eval/Returns Mean                            0.480612
eval/Returns Std                             0.40341
eval/Returns Max                             1.23588
eval/Returns Min                             0.110339
eval/Actions Mean                           -0.00861949
eval/Actions Std                             0.969427
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.480612
eval/env_infos/final/reward_dist Mean        7.25203e-07
eval/env_infos/final/reward_dist Std         1.33621e-06
eval/env_infos/final/reward_dist Max         3.39446e-06
eval/env_infos/final/reward_dist Min         2.22975e-09
eval/env_infos/initial/reward_dist Mean      0.0214851
eval/env_infos/initial/reward_dist Std       0.0111509
eval/env_infos/initial/reward_dist Max       0.0337995
eval/env_infos/initial/reward_dist Min       0.00685571
eval/env_infos/reward_dist Mean              0.0240306
eval/env_infos/reward_dist Std               0.112772
eval/env_infos/reward_dist Max               1.08564
eval/env_infos/reward_dist Min               2.22975e-09
time/data storing (s)                        0.00215921
time/evaluation sampling (s)                 0.675617
time/exploration sampling (s)                4.49336
time/logging (s)                             0.00248205
time/saving (s)                              0.00112104
time/training (s)                           31.7117
time/epoch (s)                              36.8864
time/total (s)                             318.732
Epoch                                        6
---------------------------------------  ---------------
2023-08-03 21:09:07.708592 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 7 finished
---------------------------------------  ---------------
epoch                                        7
replay_buffer/size                       14000
trainer/QF Loss                              5.49358
trainer/Policy Loss                        -38.6575
trainer/Raw Policy Loss                    -38.6575
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  36.0867
trainer/Q Predictions Std                    7.23273
trainer/Q Predictions Max                   70.8249
trainer/Q Predictions Min                   10.6575
trainer/Q Targets Mean                      36.0461
trainer/Q Targets Std                        7.75642
trainer/Q Targets Max                       75.8176
trainer/Q Targets Min                        8.32189
trainer/Bellman Errors Mean                  5.49358
trainer/Bellman Errors Std                  20.0004
trainer/Bellman Errors Max                 359.198
trainer/Bellman Errors Min                   3.93484e-08
trainer/Policy Action Mean                  -0.0349207
trainer/Policy Action Std                    0.983039
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     14000
expl/num paths total                       700
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0510046
expl/Rewards Std                             0.220089
expl/Rewards Max                             3.48219
expl/Rewards Min                             1.08868e-13
expl/Returns Mean                            1.02009
expl/Returns Std                             1.31974
expl/Returns Max                             6.12452
expl/Returns Min                             0.169874
expl/Actions Mean                            0.0228641
expl/Actions Std                             0.832755
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         1.02009
expl/env_infos/final/reward_dist Mean        0.0573096
expl/env_infos/final/reward_dist Std         0.243008
expl/env_infos/final/reward_dist Max         1.24059
expl/env_infos/final/reward_dist Min         1.08868e-13
expl/env_infos/initial/reward_dist Mean      0.0380154
expl/env_infos/initial/reward_dist Std       0.0866082
expl/env_infos/initial/reward_dist Max       0.457952
expl/env_infos/initial/reward_dist Min       0.0020574
expl/env_infos/reward_dist Mean              0.0510046
expl/env_infos/reward_dist Std               0.220089
expl/env_infos/reward_dist Max               3.48219
expl/env_infos/reward_dist Min               1.08868e-13
eval/num steps total                       800
eval/num paths total                        40
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0508584
eval/Rewards Std                             0.198905
eval/Rewards Max                             1.5822
eval/Rewards Min                             2.86502e-11
eval/Returns Mean                            1.01717
eval/Returns Std                             0.661531
eval/Returns Max                             1.91702
eval/Returns Min                             0.191225
eval/Actions Mean                            0.0110162
eval/Actions Std                             0.978067
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         1.01717
eval/env_infos/final/reward_dist Mean        0.00507224
eval/env_infos/final/reward_dist Std         0.00724723
eval/env_infos/final/reward_dist Max         0.0185839
eval/env_infos/final/reward_dist Min         2.86502e-11
eval/env_infos/initial/reward_dist Mean      0.0148443
eval/env_infos/initial/reward_dist Std       0.00474589
eval/env_infos/initial/reward_dist Max       0.0223027
eval/env_infos/initial/reward_dist Min       0.00864233
eval/env_infos/reward_dist Mean              0.0508584
eval/env_infos/reward_dist Std               0.198905
eval/env_infos/reward_dist Max               1.5822
eval/env_infos/reward_dist Min               2.86502e-11
time/data storing (s)                        0.00161321
time/evaluation sampling (s)                 0.784098
time/exploration sampling (s)                4.76425
time/logging (s)                             0.0022843
time/saving (s)                              0.00101469
time/training (s)                           25.2784
time/epoch (s)                              30.8317
time/total (s)                             349.568
Epoch                                        7
---------------------------------------  ---------------
2023-08-03 21:09:28.012644 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 8 finished
---------------------------------------  ---------------
epoch                                        8
replay_buffer/size                       14500
trainer/QF Loss                              4.19744
trainer/Policy Loss                        -25.0898
trainer/Raw Policy Loss                    -25.0898
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  24.2711
trainer/Q Predictions Std                    5.09156
trainer/Q Predictions Max                   54.9811
trainer/Q Predictions Min                    4.13446
trainer/Q Targets Mean                      24.2414
trainer/Q Targets Std                        5.47697
trainer/Q Targets Max                       54.5792
trainer/Q Targets Min                        3.88707
trainer/Bellman Errors Mean                  4.19744
trainer/Bellman Errors Std                  10.7571
trainer/Bellman Errors Max                 184.584
trainer/Bellman Errors Min                   3.35276e-08
trainer/Policy Action Mean                   0.168713
trainer/Policy Action Std                    0.962188
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     14500
expl/num paths total                       725
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.299528
expl/Rewards Std                             1.49274
expl/Rewards Max                            10
expl/Rewards Min                             8.84365e-14
expl/Returns Mean                            5.99056
expl/Returns Std                            21.8818
expl/Returns Max                           110.253
expl/Returns Min                             0.0579949
expl/Actions Mean                            0.138242
expl/Actions Std                             0.805595
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         5.99056
expl/env_infos/final/reward_dist Mean        0.445226
expl/env_infos/final/reward_dist Std         1.95435
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         8.84365e-14
expl/env_infos/initial/reward_dist Mean      0.029236
expl/env_infos/initial/reward_dist Std       0.0213123
expl/env_infos/initial/reward_dist Max       0.0862361
expl/env_infos/initial/reward_dist Min       0.00546339
expl/env_infos/reward_dist Mean              0.299528
expl/env_infos/reward_dist Std               1.49274
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               8.84365e-14
eval/num steps total                       900
eval/num paths total                        45
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0171835
eval/Rewards Std                             0.0512346
eval/Rewards Max                             0.490007
eval/Rewards Min                             2.11506e-13
eval/Returns Mean                            0.34367
eval/Returns Std                             0.275894
eval/Returns Max                             0.873509
eval/Returns Min                             0.118944
eval/Actions Mean                            0.163038
eval/Actions Std                             0.961412
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.34367
eval/env_infos/final/reward_dist Mean        0.00141203
eval/env_infos/final/reward_dist Std         0.00128706
eval/env_infos/final/reward_dist Max         0.0033967
eval/env_infos/final/reward_dist Min         2.11506e-13
eval/env_infos/initial/reward_dist Mean      0.0264528
eval/env_infos/initial/reward_dist Std       0.0137791
eval/env_infos/initial/reward_dist Max       0.0481773
eval/env_infos/initial/reward_dist Min       0.00781371
eval/env_infos/reward_dist Mean              0.0171835
eval/env_infos/reward_dist Std               0.0512346
eval/env_infos/reward_dist Max               0.490007
eval/env_infos/reward_dist Min               2.11506e-13
time/data storing (s)                        0.00298614
time/evaluation sampling (s)                 0.670885
time/exploration sampling (s)                5.76388
time/logging (s)                             0.00238095
time/saving (s)                              0.00107589
time/training (s)                           13.8547
time/epoch (s)                              20.2959
time/total (s)                             369.872
Epoch                                        8
---------------------------------------  ---------------
2023-08-03 21:09:56.621327 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 9 finished
---------------------------------------  ---------------
epoch                                        9
replay_buffer/size                       15000
trainer/QF Loss                             14.2002
trainer/Policy Loss                        -44.979
trainer/Raw Policy Loss                    -44.979
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  39.7012
trainer/Q Predictions Std                    9.57641
trainer/Q Predictions Max                   86.3945
trainer/Q Predictions Min                    8.35275
trainer/Q Targets Mean                      39.6994
trainer/Q Targets Std                       10.3605
trainer/Q Targets Max                       87.0703
trainer/Q Targets Min                        1.75331
trainer/Bellman Errors Mean                 14.2002
trainer/Bellman Errors Std                  34.7566
trainer/Bellman Errors Max                 617.331
trainer/Bellman Errors Min                   5.7627e-07
trainer/Policy Action Mean                   0.0901918
trainer/Policy Action Std                    0.967853
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     15000
expl/num paths total                       750
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.184563
expl/Rewards Std                             1.02466
expl/Rewards Max                            10
expl/Rewards Min                             1.23218e-13
expl/Returns Mean                            3.69126
expl/Returns Std                            10.5994
expl/Returns Max                            51.1207
expl/Returns Min                             0.08383
expl/Actions Mean                            0.0829283
expl/Actions Std                             0.812101
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         3.69126
expl/env_infos/final/reward_dist Mean        0.424445
expl/env_infos/final/reward_dist Std         1.95561
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         1.23218e-13
expl/env_infos/initial/reward_dist Mean      0.0308145
expl/env_infos/initial/reward_dist Std       0.019245
expl/env_infos/initial/reward_dist Max       0.0689428
expl/env_infos/initial/reward_dist Min       0.00246536
expl/env_infos/reward_dist Mean              0.184563
expl/env_infos/reward_dist Std               1.02466
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.23218e-13
eval/num steps total                      1000
eval/num paths total                        50
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0523081
eval/Rewards Std                             0.3072
eval/Rewards Max                             3.06227
eval/Rewards Min                             2.98426e-12
eval/Returns Mean                            1.04616
eval/Returns Std                             1.11586
eval/Returns Max                             3.20814
eval/Returns Min                             0.131266
eval/Actions Mean                            0.0708268
eval/Actions Std                             0.945711
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         1.04616
eval/env_infos/final/reward_dist Mean        0.00184876
eval/env_infos/final/reward_dist Std         0.00280662
eval/env_infos/final/reward_dist Max         0.00725349
eval/env_infos/final/reward_dist Min         2.98426e-12
eval/env_infos/initial/reward_dist Mean      0.0266209
eval/env_infos/initial/reward_dist Std       0.0198139
eval/env_infos/initial/reward_dist Max       0.0615581
eval/env_infos/initial/reward_dist Min       0.0088395
eval/env_infos/reward_dist Mean              0.0523081
eval/env_infos/reward_dist Std               0.3072
eval/env_infos/reward_dist Max               3.06227
eval/env_infos/reward_dist Min               2.98426e-12
time/data storing (s)                        0.00219419
time/evaluation sampling (s)                 0.875988
time/exploration sampling (s)                6.4887
time/logging (s)                             0.00299836
time/saving (s)                              0.00128608
time/training (s)                           21.2339
time/epoch (s)                              28.605
time/total (s)                             398.481
Epoch                                        9
---------------------------------------  ---------------
2023-08-03 21:10:34.848342 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 10 finished
---------------------------------------  ---------------
epoch                                       10
replay_buffer/size                       15500
trainer/QF Loss                             25.8861
trainer/Policy Loss                        -46.0239
trainer/Raw Policy Loss                    -46.0239
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  41.7097
trainer/Q Predictions Std                   14.0313
trainer/Q Predictions Max                  101.484
trainer/Q Predictions Min                   -6.31301
trainer/Q Targets Mean                      41.4938
trainer/Q Targets Std                       15.2363
trainer/Q Targets Max                      103.846
trainer/Q Targets Min                       -4.69651
trainer/Bellman Errors Mean                 25.8861
trainer/Bellman Errors Std                  64.143
trainer/Bellman Errors Max                1012.29
trainer/Bellman Errors Min                   1.34926e-06
trainer/Policy Action Mean                  -0.0644768
trainer/Policy Action Std                    0.934715
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     15500
expl/num paths total                       775
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.226851
expl/Rewards Std                             0.580319
expl/Rewards Max                             4.51814
expl/Rewards Min                             6.56777e-15
expl/Returns Mean                            4.53703
expl/Returns Std                             9.37971
expl/Returns Max                            35.331
expl/Returns Min                             0.158926
expl/Actions Mean                           -0.0348889
expl/Actions Std                             0.798893
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         4.53703
expl/env_infos/final/reward_dist Mean        0.125719
expl/env_infos/final/reward_dist Std         0.384741
expl/env_infos/final/reward_dist Max         1.9199
expl/env_infos/final/reward_dist Min         6.56777e-15
expl/env_infos/initial/reward_dist Mean      0.0414857
expl/env_infos/initial/reward_dist Std       0.0345761
expl/env_infos/initial/reward_dist Max       0.193778
expl/env_infos/initial/reward_dist Min       0.0109521
expl/env_infos/reward_dist Mean              0.226851
expl/env_infos/reward_dist Std               0.580319
expl/env_infos/reward_dist Max               4.51814
expl/env_infos/reward_dist Min               6.56777e-15
eval/num steps total                      1100
eval/num paths total                        55
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            2.16734
eval/Rewards Std                             3.75225
eval/Rewards Max                            10
eval/Rewards Min                             1.7569e-14
eval/Returns Mean                           43.3467
eval/Returns Std                            71.8671
eval/Returns Max                           185.531
eval/Returns Min                             0.474954
eval/Actions Mean                           -0.0517624
eval/Actions Std                             0.883944
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                        43.3467
eval/env_infos/final/reward_dist Mean        2.09737
eval/env_infos/final/reward_dist Std         3.95581
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.7569e-14
eval/env_infos/initial/reward_dist Mean      0.169383
eval/env_infos/initial/reward_dist Std       0.250379
eval/env_infos/initial/reward_dist Max       0.668086
eval/env_infos/initial/reward_dist Min       0.00619988
eval/env_infos/reward_dist Mean              2.16734
eval/env_infos/reward_dist Std               3.75225
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               1.7569e-14
time/data storing (s)                        0.00218779
time/evaluation sampling (s)                 1.83682
time/exploration sampling (s)                5.8599
time/logging (s)                             0.00226021
time/saving (s)                              0.000991987
time/training (s)                           30.5189
time/epoch (s)                              38.221
time/total (s)                             436.706
Epoch                                       10
---------------------------------------  ---------------
2023-08-03 21:11:16.636544 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 11 finished
---------------------------------------  ---------------
epoch                                       11
replay_buffer/size                       16000
trainer/QF Loss                             25.4806
trainer/Policy Loss                        -43.56
trainer/Raw Policy Loss                    -43.56
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  40.7254
trainer/Q Predictions Std                   16.5197
trainer/Q Predictions Max                  116.437
trainer/Q Predictions Min                  -10.5486
trainer/Q Targets Mean                      40.5617
trainer/Q Targets Std                       17.674
trainer/Q Targets Max                      111.461
trainer/Q Targets Min                      -10.6244
trainer/Bellman Errors Mean                 25.4806
trainer/Bellman Errors Std                  76.6138
trainer/Bellman Errors Max                2206.79
trainer/Bellman Errors Min                   4.63008e-07
trainer/Policy Action Mean                  -0.175947
trainer/Policy Action Std                    0.920531
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     16000
expl/num paths total                       800
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.615836
expl/Rewards Std                             2.29671
expl/Rewards Max                            10
expl/Rewards Min                             4.89813e-14
expl/Returns Mean                           12.3167
expl/Returns Std                            40.41
expl/Returns Max                           190.063
expl/Returns Min                             0.0860149
expl/Actions Mean                           -0.0773238
expl/Actions Std                             0.793502
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        12.3167
expl/env_infos/final/reward_dist Mean        0.815995
expl/env_infos/final/reward_dist Std         2.70879
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         4.89813e-14
expl/env_infos/initial/reward_dist Mean      0.040663
expl/env_infos/initial/reward_dist Std       0.018841
expl/env_infos/initial/reward_dist Max       0.0827519
expl/env_infos/initial/reward_dist Min       0.00992354
expl/env_infos/reward_dist Mean              0.615836
expl/env_infos/reward_dist Std               2.29671
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               4.89813e-14
eval/num steps total                      1200
eval/num paths total                        60
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0643564
eval/Rewards Std                             0.284769
eval/Rewards Max                             2.59511
eval/Rewards Min                             7.96282e-15
eval/Returns Mean                            1.28713
eval/Returns Std                             0.798333
eval/Returns Max                             2.81836
eval/Returns Min                             0.482826
eval/Actions Mean                           -0.0671259
eval/Actions Std                             0.937092
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         1.28713
eval/env_infos/final/reward_dist Mean        2.19185e-13
eval/env_infos/final/reward_dist Std         2.53299e-13
eval/env_infos/final/reward_dist Max         6.96319e-13
eval/env_infos/final/reward_dist Min         7.96282e-15
eval/env_infos/initial/reward_dist Mean      0.0446109
eval/env_infos/initial/reward_dist Std       0.0151943
eval/env_infos/initial/reward_dist Max       0.0647314
eval/env_infos/initial/reward_dist Min       0.020942
eval/env_infos/reward_dist Mean              0.0643564
eval/env_infos/reward_dist Std               0.284769
eval/env_infos/reward_dist Max               2.59511
eval/env_infos/reward_dist Min               7.96282e-15
time/data storing (s)                        0.00218585
time/evaluation sampling (s)                 0.766574
time/exploration sampling (s)                5.27588
time/logging (s)                             0.00237573
time/saving (s)                              0.00107102
time/training (s)                           35.7378
time/epoch (s)                              41.7859
time/total (s)                             478.494
Epoch                                       11
---------------------------------------  ---------------
2023-08-03 21:11:45.068352 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 12 finished
---------------------------------------  ---------------
epoch                                       12
replay_buffer/size                       16500
trainer/QF Loss                             28.5647
trainer/Policy Loss                        -48.4332
trainer/Raw Policy Loss                    -48.4332
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  44.66
trainer/Q Predictions Std                   18.5661
trainer/Q Predictions Max                  148.061
trainer/Q Predictions Min                   -5.78176
trainer/Q Targets Mean                      44.347
trainer/Q Targets Std                       19.5385
trainer/Q Targets Max                      148.254
trainer/Q Targets Min                       -3.4824
trainer/Bellman Errors Mean                 28.5647
trainer/Bellman Errors Std                  98.8316
trainer/Bellman Errors Max                1686.92
trainer/Bellman Errors Min                   4.71482e-09
trainer/Policy Action Mean                  -0.0245421
trainer/Policy Action Std                    0.946545
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     16500
expl/num paths total                       825
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0294677
expl/Rewards Std                             0.0906692
expl/Rewards Max                             1.2879
expl/Rewards Min                             1.52155e-06
expl/Returns Mean                            0.589355
expl/Returns Std                             0.536801
expl/Returns Max                             2.04712
expl/Returns Min                             0.151379
expl/Actions Mean                           -0.0526588
expl/Actions Std                             0.796483
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.589355
expl/env_infos/final/reward_dist Mean        0.0337685
expl/env_infos/final/reward_dist Std         0.0910809
expl/env_infos/final/reward_dist Max         0.469045
expl/env_infos/final/reward_dist Min         1.52155e-06
expl/env_infos/initial/reward_dist Mean      0.0258769
expl/env_infos/initial/reward_dist Std       0.0164527
expl/env_infos/initial/reward_dist Max       0.069035
expl/env_infos/initial/reward_dist Min       0.00227391
expl/env_infos/reward_dist Mean              0.0294677
expl/env_infos/reward_dist Std               0.0906692
expl/env_infos/reward_dist Max               1.2879
expl/env_infos/reward_dist Min               1.52155e-06
eval/num steps total                      1300
eval/num paths total                        65
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.014993
eval/Rewards Std                             0.0150608
eval/Rewards Max                             0.0528104
eval/Rewards Min                             0.000496585
eval/Returns Mean                            0.29986
eval/Returns Std                             0.0471804
eval/Returns Max                             0.361527
eval/Returns Min                             0.241339
eval/Actions Mean                           -0.103918
eval/Actions Std                             0.93894
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.29986
eval/env_infos/final/reward_dist Mean        0.0235678
eval/env_infos/final/reward_dist Std         0.0179153
eval/env_infos/final/reward_dist Max         0.0425094
eval/env_infos/final/reward_dist Min         0.00158614
eval/env_infos/initial/reward_dist Mean      0.0207773
eval/env_infos/initial/reward_dist Std       0.0101768
eval/env_infos/initial/reward_dist Max       0.0375231
eval/env_infos/initial/reward_dist Min       0.00811344
eval/env_infos/reward_dist Mean              0.014993
eval/env_infos/reward_dist Std               0.0150608
eval/env_infos/reward_dist Max               0.0528104
eval/env_infos/reward_dist Min               0.000496585
time/data storing (s)                        0.0022225
time/evaluation sampling (s)                 0.632984
time/exploration sampling (s)                4.20308
time/logging (s)                             0.00299196
time/saving (s)                              0.00123833
time/training (s)                           23.5857
time/epoch (s)                              28.4282
time/total (s)                             506.926
Epoch                                       12
---------------------------------------  ---------------
2023-08-03 21:12:18.808506 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 13 finished
---------------------------------------  ---------------
epoch                                       13
replay_buffer/size                       17000
trainer/QF Loss                             25.9849
trainer/Policy Loss                        -45.2342
trainer/Raw Policy Loss                    -45.2342
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  41.8278
trainer/Q Predictions Std                   16.6301
trainer/Q Predictions Max                  144.458
trainer/Q Predictions Min                    0.499649
trainer/Q Targets Mean                      41.8075
trainer/Q Targets Std                       17.4217
trainer/Q Targets Max                      142.712
trainer/Q Targets Min                        3.40655
trainer/Bellman Errors Mean                 25.9849
trainer/Bellman Errors Std                 127.367
trainer/Bellman Errors Max                3062.97
trainer/Bellman Errors Min                   3.83708e-06
trainer/Policy Action Mean                   0.221456
trainer/Policy Action Std                    0.914453
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     17000
expl/num paths total                       850
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0344693
expl/Rewards Std                             0.094376
expl/Rewards Max                             0.892316
expl/Rewards Min                             1.65326e-08
expl/Returns Mean                            0.689387
expl/Returns Std                             1.19041
expl/Returns Max                             6.22224
expl/Returns Min                             0.16419
expl/Actions Mean                            0.279199
expl/Actions Std                             0.744105
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.689387
expl/env_infos/final/reward_dist Mean        0.0698496
expl/env_infos/final/reward_dist Std         0.177611
expl/env_infos/final/reward_dist Max         0.892316
expl/env_infos/final/reward_dist Min         1.65326e-08
expl/env_infos/initial/reward_dist Mean      0.0169893
expl/env_infos/initial/reward_dist Std       0.0199159
expl/env_infos/initial/reward_dist Max       0.0953054
expl/env_infos/initial/reward_dist Min       0.000475494
expl/env_infos/reward_dist Mean              0.0344693
expl/env_infos/reward_dist Std               0.094376
expl/env_infos/reward_dist Max               0.892316
expl/env_infos/reward_dist Min               1.65326e-08
eval/num steps total                      1400
eval/num paths total                        70
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0163112
eval/Rewards Std                             0.011223
eval/Rewards Max                             0.0515811
eval/Rewards Min                             0.000780775
eval/Returns Mean                            0.326223
eval/Returns Std                             0.0590627
eval/Returns Max                             0.417871
eval/Returns Min                             0.241289
eval/Actions Mean                            0.434915
eval/Actions Std                             0.793104
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.326223
eval/env_infos/final/reward_dist Mean        0.0200412
eval/env_infos/final/reward_dist Std         0.00836401
eval/env_infos/final/reward_dist Max         0.0271813
eval/env_infos/final/reward_dist Min         0.00452068
eval/env_infos/initial/reward_dist Mean      0.0227871
eval/env_infos/initial/reward_dist Std       0.00952995
eval/env_infos/initial/reward_dist Max       0.0374427
eval/env_infos/initial/reward_dist Min       0.0111415
eval/env_infos/reward_dist Mean              0.0163112
eval/env_infos/reward_dist Std               0.011223
eval/env_infos/reward_dist Max               0.0515811
eval/env_infos/reward_dist Min               0.000780775
time/data storing (s)                        0.00160319
time/evaluation sampling (s)                 0.784214
time/exploration sampling (s)                5.11501
time/logging (s)                             0.00686015
time/saving (s)                              0.00111881
time/training (s)                           27.8299
time/epoch (s)                              33.7387
time/total (s)                             540.67
Epoch                                       13
---------------------------------------  ---------------
2023-08-03 21:12:30.569365 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 14 finished
---------------------------------------  ---------------
epoch                                       14
replay_buffer/size                       17500
trainer/QF Loss                             24.9675
trainer/Policy Loss                        -72.4261
trainer/Raw Policy Loss                    -72.4261
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  65.8833
trainer/Q Predictions Std                   14.225
trainer/Q Predictions Max                  140.479
trainer/Q Predictions Min                   26.2193
trainer/Q Targets Mean                      66.0006
trainer/Q Targets Std                       14.7229
trainer/Q Targets Max                      139.174
trainer/Q Targets Min                       28.0769
trainer/Bellman Errors Mean                 24.9675
trainer/Bellman Errors Std                 102.288
trainer/Bellman Errors Max                2738.69
trainer/Bellman Errors Min                   2.32831e-10
trainer/Policy Action Mean                   0.350814
trainer/Policy Action Std                    0.82584
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     17500
expl/num paths total                       875
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0352504
expl/Rewards Std                             0.134369
expl/Rewards Max                             1.63677
expl/Rewards Min                             1.12006e-09
expl/Returns Mean                            0.705008
expl/Returns Std                             0.737559
expl/Returns Max                             3.77672
expl/Returns Min                             0.112735
expl/Actions Mean                            0.266144
expl/Actions Std                             0.713867
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.705008
expl/env_infos/final/reward_dist Mean        0.0404434
expl/env_infos/final/reward_dist Std         0.0990194
expl/env_infos/final/reward_dist Max         0.489222
expl/env_infos/final/reward_dist Min         1.12006e-09
expl/env_infos/initial/reward_dist Mean      0.0260903
expl/env_infos/initial/reward_dist Std       0.0185557
expl/env_infos/initial/reward_dist Max       0.0663742
expl/env_infos/initial/reward_dist Min       0.00121371
expl/env_infos/reward_dist Mean              0.0352504
expl/env_infos/reward_dist Std               0.134369
expl/env_infos/reward_dist Max               1.63677
expl/env_infos/reward_dist Min               1.12006e-09
eval/num steps total                      1500
eval/num paths total                        75
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0286982
eval/Rewards Std                             0.0693762
eval/Rewards Max                             0.5621
eval/Rewards Min                             4.22049e-05
eval/Returns Mean                            0.573963
eval/Returns Std                             0.145198
eval/Returns Max                             0.789654
eval/Returns Min                             0.391283
eval/Actions Mean                            0.339779
eval/Actions Std                             0.749176
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.573963
eval/env_infos/final/reward_dist Mean        0.120406
eval/env_infos/final/reward_dist Std         0.221023
eval/env_infos/final/reward_dist Max         0.5621
eval/env_infos/final/reward_dist Min         0.000821882
eval/env_infos/initial/reward_dist Mean      0.0348153
eval/env_infos/initial/reward_dist Std       0.0227803
eval/env_infos/initial/reward_dist Max       0.0662614
eval/env_infos/initial/reward_dist Min       0.00450246
eval/env_infos/reward_dist Mean              0.0286982
eval/env_infos/reward_dist Std               0.0693762
eval/env_infos/reward_dist Max               0.5621
eval/env_infos/reward_dist Min               4.22049e-05
time/data storing (s)                        0.00218367
time/evaluation sampling (s)                 1.15921
time/exploration sampling (s)                5.3212
time/logging (s)                             0.0023328
time/saving (s)                              0.00101308
time/training (s)                            5.26714
time/epoch (s)                              11.7531
time/total (s)                             552.426
Epoch                                       14
---------------------------------------  ---------------
2023-08-03 21:12:40.504475 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 15 finished
---------------------------------------  ---------------
epoch                                       15
replay_buffer/size                       18000
trainer/QF Loss                             17.0577
trainer/Policy Loss                        -77.0946
trainer/Raw Policy Loss                    -77.0946
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  71.9061
trainer/Q Predictions Std                   11.9897
trainer/Q Predictions Max                  139.536
trainer/Q Predictions Min                   41.0527
trainer/Q Targets Mean                      71.877
trainer/Q Targets Std                       12.3772
trainer/Q Targets Max                      141.53
trainer/Q Targets Min                       43.0578
trainer/Bellman Errors Mean                 17.0577
trainer/Bellman Errors Std                  63.1442
trainer/Bellman Errors Max                1345.29
trainer/Bellman Errors Min                   3.18745e-07
trainer/Policy Action Mean                   0.182642
trainer/Policy Action Std                    0.861147
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     18000
expl/num paths total                       900
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.161172
expl/Rewards Std                             0.357527
expl/Rewards Max                             2.0583
expl/Rewards Min                             1.24567e-09
expl/Returns Mean                            3.22343
expl/Returns Std                             5.0965
expl/Returns Max                            16.533
expl/Returns Min                             0.148647
expl/Actions Mean                            0.173413
expl/Actions Std                             0.73528
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         3.22343
expl/env_infos/final/reward_dist Mean        0.226043
expl/env_infos/final/reward_dist Std         0.402807
expl/env_infos/final/reward_dist Max         1.34886
expl/env_infos/final/reward_dist Min         1.47814e-09
expl/env_infos/initial/reward_dist Mean      0.0254025
expl/env_infos/initial/reward_dist Std       0.0196971
expl/env_infos/initial/reward_dist Max       0.0782329
expl/env_infos/initial/reward_dist Min       0.00287016
expl/env_infos/reward_dist Mean              0.161172
expl/env_infos/reward_dist Std               0.357527
expl/env_infos/reward_dist Max               2.0583
expl/env_infos/reward_dist Min               1.24567e-09
eval/num steps total                      1600
eval/num paths total                        80
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0940291
eval/Rewards Std                             0.143387
eval/Rewards Max                             0.425246
eval/Rewards Min                             2.32946e-05
eval/Returns Mean                            1.88058
eval/Returns Std                             2.4429
eval/Returns Max                             6.72544
eval/Returns Min                             0.342934
eval/Actions Mean                            0.275988
eval/Actions Std                             0.822051
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         1.88058
eval/env_infos/final/reward_dist Mean        0.120977
eval/env_infos/final/reward_dist Std         0.1546
eval/env_infos/final/reward_dist Max         0.425246
eval/env_infos/final/reward_dist Min         0.00765193
eval/env_infos/initial/reward_dist Mean      0.011807
eval/env_infos/initial/reward_dist Std       0.00448815
eval/env_infos/initial/reward_dist Max       0.0179023
eval/env_infos/initial/reward_dist Min       0.00670016
eval/env_infos/reward_dist Mean              0.0940291
eval/env_infos/reward_dist Std               0.143387
eval/env_infos/reward_dist Max               0.425246
eval/env_infos/reward_dist Min               2.32946e-05
time/data storing (s)                        0.00154515
time/evaluation sampling (s)                 0.599355
time/exploration sampling (s)                5.25064
time/logging (s)                             0.00231951
time/saving (s)                              0.0010477
time/training (s)                            4.07652
time/epoch (s)                               9.93143
time/total (s)                             562.36
Epoch                                       15
---------------------------------------  ---------------
2023-08-03 21:12:54.034839 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 16 finished
---------------------------------------  ---------------
epoch                                       16
replay_buffer/size                       18500
trainer/QF Loss                             22.2705
trainer/Policy Loss                       -111.773
trainer/Raw Policy Loss                   -111.773
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 104.278
trainer/Q Predictions Std                   11.7162
trainer/Q Predictions Max                  153.821
trainer/Q Predictions Min                   64.1344
trainer/Q Targets Mean                     104.177
trainer/Q Targets Std                       12.1821
trainer/Q Targets Max                      150.611
trainer/Q Targets Min                       67.8586
trainer/Bellman Errors Mean                 22.2705
trainer/Bellman Errors Std                  52.163
trainer/Bellman Errors Max                1164.79
trainer/Bellman Errors Min                   1.45519e-07
trainer/Policy Action Mean                  -0.1973
trainer/Policy Action Std                    0.892548
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     18500
expl/num paths total                       925
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.264294
expl/Rewards Std                             0.932819
expl/Rewards Max                            10
expl/Rewards Min                             2.76904e-06
expl/Returns Mean                            5.28588
expl/Returns Std                             8.27191
expl/Returns Max                            40.4041
expl/Returns Min                             0.161611
expl/Actions Mean                           -0.179172
expl/Actions Std                             0.743548
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         5.28588
expl/env_infos/final/reward_dist Mean        0.54468
expl/env_infos/final/reward_dist Std         1.94107
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.76904e-06
expl/env_infos/initial/reward_dist Mean      0.0152144
expl/env_infos/initial/reward_dist Std       0.0131081
expl/env_infos/initial/reward_dist Max       0.0560567
expl/env_infos/initial/reward_dist Min       0.00301704
expl/env_infos/reward_dist Mean              0.264294
expl/env_infos/reward_dist Std               0.932819
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.76904e-06
eval/num steps total                      1700
eval/num paths total                        85
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0395739
eval/Rewards Std                             0.0785416
eval/Rewards Max                             0.493311
eval/Rewards Min                             0.000254222
eval/Returns Mean                            0.791477
eval/Returns Std                             0.494781
eval/Returns Max                             1.51025
eval/Returns Min                             0.263297
eval/Actions Mean                           -0.250722
eval/Actions Std                             0.794257
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.791477
eval/env_infos/final/reward_dist Mean        0.184036
eval/env_infos/final/reward_dist Std         0.187226
eval/env_infos/final/reward_dist Max         0.493311
eval/env_infos/final/reward_dist Min         0.00122482
eval/env_infos/initial/reward_dist Mean      0.0163673
eval/env_infos/initial/reward_dist Std       0.0101825
eval/env_infos/initial/reward_dist Max       0.0355584
eval/env_infos/initial/reward_dist Min       0.00688948
eval/env_infos/reward_dist Mean              0.0395739
eval/env_infos/reward_dist Std               0.0785416
eval/env_infos/reward_dist Max               0.493311
eval/env_infos/reward_dist Min               0.000254222
time/data storing (s)                        0.00153946
time/evaluation sampling (s)                 1.39686
time/exploration sampling (s)                8.05228
time/logging (s)                             0.00212176
time/saving (s)                              0.00996225
time/training (s)                            4.0649
time/epoch (s)                              13.5277
time/total (s)                             575.89
Epoch                                       16
---------------------------------------  ---------------
2023-08-03 21:13:07.424738 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 17 finished
---------------------------------------  ---------------
epoch                                       17
replay_buffer/size                       19000
trainer/QF Loss                             14.9953
trainer/Policy Loss                       -117.385
trainer/Raw Policy Loss                   -117.385
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 111.067
trainer/Q Predictions Std                    7.7991
trainer/Q Predictions Max                  161.454
trainer/Q Predictions Min                   82.081
trainer/Q Targets Mean                     110.913
trainer/Q Targets Std                        8.10908
trainer/Q Targets Max                      164.159
trainer/Q Targets Min                       79.7594
trainer/Bellman Errors Mean                 14.9953
trainer/Bellman Errors Std                  39.9386
trainer/Bellman Errors Max                1206.22
trainer/Bellman Errors Min                   3.10602e-06
trainer/Policy Action Mean                  -0.328596
trainer/Policy Action Std                    0.865673
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     19000
expl/num paths total                       950
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.621462
expl/Rewards Std                             1.89829
expl/Rewards Max                            10
expl/Rewards Min                             1.64483e-07
expl/Returns Mean                           12.4292
expl/Returns Std                            36.1176
expl/Returns Max                           184.208
expl/Returns Min                             0.363305
expl/Actions Mean                           -0.230188
expl/Actions Std                             0.733583
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        12.4292
expl/env_infos/final/reward_dist Mean        0.678965
expl/env_infos/final/reward_dist Std         1.97368
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         6.40861e-05
expl/env_infos/initial/reward_dist Mean      0.0384828
expl/env_infos/initial/reward_dist Std       0.0707127
expl/env_infos/initial/reward_dist Max       0.372898
expl/env_infos/initial/reward_dist Min       0.0033639
expl/env_infos/reward_dist Mean              0.621462
expl/env_infos/reward_dist Std               1.89829
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.64483e-07
eval/num steps total                      1800
eval/num paths total                        90
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.603529
eval/Rewards Std                             0.691702
eval/Rewards Max                             2.92504
eval/Rewards Min                             0.000748369
eval/Returns Mean                           12.0706
eval/Returns Std                            10.1821
eval/Returns Max                            23.8355
eval/Returns Min                             0.687835
eval/Actions Mean                           -0.31916
eval/Actions Std                             0.774685
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                        12.0706
eval/env_infos/final/reward_dist Mean        0.499531
eval/env_infos/final/reward_dist Std         0.401384
eval/env_infos/final/reward_dist Max         1.24978
eval/env_infos/final/reward_dist Min         0.094037
eval/env_infos/initial/reward_dist Mean      0.0338752
eval/env_infos/initial/reward_dist Std       0.0211312
eval/env_infos/initial/reward_dist Max       0.0745851
eval/env_infos/initial/reward_dist Min       0.016287
eval/env_infos/reward_dist Mean              0.603529
eval/env_infos/reward_dist Std               0.691702
eval/env_infos/reward_dist Max               2.92504
eval/env_infos/reward_dist Min               0.000748369
time/data storing (s)                        0.00258376
time/evaluation sampling (s)                 1.42204
time/exploration sampling (s)                7.92623
time/logging (s)                             0.00225939
time/saving (s)                              0.00104618
time/training (s)                            4.03407
time/epoch (s)                              13.3882
time/total (s)                             589.28
Epoch                                       17
---------------------------------------  ---------------
2023-08-03 21:13:17.294677 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 18 finished
---------------------------------------  ---------------
epoch                                       18
replay_buffer/size                       19500
trainer/QF Loss                             16.2824
trainer/Policy Loss                       -112.899
trainer/Raw Policy Loss                   -112.899
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 108.13
trainer/Q Predictions Std                   10.6716
trainer/Q Predictions Max                  170.835
trainer/Q Predictions Min                   89.1816
trainer/Q Targets Mean                     108.036
trainer/Q Targets Std                       11.1633
trainer/Q Targets Max                      170.995
trainer/Q Targets Min                       86.7533
trainer/Bellman Errors Mean                 16.2824
trainer/Bellman Errors Std                  53.8685
trainer/Bellman Errors Max                2191.27
trainer/Bellman Errors Min                   9.53674e-07
trainer/Policy Action Mean                  -0.279543
trainer/Policy Action Std                    0.874099
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     19500
expl/num paths total                       975
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0482963
expl/Rewards Std                             0.246799
expl/Rewards Max                             3.01958
expl/Rewards Min                             2.16962e-10
expl/Returns Mean                            0.965927
expl/Returns Std                             3.42192
expl/Returns Max                            17.6504
expl/Returns Min                             0.0432223
expl/Actions Mean                           -0.19776
expl/Actions Std                             0.774872
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.965927
expl/env_infos/final/reward_dist Mean        0.0295725
expl/env_infos/final/reward_dist Std         0.0768125
expl/env_infos/final/reward_dist Max         0.352992
expl/env_infos/final/reward_dist Min         2.16962e-10
expl/env_infos/initial/reward_dist Mean      0.014626
expl/env_infos/initial/reward_dist Std       0.014744
expl/env_infos/initial/reward_dist Max       0.0558165
expl/env_infos/initial/reward_dist Min       0.000217364
expl/env_infos/reward_dist Mean              0.0482963
expl/env_infos/reward_dist Std               0.246799
expl/env_infos/reward_dist Max               3.01958
expl/env_infos/reward_dist Min               2.16962e-10
eval/num steps total                      1900
eval/num paths total                        95
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0150397
eval/Rewards Std                             0.0365379
eval/Rewards Max                             0.333382
eval/Rewards Min                             1.33e-06
eval/Returns Mean                            0.300794
eval/Returns Std                             0.161699
eval/Returns Max                             0.55687
eval/Returns Min                             0.0960473
eval/Actions Mean                           -0.224169
eval/Actions Std                             0.885121
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.300794
eval/env_infos/final/reward_dist Mean        0.071545
eval/env_infos/final/reward_dist Std         0.13125
eval/env_infos/final/reward_dist Max         0.333382
eval/env_infos/final/reward_dist Min         2.68467e-06
eval/env_infos/initial/reward_dist Mean      0.0161883
eval/env_infos/initial/reward_dist Std       0.0165256
eval/env_infos/initial/reward_dist Max       0.0465502
eval/env_infos/initial/reward_dist Min       0.00320357
eval/env_infos/reward_dist Mean              0.0150397
eval/env_infos/reward_dist Std               0.0365379
eval/env_infos/reward_dist Max               0.333382
eval/env_infos/reward_dist Min               1.33e-06
time/data storing (s)                        0.0021687
time/evaluation sampling (s)                 0.745479
time/exploration sampling (s)                5.15128
time/logging (s)                             0.00234212
time/saving (s)                              0.000997159
time/training (s)                            3.96536
time/epoch (s)                               9.86763
time/total (s)                             599.149
Epoch                                       18
---------------------------------------  ---------------
2023-08-03 21:13:25.607498 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 19 finished
---------------------------------------  ---------------
epoch                                       19
replay_buffer/size                       20000
trainer/QF Loss                             12.9392
trainer/Policy Loss                       -127.728
trainer/Raw Policy Loss                   -127.728
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 120.362
trainer/Q Predictions Std                    8.00141
trainer/Q Predictions Max                  165.516
trainer/Q Predictions Min                   98.4376
trainer/Q Targets Mean                     120.312
trainer/Q Targets Std                        8.52737
trainer/Q Targets Max                      169.731
trainer/Q Targets Min                       98.3358
trainer/Bellman Errors Mean                 12.9392
trainer/Bellman Errors Std                  30.4143
trainer/Bellman Errors Max                 666.949
trainer/Bellman Errors Min                   6.91565e-07
trainer/Policy Action Mean                  -0.0795504
trainer/Policy Action Std                    0.961872
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     20000
expl/num paths total                      1000
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00187314
expl/Rewards Std                             0.00659376
expl/Rewards Max                             0.0628848
expl/Rewards Min                             1.0217e-08
expl/Returns Mean                            0.0374629
expl/Returns Std                             0.0372784
expl/Returns Max                             0.15596
expl/Returns Min                             0.00273733
expl/Actions Mean                            0.000719742
expl/Actions Std                             0.845769
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.0374629
expl/env_infos/final/reward_dist Mean        0.000868356
expl/env_infos/final/reward_dist Std         0.00224006
expl/env_infos/final/reward_dist Max         0.00980368
expl/env_infos/final/reward_dist Min         1.0217e-08
expl/env_infos/initial/reward_dist Mean      0.0109799
expl/env_infos/initial/reward_dist Std       0.0178046
expl/env_infos/initial/reward_dist Max       0.0628848
expl/env_infos/initial/reward_dist Min       1.1189e-05
expl/env_infos/reward_dist Mean              0.00187314
expl/env_infos/reward_dist Std               0.00659376
expl/env_infos/reward_dist Max               0.0628848
expl/env_infos/reward_dist Min               1.0217e-08
eval/num steps total                      2000
eval/num paths total                       100
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.0152832
eval/Rewards Std                             0.0797481
eval/Rewards Max                             0.671065
eval/Rewards Min                             2.90835e-07
eval/Returns Mean                            0.305665
eval/Returns Std                             0.575248
eval/Returns Max                             1.456
eval/Returns Min                             0.0094377
eval/Actions Mean                            0.0219266
eval/Actions Std                             0.967895
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.305665
eval/env_infos/final/reward_dist Mean        0.000196307
eval/env_infos/final/reward_dist Std         0.000228877
eval/env_infos/final/reward_dist Max         0.000637022
eval/env_infos/final/reward_dist Min         4.28236e-05
eval/env_infos/initial/reward_dist Mean      0.00259797
eval/env_infos/initial/reward_dist Std       0.00366606
eval/env_infos/initial/reward_dist Max       0.00987247
eval/env_infos/initial/reward_dist Min       0.000346295
eval/env_infos/reward_dist Mean              0.0152832
eval/env_infos/reward_dist Std               0.0797481
eval/env_infos/reward_dist Max               0.671065
eval/env_infos/reward_dist Min               2.90835e-07
time/data storing (s)                        0.00155001
time/evaluation sampling (s)                 0.786826
time/exploration sampling (s)                3.45998
time/logging (s)                             0.00234716
time/saving (s)                              0.00103282
time/training (s)                            4.05862
time/epoch (s)                               8.31035
time/total (s)                             607.462
Epoch                                       19
---------------------------------------  ---------------
2023-08-03 21:13:36.038799 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 20 finished
---------------------------------------  ---------------
epoch                                       20
replay_buffer/size                       20500
trainer/QF Loss                             11.4786
trainer/Policy Loss                       -115.488
trainer/Raw Policy Loss                   -115.488
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 111.159
trainer/Q Predictions Std                    6.78761
trainer/Q Predictions Max                  166.626
trainer/Q Predictions Min                   87.0087
trainer/Q Targets Mean                     111.139
trainer/Q Targets Std                        7.49948
trainer/Q Targets Max                      168.95
trainer/Q Targets Min                       82.9067
trainer/Bellman Errors Mean                 11.4786
trainer/Bellman Errors Std                  35.4405
trainer/Bellman Errors Max                 607.922
trainer/Bellman Errors Min                   1.51398e-07
trainer/Policy Action Mean                  -0.0529414
trainer/Policy Action Std                    0.939791
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     20500
expl/num paths total                      1025
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.100257
expl/Rewards Std                             0.31329
expl/Rewards Max                             3.00017
expl/Rewards Min                             4.70795e-10
expl/Returns Mean                            2.00513
expl/Returns Std                             3.84406
expl/Returns Max                            14.5487
expl/Returns Min                             0.0827836
expl/Actions Mean                            0.022689
expl/Actions Std                             0.802935
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         2.00513
expl/env_infos/final/reward_dist Mean        0.133475
expl/env_infos/final/reward_dist Std         0.313721
expl/env_infos/final/reward_dist Max         1.14298
expl/env_infos/final/reward_dist Min         4.70795e-10
expl/env_infos/initial/reward_dist Mean      0.0138825
expl/env_infos/initial/reward_dist Std       0.0140951
expl/env_infos/initial/reward_dist Max       0.0574249
expl/env_infos/initial/reward_dist Min       0.00080035
expl/env_infos/reward_dist Mean              0.100257
expl/env_infos/reward_dist Std               0.31329
expl/env_infos/reward_dist Max               3.00017
expl/env_infos/reward_dist Min               4.70795e-10
eval/num steps total                      2100
eval/num paths total                       105
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.439777
eval/Rewards Std                             1.95566
eval/Rewards Max                            10
eval/Rewards Min                             3.04308e-06
eval/Returns Mean                            8.79554
eval/Returns Std                            15.8254
eval/Returns Max                            40.4348
eval/Returns Min                             0.160022
eval/Actions Mean                            0.0264194
eval/Actions Std                             0.927358
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         8.79554
eval/env_infos/final/reward_dist Mean        2.00013
eval/env_infos/final/reward_dist Std         3.99994
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.04308e-06
eval/env_infos/initial/reward_dist Mean      0.0335871
eval/env_infos/initial/reward_dist Std       0.0211367
eval/env_infos/initial/reward_dist Max       0.0616609
eval/env_infos/initial/reward_dist Min       0.00141259
eval/env_infos/reward_dist Mean              0.439777
eval/env_infos/reward_dist Std               1.95566
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               3.04308e-06
time/data storing (s)                        0.00160536
time/evaluation sampling (s)                 0.853595
time/exploration sampling (s)                5.3617
time/logging (s)                             0.00232297
time/saving (s)                              0.00103138
time/training (s)                            4.20849
time/epoch (s)                              10.4287
time/total (s)                             617.893
Epoch                                       20
---------------------------------------  ---------------
2023-08-03 21:13:46.661363 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 21 finished
---------------------------------------  ---------------
epoch                                       21
replay_buffer/size                       21000
trainer/QF Loss                             20.0999
trainer/Policy Loss                       -124.033
trainer/Raw Policy Loss                   -124.033
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 115.991
trainer/Q Predictions Std                   13.4769
trainer/Q Predictions Max                  182.834
trainer/Q Predictions Min                   97.7361
trainer/Q Targets Mean                     115.933
trainer/Q Targets Std                       14.2449
trainer/Q Targets Max                      178.703
trainer/Q Targets Min                       96.5402
trainer/Bellman Errors Mean                 20.0999
trainer/Bellman Errors Std                  62.0017
trainer/Bellman Errors Max                1352.11
trainer/Bellman Errors Min                   1.1269e-07
trainer/Policy Action Mean                  -0.0322465
trainer/Policy Action Std                    0.964604
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     21000
expl/num paths total                      1050
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.00933416
expl/Rewards Std                             0.0594174
expl/Rewards Max                             0.986466
expl/Rewards Min                             3.75604e-10
expl/Returns Mean                            0.186683
expl/Returns Std                             0.27346
expl/Returns Max                             1.24007
expl/Returns Min                             0.00792565
expl/Actions Mean                           -0.154606
expl/Actions Std                             0.819381
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.186683
expl/env_infos/final/reward_dist Mean        0.00128969
expl/env_infos/final/reward_dist Std         0.00361394
expl/env_infos/final/reward_dist Max         0.0171669
expl/env_infos/final/reward_dist Min         2.05768e-09
expl/env_infos/initial/reward_dist Mean      0.00392061
expl/env_infos/initial/reward_dist Std       0.00475877
expl/env_infos/initial/reward_dist Max       0.0198888
expl/env_infos/initial/reward_dist Min       1.61159e-05
expl/env_infos/reward_dist Mean              0.00933416
expl/env_infos/reward_dist Std               0.0594174
expl/env_infos/reward_dist Max               0.986466
expl/env_infos/reward_dist Min               3.75604e-10
eval/num steps total                      2200
eval/num paths total                       110
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00222704
eval/Rewards Std                             0.00727836
eval/Rewards Max                             0.0552294
eval/Rewards Min                             4.62737e-08
eval/Returns Mean                            0.0445407
eval/Returns Std                             0.0149386
eval/Returns Max                             0.0633265
eval/Returns Min                             0.0296301
eval/Actions Mean                           -0.176309
eval/Actions Std                             0.960347
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0445407
eval/env_infos/final/reward_dist Mean        0.000542114
eval/env_infos/final/reward_dist Std         0.00104691
eval/env_infos/final/reward_dist Max         0.00263525
eval/env_infos/final/reward_dist Min         4.68065e-07
eval/env_infos/initial/reward_dist Mean      0.00320473
eval/env_infos/initial/reward_dist Std       0.00363237
eval/env_infos/initial/reward_dist Max       0.00846601
eval/env_infos/initial/reward_dist Min       6.19566e-05
eval/env_infos/reward_dist Mean              0.00222704
eval/env_infos/reward_dist Std               0.00727836
eval/env_infos/reward_dist Max               0.0552294
eval/env_infos/reward_dist Min               4.62737e-08
time/data storing (s)                        0.00217416
time/evaluation sampling (s)                 0.879583
time/exploration sampling (s)                5.73415
time/logging (s)                             0.00225203
time/saving (s)                              0.00107198
time/training (s)                            4.00078
time/epoch (s)                              10.62
time/total (s)                             628.515
Epoch                                       21
---------------------------------------  ---------------
2023-08-03 21:13:56.558881 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 22 finished
---------------------------------------  ---------------
epoch                                       22
replay_buffer/size                       21500
trainer/QF Loss                             23.7761
trainer/Policy Loss                       -126.45
trainer/Raw Policy Loss                   -126.45
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 120.942
trainer/Q Predictions Std                   13.9869
trainer/Q Predictions Max                  174.934
trainer/Q Predictions Min                  102.716
trainer/Q Targets Mean                     120.939
trainer/Q Targets Std                       14.8081
trainer/Q Targets Max                      174.829
trainer/Q Targets Min                      100.115
trainer/Bellman Errors Mean                 23.7761
trainer/Bellman Errors Std                  73.5118
trainer/Bellman Errors Max                1427.48
trainer/Bellman Errors Min                   1.23167e-07
trainer/Policy Action Mean                   0.0258709
trainer/Policy Action Std                    0.945956
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     21500
expl/num paths total                      1075
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0030487
expl/Rewards Std                             0.00626286
expl/Rewards Max                             0.0568486
expl/Rewards Min                             1.75076e-09
expl/Returns Mean                            0.060974
expl/Returns Std                             0.0378611
expl/Returns Max                             0.161036
expl/Returns Min                             0.00726147
expl/Actions Mean                            0.0500219
expl/Actions Std                             0.8075
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.060974
expl/env_infos/final/reward_dist Mean        0.00372655
expl/env_infos/final/reward_dist Std         0.0113393
expl/env_infos/final/reward_dist Max         0.0568486
expl/env_infos/final/reward_dist Min         3.1014e-09
expl/env_infos/initial/reward_dist Mean      0.0046249
expl/env_infos/initial/reward_dist Std       0.00654199
expl/env_infos/initial/reward_dist Max       0.0212918
expl/env_infos/initial/reward_dist Min       2.66255e-05
expl/env_infos/reward_dist Mean              0.0030487
expl/env_infos/reward_dist Std               0.00626286
expl/env_infos/reward_dist Max               0.0568486
expl/env_infos/reward_dist Min               1.75076e-09
eval/num steps total                      2300
eval/num paths total                       115
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00288682
eval/Rewards Std                             0.00580618
eval/Rewards Max                             0.0387489
eval/Rewards Min                             5.34644e-07
eval/Returns Mean                            0.0577364
eval/Returns Std                             0.0154001
eval/Returns Max                             0.0744936
eval/Returns Min                             0.0336327
eval/Actions Mean                            0.0225893
eval/Actions Std                             0.912454
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0577364
eval/env_infos/final/reward_dist Mean        0.0022525
eval/env_infos/final/reward_dist Std         0.00220724
eval/env_infos/final/reward_dist Max         0.00568904
eval/env_infos/final/reward_dist Min         6.03622e-07
eval/env_infos/initial/reward_dist Mean      0.00632405
eval/env_infos/initial/reward_dist Std       0.00618859
eval/env_infos/initial/reward_dist Max       0.0140944
eval/env_infos/initial/reward_dist Min       0.00041212
eval/env_infos/reward_dist Mean              0.00288682
eval/env_infos/reward_dist Std               0.00580618
eval/env_infos/reward_dist Max               0.0387489
eval/env_infos/reward_dist Min               5.34644e-07
time/data storing (s)                        0.00160068
time/evaluation sampling (s)                 0.870786
time/exploration sampling (s)                4.86407
time/logging (s)                             0.00235048
time/saving (s)                              0.00100304
time/training (s)                            4.15492
time/epoch (s)                               9.89472
time/total (s)                             638.412
Epoch                                       22
---------------------------------------  ---------------
2023-08-03 21:14:06.721549 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 23 finished
---------------------------------------  ---------------
epoch                                       23
replay_buffer/size                       22000
trainer/QF Loss                             21.267
trainer/Policy Loss                       -120.394
trainer/Raw Policy Loss                   -120.394
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 115.742
trainer/Q Predictions Std                   12.9543
trainer/Q Predictions Max                  164.945
trainer/Q Predictions Min                   86.5954
trainer/Q Targets Mean                     115.586
trainer/Q Targets Std                       13.6815
trainer/Q Targets Max                      168.973
trainer/Q Targets Min                       82.1218
trainer/Bellman Errors Mean                 21.267
trainer/Bellman Errors Std                  62.2778
trainer/Bellman Errors Max                 832.611
trainer/Bellman Errors Min                   2.61294e-07
trainer/Policy Action Mean                  -0.186039
trainer/Policy Action Std                    0.922337
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     22000
expl/num paths total                      1100
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0108331
expl/Rewards Std                             0.0384382
expl/Rewards Max                             0.474224
expl/Rewards Min                             3.45758e-09
expl/Returns Mean                            0.216663
expl/Returns Std                             0.563965
expl/Returns Max                             2.91884
expl/Returns Min                             0.00560997
expl/Actions Mean                           -0.245055
expl/Actions Std                             0.77826
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         0.216663
expl/env_infos/final/reward_dist Mean        0.00626664
expl/env_infos/final/reward_dist Std         0.014656
expl/env_infos/final/reward_dist Max         0.0608649
expl/env_infos/final/reward_dist Min         5.09939e-09
expl/env_infos/initial/reward_dist Mean      0.00851691
expl/env_infos/initial/reward_dist Std       0.0135385
expl/env_infos/initial/reward_dist Max       0.0567498
expl/env_infos/initial/reward_dist Min       7.6845e-05
expl/env_infos/reward_dist Mean              0.0108331
expl/env_infos/reward_dist Std               0.0384382
expl/env_infos/reward_dist Max               0.474224
expl/env_infos/reward_dist Min               3.45758e-09
eval/num steps total                      2400
eval/num paths total                       120
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00222111
eval/Rewards Std                             0.00684187
eval/Rewards Max                             0.06058
eval/Rewards Min                             3.27713e-09
eval/Returns Mean                            0.0444222
eval/Returns Std                             0.0256781
eval/Returns Max                             0.0771712
eval/Returns Min                             0.0182175
eval/Actions Mean                           -0.257634
eval/Actions Std                             0.924232
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0444222
eval/env_infos/final/reward_dist Mean        1.5048e-05
eval/env_infos/final/reward_dist Std         3.00621e-05
eval/env_infos/final/reward_dist Max         7.51721e-05
eval/env_infos/final/reward_dist Min         3.27713e-09
eval/env_infos/initial/reward_dist Mean      0.0194801
eval/env_infos/initial/reward_dist Std       0.0222462
eval/env_infos/initial/reward_dist Max       0.06058
eval/env_infos/initial/reward_dist Min       0.000192084
eval/env_infos/reward_dist Mean              0.00222111
eval/env_infos/reward_dist Std               0.00684187
eval/env_infos/reward_dist Max               0.06058
eval/env_infos/reward_dist Min               3.27713e-09
time/data storing (s)                        0.00154978
time/evaluation sampling (s)                 1.23923
time/exploration sampling (s)                5.05159
time/logging (s)                             0.00240303
time/saving (s)                              0.000979998
time/training (s)                            3.86443
time/epoch (s)                              10.1602
time/total (s)                             648.574
Epoch                                       23
---------------------------------------  ---------------
2023-08-03 21:14:16.128359 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 24 finished
---------------------------------------  ---------------
epoch                                       24
replay_buffer/size                       22500
trainer/QF Loss                             21.9827
trainer/Policy Loss                       -114.275
trainer/Raw Policy Loss                   -114.275
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 107.761
trainer/Q Predictions Std                   13.7316
trainer/Q Predictions Max                  161.571
trainer/Q Predictions Min                   80.1209
trainer/Q Targets Mean                     107.657
trainer/Q Targets Std                       14.6777
trainer/Q Targets Max                      168.527
trainer/Q Targets Min                       75.2704
trainer/Bellman Errors Mean                 21.9827
trainer/Bellman Errors Std                  57.3542
trainer/Bellman Errors Max                 780.312
trainer/Bellman Errors Min                   4.9267e-07
trainer/Policy Action Mean                   0.216286
trainer/Policy Action Std                    0.917492
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     22500
expl/num paths total                      1125
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.0534271
expl/Rewards Std                             0.230723
expl/Rewards Max                             1.7643
expl/Rewards Min                             5.33764e-09
expl/Returns Mean                            1.06854
expl/Returns Std                             3.63604
expl/Returns Max                            15.9555
expl/Returns Min                             0.00331622
expl/Actions Mean                            0.202709
expl/Actions Std                             0.817047
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         1.06854
expl/env_infos/final/reward_dist Mean        0.0151463
expl/env_infos/final/reward_dist Std         0.067282
expl/env_infos/final/reward_dist Max         0.343525
expl/env_infos/final/reward_dist Min         5.33764e-09
expl/env_infos/initial/reward_dist Mean      0.0107325
expl/env_infos/initial/reward_dist Std       0.0138345
expl/env_infos/initial/reward_dist Max       0.0648418
expl/env_infos/initial/reward_dist Min       1.21572e-05
expl/env_infos/reward_dist Mean              0.0534271
expl/env_infos/reward_dist Std               0.230723
expl/env_infos/reward_dist Max               1.7643
expl/env_infos/reward_dist Min               5.33764e-09
eval/num steps total                      2500
eval/num paths total                       125
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00105931
eval/Rewards Std                             0.00183305
eval/Rewards Max                             0.0120615
eval/Rewards Min                             6.01636e-06
eval/Returns Mean                            0.0211862
eval/Returns Std                             0.00621931
eval/Returns Max                             0.0271406
eval/Returns Min                             0.0100603
eval/Actions Mean                            0.245064
eval/Actions Std                             0.933568
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.0211862
eval/env_infos/final/reward_dist Mean        0.000429157
eval/env_infos/final/reward_dist Std         0.000308604
eval/env_infos/final/reward_dist Max         0.000886705
eval/env_infos/final/reward_dist Min         8.66311e-05
eval/env_infos/initial/reward_dist Mean      0.00253708
eval/env_infos/initial/reward_dist Std       0.00228818
eval/env_infos/initial/reward_dist Max       0.00540594
eval/env_infos/initial/reward_dist Min       0.00020467
eval/env_infos/reward_dist Mean              0.00105931
eval/env_infos/reward_dist Std               0.00183305
eval/env_infos/reward_dist Max               0.0120615
eval/env_infos/reward_dist Min               6.01636e-06
time/data storing (s)                        0.00160366
time/evaluation sampling (s)                 0.674186
time/exploration sampling (s)                4.72805
time/logging (s)                             0.00223965
time/saving (s)                              0.00102161
time/training (s)                            3.99515
time/epoch (s)                               9.40225
time/total (s)                             657.98
Epoch                                       24
---------------------------------------  ---------------
2023-08-03 21:14:25.041194 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 25 finished
---------------------------------------  ---------------
epoch                                       25
replay_buffer/size                       23000
trainer/QF Loss                              8.05345
trainer/Policy Loss                       -112.665
trainer/Raw Policy Loss                   -112.665
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 108.424
trainer/Q Predictions Std                    6.17059
trainer/Q Predictions Max                  143.755
trainer/Q Predictions Min                   66.8442
trainer/Q Targets Mean                     108.366
trainer/Q Targets Std                        6.58493
trainer/Q Targets Max                      147.318
trainer/Q Targets Min                       66.4545
trainer/Bellman Errors Mean                  8.05346
trainer/Bellman Errors Std                  20.9576
trainer/Bellman Errors Max                 439.801
trainer/Bellman Errors Min                   3.01749e-07
trainer/Policy Action Mean                   0.0781964
trainer/Policy Action Std                    0.912823
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     23000
expl/num paths total                      1150
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.13146
expl/Rewards Std                             0.447673
expl/Rewards Max                             2.64172
expl/Rewards Min                             1.6754e-09
expl/Returns Mean                            2.6292
expl/Returns Std                             7.24987
expl/Returns Max                            30.7681
expl/Returns Min                             0.0149583
expl/Actions Mean                            0.104688
expl/Actions Std                             0.795547
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                         2.6292
expl/env_infos/final/reward_dist Mean        0.111816
expl/env_infos/final/reward_dist Std         0.516618
expl/env_infos/final/reward_dist Max         2.64172
expl/env_infos/final/reward_dist Min         1.6754e-09
expl/env_infos/initial/reward_dist Mean      0.0488544
expl/env_infos/initial/reward_dist Std       0.0997246
expl/env_infos/initial/reward_dist Max       0.453083
expl/env_infos/initial/reward_dist Min       0.000114172
expl/env_infos/reward_dist Mean              0.13146
expl/env_infos/reward_dist Std               0.447673
expl/env_infos/reward_dist Max               2.64172
expl/env_infos/reward_dist Min               1.6754e-09
eval/num steps total                      2600
eval/num paths total                       130
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00525348
eval/Rewards Std                             0.0136759
eval/Rewards Max                             0.0753514
eval/Rewards Min                             4.20805e-06
eval/Returns Mean                            0.10507
eval/Returns Std                             0.0500089
eval/Returns Max                             0.154556
eval/Returns Min                             0.00979491
eval/Actions Mean                            0.149616
eval/Actions Std                             0.896588
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.10507
eval/env_infos/final/reward_dist Mean        0.028936
eval/env_infos/final/reward_dist Std         0.0227426
eval/env_infos/final/reward_dist Max         0.0591454
eval/env_infos/final/reward_dist Min         0.000632704
eval/env_infos/initial/reward_dist Mean      0.0184631
eval/env_infos/initial/reward_dist Std       0.0150869
eval/env_infos/initial/reward_dist Max       0.0402948
eval/env_infos/initial/reward_dist Min       0.000365981
eval/env_infos/reward_dist Mean              0.00525348
eval/env_infos/reward_dist Std               0.0136759
eval/env_infos/reward_dist Max               0.0753514
eval/env_infos/reward_dist Min               4.20805e-06
time/data storing (s)                        0.00194922
time/evaluation sampling (s)                 0.545712
time/exploration sampling (s)                3.86119
time/logging (s)                             0.0022777
time/saving (s)                              0.00101367
time/training (s)                            4.49826
time/epoch (s)                               8.9104
time/total (s)                             666.893
Epoch                                       25
---------------------------------------  ---------------
2023-08-03 21:14:36.186411 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 26 finished
---------------------------------------  ---------------
epoch                                       26
replay_buffer/size                       23500
trainer/QF Loss                              7.18229
trainer/Policy Loss                        -93.1097
trainer/Raw Policy Loss                    -93.1097
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  89.2101
trainer/Q Predictions Std                    6.16852
trainer/Q Predictions Max                  129.459
trainer/Q Predictions Min                   55.1062
trainer/Q Targets Mean                      89.2189
trainer/Q Targets Std                        6.66223
trainer/Q Targets Max                      136.578
trainer/Q Targets Min                       54.043
trainer/Bellman Errors Mean                  7.18229
trainer/Bellman Errors Std                  19.4117
trainer/Bellman Errors Max                 411.357
trainer/Bellman Errors Min                   3.36207e-07
trainer/Policy Action Mean                  -0.158462
trainer/Policy Action Std                    0.891364
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     23500
expl/num paths total                      1175
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.592063
expl/Rewards Std                             1.55814
expl/Rewards Max                            10
expl/Rewards Min                             1.13576e-08
expl/Returns Mean                           11.8413
expl/Returns Std                            21.7051
expl/Returns Max                           100.461
expl/Returns Min                             0.224051
expl/Actions Mean                           -0.116355
expl/Actions Std                             0.777199
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        11.8413
expl/env_infos/final/reward_dist Mean        0.943993
expl/env_infos/final/reward_dist Std         2.05611
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         1.13576e-08
expl/env_infos/initial/reward_dist Mean      0.0180648
expl/env_infos/initial/reward_dist Std       0.0177279
expl/env_infos/initial/reward_dist Max       0.0731301
expl/env_infos/initial/reward_dist Min       0.000576302
expl/env_infos/reward_dist Mean              0.592063
expl/env_infos/reward_dist Std               1.55814
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.13576e-08
eval/num steps total                      2700
eval/num paths total                       135
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.335727
eval/Rewards Std                             0.591507
eval/Rewards Max                             2.71395
eval/Rewards Min                             0.000152301
eval/Returns Mean                            6.71455
eval/Returns Std                             8.34184
eval/Returns Max                            22.3262
eval/Returns Min                             0.571915
eval/Actions Mean                           -0.189469
eval/Actions Std                             0.860206
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         6.71455
eval/env_infos/final/reward_dist Mean        0.494428
eval/env_infos/final/reward_dist Std         0.692495
eval/env_infos/final/reward_dist Max         1.79343
eval/env_infos/final/reward_dist Min         0.000152301
eval/env_infos/initial/reward_dist Mean      0.0241129
eval/env_infos/initial/reward_dist Std       0.0160672
eval/env_infos/initial/reward_dist Max       0.0409588
eval/env_infos/initial/reward_dist Min       0.00426064
eval/env_infos/reward_dist Mean              0.335727
eval/env_infos/reward_dist Std               0.591507
eval/env_infos/reward_dist Max               2.71395
eval/env_infos/reward_dist Min               0.000152301
time/data storing (s)                        0.00156698
time/evaluation sampling (s)                 0.98158
time/exploration sampling (s)                6.02532
time/logging (s)                             0.00227924
time/saving (s)                              0.000982199
time/training (s)                            4.1261
time/epoch (s)                              11.1378
time/total (s)                             678.037
Epoch                                       26
---------------------------------------  ---------------
2023-08-03 21:14:48.945167 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 27 finished
---------------------------------------  ---------------
epoch                                       27
replay_buffer/size                       24000
trainer/QF Loss                             12.8908
trainer/Policy Loss                        -89.7163
trainer/Raw Policy Loss                    -89.7163
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  85.0279
trainer/Q Predictions Std                    9.32716
trainer/Q Predictions Max                  141.491
trainer/Q Predictions Min                   44.6835
trainer/Q Targets Mean                      85.0445
trainer/Q Targets Std                       10.2148
trainer/Q Targets Max                      145.285
trainer/Q Targets Min                       41.7647
trainer/Bellman Errors Mean                 12.8908
trainer/Bellman Errors Std                  62.2838
trainer/Bellman Errors Max                2351.85
trainer/Bellman Errors Min                   9.31323e-10
trainer/Policy Action Mean                  -0.0115717
trainer/Policy Action Std                    0.872592
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     24000
expl/num paths total                      1200
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            1.71163
expl/Rewards Std                             3.0434
expl/Rewards Max                            10
expl/Rewards Min                             4.04484e-08
expl/Returns Mean                           34.2326
expl/Returns Std                            49.8575
expl/Returns Max                           172.529
expl/Returns Min                             0.063189
expl/Actions Mean                            0.0229052
expl/Actions Std                             0.71632
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        34.2326
expl/env_infos/final/reward_dist Mean        2.33851
expl/env_infos/final/reward_dist Std         3.54992
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         4.04484e-08
expl/env_infos/initial/reward_dist Mean      0.0434241
expl/env_infos/initial/reward_dist Std       0.030572
expl/env_infos/initial/reward_dist Max       0.149755
expl/env_infos/initial/reward_dist Min       0.00424948
expl/env_infos/reward_dist Mean              1.71163
expl/env_infos/reward_dist Std               3.0434
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               4.04484e-08
eval/num steps total                      2800
eval/num paths total                       140
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            1.33272
eval/Rewards Std                             1.37676
eval/Rewards Max                             4.54634
eval/Rewards Min                             0.00497017
eval/Returns Mean                           26.6543
eval/Returns Std                            15.4926
eval/Returns Max                            44.0047
eval/Returns Min                             3.00578
eval/Actions Mean                           -0.103356
eval/Actions Std                             0.683519
eval/Actions Max                             1
eval/Actions Min                            -0.999997
eval/Num Paths                               5
eval/Average Returns                        26.6543
eval/env_infos/final/reward_dist Mean        1.54755
eval/env_infos/final/reward_dist Std         1.62961
eval/env_infos/final/reward_dist Max         4.41937
eval/env_infos/final/reward_dist Min         0.0150555
eval/env_infos/initial/reward_dist Mean      0.0358358
eval/env_infos/initial/reward_dist Std       0.0192569
eval/env_infos/initial/reward_dist Max       0.0641012
eval/env_infos/initial/reward_dist Min       0.00497017
eval/env_infos/reward_dist Mean              1.33272
eval/env_infos/reward_dist Std               1.37676
eval/env_infos/reward_dist Max               4.54634
eval/env_infos/reward_dist Min               0.00497017
time/data storing (s)                        0.00217193
time/evaluation sampling (s)                 1.57308
time/exploration sampling (s)                6.89191
time/logging (s)                             0.00228535
time/saving (s)                              0.00100073
time/training (s)                            4.28584
time/epoch (s)                              12.7563
time/total (s)                             690.796
Epoch                                       27
---------------------------------------  ---------------
2023-08-03 21:15:02.925842 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 28 finished
---------------------------------------  ---------------
epoch                                       28
replay_buffer/size                       24500
trainer/QF Loss                             27.526
trainer/Policy Loss                       -106.952
trainer/Raw Policy Loss                   -106.952
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                  98.955
trainer/Q Predictions Std                   16.1296
trainer/Q Predictions Max                  165.174
trainer/Q Predictions Min                   50.0813
trainer/Q Targets Mean                      98.8018
trainer/Q Targets Std                       17.0939
trainer/Q Targets Max                      168.412
trainer/Q Targets Min                       48.6682
trainer/Bellman Errors Mean                 27.526
trainer/Bellman Errors Std                  88.7155
trainer/Bellman Errors Max                1379.21
trainer/Bellman Errors Min                   3.63798e-08
trainer/Policy Action Mean                   0.0795423
trainer/Policy Action Std                    0.872072
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     24500
expl/num paths total                      1225
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.918949
expl/Rewards Std                             1.66517
expl/Rewards Max                            10
expl/Rewards Min                             1.97426e-09
expl/Returns Mean                           18.379
expl/Returns Std                            23.7771
expl/Returns Max                           103.644
expl/Returns Min                             0.284699
expl/Actions Mean                            0.0652571
expl/Actions Std                             0.715373
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        18.379
expl/env_infos/final/reward_dist Mean        1.44542
expl/env_infos/final/reward_dist Std         2.65982
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.2851e-08
expl/env_infos/initial/reward_dist Mean      0.0345625
expl/env_infos/initial/reward_dist Std       0.0205863
expl/env_infos/initial/reward_dist Max       0.0900121
expl/env_infos/initial/reward_dist Min       0.00613565
expl/env_infos/reward_dist Mean              0.918949
expl/env_infos/reward_dist Std               1.66517
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.97426e-09
eval/num steps total                      2900
eval/num paths total                       145
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            2.05462
eval/Rewards Std                             1.20645
eval/Rewards Max                             4.36283
eval/Rewards Min                             0.0131843
eval/Returns Mean                           41.0924
eval/Returns Std                             9.13125
eval/Returns Max                            55.413
eval/Returns Min                            28.6716
eval/Actions Mean                           -0.00290359
eval/Actions Std                             0.64929
eval/Actions Max                             1
eval/Actions Min                            -0.999993
eval/Num Paths                               5
eval/Average Returns                        41.0924
eval/env_infos/final/reward_dist Mean        2.69924
eval/env_infos/final/reward_dist Std         0.871227
eval/env_infos/final/reward_dist Max         3.82369
eval/env_infos/final/reward_dist Min         1.23167
eval/env_infos/initial/reward_dist Mean      0.0320556
eval/env_infos/initial/reward_dist Std       0.00460911
eval/env_infos/initial/reward_dist Max       0.0397043
eval/env_infos/initial/reward_dist Min       0.0260339
eval/env_infos/reward_dist Mean              2.05462
eval/env_infos/reward_dist Std               1.20645
eval/env_infos/reward_dist Max               4.36283
eval/env_infos/reward_dist Min               0.0131843
time/data storing (s)                        0.00295479
time/evaluation sampling (s)                 1.61741
time/exploration sampling (s)                7.59969
time/logging (s)                             0.00229377
time/saving (s)                              0.00101996
time/training (s)                            4.75486
time/epoch (s)                              13.9782
time/total (s)                             704.776
Epoch                                       28
---------------------------------------  ---------------
2023-08-03 21:15:15.985222 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 29 finished
---------------------------------------  ---------------
epoch                                       29
replay_buffer/size                       25000
trainer/QF Loss                             58.3186
trainer/Policy Loss                       -139.321
trainer/Raw Policy Loss                   -139.321
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 128.036
trainer/Q Predictions Std                   25.4468
trainer/Q Predictions Max                  212.543
trainer/Q Predictions Min                   60.2609
trainer/Q Targets Mean                     127.877
trainer/Q Targets Std                       26.9492
trainer/Q Targets Max                      216.617
trainer/Q Targets Min                       53.4037
trainer/Bellman Errors Mean                 58.3186
trainer/Bellman Errors Std                 243.163
trainer/Bellman Errors Max                7408.15
trainer/Bellman Errors Min                   1.14087e-08
trainer/Policy Action Mean                  -0.00303128
trainer/Policy Action Std                    0.847792
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     25000
expl/num paths total                      1250
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.37863
expl/Rewards Std                             3.6947
expl/Rewards Max                            10
expl/Rewards Min                             1.56923e-06
expl/Returns Mean                           47.5727
expl/Returns Std                            65.6988
expl/Returns Max                           190.073
expl/Returns Min                             0.197722
expl/Actions Mean                           -0.0763252
expl/Actions Std                             0.687952
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        47.5727
expl/env_infos/final/reward_dist Mean        2.69107
expl/env_infos/final/reward_dist Std         4.15205
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.58711e-05
expl/env_infos/initial/reward_dist Mean      0.0510771
expl/env_infos/initial/reward_dist Std       0.0319227
expl/env_infos/initial/reward_dist Max       0.175687
expl/env_infos/initial/reward_dist Min       0.0108032
expl/env_infos/reward_dist Mean              2.37863
expl/env_infos/reward_dist Std               3.6947
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.56923e-06
eval/num steps total                      3000
eval/num paths total                       150
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            4.43328
eval/Rewards Std                             4.11607
eval/Rewards Max                            10
eval/Rewards Min                             0.0077864
eval/Returns Mean                           88.6656
eval/Returns Std                            67.9835
eval/Returns Max                           173.351
eval/Returns Min                            25.2486
eval/Actions Mean                           -0.131159
eval/Actions Std                             0.611234
eval/Actions Max                             1
eval/Actions Min                            -0.999981
eval/Num Paths                               5
eval/Average Returns                        88.6656
eval/env_infos/final/reward_dist Mean        4.61577
eval/env_infos/final/reward_dist Std         4.43011
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0532136
eval/env_infos/initial/reward_dist Mean      0.0424357
eval/env_infos/initial/reward_dist Std       0.02022
eval/env_infos/initial/reward_dist Max       0.0710826
eval/env_infos/initial/reward_dist Min       0.00903337
eval/env_infos/reward_dist Mean              4.43328
eval/env_infos/reward_dist Std               4.11607
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0077864
time/data storing (s)                        0.00224348
time/evaluation sampling (s)                 1.30143
time/exploration sampling (s)                7.54032
time/logging (s)                             0.00228428
time/saving (s)                              0.0101779
time/training (s)                            4.20038
time/epoch (s)                              13.0568
time/total (s)                             717.835
Epoch                                       29
---------------------------------------  ---------------
2023-08-03 21:15:28.114173 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 30 finished
---------------------------------------  ---------------
epoch                                       30
replay_buffer/size                       25500
trainer/QF Loss                             90.3288
trainer/Policy Loss                       -187.072
trainer/Raw Policy Loss                   -187.072
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 172.417
trainer/Q Predictions Std                   33.6589
trainer/Q Predictions Max                  269.049
trainer/Q Predictions Min                   72.0426
trainer/Q Targets Mean                     172.097
trainer/Q Targets Std                       35.0851
trainer/Q Targets Max                      272.813
trainer/Q Targets Min                       68.2486
trainer/Bellman Errors Mean                 90.3288
trainer/Bellman Errors Std                 320.106
trainer/Bellman Errors Max                7035.71
trainer/Bellman Errors Min                   1.27498e-06
trainer/Policy Action Mean                   0.0780443
trainer/Policy Action Std                    0.829935
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     25500
expl/num paths total                      1275
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.2666
expl/Rewards Std                             3.91656
expl/Rewards Max                            10
expl/Rewards Min                             3.82054e-05
expl/Returns Mean                           45.3321
expl/Returns Std                            65.9125
expl/Returns Max                           180.24
expl/Returns Min                             0.24072
expl/Actions Mean                            0.0261165
expl/Actions Std                             0.667703
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        45.3321
expl/env_infos/final/reward_dist Mean        3.31725
expl/env_infos/final/reward_dist Std         4.59313
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         3.82054e-05
expl/env_infos/initial/reward_dist Mean      0.0272607
expl/env_infos/initial/reward_dist Std       0.0159678
expl/env_infos/initial/reward_dist Max       0.0598388
expl/env_infos/initial/reward_dist Min       0.00669365
expl/env_infos/reward_dist Mean              2.2666
expl/env_infos/reward_dist Std               3.91656
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               3.82054e-05
eval/num steps total                      3100
eval/num paths total                       155
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            5.60546
eval/Rewards Std                             4.12814
eval/Rewards Max                            10
eval/Rewards Min                             0.0164823
eval/Returns Mean                          112.109
eval/Returns Std                            49.3512
eval/Returns Max                           170.607
eval/Returns Min                            38.0196
eval/Actions Mean                           -0.0247261
eval/Actions Std                             0.534501
eval/Actions Max                             1
eval/Actions Min                            -0.999478
eval/Num Paths                               5
eval/Average Returns                       112.109
eval/env_infos/final/reward_dist Mean        8.55982
eval/env_infos/final/reward_dist Std         2.88037
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         2.79908
eval/env_infos/initial/reward_dist Mean      0.0965094
eval/env_infos/initial/reward_dist Std       0.0896192
eval/env_infos/initial/reward_dist Max       0.275132
eval/env_infos/initial/reward_dist Min       0.0445574
eval/env_infos/reward_dist Mean              5.60546
eval/env_infos/reward_dist Std               4.12814
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0164823
time/data storing (s)                        0.00217774
time/evaluation sampling (s)                 1.16885
time/exploration sampling (s)                6.34344
time/logging (s)                             0.00235666
time/saving (s)                              0.00100837
time/training (s)                            4.60785
time/epoch (s)                              12.1257
time/total (s)                             729.963
Epoch                                       30
---------------------------------------  ---------------
2023-08-03 21:15:41.157492 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 31 finished
---------------------------------------  ---------------
epoch                                       31
replay_buffer/size                       26000
trainer/QF Loss                            126.147
trainer/Policy Loss                       -226.684
trainer/Raw Policy Loss                   -226.684
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 210.673
trainer/Q Predictions Std                   40.9535
trainer/Q Predictions Max                  321.258
trainer/Q Predictions Min                   89.0765
trainer/Q Targets Mean                     210.951
trainer/Q Targets Std                       42.814
trainer/Q Targets Max                      331.192
trainer/Q Targets Min                       84.4792
trainer/Bellman Errors Mean                126.147
trainer/Bellman Errors Std                 514.061
trainer/Bellman Errors Max               18095.3
trainer/Bellman Errors Min                   5.96046e-08
trainer/Policy Action Mean                   0.0167841
trainer/Policy Action Std                    0.823881
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     26000
expl/num paths total                      1300
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            1.23464
expl/Rewards Std                             2.58194
expl/Rewards Max                            10
expl/Rewards Min                             3.64868e-05
expl/Returns Mean                           24.6928
expl/Returns Std                            45.9935
expl/Returns Max                           184.489
expl/Returns Min                             0.286979
expl/Actions Mean                           -0.0684393
expl/Actions Std                             0.676476
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        24.6928
expl/env_infos/final/reward_dist Mean        1.32175
expl/env_infos/final/reward_dist Std         2.72061
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000255809
expl/env_infos/initial/reward_dist Mean      0.0454667
expl/env_infos/initial/reward_dist Std       0.0456663
expl/env_infos/initial/reward_dist Max       0.242947
expl/env_infos/initial/reward_dist Min       0.00288095
expl/env_infos/reward_dist Mean              1.23464
expl/env_infos/reward_dist Std               2.58194
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               3.64868e-05
eval/num steps total                      3200
eval/num paths total                       160
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.12584
eval/Rewards Std                             4.23678
eval/Rewards Max                            10
eval/Rewards Min                             0.0104884
eval/Returns Mean                          122.517
eval/Returns Std                            67.1149
eval/Returns Max                           183.711
eval/Returns Min                            28.3725
eval/Actions Mean                           -0.0850228
eval/Actions Std                             0.499831
eval/Actions Max                             0.999969
eval/Actions Min                            -0.999967
eval/Num Paths                               5
eval/Average Returns                       122.517
eval/env_infos/final/reward_dist Mean        6.52636
eval/env_infos/final/reward_dist Std         4.27577
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.639708
eval/env_infos/initial/reward_dist Mean      0.0416735
eval/env_infos/initial/reward_dist Std       0.0144342
eval/env_infos/initial/reward_dist Max       0.0679545
eval/env_infos/initial/reward_dist Min       0.0288036
eval/env_infos/reward_dist Mean              6.12584
eval/env_infos/reward_dist Std               4.23678
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0104884
time/data storing (s)                        0.00218466
time/evaluation sampling (s)                 1.31268
time/exploration sampling (s)                6.81421
time/logging (s)                             0.00227567
time/saving (s)                              0.000979693
time/training (s)                            4.90828
time/epoch (s)                              13.0406
time/total (s)                             743.006
Epoch                                       31
---------------------------------------  ---------------
2023-08-03 21:15:54.033040 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 32 finished
---------------------------------------  ---------------
epoch                                       32
replay_buffer/size                       26500
trainer/QF Loss                            157.026
trainer/Policy Loss                       -260.035
trainer/Raw Policy Loss                   -260.035
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 243.124
trainer/Q Predictions Std                   46.2323
trainer/Q Predictions Max                  366.793
trainer/Q Predictions Min                  104.476
trainer/Q Targets Mean                     242.897
trainer/Q Targets Std                       48.216
trainer/Q Targets Max                      374.126
trainer/Q Targets Min                       99.939
trainer/Bellman Errors Mean                157.026
trainer/Bellman Errors Std                 623.323
trainer/Bellman Errors Max               17397.6
trainer/Bellman Errors Min                   2.56635e-05
trainer/Policy Action Mean                  -0.0450221
trainer/Policy Action Std                    0.816969
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     26500
expl/num paths total                      1325
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            1.31112
expl/Rewards Std                             2.67559
expl/Rewards Max                            10
expl/Rewards Min                             0.000126522
expl/Returns Mean                           26.2223
expl/Returns Std                            46.2314
expl/Returns Max                           180.213
expl/Returns Min                             0.232834
expl/Actions Mean                           -0.0650541
expl/Actions Std                             0.658303
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        26.2223
expl/env_infos/final/reward_dist Mean        1.87252
expl/env_infos/final/reward_dist Std         3.17668
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00048735
expl/env_infos/initial/reward_dist Mean      0.0451016
expl/env_infos/initial/reward_dist Std       0.018368
expl/env_infos/initial/reward_dist Max       0.0757607
expl/env_infos/initial/reward_dist Min       0.0106925
expl/env_infos/reward_dist Mean              1.31112
expl/env_infos/reward_dist Std               2.67559
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000126522
eval/num steps total                      3300
eval/num paths total                       165
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.09198
eval/Rewards Std                             4.43405
eval/Rewards Max                            10
eval/Rewards Min                             0.00489489
eval/Returns Mean                          121.84
eval/Returns Std                            60.2121
eval/Returns Max                           190.027
eval/Returns Min                            23.2185
eval/Actions Mean                           -0.134022
eval/Actions Std                             0.498654
eval/Actions Max                             0.999887
eval/Actions Min                            -0.999956
eval/Num Paths                               5
eval/Average Returns                       121.84
eval/env_infos/final/reward_dist Mean        8.15913
eval/env_infos/final/reward_dist Std         3.68173
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.795669
eval/env_infos/initial/reward_dist Mean      0.0315678
eval/env_infos/initial/reward_dist Std       0.0180754
eval/env_infos/initial/reward_dist Max       0.0576422
eval/env_infos/initial/reward_dist Min       0.00885563
eval/env_infos/reward_dist Mean              6.09198
eval/env_infos/reward_dist Std               4.43405
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00489489
time/data storing (s)                        0.00159772
time/evaluation sampling (s)                 1.35241
time/exploration sampling (s)                6.84437
time/logging (s)                             0.00226264
time/saving (s)                              0.000993991
time/training (s)                            4.67132
time/epoch (s)                              12.8729
time/total (s)                             755.881
Epoch                                       32
---------------------------------------  ---------------
2023-08-03 21:16:06.597571 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 33 finished
---------------------------------------  ---------------
epoch                                       33
replay_buffer/size                       27000
trainer/QF Loss                            177.369
trainer/Policy Loss                       -293.184
trainer/Raw Policy Loss                   -293.184
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 274.444
trainer/Q Predictions Std                   49.6044
trainer/Q Predictions Max                  415.996
trainer/Q Predictions Min                  119.296
trainer/Q Targets Mean                     273.822
trainer/Q Targets Std                       51.8299
trainer/Q Targets Max                      415.408
trainer/Q Targets Min                      111.041
trainer/Bellman Errors Mean                177.369
trainer/Bellman Errors Std                 672.401
trainer/Bellman Errors Max               13099.6
trainer/Bellman Errors Min                   8.3819e-09
trainer/Policy Action Mean                  -0.050677
trainer/Policy Action Std                    0.81782
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     27000
expl/num paths total                      1350
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            1.31461
expl/Rewards Std                             2.83705
expl/Rewards Max                            10
expl/Rewards Min                             5.05804e-06
expl/Returns Mean                           26.2922
expl/Returns Std                            48.6005
expl/Returns Max                           166.153
expl/Returns Min                             0.338308
expl/Actions Mean                           -0.0743025
expl/Actions Std                             0.667093
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        26.2922
expl/env_infos/final/reward_dist Mean        1.76948
expl/env_infos/final/reward_dist Std         3.21175
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         8.37114e-06
expl/env_infos/initial/reward_dist Mean      0.0503657
expl/env_infos/initial/reward_dist Std       0.0506254
expl/env_infos/initial/reward_dist Max       0.283189
expl/env_infos/initial/reward_dist Min       0.00908723
expl/env_infos/reward_dist Mean              1.31461
expl/env_infos/reward_dist Std               2.83705
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               5.05804e-06
eval/num steps total                      3400
eval/num paths total                       170
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            4.65464
eval/Rewards Std                             4.43314
eval/Rewards Max                            10
eval/Rewards Min                             0.000235742
eval/Returns Mean                           93.0928
eval/Returns Std                            51.3757
eval/Returns Max                           142.045
eval/Returns Min                             0.52327
eval/Actions Mean                           -0.063201
eval/Actions Std                             0.54666
eval/Actions Max                             0.999999
eval/Actions Min                            -0.999998
eval/Num Paths                               5
eval/Average Returns                        93.0928
eval/env_infos/final/reward_dist Mean        8.00355
eval/env_infos/final/reward_dist Std         3.99289
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0177659
eval/env_infos/initial/reward_dist Mean      0.0339908
eval/env_infos/initial/reward_dist Std       0.0110447
eval/env_infos/initial/reward_dist Max       0.0472502
eval/env_infos/initial/reward_dist Min       0.0191381
eval/env_infos/reward_dist Mean              4.65464
eval/env_infos/reward_dist Std               4.43314
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.000235742
time/data storing (s)                        0.00157358
time/evaluation sampling (s)                 1.40162
time/exploration sampling (s)                7.00148
time/logging (s)                             0.00229966
time/saving (s)                              0.00107568
time/training (s)                            4.15365
time/epoch (s)                              12.5617
time/total (s)                             768.445
Epoch                                       33
---------------------------------------  ---------------
2023-08-03 21:16:19.730312 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 34 finished
---------------------------------------  ---------------
epoch                                       34
replay_buffer/size                       27500
trainer/QF Loss                            214.419
trainer/Policy Loss                       -322.683
trainer/Raw Policy Loss                   -322.683
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 302.414
trainer/Q Predictions Std                   56.8827
trainer/Q Predictions Max                  462.119
trainer/Q Predictions Min                  137.548
trainer/Q Targets Mean                     302.43
trainer/Q Targets Std                       58.7864
trainer/Q Targets Max                      465.153
trainer/Q Targets Min                      126.892
trainer/Bellman Errors Mean                214.419
trainer/Bellman Errors Std                 914.098
trainer/Bellman Errors Max               22202.4
trainer/Bellman Errors Min                   4.46672e-05
trainer/Policy Action Mean                  -0.0706228
trainer/Policy Action Std                    0.82051
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     27500
expl/num paths total                      1375
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.90027
expl/Rewards Std                             4.14774
expl/Rewards Max                            10
expl/Rewards Min                             4.76217e-06
expl/Returns Mean                           58.0054
expl/Returns Std                            65.4381
expl/Returns Max                           180.191
expl/Returns Min                             0.408181
expl/Actions Mean                           -0.0920058
expl/Actions Std                             0.65679
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        58.0054
expl/env_infos/final/reward_dist Mean        4.65898
expl/env_infos/final/reward_dist Std         4.76556
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0115967
expl/env_infos/initial/reward_dist Mean      0.0391914
expl/env_infos/initial/reward_dist Std       0.0254662
expl/env_infos/initial/reward_dist Max       0.092982
expl/env_infos/initial/reward_dist Min       0.00337305
expl/env_infos/reward_dist Mean              2.90027
expl/env_infos/reward_dist Std               4.14774
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               4.76217e-06
eval/num steps total                      3500
eval/num paths total                       175
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            3.70562
eval/Rewards Std                             4.75632
eval/Rewards Max                            10
eval/Rewards Min                             0.00467956
eval/Returns Mean                           74.1124
eval/Returns Std                            90.0321
eval/Returns Max                           190.078
eval/Returns Min                             0.633599
eval/Actions Mean                           -0.079785
eval/Actions Std                             0.635674
eval/Actions Max                             0.999976
eval/Actions Min                            -0.999996
eval/Num Paths                               5
eval/Average Returns                        74.1124
eval/env_infos/final/reward_dist Mean        4.02433
eval/env_infos/final/reward_dist Std         4.87916
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0182765
eval/env_infos/initial/reward_dist Mean      0.0633849
eval/env_infos/initial/reward_dist Std       0.0344018
eval/env_infos/initial/reward_dist Max       0.124381
eval/env_infos/initial/reward_dist Min       0.0342082
eval/env_infos/reward_dist Mean              3.70562
eval/env_infos/reward_dist Std               4.75632
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00467956
time/data storing (s)                        0.00155115
time/evaluation sampling (s)                 1.56426
time/exploration sampling (s)                7.43628
time/logging (s)                             0.00231842
time/saving (s)                              0.00100973
time/training (s)                            4.12447
time/epoch (s)                              13.1299
time/total (s)                             781.577
Epoch                                       34
---------------------------------------  ---------------
2023-08-03 21:16:33.279502 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 35 finished
---------------------------------------  ---------------
epoch                                       35
replay_buffer/size                       28000
trainer/QF Loss                            247.74
trainer/Policy Loss                       -360.294
trainer/Raw Policy Loss                   -360.294
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 338.189
trainer/Q Predictions Std                   59.6635
trainer/Q Predictions Max                  509.211
trainer/Q Predictions Min                  158.089
trainer/Q Targets Mean                     338.039
trainer/Q Targets Std                       61.6468
trainer/Q Targets Max                      505.612
trainer/Q Targets Min                      157.327
trainer/Bellman Errors Mean                247.74
trainer/Bellman Errors Std                 944.007
trainer/Bellman Errors Max               18472.2
trainer/Bellman Errors Min                   5.81238e-06
trainer/Policy Action Mean                  -0.0635455
trainer/Policy Action Std                    0.830913
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     28000
expl/num paths total                      1400
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            1.37564
expl/Rewards Std                             2.76038
expl/Rewards Max                            10
expl/Rewards Min                             6.99621e-09
expl/Returns Mean                           27.5129
expl/Returns Std                            46.9846
expl/Returns Max                           190.159
expl/Returns Min                             0.260068
expl/Actions Mean                           -0.0945793
expl/Actions Std                             0.677008
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        27.5129
expl/env_infos/final/reward_dist Mean        2.36316
expl/env_infos/final/reward_dist Std         3.46626
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         4.4924e-07
expl/env_infos/initial/reward_dist Mean      0.0361903
expl/env_infos/initial/reward_dist Std       0.0300156
expl/env_infos/initial/reward_dist Max       0.158648
expl/env_infos/initial/reward_dist Min       0.0053715
expl/env_infos/reward_dist Mean              1.37564
expl/env_infos/reward_dist Std               2.76038
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.99621e-09
eval/num steps total                      3600
eval/num paths total                       180
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            2.74753
eval/Rewards Std                             4.34916
eval/Rewards Max                            10
eval/Rewards Min                             0.00241291
eval/Returns Mean                           54.9506
eval/Returns Std                            69.4629
eval/Returns Max                           168.024
eval/Returns Min                             0.521496
eval/Actions Mean                           -0.127984
eval/Actions Std                             0.628285
eval/Actions Max                             0.999801
eval/Actions Min                            -0.999999
eval/Num Paths                               5
eval/Average Returns                        54.9506
eval/env_infos/final/reward_dist Mean        4.02565
eval/env_infos/final/reward_dist Std         4.87809
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0168663
eval/env_infos/initial/reward_dist Mean      0.0344879
eval/env_infos/initial/reward_dist Std       0.0224889
eval/env_infos/initial/reward_dist Max       0.0662649
eval/env_infos/initial/reward_dist Min       0.011317
eval/env_infos/reward_dist Mean              2.74753
eval/env_infos/reward_dist Std               4.34916
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00241291
time/data storing (s)                        0.00156283
time/evaluation sampling (s)                 1.61917
time/exploration sampling (s)                7.79882
time/logging (s)                             0.0024006
time/saving (s)                              0.00103962
time/training (s)                            4.1234
time/epoch (s)                              13.5464
time/total (s)                             795.126
Epoch                                       35
---------------------------------------  ---------------
2023-08-03 21:16:46.135831 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 36 finished
---------------------------------------  ---------------
epoch                                       36
replay_buffer/size                       28500
trainer/QF Loss                            281.252
trainer/Policy Loss                       -396.985
trainer/Raw Policy Loss                   -396.985
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 373.322
trainer/Q Predictions Std                   61.0771
trainer/Q Predictions Max                  543.897
trainer/Q Predictions Min                  183.441
trainer/Q Targets Mean                     373.119
trainer/Q Targets Std                       63.0611
trainer/Q Targets Max                      543.802
trainer/Q Targets Min                      179.435
trainer/Bellman Errors Mean                281.252
trainer/Bellman Errors Std                1235.24
trainer/Bellman Errors Max               40838
trainer/Bellman Errors Min                   5.91427e-05
trainer/Policy Action Mean                  -0.0474663
trainer/Policy Action Std                    0.836628
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     28500
expl/num paths total                      1425
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            1.41048
expl/Rewards Std                             2.71114
expl/Rewards Max                            10
expl/Rewards Min                             1.44286e-05
expl/Returns Mean                           28.2097
expl/Returns Std                            41.31
expl/Returns Max                           163.259
expl/Returns Min                             0.231536
expl/Actions Mean                           -0.0630113
expl/Actions Std                             0.682554
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        28.2097
expl/env_infos/final/reward_dist Mean        2.2405
expl/env_infos/final/reward_dist Std         3.89195
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0138461
expl/env_infos/initial/reward_dist Mean      0.070485
expl/env_infos/initial/reward_dist Std       0.0798188
expl/env_infos/initial/reward_dist Max       0.323234
expl/env_infos/initial/reward_dist Min       0.00891963
expl/env_infos/reward_dist Mean              1.41048
expl/env_infos/reward_dist Std               2.71114
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.44286e-05
eval/num steps total                      3700
eval/num paths total                       185
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            5.98631
eval/Rewards Std                             4.29587
eval/Rewards Max                            10
eval/Rewards Min                             0.0187184
eval/Returns Mean                          119.726
eval/Returns Std                            68.6253
eval/Returns Max                           182.465
eval/Returns Min                            32.2128
eval/Actions Mean                           -0.16876
eval/Actions Std                             0.527187
eval/Actions Max                             1
eval/Actions Min                            -0.999989
eval/Num Paths                               5
eval/Average Returns                       119.726
eval/env_infos/final/reward_dist Mean        6.54799
eval/env_infos/final/reward_dist Std         4.23112
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.10634
eval/env_infos/initial/reward_dist Mean      0.0405735
eval/env_infos/initial/reward_dist Std       0.015663
eval/env_infos/initial/reward_dist Max       0.0652931
eval/env_infos/initial/reward_dist Min       0.0222244
eval/env_infos/reward_dist Mean              5.98631
eval/env_infos/reward_dist Std               4.29587
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0187184
time/data storing (s)                        0.00155775
time/evaluation sampling (s)                 1.19908
time/exploration sampling (s)                7.84956
time/logging (s)                             0.00227359
time/saving (s)                              0.00102094
time/training (s)                            3.79839
time/epoch (s)                              12.8519
time/total (s)                             807.982
Epoch                                       36
---------------------------------------  ---------------
2023-08-03 21:16:59.271960 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 37 finished
---------------------------------------  ---------------
epoch                                       37
replay_buffer/size                       29000
trainer/QF Loss                            299.316
trainer/Policy Loss                       -425.293
trainer/Raw Policy Loss                   -425.293
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 400.681
trainer/Q Predictions Std                   64.2698
trainer/Q Predictions Max                  574.884
trainer/Q Predictions Min                  209.044
trainer/Q Targets Mean                     401.541
trainer/Q Targets Std                       66.5155
trainer/Q Targets Max                      579.083
trainer/Q Targets Min                      191.854
trainer/Bellman Errors Mean                299.316
trainer/Bellman Errors Std                1112.56
trainer/Bellman Errors Max               36869.2
trainer/Bellman Errors Min                   3.29167e-05
trainer/Policy Action Mean                  -0.00783299
trainer/Policy Action Std                    0.838611
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     29000
expl/num paths total                      1450
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.00828
expl/Rewards Std                             3.35109
expl/Rewards Max                            10
expl/Rewards Min                             0.000142252
expl/Returns Mean                           40.1655
expl/Returns Std                            55.6915
expl/Returns Max                           190.22
expl/Returns Min                             0.311772
expl/Actions Mean                           -0.0119934
expl/Actions Std                             0.680582
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        40.1655
expl/env_infos/final/reward_dist Mean        2.67394
expl/env_infos/final/reward_dist Std         3.79229
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00908823
expl/env_infos/initial/reward_dist Mean      0.0367457
expl/env_infos/initial/reward_dist Std       0.0417363
expl/env_infos/initial/reward_dist Max       0.220333
expl/env_infos/initial/reward_dist Min       0.00127047
expl/env_infos/reward_dist Mean              2.00828
expl/env_infos/reward_dist Std               3.35109
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000142252
eval/num steps total                      3800
eval/num paths total                       190
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            5.69385
eval/Rewards Std                             4.57008
eval/Rewards Max                            10
eval/Rewards Min                             0.00423705
eval/Returns Mean                          113.877
eval/Returns Std                            56.8088
eval/Returns Max                           147.892
eval/Returns Min                             0.502529
eval/Actions Mean                           -0.129118
eval/Actions Std                             0.554526
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       113.877
eval/env_infos/final/reward_dist Mean        8.00199
eval/env_infos/final/reward_dist Std         3.99601
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.00996712
eval/env_infos/initial/reward_dist Mean      0.0473865
eval/env_infos/initial/reward_dist Std       0.0253151
eval/env_infos/initial/reward_dist Max       0.071395
eval/env_infos/initial/reward_dist Min       0.00825383
eval/env_infos/reward_dist Mean              5.69385
eval/env_infos/reward_dist Std               4.57008
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00423705
time/data storing (s)                        0.00161017
time/evaluation sampling (s)                 1.20005
time/exploration sampling (s)                7.29908
time/logging (s)                             0.002273
time/saving (s)                              0.00101104
time/training (s)                            4.62957
time/epoch (s)                              13.1336
time/total (s)                             821.117
Epoch                                       37
---------------------------------------  ---------------
2023-08-03 21:17:12.058650 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 38 finished
---------------------------------------  ---------------
epoch                                       38
replay_buffer/size                       29500
trainer/QF Loss                            294.122
trainer/Policy Loss                       -454.409
trainer/Raw Policy Loss                   -454.409
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 428.514
trainer/Q Predictions Std                   63.5986
trainer/Q Predictions Max                  605.934
trainer/Q Predictions Min                  227.185
trainer/Q Targets Mean                     429.105
trainer/Q Targets Std                       65.7935
trainer/Q Targets Max                      603.384
trainer/Q Targets Min                      221.196
trainer/Bellman Errors Mean                294.122
trainer/Bellman Errors Std                 986.181
trainer/Bellman Errors Max               22573.1
trainer/Bellman Errors Min                   3.36207e-07
trainer/Policy Action Mean                  -0.00138347
trainer/Policy Action Std                    0.833684
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     29500
expl/num paths total                      1475
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            1.9852
expl/Rewards Std                             3.31522
expl/Rewards Max                            10
expl/Rewards Min                             5.69816e-06
expl/Returns Mean                           39.7039
expl/Returns Std                            54.7402
expl/Returns Max                           173.598
expl/Returns Min                             0.198755
expl/Actions Mean                           -0.0644811
expl/Actions Std                             0.682387
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        39.7039
expl/env_infos/final/reward_dist Mean        2.64359
expl/env_infos/final/reward_dist Std         3.77863
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000214846
expl/env_infos/initial/reward_dist Mean      0.0382641
expl/env_infos/initial/reward_dist Std       0.0409915
expl/env_infos/initial/reward_dist Max       0.218911
expl/env_infos/initial/reward_dist Min       0.00395708
expl/env_infos/reward_dist Mean              1.9852
expl/env_infos/reward_dist Std               3.31522
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               5.69816e-06
eval/num steps total                      3900
eval/num paths total                       195
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.12546
eval/Rewards Std                             3.87445
eval/Rewards Max                            10
eval/Rewards Min                             0.0236144
eval/Returns Mean                          142.509
eval/Returns Std                            48.1176
eval/Returns Max                           190.055
eval/Returns Min                            50.029
eval/Actions Mean                           -0.174136
eval/Actions Std                             0.480117
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       142.509
eval/env_infos/final/reward_dist Mean        8.61398
eval/env_infos/final/reward_dist Std         2.77205
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.06989
eval/env_infos/initial/reward_dist Mean      0.0379927
eval/env_infos/initial/reward_dist Std       0.0123726
eval/env_infos/initial/reward_dist Max       0.0548854
eval/env_infos/initial/reward_dist Min       0.0236144
eval/env_infos/reward_dist Mean              7.12546
eval/env_infos/reward_dist Std               3.87445
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0236144
time/data storing (s)                        0.00216555
time/evaluation sampling (s)                 1.11761
time/exploration sampling (s)                7.53595
time/logging (s)                             0.00227805
time/saving (s)                              0.000984132
time/training (s)                            4.1252
time/epoch (s)                              12.7842
time/total (s)                             833.903
Epoch                                       38
---------------------------------------  ---------------
2023-08-03 21:17:23.744737 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 39 finished
---------------------------------------  ---------------
epoch                                       39
replay_buffer/size                       30000
trainer/QF Loss                            294.863
trainer/Policy Loss                       -478.238
trainer/Raw Policy Loss                   -478.238
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 452.519
trainer/Q Predictions Std                   62.342
trainer/Q Predictions Max                  638.326
trainer/Q Predictions Min                  255.991
trainer/Q Targets Mean                     451.908
trainer/Q Targets Std                       64.5761
trainer/Q Targets Max                      626.379
trainer/Q Targets Min                      237.032
trainer/Bellman Errors Mean                294.864
trainer/Bellman Errors Std                 957.316
trainer/Bellman Errors Max               15969.7
trainer/Bellman Errors Min                   8.95001e-07
trainer/Policy Action Mean                   0.0174435
trainer/Policy Action Std                    0.831966
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     30000
expl/num paths total                      1500
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.1759
expl/Rewards Std                             3.48132
expl/Rewards Max                            10
expl/Rewards Min                             1.92311e-05
expl/Returns Mean                           43.518
expl/Returns Std                            59.4738
expl/Returns Max                           191.038
expl/Returns Min                             0.293385
expl/Actions Mean                           -0.0213984
expl/Actions Std                             0.681599
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        43.518
expl/env_infos/final/reward_dist Mean        2.67901
expl/env_infos/final/reward_dist Std         3.77996
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000227189
expl/env_infos/initial/reward_dist Mean      0.0802158
expl/env_infos/initial/reward_dist Std       0.19704
expl/env_infos/initial/reward_dist Max       1.03798
expl/env_infos/initial/reward_dist Min       0.00116459
expl/env_infos/reward_dist Mean              2.1759
expl/env_infos/reward_dist Std               3.48132
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.92311e-05
eval/num steps total                      4000
eval/num paths total                       200
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.06681
eval/Rewards Std                             4.56286
eval/Rewards Max                            10
eval/Rewards Min                             0.00179465
eval/Returns Mean                          121.336
eval/Returns Std                            69.4543
eval/Returns Max                           190.078
eval/Returns Min                             0.514601
eval/Actions Mean                           -0.0803823
eval/Actions Std                             0.538183
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       121.336
eval/env_infos/final/reward_dist Mean        8.00202
eval/env_infos/final/reward_dist Std         3.99597
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0100779
eval/env_infos/initial/reward_dist Mean      0.0469242
eval/env_infos/initial/reward_dist Std       0.0178648
eval/env_infos/initial/reward_dist Max       0.0780471
eval/env_infos/initial/reward_dist Min       0.0261591
eval/env_infos/reward_dist Mean              6.06681
eval/env_infos/reward_dist Std               4.56286
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00179465
time/data storing (s)                        0.0015973
time/evaluation sampling (s)                 1.10644
time/exploration sampling (s)                6.11608
time/logging (s)                             0.00240625
time/saving (s)                              0.00104392
time/training (s)                            4.45616
time/epoch (s)                              11.6837
time/total (s)                             845.589
Epoch                                       39
---------------------------------------  ---------------
2023-08-03 21:17:36.035656 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 40 finished
---------------------------------------  ---------------
epoch                                       40
replay_buffer/size                       30500
trainer/QF Loss                            311.531
trainer/Policy Loss                       -491.225
trainer/Raw Policy Loss                   -491.225
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 465.786
trainer/Q Predictions Std                   61.4582
trainer/Q Predictions Max                  640.25
trainer/Q Predictions Min                  276.662
trainer/Q Targets Mean                     465.316
trainer/Q Targets Std                       63.9822
trainer/Q Targets Max                      641.418
trainer/Q Targets Min                      259.862
trainer/Bellman Errors Mean                311.531
trainer/Bellman Errors Std                1088.68
trainer/Bellman Errors Max               22706.9
trainer/Bellman Errors Min                   7.37701e-06
trainer/Policy Action Mean                  -0.00104384
trainer/Policy Action Std                    0.830537
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     30500
expl/num paths total                      1525
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.13369
expl/Rewards Std                             3.43358
expl/Rewards Max                            10
expl/Rewards Min                             2.0488e-05
expl/Returns Mean                           42.6739
expl/Returns Std                            56.9703
expl/Returns Max                           182.836
expl/Returns Min                             0.167952
expl/Actions Mean                           -0.0383382
expl/Actions Std                             0.678226
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        42.6739
expl/env_infos/final/reward_dist Mean        3.91421
expl/env_infos/final/reward_dist Std         4.33831
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000324605
expl/env_infos/initial/reward_dist Mean      0.0422605
expl/env_infos/initial/reward_dist Std       0.0229296
expl/env_infos/initial/reward_dist Max       0.11885
expl/env_infos/initial/reward_dist Min       0.00955516
expl/env_infos/reward_dist Mean              2.13369
expl/env_infos/reward_dist Std               3.43358
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.0488e-05
eval/num steps total                      4100
eval/num paths total                       205
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.2778
eval/Rewards Std                             3.6736
eval/Rewards Max                            10
eval/Rewards Min                             0.0240859
eval/Returns Mean                          145.556
eval/Returns Std                            41.8904
eval/Returns Max                           174.481
eval/Returns Min                            62.4473
eval/Actions Mean                           -0.16393
eval/Actions Std                             0.412273
eval/Actions Max                             0.999999
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       145.556
eval/env_infos/final/reward_dist Mean        8.36013
eval/env_infos/final/reward_dist Std         3.27975
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.80064
eval/env_infos/initial/reward_dist Mean      0.0583995
eval/env_infos/initial/reward_dist Std       0.014485
eval/env_infos/initial/reward_dist Max       0.0771462
eval/env_infos/initial/reward_dist Min       0.0420265
eval/env_infos/reward_dist Mean              7.2778
eval/env_infos/reward_dist Std               3.6736
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0240859
time/data storing (s)                        0.00161114
time/evaluation sampling (s)                 1.63538
time/exploration sampling (s)                6.22524
time/logging (s)                             0.00915844
time/saving (s)                              0.00121556
time/training (s)                            4.42068
time/epoch (s)                              12.2933
time/total (s)                             857.886
Epoch                                       40
---------------------------------------  ---------------
2023-08-03 21:17:48.657057 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 41 finished
---------------------------------------  ---------------
epoch                                       41
replay_buffer/size                       31000
trainer/QF Loss                            300.009
trainer/Policy Loss                       -500.182
trainer/Raw Policy Loss                   -500.182
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 475.267
trainer/Q Predictions Std                   60.8946
trainer/Q Predictions Max                  646.284
trainer/Q Predictions Min                  283.417
trainer/Q Targets Mean                     475.622
trainer/Q Targets Std                       63.2498
trainer/Q Targets Max                      652.532
trainer/Q Targets Min                      278.942
trainer/Bellman Errors Mean                300.009
trainer/Bellman Errors Std                 985.464
trainer/Bellman Errors Max               21146.4
trainer/Bellman Errors Min                   1.77361e-05
trainer/Policy Action Mean                   0.0144038
trainer/Policy Action Std                    0.82073
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     31000
expl/num paths total                      1550
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.04592
expl/Rewards Std                             3.25958
expl/Rewards Max                            10
expl/Rewards Min                             1.24952e-05
expl/Returns Mean                           40.9183
expl/Returns Std                            59.2984
expl/Returns Max                           190.113
expl/Returns Min                             0.129027
expl/Actions Mean                           -0.0692738
expl/Actions Std                             0.678435
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        40.9183
expl/env_infos/final/reward_dist Mean        2.6976
expl/env_infos/final/reward_dist Std         3.49389
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000171844
expl/env_infos/initial/reward_dist Mean      0.0485311
expl/env_infos/initial/reward_dist Std       0.0438795
expl/env_infos/initial/reward_dist Max       0.23464
expl/env_infos/initial/reward_dist Min       0.00976344
expl/env_infos/reward_dist Mean              2.04592
expl/env_infos/reward_dist Std               3.25958
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.24952e-05
eval/num steps total                      4200
eval/num paths total                       210
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.93901
eval/Rewards Std                             3.94638
eval/Rewards Max                            10
eval/Rewards Min                             0.0171974
eval/Returns Mean                          138.78
eval/Returns Std                            50.61
eval/Returns Max                           190.091
eval/Returns Min                            46.5927
eval/Actions Mean                           -0.119696
eval/Actions Std                             0.44032
eval/Actions Max                             1
eval/Actions Min                            -0.999977
eval/Num Paths                               5
eval/Average Returns                       138.78
eval/env_infos/final/reward_dist Mean        8.26649
eval/env_infos/final/reward_dist Std         3.46702
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.33246
eval/env_infos/initial/reward_dist Mean      0.0638181
eval/env_infos/initial/reward_dist Std       0.0288563
eval/env_infos/initial/reward_dist Max       0.104003
eval/env_infos/initial/reward_dist Min       0.0292416
eval/env_infos/reward_dist Mean              6.93901
eval/env_infos/reward_dist Std               3.94638
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0171974
time/data storing (s)                        0.00154788
time/evaluation sampling (s)                 1.5017
time/exploration sampling (s)                6.28024
time/logging (s)                             0.00238512
time/saving (s)                              0.000998915
time/training (s)                            4.8256
time/epoch (s)                              12.6125
time/total (s)                             870.5
Epoch                                       41
---------------------------------------  ---------------
2023-08-03 21:18:01.310264 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 42 finished
---------------------------------------  ---------------
epoch                                       42
replay_buffer/size                       31500
trainer/QF Loss                            304.544
trainer/Policy Loss                       -502.901
trainer/Raw Policy Loss                   -502.901
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 478.674
trainer/Q Predictions Std                   57.7278
trainer/Q Predictions Max                  646.088
trainer/Q Predictions Min                  309.433
trainer/Q Targets Mean                     478.676
trainer/Q Targets Std                       60.6602
trainer/Q Targets Max                      644.98
trainer/Q Targets Min                      294.85
trainer/Bellman Errors Mean                304.544
trainer/Bellman Errors Std                 948.116
trainer/Bellman Errors Max               14951.2
trainer/Bellman Errors Min                   1.38618e-05
trainer/Policy Action Mean                   0.0276926
trainer/Policy Action Std                    0.824104
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     31500
expl/num paths total                      1575
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.00941
expl/Rewards Std                             3.15001
expl/Rewards Max                            10
expl/Rewards Min                             4.1027e-05
expl/Returns Mean                           40.1881
expl/Returns Std                            43.7853
expl/Returns Max                           149.067
expl/Returns Min                             0.296514
expl/Actions Mean                           -0.0293493
expl/Actions Std                             0.660529
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        40.1881
expl/env_infos/final/reward_dist Mean        3.78989
expl/env_infos/final/reward_dist Std         4.02076
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         4.1027e-05
expl/env_infos/initial/reward_dist Mean      0.0608886
expl/env_infos/initial/reward_dist Std       0.131255
expl/env_infos/initial/reward_dist Max       0.695147
expl/env_infos/initial/reward_dist Min       0.0080204
expl/env_infos/reward_dist Mean              2.00941
expl/env_infos/reward_dist Std               3.15001
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               4.1027e-05
eval/num steps total                      4300
eval/num paths total                       215
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.03711
eval/Rewards Std                             3.52574
eval/Rewards Max                            10
eval/Rewards Min                             0.0104065
eval/Returns Mean                          160.742
eval/Returns Std                             9.2056
eval/Returns Max                           174.623
eval/Returns Min                           151.634
eval/Actions Mean                           -0.113029
eval/Actions Std                             0.420706
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       160.742
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0344886
eval/env_infos/initial/reward_dist Std       0.0181894
eval/env_infos/initial/reward_dist Max       0.0566154
eval/env_infos/initial/reward_dist Min       0.0104065
eval/env_infos/reward_dist Mean              8.03711
eval/env_infos/reward_dist Std               3.52574
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0104065
time/data storing (s)                        0.00154637
time/evaluation sampling (s)                 1.29232
time/exploration sampling (s)                7.03862
time/logging (s)                             0.00289463
time/saving (s)                              0.00110842
time/training (s)                            4.31291
time/epoch (s)                              12.6494
time/total (s)                             883.154
Epoch                                       42
---------------------------------------  ---------------
2023-08-03 21:18:14.809701 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 43 finished
---------------------------------------  ---------------
epoch                                       43
replay_buffer/size                       32000
trainer/QF Loss                            328.79
trainer/Policy Loss                       -503.015
trainer/Raw Policy Loss                   -503.015
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 478.941
trainer/Q Predictions Std                   58.1156
trainer/Q Predictions Max                  641.859
trainer/Q Predictions Min                  293.339
trainer/Q Targets Mean                     478.594
trainer/Q Targets Std                       60.325
trainer/Q Targets Max                      642.115
trainer/Q Targets Min                      317.939
trainer/Bellman Errors Mean                328.79
trainer/Bellman Errors Std                1160.63
trainer/Bellman Errors Max               28795.3
trainer/Bellman Errors Min                   1.07661e-06
trainer/Policy Action Mean                   0.0176764
trainer/Policy Action Std                    0.819697
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     32000
expl/num paths total                      1600
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            1.65559
expl/Rewards Std                             2.47347
expl/Rewards Max                            10
expl/Rewards Min                             5.42007e-09
expl/Returns Mean                           33.1119
expl/Returns Std                            36.8419
expl/Returns Max                           175.274
expl/Returns Min                             0.28713
expl/Actions Mean                           -0.0449951
expl/Actions Std                             0.67207
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        33.1119
expl/env_infos/final/reward_dist Mean        2.50057
expl/env_infos/final/reward_dist Std         3.44621
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         5.42007e-09
expl/env_infos/initial/reward_dist Mean      0.0592502
expl/env_infos/initial/reward_dist Std       0.090232
expl/env_infos/initial/reward_dist Max       0.462237
expl/env_infos/initial/reward_dist Min       0.00294824
expl/env_infos/reward_dist Mean              1.65559
expl/env_infos/reward_dist Std               2.47347
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               5.42007e-09
eval/num steps total                      4400
eval/num paths total                       220
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            4.71754
eval/Rewards Std                             4.77056
eval/Rewards Max                            10
eval/Rewards Min                             0.00252934
eval/Returns Mean                           94.3509
eval/Returns Std                            79.1848
eval/Returns Max                           182.026
eval/Returns Min                             0.544012
eval/Actions Mean                           -0.0731015
eval/Actions Std                             0.580938
eval/Actions Max                             1
eval/Actions Min                            -0.999992
eval/Num Paths                               5
eval/Average Returns                        94.3509
eval/env_infos/final/reward_dist Mean        6.00932
eval/env_infos/final/reward_dist Std         4.88758
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.00404168
eval/env_infos/initial/reward_dist Mean      0.0472354
eval/env_infos/initial/reward_dist Std       0.0195746
eval/env_infos/initial/reward_dist Max       0.0749871
eval/env_infos/initial/reward_dist Min       0.020975
eval/env_infos/reward_dist Mean              4.71754
eval/env_infos/reward_dist Std               4.77056
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00252934
time/data storing (s)                        0.00160056
time/evaluation sampling (s)                 1.1202
time/exploration sampling (s)                7.92314
time/logging (s)                             0.00227047
time/saving (s)                              0.000998085
time/training (s)                            4.44729
time/epoch (s)                              13.4955
time/total (s)                             896.652
Epoch                                       43
---------------------------------------  ---------------
2023-08-03 21:18:28.550891 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 44 finished
---------------------------------------  ---------------
epoch                                       44
replay_buffer/size                       32500
trainer/QF Loss                            300.114
trainer/Policy Loss                       -501.891
trainer/Raw Policy Loss                   -501.891
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 478.389
trainer/Q Predictions Std                   57.7599
trainer/Q Predictions Max                  640.291
trainer/Q Predictions Min                  303.064
trainer/Q Targets Mean                     478.714
trainer/Q Targets Std                       60.185
trainer/Q Targets Max                      635.25
trainer/Q Targets Min                      299.5
trainer/Bellman Errors Mean                300.114
trainer/Bellman Errors Std                 993.499
trainer/Bellman Errors Max               21706.3
trainer/Bellman Errors Min                   2.0125e-05
trainer/Policy Action Mean                   0.0209335
trainer/Policy Action Std                    0.812891
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     32500
expl/num paths total                      1625
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.17227
expl/Rewards Std                             3.66568
expl/Rewards Max                            10
expl/Rewards Min                             0.000151723
expl/Returns Mean                           63.4454
expl/Returns Std                            54.8043
expl/Returns Max                           165.715
expl/Returns Min                             0.412296
expl/Actions Mean                           -0.0614042
expl/Actions Std                             0.639428
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        63.4454
expl/env_infos/final/reward_dist Mean        4.82146
expl/env_infos/final/reward_dist Std         4.01276
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0014746
expl/env_infos/initial/reward_dist Mean      0.0332935
expl/env_infos/initial/reward_dist Std       0.0203634
expl/env_infos/initial/reward_dist Max       0.0784194
expl/env_infos/initial/reward_dist Min       0.00784671
expl/env_infos/reward_dist Mean              3.17227
expl/env_infos/reward_dist Std               3.66568
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000151723
eval/num steps total                      4500
eval/num paths total                       225
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.07047
eval/Rewards Std                             4.12133
eval/Rewards Max                            10
eval/Rewards Min                             0.00485834
eval/Returns Mean                          141.409
eval/Returns Std                            41.4848
eval/Returns Max                           190.033
eval/Returns Min                            77.4089
eval/Actions Mean                           -0.113379
eval/Actions Std                             0.522107
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       141.409
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0408265
eval/env_infos/initial/reward_dist Std       0.0113791
eval/env_infos/initial/reward_dist Max       0.0564264
eval/env_infos/initial/reward_dist Min       0.0242618
eval/env_infos/reward_dist Mean              7.07047
eval/env_infos/reward_dist Std               4.12133
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00485834
time/data storing (s)                        0.00182315
time/evaluation sampling (s)                 1.08615
time/exploration sampling (s)                7.50666
time/logging (s)                             0.00330261
time/saving (s)                              0.0012652
time/training (s)                            5.14046
time/epoch (s)                              13.7397
time/total (s)                             910.393
Epoch                                       44
---------------------------------------  ---------------
2023-08-03 21:18:40.138983 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 45 finished
---------------------------------------  ---------------
epoch                                       45
replay_buffer/size                       33000
trainer/QF Loss                            263.275
trainer/Policy Loss                       -499.317
trainer/Raw Policy Loss                   -499.317
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 475.528
trainer/Q Predictions Std                   55.6738
trainer/Q Predictions Max                  624.609
trainer/Q Predictions Min                  309.378
trainer/Q Targets Mean                     475.163
trainer/Q Targets Std                       57.5414
trainer/Q Targets Max                      627.122
trainer/Q Targets Min                      308.697
trainer/Bellman Errors Mean                263.275
trainer/Bellman Errors Std                1007.4
trainer/Bellman Errors Max               34945.5
trainer/Bellman Errors Min                   2.81725e-06
trainer/Policy Action Mean                   0.0336893
trainer/Policy Action Std                    0.818447
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     33000
expl/num paths total                      1650
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.69241
expl/Rewards Std                             4.33829
expl/Rewards Max                            10
expl/Rewards Min                             5.80399e-06
expl/Returns Mean                           73.8481
expl/Returns Std                            69.1952
expl/Returns Max                           190.048
expl/Returns Min                             0.229664
expl/Actions Mean                           -0.0339483
expl/Actions Std                             0.663322
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        73.8481
expl/env_infos/final/reward_dist Mean        5.87603
expl/env_infos/final/reward_dist Std         4.69316
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         5.80399e-06
expl/env_infos/initial/reward_dist Mean      0.0316041
expl/env_infos/initial/reward_dist Std       0.0184173
expl/env_infos/initial/reward_dist Max       0.0771993
expl/env_infos/initial/reward_dist Min       0.00468494
expl/env_infos/reward_dist Mean              3.69241
expl/env_infos/reward_dist Std               4.33829
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               5.80399e-06
eval/num steps total                      4600
eval/num paths total                       230
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.12328
eval/Rewards Std                             3.60674
eval/Rewards Max                            10
eval/Rewards Min                             0.0185447
eval/Returns Mean                          162.466
eval/Returns Std                            18.1711
eval/Returns Max                           182.531
eval/Returns Min                           128.93
eval/Actions Mean                           -0.0735666
eval/Actions Std                             0.434264
eval/Actions Max                             1
eval/Actions Min                            -0.999996
eval/Num Paths                               5
eval/Average Returns                       162.466
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0413294
eval/env_infos/initial/reward_dist Std       0.0113771
eval/env_infos/initial/reward_dist Max       0.0554197
eval/env_infos/initial/reward_dist Min       0.0261301
eval/env_infos/reward_dist Mean              8.12328
eval/env_infos/reward_dist Std               3.60674
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0185447
time/data storing (s)                        0.00216975
time/evaluation sampling (s)                 1.08318
time/exploration sampling (s)                6.12595
time/logging (s)                             0.00234623
time/saving (s)                              0.00100026
time/training (s)                            4.36901
time/epoch (s)                              11.5837
time/total (s)                             921.98
Epoch                                       45
---------------------------------------  ---------------
2023-08-03 21:18:51.860983 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 46 finished
---------------------------------------  ---------------
epoch                                       46
replay_buffer/size                       33500
trainer/QF Loss                            256.011
trainer/Policy Loss                       -496.476
trainer/Raw Policy Loss                   -496.476
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 473.378
trainer/Q Predictions Std                   54.8071
trainer/Q Predictions Max                  612.157
trainer/Q Predictions Min                  304.866
trainer/Q Targets Mean                     472.934
trainer/Q Targets Std                       57.4031
trainer/Q Targets Max                      616.235
trainer/Q Targets Min                      295.717
trainer/Bellman Errors Mean                256.011
trainer/Bellman Errors Std                 790.491
trainer/Bellman Errors Max               10812.6
trainer/Bellman Errors Min                   0.000133776
trainer/Policy Action Mean                   0.0247869
trainer/Policy Action Std                    0.813125
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     33500
expl/num paths total                      1675
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.09653
expl/Rewards Std                             4.0595
expl/Rewards Max                            10
expl/Rewards Min                             1.97446e-05
expl/Returns Mean                           61.9307
expl/Returns Std                            65.4395
expl/Returns Max                           181.732
expl/Returns Min                             0.294476
expl/Actions Mean                           -0.0409164
expl/Actions Std                             0.668912
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        61.9307
expl/env_infos/final/reward_dist Mean        4.69705
expl/env_infos/final/reward_dist Std         4.47808
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000194229
expl/env_infos/initial/reward_dist Mean      0.0395301
expl/env_infos/initial/reward_dist Std       0.0281579
expl/env_infos/initial/reward_dist Max       0.136387
expl/env_infos/initial/reward_dist Min       0.00769138
expl/env_infos/reward_dist Mean              3.09653
expl/env_infos/reward_dist Std               4.0595
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.97446e-05
eval/num steps total                      4700
eval/num paths total                       235
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.36247
eval/Rewards Std                             4.02687
eval/Rewards Max                            10
eval/Rewards Min                             0.00646424
eval/Returns Mean                          127.249
eval/Returns Std                            38.1453
eval/Returns Max                           163.602
eval/Returns Min                            54.8253
eval/Actions Mean                           -0.0749733
eval/Actions Std                             0.42243
eval/Actions Max                             1
eval/Actions Min                            -0.999912
eval/Num Paths                               5
eval/Average Returns                       127.249
eval/env_infos/final/reward_dist Mean        8.62188
eval/env_infos/final/reward_dist Std         2.75624
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.10939
eval/env_infos/initial/reward_dist Mean      0.0553904
eval/env_infos/initial/reward_dist Std       0.0208229
eval/env_infos/initial/reward_dist Max       0.0788605
eval/env_infos/initial/reward_dist Min       0.0265549
eval/env_infos/reward_dist Mean              6.36247
eval/env_infos/reward_dist Std               4.02687
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00646424
time/data storing (s)                        0.00157097
time/evaluation sampling (s)                 1.22487
time/exploration sampling (s)                5.90985
time/logging (s)                             0.00334612
time/saving (s)                              0.00143274
time/training (s)                            4.57864
time/epoch (s)                              11.7197
time/total (s)                             933.702
Epoch                                       46
---------------------------------------  ---------------
2023-08-03 21:19:04.249900 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 47 finished
---------------------------------------  ---------------
epoch                                       47
replay_buffer/size                       34000
trainer/QF Loss                            272.759
trainer/Policy Loss                       -494.057
trainer/Raw Policy Loss                   -494.057
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 471.569
trainer/Q Predictions Std                   51.54
trainer/Q Predictions Max                  603.937
trainer/Q Predictions Min                  319.028
trainer/Q Targets Mean                     470.714
trainer/Q Targets Std                       53.4092
trainer/Q Targets Max                      607.668
trainer/Q Targets Min                      314.234
trainer/Bellman Errors Mean                272.759
trainer/Bellman Errors Std                1002.62
trainer/Bellman Errors Max               33513
trainer/Bellman Errors Min                   3.24193e-06
trainer/Policy Action Mean                   0.0351754
trainer/Policy Action Std                    0.811545
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     34000
expl/num paths total                      1700
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.91055
expl/Rewards Std                             3.59035
expl/Rewards Max                            10
expl/Rewards Min                             5.6529e-06
expl/Returns Mean                           58.2111
expl/Returns Std                            57.7275
expl/Returns Max                           190.548
expl/Returns Min                             0.141907
expl/Actions Mean                           -0.0146289
expl/Actions Std                             0.665105
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        58.2111
expl/env_infos/final/reward_dist Mean        4.55334
expl/env_infos/final/reward_dist Std         4.49476
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         5.6529e-06
expl/env_infos/initial/reward_dist Mean      0.0774976
expl/env_infos/initial/reward_dist Std       0.152994
expl/env_infos/initial/reward_dist Max       0.634238
expl/env_infos/initial/reward_dist Min       0.00664731
expl/env_infos/reward_dist Mean              2.91055
expl/env_infos/reward_dist Std               3.59035
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               5.6529e-06
eval/num steps total                      4800
eval/num paths total                       240
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            4.75187
eval/Rewards Std                             4.46185
eval/Rewards Max                            10
eval/Rewards Min                             0.00430605
eval/Returns Mean                           95.0375
eval/Returns Std                            60.2745
eval/Returns Max                           180.447
eval/Returns Min                            17.8673
eval/Actions Mean                           -0.0335494
eval/Actions Std                             0.60958
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                        95.0375
eval/env_infos/final/reward_dist Mean        8.61607
eval/env_infos/final/reward_dist Std         2.76786
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.08034
eval/env_infos/initial/reward_dist Mean      0.0361047
eval/env_infos/initial/reward_dist Std       0.0227343
eval/env_infos/initial/reward_dist Max       0.0691751
eval/env_infos/initial/reward_dist Min       0.00521679
eval/env_infos/reward_dist Mean              4.75187
eval/env_infos/reward_dist Std               4.46185
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00430605
time/data storing (s)                        0.00154763
time/evaluation sampling (s)                 1.3665
time/exploration sampling (s)                7.3427
time/logging (s)                             0.00226719
time/saving (s)                              0.000996129
time/training (s)                            3.6699
time/epoch (s)                              12.3839
time/total (s)                             946.089
Epoch                                       47
---------------------------------------  ---------------
2023-08-03 21:19:17.115411 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 48 finished
---------------------------------------  ---------------
epoch                                       48
replay_buffer/size                       34500
trainer/QF Loss                            237.172
trainer/Policy Loss                       -482.529
trainer/Raw Policy Loss                   -482.529
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 461.162
trainer/Q Predictions Std                   48.1866
trainer/Q Predictions Max                  584.448
trainer/Q Predictions Min                  323.646
trainer/Q Targets Mean                     461.186
trainer/Q Targets Std                       50.0677
trainer/Q Targets Max                      592.613
trainer/Q Targets Min                      325.43
trainer/Bellman Errors Mean                237.172
trainer/Bellman Errors Std                 816.241
trainer/Bellman Errors Max               25336
trainer/Bellman Errors Min                   8.3819e-09
trainer/Policy Action Mean                   0.00381452
trainer/Policy Action Std                    0.819857
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     34500
expl/num paths total                      1725
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.96131
expl/Rewards Std                             3.89215
expl/Rewards Max                            10
expl/Rewards Min                             3.03662e-05
expl/Returns Mean                           59.2261
expl/Returns Std                            57.335
expl/Returns Max                           180.162
expl/Returns Min                             0.321173
expl/Actions Mean                           -0.0786718
expl/Actions Std                             0.6781
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        59.2261
expl/env_infos/final/reward_dist Mean        4.76584
expl/env_infos/final/reward_dist Std         4.41199
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000170656
expl/env_infos/initial/reward_dist Mean      0.0284572
expl/env_infos/initial/reward_dist Std       0.0198692
expl/env_infos/initial/reward_dist Max       0.0828636
expl/env_infos/initial/reward_dist Min       0.00518641
expl/env_infos/reward_dist Mean              2.96131
expl/env_infos/reward_dist Std               3.89215
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               3.03662e-05
eval/num steps total                      4900
eval/num paths total                       245
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.24505
eval/Rewards Std                             4.04573
eval/Rewards Max                            10
eval/Rewards Min                             0.00784702
eval/Returns Mean                          144.901
eval/Returns Std                            33.6081
eval/Returns Max                           190.223
eval/Returns Min                           112.752
eval/Actions Mean                           -0.123147
eval/Actions Std                             0.518166
eval/Actions Max                             0.999999
eval/Actions Min                            -0.999999
eval/Num Paths                               5
eval/Average Returns                       144.901
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0959881
eval/env_infos/initial/reward_dist Std       0.0644304
eval/env_infos/initial/reward_dist Max       0.223318
eval/env_infos/initial/reward_dist Min       0.0470136
eval/env_infos/reward_dist Mean              7.24505
eval/env_infos/reward_dist Std               4.04573
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00784702
time/data storing (s)                        0.00158257
time/evaluation sampling (s)                 1.19451
time/exploration sampling (s)                7.30868
time/logging (s)                             0.0022761
time/saving (s)                              0.00100415
time/training (s)                            4.35491
time/epoch (s)                              12.863
time/total (s)                             958.954
Epoch                                       48
---------------------------------------  ---------------
2023-08-03 21:19:29.260061 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 49 finished
---------------------------------------  ---------------
epoch                                       49
replay_buffer/size                       35000
trainer/QF Loss                            227.225
trainer/Policy Loss                       -472.326
trainer/Raw Policy Loss                   -472.326
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 451.806
trainer/Q Predictions Std                   45.8462
trainer/Q Predictions Max                  571.669
trainer/Q Predictions Min                  320.161
trainer/Q Targets Mean                     452.125
trainer/Q Targets Std                       48.2876
trainer/Q Targets Max                      576.643
trainer/Q Targets Min                      327.929
trainer/Bellman Errors Mean                227.225
trainer/Bellman Errors Std                 766.691
trainer/Bellman Errors Max               13375.9
trainer/Bellman Errors Min                   8.05501e-06
trainer/Policy Action Mean                   0.0277744
trainer/Policy Action Std                    0.818226
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     35000
expl/num paths total                      1750
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.47698
expl/Rewards Std                             3.70894
expl/Rewards Max                            10
expl/Rewards Min                             0.000180719
expl/Returns Mean                           49.5395
expl/Returns Std                            56.9285
expl/Returns Max                           179.067
expl/Returns Min                             0.347152
expl/Actions Mean                           -0.042745
expl/Actions Std                             0.683341
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        49.5395
expl/env_infos/final/reward_dist Mean        3.65243
expl/env_infos/final/reward_dist Std         4.39804
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000512861
expl/env_infos/initial/reward_dist Mean      0.0355217
expl/env_infos/initial/reward_dist Std       0.0214188
expl/env_infos/initial/reward_dist Max       0.0751202
expl/env_infos/initial/reward_dist Min       0.00989093
expl/env_infos/reward_dist Mean              2.47698
expl/env_infos/reward_dist Std               3.70894
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000180719
eval/num steps total                      5000
eval/num paths total                       250
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            5.63855
eval/Rewards Std                             4.4024
eval/Rewards Max                            10
eval/Rewards Min                             0.00496942
eval/Returns Mean                          112.771
eval/Returns Std                            57.5755
eval/Returns Max                           167.924
eval/Returns Min                            34.6715
eval/Actions Mean                           -0.0419699
eval/Actions Std                             0.614971
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       112.771
eval/env_infos/final/reward_dist Mean        8.73954
eval/env_infos/final/reward_dist Std         2.52093
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.69768
eval/env_infos/initial/reward_dist Mean      0.0249544
eval/env_infos/initial/reward_dist Std       0.0156517
eval/env_infos/initial/reward_dist Max       0.0503313
eval/env_infos/initial/reward_dist Min       0.00496942
eval/env_infos/reward_dist Mean              5.63855
eval/env_infos/reward_dist Std               4.4024
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00496942
time/data storing (s)                        0.00217055
time/evaluation sampling (s)                 1.12325
time/exploration sampling (s)                6.80746
time/logging (s)                             0.00232962
time/saving (s)                              0.00111541
time/training (s)                            4.20584
time/epoch (s)                              12.1422
time/total (s)                             971.098
Epoch                                       49
---------------------------------------  ---------------
2023-08-03 21:19:40.761587 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 50 finished
---------------------------------------  ---------------
epoch                                       50
replay_buffer/size                       35500
trainer/QF Loss                            182.226
trainer/Policy Loss                       -456.666
trainer/Raw Policy Loss                   -456.666
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 437.323
trainer/Q Predictions Std                   44.1998
trainer/Q Predictions Max                  552.443
trainer/Q Predictions Min                  304.052
trainer/Q Targets Mean                     436.762
trainer/Q Targets Std                       45.8527
trainer/Q Targets Max                      557.84
trainer/Q Targets Min                      306.125
trainer/Bellman Errors Mean                182.226
trainer/Bellman Errors Std                 510.969
trainer/Bellman Errors Max                7105.83
trainer/Bellman Errors Min                   5.09992e-06
trainer/Policy Action Mean                   0.00901029
trainer/Policy Action Std                    0.820452
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     35500
expl/num paths total                      1775
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.82494
expl/Rewards Std                             4.10509
expl/Rewards Max                            10
expl/Rewards Min                             8.31153e-05
expl/Returns Mean                           76.4987
expl/Returns Std                            60.2773
expl/Returns Max                           190.051
expl/Returns Min                             0.209909
expl/Actions Mean                           -0.0508648
expl/Actions Std                             0.656396
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        76.4987
expl/env_infos/final/reward_dist Mean        6.64999
expl/env_infos/final/reward_dist Std         3.97454
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00428244
expl/env_infos/initial/reward_dist Mean      0.0512866
expl/env_infos/initial/reward_dist Std       0.079707
expl/env_infos/initial/reward_dist Max       0.420113
expl/env_infos/initial/reward_dist Min       0.00436187
expl/env_infos/reward_dist Mean              3.82494
expl/env_infos/reward_dist Std               4.10509
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               8.31153e-05
eval/num steps total                      5100
eval/num paths total                       255
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.47288
eval/Rewards Std                             4.12079
eval/Rewards Max                            10
eval/Rewards Min                             0.01446
eval/Returns Mean                          129.458
eval/Returns Std                            43.2204
eval/Returns Max                           167.784
eval/Returns Min                            51.7409
eval/Actions Mean                           -0.123844
eval/Actions Std                             0.57977
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       129.458
eval/env_infos/final/reward_dist Mean        8.71124
eval/env_infos/final/reward_dist Std         2.57752
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.55619
eval/env_infos/initial/reward_dist Mean      0.0281949
eval/env_infos/initial/reward_dist Std       0.00789765
eval/env_infos/initial/reward_dist Max       0.0387194
eval/env_infos/initial/reward_dist Min       0.01446
eval/env_infos/reward_dist Mean              6.47288
eval/env_infos/reward_dist Std               4.12079
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.01446
time/data storing (s)                        0.00157925
time/evaluation sampling (s)                 1.11326
time/exploration sampling (s)                6.19746
time/logging (s)                             0.00231974
time/saving (s)                              0.000994575
time/training (s)                            4.18165
time/epoch (s)                              11.4973
time/total (s)                             982.599
Epoch                                       50
---------------------------------------  ---------------
2023-08-03 21:19:53.926818 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 51 finished
---------------------------------------  ---------------
epoch                                       51
replay_buffer/size                       36000
trainer/QF Loss                            165.67
trainer/Policy Loss                       -442.209
trainer/Raw Policy Loss                   -442.209
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 423.346
trainer/Q Predictions Std                   42.3125
trainer/Q Predictions Max                  538.543
trainer/Q Predictions Min                  297.569
trainer/Q Targets Mean                     422.934
trainer/Q Targets Std                       44.0396
trainer/Q Targets Max                      538.218
trainer/Q Targets Min                      301.166
trainer/Bellman Errors Mean                165.67
trainer/Bellman Errors Std                 520.715
trainer/Bellman Errors Max               10798.7
trainer/Bellman Errors Min                   2.38419e-07
trainer/Policy Action Mean                   0.0146064
trainer/Policy Action Std                    0.820315
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     36000
expl/num paths total                      1800
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.22301
expl/Rewards Std                             3.93963
expl/Rewards Max                            10
expl/Rewards Min                             2.59163e-05
expl/Returns Mean                           64.4601
expl/Returns Std                            59.8333
expl/Returns Max                           176.772
expl/Returns Min                             0.19628
expl/Actions Mean                           -0.0421459
expl/Actions Std                             0.674297
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        64.4601
expl/env_infos/final/reward_dist Mean        5.12424
expl/env_infos/final/reward_dist Std         4.39587
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.59163e-05
expl/env_infos/initial/reward_dist Mean      0.0370284
expl/env_infos/initial/reward_dist Std       0.0213127
expl/env_infos/initial/reward_dist Max       0.0803919
expl/env_infos/initial/reward_dist Min       0.0102426
expl/env_infos/reward_dist Mean              3.22301
expl/env_infos/reward_dist Std               3.93963
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.59163e-05
eval/num steps total                      5200
eval/num paths total                       260
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.48544
eval/Rewards Std                             4.01415
eval/Rewards Max                            10
eval/Rewards Min                             0.00876617
eval/Returns Mean                          149.709
eval/Returns Std                            27.9226
eval/Returns Max                           173.597
eval/Returns Min                            97.1346
eval/Actions Mean                           -0.0642484
eval/Actions Std                             0.504301
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                               5
eval/Average Returns                       149.709
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.029619
eval/env_infos/initial/reward_dist Std       0.0133733
eval/env_infos/initial/reward_dist Max       0.0494613
eval/env_infos/initial/reward_dist Min       0.00876617
eval/env_infos/reward_dist Mean              7.48544
eval/env_infos/reward_dist Std               4.01415
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00876617
time/data storing (s)                        0.00158353
time/evaluation sampling (s)                 1.58158
time/exploration sampling (s)                7.37548
time/logging (s)                             0.00230093
time/saving (s)                              0.00104294
time/training (s)                            4.20055
time/epoch (s)                              13.1625
time/total (s)                             995.764
Epoch                                       51
---------------------------------------  ---------------
2023-08-03 21:20:05.730960 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 52 finished
---------------------------------------  ---------------
epoch                                       52
replay_buffer/size                       36500
trainer/QF Loss                            166.282
trainer/Policy Loss                       -429.569
trainer/Raw Policy Loss                   -429.569
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 411.707
trainer/Q Predictions Std                   41.3044
trainer/Q Predictions Max                  520.361
trainer/Q Predictions Min                  309.638
trainer/Q Targets Mean                     412.123
trainer/Q Targets Std                       43.3029
trainer/Q Targets Max                      517.738
trainer/Q Targets Min                      304.146
trainer/Bellman Errors Mean                166.282
trainer/Bellman Errors Std                 484.16
trainer/Bellman Errors Max                7904.88
trainer/Bellman Errors Min                   1.69734e-05
trainer/Policy Action Mean                   0.0328905
trainer/Policy Action Std                    0.81376
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     36500
expl/num paths total                      1825
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.71316
expl/Rewards Std                             4.2673
expl/Rewards Max                            10
expl/Rewards Min                             6.79738e-07
expl/Returns Mean                           74.2633
expl/Returns Std                            65.8394
expl/Returns Max                           180.6
expl/Returns Min                             0.299984
expl/Actions Mean                           -0.0702572
expl/Actions Std                             0.679613
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        74.2633
expl/env_infos/final/reward_dist Mean        5.62419
expl/env_infos/final/reward_dist Std         4.59402
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000206598
expl/env_infos/initial/reward_dist Mean      0.0339451
expl/env_infos/initial/reward_dist Std       0.0216816
expl/env_infos/initial/reward_dist Max       0.079873
expl/env_infos/initial/reward_dist Min       0.000680135
expl/env_infos/reward_dist Mean              3.71316
expl/env_infos/reward_dist Std               4.2673
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.79738e-07
eval/num steps total                      5300
eval/num paths total                       265
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.40405
eval/Rewards Std                             3.47726
eval/Rewards Max                            10
eval/Rewards Min                             0.020775
eval/Returns Mean                          168.081
eval/Returns Std                            15.7528
eval/Returns Max                           180.92
eval/Returns Min                           138.834
eval/Actions Mean                           -0.124491
eval/Actions Std                             0.524101
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       168.081
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.028868
eval/env_infos/initial/reward_dist Std       0.00668443
eval/env_infos/initial/reward_dist Max       0.0414424
eval/env_infos/initial/reward_dist Min       0.0238831
eval/env_infos/reward_dist Mean              8.40405
eval/env_infos/reward_dist Std               3.47726
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.020775
time/data storing (s)                        0.00158417
time/evaluation sampling (s)                 0.990481
time/exploration sampling (s)                6.71229
time/logging (s)                             0.00230803
time/saving (s)                              0.00102808
time/training (s)                            4.09386
time/epoch (s)                              11.8015
time/total (s)                            1007.57
Epoch                                       52
---------------------------------------  ---------------
2023-08-03 21:20:16.618587 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 53 finished
---------------------------------------  ---------------
epoch                                       53
replay_buffer/size                       37000
trainer/QF Loss                            147.992
trainer/Policy Loss                       -418.535
trainer/Raw Policy Loss                   -418.535
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 400.582
trainer/Q Predictions Std                   41.1793
trainer/Q Predictions Max                  505.39
trainer/Q Predictions Min                  271.324
trainer/Q Targets Mean                     400.181
trainer/Q Targets Std                       42.7168
trainer/Q Targets Max                      503.774
trainer/Q Targets Min                      271.821
trainer/Bellman Errors Mean                147.992
trainer/Bellman Errors Std                 429.093
trainer/Bellman Errors Max                9579.67
trainer/Bellman Errors Min                   2.69152e-07
trainer/Policy Action Mean                   0.0347801
trainer/Policy Action Std                    0.815274
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     37000
expl/num paths total                      1850
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.66347
expl/Rewards Std                             3.90904
expl/Rewards Max                            10
expl/Rewards Min                             5.90061e-05
expl/Returns Mean                           53.2695
expl/Returns Std                            62.5332
expl/Returns Max                           180.128
expl/Returns Min                             0.349281
expl/Actions Mean                            0.0307534
expl/Actions Std                             0.697323
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        53.2695
expl/env_infos/final/reward_dist Mean        4.1631
expl/env_infos/final/reward_dist Std         4.46495
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00865367
expl/env_infos/initial/reward_dist Mean      0.031521
expl/env_infos/initial/reward_dist Std       0.0217945
expl/env_infos/initial/reward_dist Max       0.0728856
expl/env_infos/initial/reward_dist Min       0.00627959
expl/env_infos/reward_dist Mean              2.66347
expl/env_infos/reward_dist Std               3.90904
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               5.90061e-05
eval/num steps total                      5400
eval/num paths total                       270
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.86932
eval/Rewards Std                             3.86554
eval/Rewards Max                            10
eval/Rewards Min                             0.0135483
eval/Returns Mean                          157.386
eval/Returns Std                            11.3583
eval/Returns Max                           170.617
eval/Returns Min                           136.205
eval/Actions Mean                           -0.0639049
eval/Actions Std                             0.510695
eval/Actions Max                             0.999999
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       157.386
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0287223
eval/env_infos/initial/reward_dist Std       0.00992767
eval/env_infos/initial/reward_dist Max       0.0440731
eval/env_infos/initial/reward_dist Min       0.0168853
eval/env_infos/reward_dist Mean              7.86932
eval/env_infos/reward_dist Std               3.86554
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0135483
time/data storing (s)                        0.00158218
time/evaluation sampling (s)                 1.00259
time/exploration sampling (s)                5.7877
time/logging (s)                             0.00233854
time/saving (s)                              0.00101804
time/training (s)                            4.08985
time/epoch (s)                              10.8851
time/total (s)                            1018.45
Epoch                                       53
---------------------------------------  ---------------
2023-08-03 21:20:27.916036 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 54 finished
---------------------------------------  ---------------
epoch                                       54
replay_buffer/size                       37500
trainer/QF Loss                            129.746
trainer/Policy Loss                       -406.772
trainer/Raw Policy Loss                   -406.772
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 389.228
trainer/Q Predictions Std                   40.9222
trainer/Q Predictions Max                  493.302
trainer/Q Predictions Min                  274.188
trainer/Q Targets Mean                     389.075
trainer/Q Targets Std                       42.3995
trainer/Q Targets Max                      492.972
trainer/Q Targets Min                      276.891
trainer/Bellman Errors Mean                129.746
trainer/Bellman Errors Std                 381.512
trainer/Bellman Errors Max                6680.75
trainer/Bellman Errors Min                   2.69152e-05
trainer/Policy Action Mean                   0.0411884
trainer/Policy Action Std                    0.814599
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     37500
expl/num paths total                      1875
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.03695
expl/Rewards Std                             4.14083
expl/Rewards Max                            10
expl/Rewards Min                             1.09261e-05
expl/Returns Mean                           60.739
expl/Returns Std                            66.2201
expl/Returns Max                           182.469
expl/Returns Min                             0.275874
expl/Actions Mean                            0.0144983
expl/Actions Std                             0.675823
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        60.739
expl/env_infos/final/reward_dist Mean        4.79035
expl/env_infos/final/reward_dist Std         4.66772
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00372013
expl/env_infos/initial/reward_dist Mean      0.0347768
expl/env_infos/initial/reward_dist Std       0.0236981
expl/env_infos/initial/reward_dist Max       0.0774558
expl/env_infos/initial/reward_dist Min       0.00790469
expl/env_infos/reward_dist Mean              3.03695
expl/env_infos/reward_dist Std               4.14083
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.09261e-05
eval/num steps total                      5500
eval/num paths total                       275
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.006
eval/Rewards Std                             3.45579
eval/Rewards Max                            10
eval/Rewards Min                             0.00697492
eval/Returns Mean                          160.12
eval/Returns Std                            11.8433
eval/Returns Max                           169.959
eval/Returns Min                           137.121
eval/Actions Mean                           -0.12587
eval/Actions Std                             0.47482
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       160.12
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.100548
eval/env_infos/initial/reward_dist Std       0.119027
eval/env_infos/initial/reward_dist Max       0.335432
eval/env_infos/initial/reward_dist Min       0.00697492
eval/env_infos/reward_dist Mean              8.006
eval/env_infos/reward_dist Std               3.45579
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00697492
time/data storing (s)                        0.00157451
time/evaluation sampling (s)                 1.30105
time/exploration sampling (s)                6.10596
time/logging (s)                             0.00230621
time/saving (s)                              0.00102263
time/training (s)                            3.88248
time/epoch (s)                              11.2944
time/total (s)                            1029.75
Epoch                                       54
---------------------------------------  ---------------
2023-08-03 21:20:40.332049 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 55 finished
---------------------------------------  ---------------
epoch                                       55
replay_buffer/size                       38000
trainer/QF Loss                            151.478
trainer/Policy Loss                       -398.577
trainer/Raw Policy Loss                   -398.577
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 381.658
trainer/Q Predictions Std                   40.8331
trainer/Q Predictions Max                  486.524
trainer/Q Predictions Min                  278.169
trainer/Q Targets Mean                     382.233
trainer/Q Targets Std                       42.5239
trainer/Q Targets Max                      484.181
trainer/Q Targets Min                      282.508
trainer/Bellman Errors Mean                151.478
trainer/Bellman Errors Std                 476.825
trainer/Bellman Errors Max                7897.85
trainer/Bellman Errors Min                   6.41588e-06
trainer/Policy Action Mean                   0.0583867
trainer/Policy Action Std                    0.810705
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     38000
expl/num paths total                      1900
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.6747
expl/Rewards Std                             4.30422
expl/Rewards Max                            10
expl/Rewards Min                             0.000182793
expl/Returns Mean                           93.4941
expl/Returns Std                            68.3092
expl/Returns Max                           190.219
expl/Returns Min                             0.623445
expl/Actions Mean                           -0.0158497
expl/Actions Std                             0.662045
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        93.4941
expl/env_infos/final/reward_dist Mean        5.99747
expl/env_infos/final/reward_dist Std         4.24604
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00123795
expl/env_infos/initial/reward_dist Mean      0.0487145
expl/env_infos/initial/reward_dist Std       0.0488493
expl/env_infos/initial/reward_dist Max       0.218828
expl/env_infos/initial/reward_dist Min       0.0039002
expl/env_infos/reward_dist Mean              4.6747
expl/env_infos/reward_dist Std               4.30422
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000182793
eval/num steps total                      5600
eval/num paths total                       280
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.11867
eval/Rewards Std                             3.55878
eval/Rewards Max                            10
eval/Rewards Min                             0.0103243
eval/Returns Mean                          162.373
eval/Returns Std                            10.742
eval/Returns Max                           178.299
eval/Returns Min                           147.86
eval/Actions Mean                           -0.10076
eval/Actions Std                             0.458602
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       162.373
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0414975
eval/env_infos/initial/reward_dist Std       0.0124015
eval/env_infos/initial/reward_dist Max       0.0566137
eval/env_infos/initial/reward_dist Min       0.0263279
eval/env_infos/reward_dist Mean              8.11867
eval/env_infos/reward_dist Std               3.55878
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0103243
time/data storing (s)                        0.00216694
time/evaluation sampling (s)                 1.01279
time/exploration sampling (s)                7.34647
time/logging (s)                             0.00224074
time/saving (s)                              0.00098905
time/training (s)                            4.04869
time/epoch (s)                              12.4133
time/total (s)                            1042.17
Epoch                                       55
---------------------------------------  ---------------
2023-08-03 21:20:51.024502 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 56 finished
---------------------------------------  ---------------
epoch                                       56
replay_buffer/size                       38500
trainer/QF Loss                            139.18
trainer/Policy Loss                       -390.968
trainer/Raw Policy Loss                   -390.968
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 374.118
trainer/Q Predictions Std                   40.4388
trainer/Q Predictions Max                  477.08
trainer/Q Predictions Min                  276.002
trainer/Q Targets Mean                     374.299
trainer/Q Targets Std                       42.1189
trainer/Q Targets Max                      479.435
trainer/Q Targets Min                      271.814
trainer/Bellman Errors Mean                139.18
trainer/Bellman Errors Std                 405.71
trainer/Bellman Errors Max                5718.89
trainer/Bellman Errors Min                   5.82077e-07
trainer/Policy Action Mean                   0.0524942
trainer/Policy Action Std                    0.812661
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     38500
expl/num paths total                      1925
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.71341
expl/Rewards Std                             4.22503
expl/Rewards Max                            10
expl/Rewards Min                             0.000104941
expl/Returns Mean                           74.2682
expl/Returns Std                            65.4155
expl/Returns Max                           190.062
expl/Returns Min                             0.404797
expl/Actions Mean                           -0.027853
expl/Actions Std                             0.679246
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        74.2682
expl/env_infos/final/reward_dist Mean        5.1126
expl/env_infos/final/reward_dist Std         4.42055
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00764036
expl/env_infos/initial/reward_dist Mean      0.034472
expl/env_infos/initial/reward_dist Std       0.0216395
expl/env_infos/initial/reward_dist Max       0.0886233
expl/env_infos/initial/reward_dist Min       0.00521693
expl/env_infos/reward_dist Mean              3.71341
expl/env_infos/reward_dist Std               4.22503
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000104941
eval/num steps total                      5700
eval/num paths total                       285
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.77195
eval/Rewards Std                             4.32471
eval/Rewards Max                            10
eval/Rewards Min                             0.00811961
eval/Returns Mean                          135.439
eval/Returns Std                             5.12554
eval/Returns Max                           144.605
eval/Returns Min                           130.855
eval/Actions Mean                           -0.0515483
eval/Actions Std                             0.545498
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       135.439
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.029358
eval/env_infos/initial/reward_dist Std       0.0200902
eval/env_infos/initial/reward_dist Max       0.065268
eval/env_infos/initial/reward_dist Min       0.00811961
eval/env_infos/reward_dist Mean              6.77195
eval/env_infos/reward_dist Std               4.32471
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00811961
time/data storing (s)                        0.00160747
time/evaluation sampling (s)                 1.00821
time/exploration sampling (s)                5.62741
time/logging (s)                             0.00228911
time/saving (s)                              0.00101231
time/training (s)                            4.04939
time/epoch (s)                              10.6899
time/total (s)                            1052.86
Epoch                                       56
---------------------------------------  ---------------
2023-08-03 21:21:03.458208 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 57 finished
---------------------------------------  ---------------
epoch                                       57
replay_buffer/size                       39000
trainer/QF Loss                            123.84
trainer/Policy Loss                       -383.262
trainer/Raw Policy Loss                   -383.262
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 367.127
trainer/Q Predictions Std                   38.8354
trainer/Q Predictions Max                  466.749
trainer/Q Predictions Min                  287.426
trainer/Q Targets Mean                     367.338
trainer/Q Targets Std                       40.2687
trainer/Q Targets Max                      468.43
trainer/Q Targets Min                      278.187
trainer/Bellman Errors Mean                123.84
trainer/Bellman Errors Std                 379.02
trainer/Bellman Errors Max                6420.4
trainer/Bellman Errors Min                   7.37701e-06
trainer/Policy Action Mean                   0.044283
trainer/Policy Action Std                    0.812778
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     39000
expl/num paths total                      1950
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.22068
expl/Rewards Std                             4.46938
expl/Rewards Max                            10
expl/Rewards Min                             7.60414e-05
expl/Returns Mean                           84.4136
expl/Returns Std                            69.9127
expl/Returns Max                           180.577
expl/Returns Min                             0.340372
expl/Actions Mean                           -0.0372885
expl/Actions Std                             0.704706
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        84.4136
expl/env_infos/final/reward_dist Mean        6.18203
expl/env_infos/final/reward_dist Std         4.39864
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00183044
expl/env_infos/initial/reward_dist Mean      0.0274588
expl/env_infos/initial/reward_dist Std       0.016138
expl/env_infos/initial/reward_dist Max       0.0780749
expl/env_infos/initial/reward_dist Min       0.00400156
expl/env_infos/reward_dist Mean              4.22068
expl/env_infos/reward_dist Std               4.46938
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               7.60414e-05
eval/num steps total                      5800
eval/num paths total                       290
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.15547
eval/Rewards Std                             4.63521
eval/Rewards Max                            10
eval/Rewards Min                             0.00408169
eval/Returns Mean                          123.109
eval/Returns Std                            62.711
eval/Returns Max                           174.617
eval/Returns Min                             0.529719
eval/Actions Mean                           -0.156412
eval/Actions Std                             0.5984
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       123.109
eval/env_infos/final/reward_dist Mean        8.00396
eval/env_infos/final/reward_dist Std         3.99208
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0197885
eval/env_infos/initial/reward_dist Mean      0.0422639
eval/env_infos/initial/reward_dist Std       0.0175135
eval/env_infos/initial/reward_dist Max       0.0618784
eval/env_infos/initial/reward_dist Min       0.0186884
eval/env_infos/reward_dist Mean              6.15547
eval/env_infos/reward_dist Std               4.63521
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00408169
time/data storing (s)                        0.00158972
time/evaluation sampling (s)                 1.44401
time/exploration sampling (s)                6.7019
time/logging (s)                             0.00231281
time/saving (s)                              0.00100768
time/training (s)                            4.28013
time/epoch (s)                              12.431
time/total (s)                            1065.29
Epoch                                       57
---------------------------------------  ---------------
2023-08-03 21:21:14.949575 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 58 finished
---------------------------------------  ---------------
epoch                                       58
replay_buffer/size                       39500
trainer/QF Loss                            131.334
trainer/Policy Loss                       -379.55
trainer/Raw Policy Loss                   -379.55
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 363.141
trainer/Q Predictions Std                   37.5146
trainer/Q Predictions Max                  462.99
trainer/Q Predictions Min                  298.848
trainer/Q Targets Mean                     362.858
trainer/Q Targets Std                       38.7364
trainer/Q Targets Max                      460.375
trainer/Q Targets Min                      291.574
trainer/Bellman Errors Mean                131.334
trainer/Bellman Errors Std                 365.042
trainer/Bellman Errors Max                6281.98
trainer/Bellman Errors Min                   1.1269e-07
trainer/Policy Action Mean                   0.0561335
trainer/Policy Action Std                    0.811775
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     39500
expl/num paths total                      1975
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.7691
expl/Rewards Std                             3.76317
expl/Rewards Max                            10
expl/Rewards Min                             0.000101165
expl/Returns Mean                           55.382
expl/Returns Std                            58.4656
expl/Returns Max                           181.171
expl/Returns Min                             0.32451
expl/Actions Mean                            0.0133513
expl/Actions Std                             0.690501
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        55.382
expl/env_infos/final/reward_dist Mean        4.49478
expl/env_infos/final/reward_dist Std         4.33818
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000101165
expl/env_infos/initial/reward_dist Mean      0.0559367
expl/env_infos/initial/reward_dist Std       0.0912396
expl/env_infos/initial/reward_dist Max       0.388877
expl/env_infos/initial/reward_dist Min       0.00206306
expl/env_infos/reward_dist Mean              2.7691
expl/env_infos/reward_dist Std               3.76317
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000101165
eval/num steps total                      5900
eval/num paths total                       295
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.11214
eval/Rewards Std                             3.61122
eval/Rewards Max                            10
eval/Rewards Min                             0.0197542
eval/Returns Mean                          162.243
eval/Returns Std                            21.1328
eval/Returns Max                           182.439
eval/Returns Min                           124.264
eval/Actions Mean                           -0.0191378
eval/Actions Std                             0.566106
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       162.243
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.040357
eval/env_infos/initial/reward_dist Std       0.0108075
eval/env_infos/initial/reward_dist Max       0.0545637
eval/env_infos/initial/reward_dist Min       0.0270989
eval/env_infos/reward_dist Mean              8.11214
eval/env_infos/reward_dist Std               3.61122
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0197542
time/data storing (s)                        0.00190605
time/evaluation sampling (s)                 1.03589
time/exploration sampling (s)                6.37106
time/logging (s)                             0.00227916
time/saving (s)                              0.00100691
time/training (s)                            4.07654
time/epoch (s)                              11.4887
time/total (s)                            1076.78
Epoch                                       58
---------------------------------------  ---------------
2023-08-03 21:21:26.314960 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 59 finished
---------------------------------------  ---------------
epoch                                       59
replay_buffer/size                       40000
trainer/QF Loss                            128.169
trainer/Policy Loss                       -372.176
trainer/Raw Policy Loss                   -372.176
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 356.98
trainer/Q Predictions Std                   35.5284
trainer/Q Predictions Max                  451.684
trainer/Q Predictions Min                  280.256
trainer/Q Targets Mean                     356.725
trainer/Q Targets Std                       37.0828
trainer/Q Targets Max                      450.033
trainer/Q Targets Min                      282.586
trainer/Bellman Errors Mean                128.169
trainer/Bellman Errors Std                 365.88
trainer/Bellman Errors Max                4923.71
trainer/Bellman Errors Min                   2.42237e-06
trainer/Policy Action Mean                   0.0465352
trainer/Policy Action Std                    0.81155
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     40000
expl/num paths total                      2000
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.90898
expl/Rewards Std                             4.0944
expl/Rewards Max                            10
expl/Rewards Min                             0.000176053
expl/Returns Mean                           78.1796
expl/Returns Std                            58.2212
expl/Returns Max                           174.792
expl/Returns Min                             0.25863
expl/Actions Mean                           -0.0434438
expl/Actions Std                             0.676861
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        78.1796
expl/env_infos/final/reward_dist Mean        5.98349
expl/env_infos/final/reward_dist Std         4.26422
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00587656
expl/env_infos/initial/reward_dist Mean      0.0665745
expl/env_infos/initial/reward_dist Std       0.130306
expl/env_infos/initial/reward_dist Max       0.545344
expl/env_infos/initial/reward_dist Min       0.00292514
expl/env_infos/reward_dist Mean              3.90898
expl/env_infos/reward_dist Std               4.0944
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000176053
eval/num steps total                      6000
eval/num paths total                       300
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.67972
eval/Rewards Std                             3.92741
eval/Rewards Max                            10
eval/Rewards Min                             0.00952995
eval/Returns Mean                          153.594
eval/Returns Std                            31.4759
eval/Returns Max                           175.46
eval/Returns Min                            91.0433
eval/Actions Mean                           -0.0435041
eval/Actions Std                             0.540281
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       153.594
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0470312
eval/env_infos/initial/reward_dist Std       0.0196766
eval/env_infos/initial/reward_dist Max       0.0671161
eval/env_infos/initial/reward_dist Min       0.0180577
eval/env_infos/reward_dist Mean              7.67972
eval/env_infos/reward_dist Std               3.92741
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00952995
time/data storing (s)                        0.00160551
time/evaluation sampling (s)                 1.04681
time/exploration sampling (s)                6.18869
time/logging (s)                             0.00228773
time/saving (s)                              0.0010152
time/training (s)                            4.12236
time/epoch (s)                              11.3628
time/total (s)                            1088.15
Epoch                                       59
---------------------------------------  ---------------
2023-08-03 21:21:38.165175 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 60 finished
---------------------------------------  ---------------
epoch                                       60
replay_buffer/size                       40500
trainer/QF Loss                            102.273
trainer/Policy Loss                       -364.783
trainer/Raw Policy Loss                   -364.783
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 350.14
trainer/Q Predictions Std                   34.4265
trainer/Q Predictions Max                  466.679
trainer/Q Predictions Min                  290.639
trainer/Q Targets Mean                     349.99
trainer/Q Targets Std                       35.526
trainer/Q Targets Max                      446.685
trainer/Q Targets Min                      281.168
trainer/Bellman Errors Mean                102.273
trainer/Bellman Errors Std                 284.242
trainer/Bellman Errors Max                5704.73
trainer/Bellman Errors Min                   2.72328e-05
trainer/Policy Action Mean                   0.0526214
trainer/Policy Action Std                    0.812548
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     40500
expl/num paths total                      2025
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.20461
expl/Rewards Std                             4.37572
expl/Rewards Max                            10
expl/Rewards Min                             0.00018142
expl/Returns Mean                           84.0921
expl/Returns Std                            67.7641
expl/Returns Max                           180.957
expl/Returns Min                             0.668871
expl/Actions Mean                            0.0091878
expl/Actions Std                             0.67687
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        84.0921
expl/env_infos/final/reward_dist Mean        6.30244
expl/env_infos/final/reward_dist Std         4.25782
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0144673
expl/env_infos/initial/reward_dist Mean      0.0292527
expl/env_infos/initial/reward_dist Std       0.0193956
expl/env_infos/initial/reward_dist Max       0.0887917
expl/env_infos/initial/reward_dist Min       0.000890783
expl/env_infos/reward_dist Mean              4.20461
expl/env_infos/reward_dist Std               4.37572
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00018142
eval/num steps total                      6100
eval/num paths total                       305
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.16301
eval/Rewards Std                             4.17792
eval/Rewards Max                            10
eval/Rewards Min                             0.00775795
eval/Returns Mean                          143.26
eval/Returns Std                            33.1555
eval/Returns Max                           175.083
eval/Returns Min                            81.5891
eval/Actions Mean                           -0.0251244
eval/Actions Std                             0.568315
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       143.26
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0324307
eval/env_infos/initial/reward_dist Std       0.0179136
eval/env_infos/initial/reward_dist Max       0.0637211
eval/env_infos/initial/reward_dist Min       0.0107876
eval/env_infos/reward_dist Mean              7.16301
eval/env_infos/reward_dist Std               4.17792
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00775795
time/data storing (s)                        0.00154451
time/evaluation sampling (s)                 1.48584
time/exploration sampling (s)                6.12134
time/logging (s)                             0.00233961
time/saving (s)                              0.00101986
time/training (s)                            4.23541
time/epoch (s)                              11.8475
time/total (s)                            1100
Epoch                                       60
---------------------------------------  ---------------
2023-08-03 21:21:50.232551 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 61 finished
---------------------------------------  ---------------
epoch                                       61
replay_buffer/size                       41000
trainer/QF Loss                            106.784
trainer/Policy Loss                       -356.145
trainer/Raw Policy Loss                   -356.145
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 342.26
trainer/Q Predictions Std                   33.9935
trainer/Q Predictions Max                  449.618
trainer/Q Predictions Min                  279.74
trainer/Q Targets Mean                     342.245
trainer/Q Targets Std                       35.1263
trainer/Q Targets Max                      446.536
trainer/Q Targets Min                      276.695
trainer/Bellman Errors Mean                106.784
trainer/Bellman Errors Std                 306.853
trainer/Bellman Errors Max                5055.73
trainer/Bellman Errors Min                   3.32678e-05
trainer/Policy Action Mean                   0.049757
trainer/Policy Action Std                    0.8144
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     41000
expl/num paths total                      2050
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.86657
expl/Rewards Std                             4.24724
expl/Rewards Max                            10
expl/Rewards Min                             3.56359e-05
expl/Returns Mean                           77.3315
expl/Returns Std                            67.9459
expl/Returns Max                           190.276
expl/Returns Min                             0.370629
expl/Actions Mean                           -0.00997494
expl/Actions Std                             0.680714
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        77.3315
expl/env_infos/final/reward_dist Mean        5.61036
expl/env_infos/final/reward_dist Std         4.37193
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00720941
expl/env_infos/initial/reward_dist Mean      0.0442825
expl/env_infos/initial/reward_dist Std       0.0550889
expl/env_infos/initial/reward_dist Max       0.27633
expl/env_infos/initial/reward_dist Min       0.00334178
expl/env_infos/reward_dist Mean              3.86657
expl/env_infos/reward_dist Std               4.24724
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               3.56359e-05
eval/num steps total                      6200
eval/num paths total                       310
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.74836
eval/Rewards Std                             3.88732
eval/Rewards Max                            10
eval/Rewards Min                             0.00527473
eval/Returns Mean                          154.967
eval/Returns Std                            13.1128
eval/Returns Max                           170.082
eval/Returns Min                           136.057
eval/Actions Mean                           -0.081973
eval/Actions Std                             0.622174
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       154.967
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0558468
eval/env_infos/initial/reward_dist Std       0.082999
eval/env_infos/initial/reward_dist Max       0.220987
eval/env_infos/initial/reward_dist Min       0.00527473
eval/env_infos/reward_dist Mean              7.74836
eval/env_infos/reward_dist Std               3.88732
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00527473
time/data storing (s)                        0.00155696
time/evaluation sampling (s)                 1.30356
time/exploration sampling (s)                7.24032
time/logging (s)                             0.00231076
time/saving (s)                              0.00101292
time/training (s)                            3.5155
time/epoch (s)                              12.0643
time/total (s)                            1112.06
Epoch                                       61
---------------------------------------  ---------------
2023-08-03 21:22:02.674331 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 62 finished
---------------------------------------  ---------------
epoch                                       62
replay_buffer/size                       41500
trainer/QF Loss                            109.167
trainer/Policy Loss                       -347.803
trainer/Raw Policy Loss                   -347.803
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 334.621
trainer/Q Predictions Std                   33.7221
trainer/Q Predictions Max                  443.694
trainer/Q Predictions Min                  247.786
trainer/Q Targets Mean                     334.796
trainer/Q Targets Std                       35.0141
trainer/Q Targets Max                      456.108
trainer/Q Targets Min                      250.74
trainer/Bellman Errors Mean                109.167
trainer/Bellman Errors Std                 311.259
trainer/Bellman Errors Max                4341.65
trainer/Bellman Errors Min                   2.23611e-06
trainer/Policy Action Mean                   0.0520828
trainer/Policy Action Std                    0.812112
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     41500
expl/num paths total                      2075
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.94003
expl/Rewards Std                             4.27373
expl/Rewards Max                            10
expl/Rewards Min                             0.000969803
expl/Returns Mean                           78.8005
expl/Returns Std                            65.4179
expl/Returns Max                           190.092
expl/Returns Min                             0.38669
expl/Actions Mean                           -0.000700017
expl/Actions Std                             0.677743
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        78.8005
expl/env_infos/final/reward_dist Mean        6.24595
expl/env_infos/final/reward_dist Std         4.31399
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00199166
expl/env_infos/initial/reward_dist Mean      0.0440264
expl/env_infos/initial/reward_dist Std       0.0580754
expl/env_infos/initial/reward_dist Max       0.303888
expl/env_infos/initial/reward_dist Min       0.00109873
expl/env_infos/reward_dist Mean              3.94003
expl/env_infos/reward_dist Std               4.27373
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000969803
eval/num steps total                      6300
eval/num paths total                       315
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.59672
eval/Rewards Std                             3.80098
eval/Rewards Max                            10
eval/Rewards Min                             0.0108013
eval/Returns Mean                          151.934
eval/Returns Std                            13.306
eval/Returns Max                           173.573
eval/Returns Min                           136.192
eval/Actions Mean                           -0.0108339
eval/Actions Std                             0.6246
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       151.934
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0205726
eval/env_infos/initial/reward_dist Std       0.00908625
eval/env_infos/initial/reward_dist Max       0.0359256
eval/env_infos/initial/reward_dist Min       0.0108013
eval/env_infos/reward_dist Mean              7.59672
eval/env_infos/reward_dist Std               3.80098
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0108013
time/data storing (s)                        0.00217267
time/evaluation sampling (s)                 1.02693
time/exploration sampling (s)                7.10502
time/logging (s)                             0.00224924
time/saving (s)                              0.000997862
time/training (s)                            4.30171
time/epoch (s)                              12.4391
time/total (s)                            1124.5
Epoch                                       62
---------------------------------------  ---------------
2023-08-03 21:22:13.835347 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 63 finished
---------------------------------------  ---------------
epoch                                       63
replay_buffer/size                       42000
trainer/QF Loss                            113.85
trainer/Policy Loss                       -339.139
trainer/Raw Policy Loss                   -339.139
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 326.761
trainer/Q Predictions Std                   34.3354
trainer/Q Predictions Max                  465.61
trainer/Q Predictions Min                  247.208
trainer/Q Targets Mean                     327.091
trainer/Q Targets Std                       35.7338
trainer/Q Targets Max                      465.484
trainer/Q Targets Min                      235.31
trainer/Bellman Errors Mean                113.85
trainer/Bellman Errors Std                 344.558
trainer/Bellman Errors Max                6891.63
trainer/Bellman Errors Min                   4.56348e-08
trainer/Policy Action Mean                   0.0308378
trainer/Policy Action Std                    0.80888
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     42000
expl/num paths total                      2100
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.62311
expl/Rewards Std                             4.18446
expl/Rewards Max                            10
expl/Rewards Min                             2.28415e-07
expl/Returns Mean                           72.4621
expl/Returns Std                            61.8764
expl/Returns Max                           181.027
expl/Returns Min                             0.256793
expl/Actions Mean                            0.00160665
expl/Actions Std                             0.690575
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        72.4621
expl/env_infos/final/reward_dist Mean        5.7418
expl/env_infos/final/reward_dist Std         4.53107
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.28415e-07
expl/env_infos/initial/reward_dist Mean      0.0285232
expl/env_infos/initial/reward_dist Std       0.0194181
expl/env_infos/initial/reward_dist Max       0.0631378
expl/env_infos/initial/reward_dist Min       0.00180294
expl/env_infos/reward_dist Mean              3.62311
expl/env_infos/reward_dist Std               4.18446
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.28415e-07
eval/num steps total                      6400
eval/num paths total                       320
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.00047
eval/Rewards Std                             3.82058
eval/Rewards Max                            10
eval/Rewards Min                             0.00531559
eval/Returns Mean                          160.009
eval/Returns Std                            21.2848
eval/Returns Max                           190.471
eval/Returns Min                           125.889
eval/Actions Mean                           -0.0372664
eval/Actions Std                             0.529507
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       160.009
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.11996
eval/env_infos/initial/reward_dist Std       0.176292
eval/env_infos/initial/reward_dist Max       0.47132
eval/env_infos/initial/reward_dist Min       0.00531559
eval/env_infos/reward_dist Mean              8.00047
eval/env_infos/reward_dist Std               3.82058
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00531559
time/data storing (s)                        0.00155055
time/evaluation sampling (s)                 1.03304
time/exploration sampling (s)                5.91208
time/logging (s)                             0.0023103
time/saving (s)                              0.000987535
time/training (s)                            4.20848
time/epoch (s)                              11.1584
time/total (s)                            1135.66
Epoch                                       63
---------------------------------------  ---------------
2023-08-03 21:22:25.425486 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 64 finished
---------------------------------------  ---------------
epoch                                       64
replay_buffer/size                       42500
trainer/QF Loss                            113.004
trainer/Policy Loss                       -332.252
trainer/Raw Policy Loss                   -332.252
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 320.163
trainer/Q Predictions Std                   34.4135
trainer/Q Predictions Max                  462.35
trainer/Q Predictions Min                  231.725
trainer/Q Targets Mean                     320.221
trainer/Q Targets Std                       36.0484
trainer/Q Targets Max                      464.454
trainer/Q Targets Min                      235.436
trainer/Bellman Errors Mean                113.004
trainer/Bellman Errors Std                 307.192
trainer/Bellman Errors Max                4369.39
trainer/Bellman Errors Min                   1.02678e-05
trainer/Policy Action Mean                   0.0256991
trainer/Policy Action Std                    0.813644
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     42500
expl/num paths total                      2125
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.74345
expl/Rewards Std                             4.0724
expl/Rewards Max                            10
expl/Rewards Min                             7.05838e-06
expl/Returns Mean                           54.869
expl/Returns Std                            67.4001
expl/Returns Max                           183.932
expl/Returns Min                             0.222974
expl/Actions Mean                            0.0222809
expl/Actions Std                             0.723625
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        54.869
expl/env_infos/final/reward_dist Mean        3.96229
expl/env_infos/final/reward_dist Std         4.6292
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         6.94743e-05
expl/env_infos/initial/reward_dist Mean      0.0274756
expl/env_infos/initial/reward_dist Std       0.0211935
expl/env_infos/initial/reward_dist Max       0.0778231
expl/env_infos/initial/reward_dist Min       0.00136977
expl/env_infos/reward_dist Mean              2.74345
expl/env_infos/reward_dist Std               4.0724
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               7.05838e-06
eval/num steps total                      6500
eval/num paths total                       325
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            3.92102
eval/Rewards Std                             4.61055
eval/Rewards Max                            10
eval/Rewards Min                             0.0015869
eval/Returns Mean                           78.4204
eval/Returns Std                            83.7273
eval/Returns Max                           180.097
eval/Returns Min                             0.360508
eval/Actions Mean                            0.0212511
eval/Actions Std                             0.70221
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                        78.4204
eval/env_infos/final/reward_dist Mean        4.22553
eval/env_infos/final/reward_dist Std         4.73001
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0185024
eval/env_infos/initial/reward_dist Mean      0.0250454
eval/env_infos/initial/reward_dist Std       0.0134657
eval/env_infos/initial/reward_dist Max       0.0421712
eval/env_infos/initial/reward_dist Min       0.00816802
eval/env_infos/reward_dist Mean              3.92102
eval/env_infos/reward_dist Std               4.61055
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0015869
time/data storing (s)                        0.00156806
time/evaluation sampling (s)                 1.2103
time/exploration sampling (s)                6.12082
time/logging (s)                             0.00227635
time/saving (s)                              0.000989367
time/training (s)                            4.25141
time/epoch (s)                              11.5874
time/total (s)                            1147.25
Epoch                                       64
---------------------------------------  ---------------
2023-08-03 21:22:37.153645 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 65 finished
---------------------------------------  ---------------
epoch                                       65
replay_buffer/size                       43000
trainer/QF Loss                            137.382
trainer/Policy Loss                       -325.738
trainer/Raw Policy Loss                   -325.738
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 313.799
trainer/Q Predictions Std                   35.8117
trainer/Q Predictions Max                  450.39
trainer/Q Predictions Min                  220.194
trainer/Q Targets Mean                     313.75
trainer/Q Targets Std                       37.7396
trainer/Q Targets Max                      452.017
trainer/Q Targets Min                      216.51
trainer/Bellman Errors Mean                137.382
trainer/Bellman Errors Std                 441.668
trainer/Bellman Errors Max               10550.9
trainer/Bellman Errors Min                   4.9267e-07
trainer/Policy Action Mean                  -0.0206558
trainer/Policy Action Std                    0.83163
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     43000
expl/num paths total                      2150
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            2.51402
expl/Rewards Std                             3.92815
expl/Rewards Max                            10
expl/Rewards Min                             1.03648e-08
expl/Returns Mean                           50.2803
expl/Returns Std                            65.8978
expl/Returns Max                           190.495
expl/Returns Min                             0.154925
expl/Actions Mean                           -0.0193928
expl/Actions Std                             0.720477
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        50.2803
expl/env_infos/final/reward_dist Mean        3.73671
expl/env_infos/final/reward_dist Std         4.41936
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         3.57413e-08
expl/env_infos/initial/reward_dist Mean      0.0482956
expl/env_infos/initial/reward_dist Std       0.0931716
expl/env_infos/initial/reward_dist Max       0.494866
expl/env_infos/initial/reward_dist Min       0.000329829
expl/env_infos/reward_dist Mean              2.51402
expl/env_infos/reward_dist Std               3.92815
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.03648e-08
eval/num steps total                      6600
eval/num paths total                       330
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.40621
eval/Rewards Std                             4.71237
eval/Rewards Max                            10
eval/Rewards Min                             0.000205483
eval/Returns Mean                          128.124
eval/Returns Std                            65.0175
eval/Returns Max                           181.576
eval/Returns Min                             2.07275
eval/Actions Mean                           -0.0525608
eval/Actions Std                             0.694946
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       128.124
eval/env_infos/final/reward_dist Mean        8.17389
eval/env_infos/final/reward_dist Std         3.65223
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.869437
eval/env_infos/initial/reward_dist Mean      0.0181855
eval/env_infos/initial/reward_dist Std       0.0216078
eval/env_infos/initial/reward_dist Max       0.0498296
eval/env_infos/initial/reward_dist Min       0.000205483
eval/env_infos/reward_dist Mean              6.40621
eval/env_infos/reward_dist Std               4.71237
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.000205483
time/data storing (s)                        0.00283602
time/evaluation sampling (s)                 1.00689
time/exploration sampling (s)                6.20076
time/logging (s)                             0.0032833
time/saving (s)                              0.00123258
time/training (s)                            4.51147
time/epoch (s)                              11.7265
time/total (s)                            1158.98
Epoch                                       65
---------------------------------------  ---------------
2023-08-03 21:22:47.348825 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 66 finished
---------------------------------------  ---------------
epoch                                       66
replay_buffer/size                       43500
trainer/QF Loss                            155.345
trainer/Policy Loss                       -321.868
trainer/Raw Policy Loss                   -321.868
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 309.457
trainer/Q Predictions Std                   35.7125
trainer/Q Predictions Max                  469.37
trainer/Q Predictions Min                  231.897
trainer/Q Targets Mean                     309.837
trainer/Q Targets Std                       37.646
trainer/Q Targets Max                      455.372
trainer/Q Targets Min                      214.288
trainer/Bellman Errors Mean                155.345
trainer/Bellman Errors Std                 520.434
trainer/Bellman Errors Max                9303.87
trainer/Bellman Errors Min                   4.10713e-07
trainer/Policy Action Mean                  -0.04393
trainer/Policy Action Std                    0.849233
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     43500
expl/num paths total                      2175
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.65929
expl/Rewards Std                             4.57687
expl/Rewards Max                            10
expl/Rewards Min                             5.60551e-13
expl/Returns Mean                           73.1857
expl/Returns Std                            76.5291
expl/Returns Max                           190.292
expl/Returns Min                             0.0179291
expl/Actions Mean                           -0.0880409
expl/Actions Std                             0.726608
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        73.1857
expl/env_infos/final/reward_dist Mean        4.58486
expl/env_infos/final/reward_dist Std         4.82723
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         5.60551e-13
expl/env_infos/initial/reward_dist Mean      0.037219
expl/env_infos/initial/reward_dist Std       0.0557967
expl/env_infos/initial/reward_dist Max       0.291926
expl/env_infos/initial/reward_dist Min       0.000188649
expl/env_infos/reward_dist Mean              3.65929
expl/env_infos/reward_dist Std               4.57687
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               5.60551e-13
eval/num steps total                      6700
eval/num paths total                       335
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            1.9039
eval/Rewards Std                             3.52108
eval/Rewards Max                            10
eval/Rewards Min                             2.9699e-08
eval/Returns Mean                           38.0781
eval/Returns Std                            62.2247
eval/Returns Max                           160.487
eval/Returns Min                             0.103128
eval/Actions Mean                           -0.0639049
eval/Actions Std                             0.819522
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                        38.0781
eval/env_infos/final/reward_dist Mean        2.29783
eval/env_infos/final/reward_dist Std         3.89299
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         2.9699e-08
eval/env_infos/initial/reward_dist Mean      0.0216072
eval/env_infos/initial/reward_dist Std       0.00559398
eval/env_infos/initial/reward_dist Max       0.0312803
eval/env_infos/initial/reward_dist Min       0.014885
eval/env_infos/reward_dist Mean              1.9039
eval/env_infos/reward_dist Std               3.52108
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               2.9699e-08
time/data storing (s)                        0.00217321
time/evaluation sampling (s)                 0.899709
time/exploration sampling (s)                5.12212
time/logging (s)                             0.00238069
time/saving (s)                              0.00100876
time/training (s)                            4.16326
time/epoch (s)                              10.1907
time/total (s)                            1169.18
Epoch                                       66
---------------------------------------  ---------------
2023-08-03 21:22:58.320452 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 67 finished
---------------------------------------  ---------------
epoch                                       67
replay_buffer/size                       44000
trainer/QF Loss                            143.759
trainer/Policy Loss                       -327.766
trainer/Raw Policy Loss                   -327.766
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 314.696
trainer/Q Predictions Std                   33.9493
trainer/Q Predictions Max                  415.544
trainer/Q Predictions Min                  241.775
trainer/Q Targets Mean                     314.648
trainer/Q Targets Std                       36.3222
trainer/Q Targets Max                      410.902
trainer/Q Targets Min                      250.645
trainer/Bellman Errors Mean                143.759
trainer/Bellman Errors Std                 441.432
trainer/Bellman Errors Max                6141.67
trainer/Bellman Errors Min                   1.3411e-07
trainer/Policy Action Mean                   0.00879261
trainer/Policy Action Std                    0.868484
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     44000
expl/num paths total                      2200
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            1.27464
expl/Rewards Std                             2.94127
expl/Rewards Max                            10
expl/Rewards Min                             6.78525e-15
expl/Returns Mean                           25.4927
expl/Returns Std                            53.0054
expl/Returns Max                           180.226
expl/Returns Min                             0.00515215
expl/Actions Mean                            0.00996894
expl/Actions Std                             0.788798
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        25.4927
expl/env_infos/final/reward_dist Mean        1.55888
expl/env_infos/final/reward_dist Std         3.28744
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         6.78525e-15
expl/env_infos/initial/reward_dist Mean      0.0236003
expl/env_infos/initial/reward_dist Std       0.0218889
expl/env_infos/initial/reward_dist Max       0.0685816
expl/env_infos/initial/reward_dist Min       5.71241e-06
expl/env_infos/reward_dist Mean              1.27464
expl/env_infos/reward_dist Std               2.94127
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.78525e-15
eval/num steps total                      6800
eval/num paths total                       340
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            0.00593475
eval/Rewards Std                             0.0125207
eval/Rewards Max                             0.0621576
eval/Rewards Min                             6.24252e-13
eval/Returns Mean                            0.118695
eval/Returns Std                             0.0397962
eval/Returns Max                             0.183169
eval/Returns Min                             0.0724979
eval/Actions Mean                            0.042557
eval/Actions Std                             0.939471
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                         0.118695
eval/env_infos/final/reward_dist Mean        0.00446539
eval/env_infos/final/reward_dist Std         0.00893077
eval/env_infos/final/reward_dist Max         0.0223269
eval/env_infos/final/reward_dist Min         6.24252e-13
eval/env_infos/initial/reward_dist Mean      0.0105006
eval/env_infos/initial/reward_dist Std       0.00991505
eval/env_infos/initial/reward_dist Max       0.026945
eval/env_infos/initial/reward_dist Min       9.67624e-06
eval/env_infos/reward_dist Mean              0.00593475
eval/env_infos/reward_dist Std               0.0125207
eval/env_infos/reward_dist Max               0.0621576
eval/env_infos/reward_dist Min               6.24252e-13
time/data storing (s)                        0.00154686
time/evaluation sampling (s)                 1.03537
time/exploration sampling (s)                5.53753
time/logging (s)                             0.00228075
time/saving (s)                              0.00104529
time/training (s)                            4.38923
time/epoch (s)                              10.967
time/total (s)                            1180.15
Epoch                                       67
---------------------------------------  ---------------
2023-08-03 21:23:08.609076 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 68 finished
---------------------------------------  ---------------
epoch                                       68
replay_buffer/size                       44500
trainer/QF Loss                            110.04
trainer/Policy Loss                       -319.933
trainer/Raw Policy Loss                   -319.933
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 306.943
trainer/Q Predictions Std                   30.5802
trainer/Q Predictions Max                  407.581
trainer/Q Predictions Min                  249.024
trainer/Q Targets Mean                     307.097
trainer/Q Targets Std                       32.2176
trainer/Q Targets Max                      418.212
trainer/Q Targets Min                      249.06
trainer/Bellman Errors Mean                110.04
trainer/Bellman Errors Std                 265.193
trainer/Bellman Errors Max                4383.55
trainer/Bellman Errors Min                   4.58993e-05
trainer/Policy Action Mean                  -0.152493
trainer/Policy Action Std                    0.874907
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     44500
expl/num paths total                      2225
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            0.75987
expl/Rewards Std                             2.39792
expl/Rewards Max                            10
expl/Rewards Min                             1.15273e-12
expl/Returns Mean                           15.1974
expl/Returns Std                            42.2623
expl/Returns Max                           167.347
expl/Returns Min                             0.00958605
expl/Actions Mean                           -0.174009
expl/Actions Std                             0.796388
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        15.1974
expl/env_infos/final/reward_dist Mean        0.904116
expl/env_infos/final/reward_dist Std         2.73006
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         1.15273e-12
expl/env_infos/initial/reward_dist Mean      0.0196641
expl/env_infos/initial/reward_dist Std       0.0212618
expl/env_infos/initial/reward_dist Max       0.0715474
expl/env_infos/initial/reward_dist Min       9.83984e-06
expl/env_infos/reward_dist Mean              0.75987
expl/env_infos/reward_dist Std               2.39792
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.15273e-12
eval/num steps total                      6900
eval/num paths total                       345
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            2.48088
eval/Rewards Std                             4.16295
eval/Rewards Max                            10
eval/Rewards Min                             3.03638e-11
eval/Returns Mean                           49.6176
eval/Returns Std                            60.7753
eval/Returns Max                           126.378
eval/Returns Min                             0.00499994
eval/Actions Mean                           -0.171794
eval/Actions Std                             0.876416
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                        49.6176
eval/env_infos/final/reward_dist Mean        4
eval/env_infos/final/reward_dist Std         4.89898
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.03638e-11
eval/env_infos/initial/reward_dist Mean      0.000720507
eval/env_infos/initial/reward_dist Std       0.00111748
eval/env_infos/initial/reward_dist Max       0.00291469
eval/env_infos/initial/reward_dist Min       8.27754e-06
eval/env_infos/reward_dist Mean              2.48088
eval/env_infos/reward_dist Std               4.16295
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               3.03638e-11
time/data storing (s)                        0.00159739
time/evaluation sampling (s)                 0.834823
time/exploration sampling (s)                5.24507
time/logging (s)                             0.00226266
time/saving (s)                              0.000994876
time/training (s)                            4.20115
time/epoch (s)                              10.2859
time/total (s)                            1190.43
Epoch                                       68
---------------------------------------  ---------------
2023-08-03 21:23:19.077123 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 69 finished
---------------------------------------  ---------------
epoch                                       69
replay_buffer/size                       45000
trainer/QF Loss                            107.102
trainer/Policy Loss                       -304.254
trainer/Raw Policy Loss                   -304.254
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 292.828
trainer/Q Predictions Std                   34.9898
trainer/Q Predictions Max                  420.482
trainer/Q Predictions Min                  162.422
trainer/Q Targets Mean                     292.555
trainer/Q Targets Std                       36.5653
trainer/Q Targets Max                      412.463
trainer/Q Targets Min                      167.961
trainer/Bellman Errors Mean                107.102
trainer/Bellman Errors Std                 312.807
trainer/Bellman Errors Max                5202.1
trainer/Bellman Errors Min                   1.47857e-05
trainer/Policy Action Mean                  -0.0270586
trainer/Policy Action Std                    0.875143
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     45000
expl/num paths total                      2250
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.54214
expl/Rewards Std                             4.37512
expl/Rewards Max                            10
expl/Rewards Min                             1.025e-08
expl/Returns Mean                           70.8428
expl/Returns Std                            65.1513
expl/Returns Max                           167.611
expl/Returns Min                             0.172346
expl/Actions Mean                           -0.044495
expl/Actions Std                             0.745993
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        70.8428
expl/env_infos/final/reward_dist Mean        5.30919
expl/env_infos/final/reward_dist Std         4.89192
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         1.025e-08
expl/env_infos/initial/reward_dist Mean      0.0244851
expl/env_infos/initial/reward_dist Std       0.0193762
expl/env_infos/initial/reward_dist Max       0.0656976
expl/env_infos/initial/reward_dist Min       0.000364724
expl/env_infos/reward_dist Mean              3.54214
expl/env_infos/reward_dist Std               4.37512
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.025e-08
eval/num steps total                      7000
eval/num paths total                       350
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            4.83647
eval/Rewards Std                             4.54708
eval/Rewards Max                            10
eval/Rewards Min                             0.000653726
eval/Returns Mean                           96.7294
eval/Returns Std                            59.966
eval/Returns Max                           161.758
eval/Returns Min                             0.448572
eval/Actions Mean                           -0.0714491
eval/Actions Std                             0.762337
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                        96.7294
eval/env_infos/final/reward_dist Mean        8.0103
eval/env_infos/final/reward_dist Std         3.9794
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0515043
eval/env_infos/initial/reward_dist Mean      0.0651267
eval/env_infos/initial/reward_dist Std       0.0856613
eval/env_infos/initial/reward_dist Max       0.229973
eval/env_infos/initial/reward_dist Min       0.00235897
eval/env_infos/reward_dist Mean              4.83647
eval/env_infos/reward_dist Std               4.54708
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.000653726
time/data storing (s)                        0.00158709
time/evaluation sampling (s)                 1.0579
time/exploration sampling (s)                5.25342
time/logging (s)                             0.00228888
time/saving (s)                              0.00105952
time/training (s)                            4.14914
time/epoch (s)                              10.4654
time/total (s)                            1200.9
Epoch                                       69
---------------------------------------  ---------------
2023-08-03 21:23:31.005590 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 70 finished
---------------------------------------  ---------------
epoch                                       70
replay_buffer/size                       45500
trainer/QF Loss                            105.273
trainer/Policy Loss                       -299.763
trainer/Raw Policy Loss                   -299.763
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 286.93
trainer/Q Predictions Std                   36.0316
trainer/Q Predictions Max                  401.908
trainer/Q Predictions Min                  154.638
trainer/Q Targets Mean                     286.594
trainer/Q Targets Std                       37.6192
trainer/Q Targets Max                      405.312
trainer/Q Targets Min                      142.686
trainer/Bellman Errors Mean                105.273
trainer/Bellman Errors Std                 287.564
trainer/Bellman Errors Max                4523.53
trainer/Bellman Errors Min                   5.96046e-08
trainer/Policy Action Mean                   0.0178398
trainer/Policy Action Std                    0.858989
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     45500
expl/num paths total                      2275
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.77991
expl/Rewards Std                             4.45521
expl/Rewards Max                            10
expl/Rewards Min                             8.05109e-06
expl/Returns Mean                           95.5982
expl/Returns Std                            62.9114
expl/Returns Max                           180.896
expl/Returns Min                             0.263621
expl/Actions Mean                           -0.078772
expl/Actions Std                             0.729971
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        95.5982
expl/env_infos/final/reward_dist Mean        7.38408
expl/env_infos/final/reward_dist Std         4.21144
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0163868
expl/env_infos/initial/reward_dist Mean      0.0425209
expl/env_infos/initial/reward_dist Std       0.0428579
expl/env_infos/initial/reward_dist Max       0.230179
expl/env_infos/initial/reward_dist Min       0.00690181
expl/env_infos/reward_dist Mean              4.77991
expl/env_infos/reward_dist Std               4.45521
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               8.05109e-06
eval/num steps total                      7100
eval/num paths total                       355
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.53219
eval/Rewards Std                             3.90427
eval/Rewards Max                            10
eval/Rewards Min                             0.006092
eval/Returns Mean                          150.644
eval/Returns Std                            57.2929
eval/Returns Max                           190.077
eval/Returns Min                            37.2811
eval/Actions Mean                           -0.130347
eval/Actions Std                             0.753704
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       150.644
eval/env_infos/final/reward_dist Mean        8.30645
eval/env_infos/final/reward_dist Std         3.38711
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.53223
eval/env_infos/initial/reward_dist Mean      0.0273128
eval/env_infos/initial/reward_dist Std       0.0275051
eval/env_infos/initial/reward_dist Max       0.0774753
eval/env_infos/initial/reward_dist Min       0.006092
eval/env_infos/reward_dist Mean              7.53219
eval/env_infos/reward_dist Std               3.90427
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.006092
time/data storing (s)                        0.00158982
time/evaluation sampling (s)                 1.50733
time/exploration sampling (s)                6.11796
time/logging (s)                             0.00231115
time/saving (s)                              0.000984553
time/training (s)                            4.29555
time/epoch (s)                              11.9257
time/total (s)                            1212.83
Epoch                                       70
---------------------------------------  ---------------
2023-08-03 21:23:44.415979 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 71 finished
---------------------------------------  ---------------
epoch                                       71
replay_buffer/size                       46000
trainer/QF Loss                             86.487
trainer/Policy Loss                       -297.42
trainer/Raw Policy Loss                   -297.42
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 285.218
trainer/Q Predictions Std                   34.1406
trainer/Q Predictions Max                  389.16
trainer/Q Predictions Min                  165.36
trainer/Q Targets Mean                     285.347
trainer/Q Targets Std                       35.4877
trainer/Q Targets Max                      403.271
trainer/Q Targets Min                      162.335
trainer/Bellman Errors Mean                 86.487
trainer/Bellman Errors Std                 214.27
trainer/Bellman Errors Max                4049.47
trainer/Bellman Errors Min                   7.83242e-07
trainer/Policy Action Mean                   0.0841997
trainer/Policy Action Std                    0.842636
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     46000
expl/num paths total                      2300
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.68586
expl/Rewards Std                             4.55627
expl/Rewards Max                            10
expl/Rewards Min                             0.000150504
expl/Returns Mean                           93.7172
expl/Returns Std                            71.253
expl/Returns Max                           185.009
expl/Returns Min                             0.297192
expl/Actions Mean                           -0.0453021
expl/Actions Std                             0.726159
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        93.7172
expl/env_infos/final/reward_dist Mean        6.47312
expl/env_infos/final/reward_dist Std         4.43021
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0019477
expl/env_infos/initial/reward_dist Mean      0.0314095
expl/env_infos/initial/reward_dist Std       0.0152933
expl/env_infos/initial/reward_dist Max       0.0647963
expl/env_infos/initial/reward_dist Min       0.00931352
expl/env_infos/reward_dist Mean              4.68586
expl/env_infos/reward_dist Std               4.55627
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000150504
eval/num steps total                      7200
eval/num paths total                       360
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.41148
eval/Rewards Std                             3.94819
eval/Rewards Max                            10
eval/Rewards Min                             0.026634
eval/Returns Mean                          148.23
eval/Returns Std                            53.5174
eval/Returns Max                           190.521
eval/Returns Min                            42.5005
eval/Actions Mean                           -0.188524
eval/Actions Std                             0.665306
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       148.23
eval/env_infos/final/reward_dist Mean        8.26745
eval/env_infos/final/reward_dist Std         3.4651
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.33726
eval/env_infos/initial/reward_dist Mean      0.144144
eval/env_infos/initial/reward_dist Std       0.188728
eval/env_infos/initial/reward_dist Max       0.5211
eval/env_infos/initial/reward_dist Min       0.0370077
eval/env_infos/reward_dist Mean              7.41148
eval/env_infos/reward_dist Std               3.94819
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.026634
time/data storing (s)                        0.00156533
time/evaluation sampling (s)                 1.54779
time/exploration sampling (s)                7.4913
time/logging (s)                             0.00228197
time/saving (s)                              0.00104369
time/training (s)                            4.36356
time/epoch (s)                              13.4075
time/total (s)                            1226.24
Epoch                                       71
---------------------------------------  ---------------
2023-08-03 21:23:57.457174 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 72 finished
---------------------------------------  ---------------
epoch                                       72
replay_buffer/size                       46500
trainer/QF Loss                             76.0979
trainer/Policy Loss                       -290.676
trainer/Raw Policy Loss                   -290.676
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 278.835
trainer/Q Predictions Std                   32.2052
trainer/Q Predictions Max                  381.428
trainer/Q Predictions Min                  146.388
trainer/Q Targets Mean                     278.847
trainer/Q Targets Std                       33.4853
trainer/Q Targets Max                      397.64
trainer/Q Targets Min                      165.106
trainer/Bellman Errors Mean                 76.0978
trainer/Bellman Errors Std                 201.873
trainer/Bellman Errors Max                4006.76
trainer/Bellman Errors Min                   2.5183e-06
trainer/Policy Action Mean                   0.0961234
trainer/Policy Action Std                    0.834505
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     46500
expl/num paths total                      2325
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.95803
expl/Rewards Std                             4.30654
expl/Rewards Max                            10
expl/Rewards Min                             8.99036e-06
expl/Returns Mean                           79.1607
expl/Returns Std                            65.8364
expl/Returns Max                           190.637
expl/Returns Min                             0.239099
expl/Actions Mean                           -0.0253653
expl/Actions Std                             0.731734
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        79.1607
expl/env_infos/final/reward_dist Mean        6.28123
expl/env_infos/final/reward_dist Std         4.59821
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00018657
expl/env_infos/initial/reward_dist Mean      0.0613459
expl/env_infos/initial/reward_dist Std       0.119915
expl/env_infos/initial/reward_dist Max       0.636882
expl/env_infos/initial/reward_dist Min       0.00515273
expl/env_infos/reward_dist Mean              3.95803
expl/env_infos/reward_dist Std               4.30654
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               8.99036e-06
eval/num steps total                      7300
eval/num paths total                       365
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.99983
eval/Rewards Std                             4.35272
eval/Rewards Max                            10
eval/Rewards Min                             0.00378211
eval/Returns Mean                          139.997
eval/Returns Std                            36.0839
eval/Returns Max                           180.448
eval/Returns Min                            76.2336
eval/Actions Mean                           -0.0908276
eval/Actions Std                             0.677315
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       139.997
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0163458
eval/env_infos/initial/reward_dist Std       0.0107545
eval/env_infos/initial/reward_dist Max       0.0294508
eval/env_infos/initial/reward_dist Min       0.00378211
eval/env_infos/reward_dist Mean              6.99983
eval/env_infos/reward_dist Std               4.35272
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00378211
time/data storing (s)                        0.00217286
time/evaluation sampling (s)                 1.0325
time/exploration sampling (s)                7.15197
time/logging (s)                             0.00326057
time/saving (s)                              0.00126124
time/training (s)                            4.84834
time/epoch (s)                              13.0395
time/total (s)                            1239.28
Epoch                                       72
---------------------------------------  ---------------
2023-08-03 21:24:09.118279 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 73 finished
---------------------------------------  ---------------
epoch                                       73
replay_buffer/size                       47000
trainer/QF Loss                             72.3154
trainer/Policy Loss                       -281.554
trainer/Raw Policy Loss                   -281.554
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 270.291
trainer/Q Predictions Std                   29.8367
trainer/Q Predictions Max                  363.036
trainer/Q Predictions Min                  122.803
trainer/Q Targets Mean                     270.348
trainer/Q Targets Std                       31.1153
trainer/Q Targets Max                      377.624
trainer/Q Targets Min                      127.229
trainer/Bellman Errors Mean                 72.3154
trainer/Bellman Errors Std                 193.263
trainer/Bellman Errors Max                3533.85
trainer/Bellman Errors Min                   1.11668e-05
trainer/Policy Action Mean                   0.078247
trainer/Policy Action Std                    0.829901
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     47000
expl/num paths total                      2350
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.77024
expl/Rewards Std                             4.5849
expl/Rewards Max                            10
expl/Rewards Min                             7.99093e-05
expl/Returns Mean                           95.4047
expl/Returns Std                            75.4627
expl/Returns Max                           184.179
expl/Returns Min                             0.611363
expl/Actions Mean                           -0.0780712
expl/Actions Std                             0.706916
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        95.4047
expl/env_infos/final/reward_dist Mean        6.33615
expl/env_infos/final/reward_dist Std         4.54257
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000345461
expl/env_infos/initial/reward_dist Mean      0.0652742
expl/env_infos/initial/reward_dist Std       0.0997486
expl/env_infos/initial/reward_dist Max       0.512876
expl/env_infos/initial/reward_dist Min       0.00507126
expl/env_infos/reward_dist Mean              4.77024
expl/env_infos/reward_dist Std               4.5849
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               7.99093e-05
eval/num steps total                      7400
eval/num paths total                       370
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.25642
eval/Rewards Std                             3.3754
eval/Rewards Max                            10
eval/Rewards Min                             0.00666289
eval/Returns Mean                          165.128
eval/Returns Std                            18.2301
eval/Returns Max                           180.529
eval/Returns Min                           130.188
eval/Actions Mean                           -0.200043
eval/Actions Std                             0.620562
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       165.128
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0408981
eval/env_infos/initial/reward_dist Std       0.025947
eval/env_infos/initial/reward_dist Max       0.0816684
eval/env_infos/initial/reward_dist Min       0.00666289
eval/env_infos/reward_dist Mean              8.25642
eval/env_infos/reward_dist Std               3.3754
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00666289
time/data storing (s)                        0.00159841
time/evaluation sampling (s)                 1.25736
time/exploration sampling (s)                6.24311
time/logging (s)                             0.00232333
time/saving (s)                              0.000991811
time/training (s)                            4.15117
time/epoch (s)                              11.6566
time/total (s)                            1250.94
Epoch                                       73
---------------------------------------  ---------------
2023-08-03 21:24:20.319943 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 74 finished
---------------------------------------  ---------------
epoch                                       74
replay_buffer/size                       47500
trainer/QF Loss                             67.9285
trainer/Policy Loss                       -273.596
trainer/Raw Policy Loss                   -273.596
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 262.557
trainer/Q Predictions Std                   30.9394
trainer/Q Predictions Max                  353.578
trainer/Q Predictions Min                  126.725
trainer/Q Targets Mean                     262.231
trainer/Q Targets Std                       32.1413
trainer/Q Targets Max                      370.189
trainer/Q Targets Min                      123.004
trainer/Bellman Errors Mean                 67.9285
trainer/Bellman Errors Std                 190.327
trainer/Bellman Errors Max                3065.89
trainer/Bellman Errors Min                   1.57394e-07
trainer/Policy Action Mean                   0.0766523
trainer/Policy Action Std                    0.82274
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     47500
expl/num paths total                      2375
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.84141
expl/Rewards Std                             4.64933
expl/Rewards Max                            10
expl/Rewards Min                             7.54729e-07
expl/Returns Mean                           96.8282
expl/Returns Std                            73.8965
expl/Returns Max                           182.865
expl/Returns Min                             0.184189
expl/Actions Mean                           -0.0521917
expl/Actions Std                             0.702006
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        96.8282
expl/env_infos/final/reward_dist Mean        6.53059
expl/env_infos/final/reward_dist Std         4.64876
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         8.32223e-07
expl/env_infos/initial/reward_dist Mean      0.0396459
expl/env_infos/initial/reward_dist Std       0.0203646
expl/env_infos/initial/reward_dist Max       0.0718136
expl/env_infos/initial/reward_dist Min       0.00456293
expl/env_infos/reward_dist Mean              4.84141
expl/env_infos/reward_dist Std               4.64933
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               7.54729e-07
eval/num steps total                      7500
eval/num paths total                       375
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.08748
eval/Rewards Std                             3.68724
eval/Rewards Max                            10
eval/Rewards Min                             0.0145451
eval/Returns Mean                          161.75
eval/Returns Std                            20.2377
eval/Returns Max                           190.358
eval/Returns Min                           130.18
eval/Actions Mean                           -0.142787
eval/Actions Std                             0.752344
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       161.75
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0946024
eval/env_infos/initial/reward_dist Std       0.132104
eval/env_infos/initial/reward_dist Max       0.358353
eval/env_infos/initial/reward_dist Min       0.0145451
eval/env_infos/reward_dist Mean              8.08748
eval/env_infos/reward_dist Std               3.68724
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0145451
time/data storing (s)                        0.00154999
time/evaluation sampling (s)                 1.3725
time/exploration sampling (s)                5.60143
time/logging (s)                             0.00240929
time/saving (s)                              0.00100448
time/training (s)                            4.22004
time/epoch (s)                              11.1989
time/total (s)                            1262.14
Epoch                                       74
---------------------------------------  ---------------
2023-08-03 21:24:31.129855 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 75 finished
---------------------------------------  ---------------
epoch                                       75
replay_buffer/size                       48000
trainer/QF Loss                             72.6761
trainer/Policy Loss                       -268.679
trainer/Raw Policy Loss                   -268.679
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 257.564
trainer/Q Predictions Std                   32.6679
trainer/Q Predictions Max                  347.52
trainer/Q Predictions Min                  126.52
trainer/Q Targets Mean                     257.722
trainer/Q Targets Std                       33.8207
trainer/Q Targets Max                      361.089
trainer/Q Targets Min                      125.962
trainer/Bellman Errors Mean                 72.6761
trainer/Bellman Errors Std                 203.966
trainer/Bellman Errors Max                3996.24
trainer/Bellman Errors Min                   1.80304e-06
trainer/Policy Action Mean                   0.0751797
trainer/Policy Action Std                    0.819516
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     48000
expl/num paths total                      2400
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.45932
expl/Rewards Std                             4.58777
expl/Rewards Max                            10
expl/Rewards Min                             0.000773002
expl/Returns Mean                          109.186
expl/Returns Std                            59.8864
expl/Returns Max                           190.283
expl/Returns Min                             0.672107
expl/Actions Mean                           -0.0528412
expl/Actions Std                             0.704666
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       109.186
expl/env_infos/final/reward_dist Mean        8.07308
expl/env_infos/final/reward_dist Std         3.86525
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0163049
expl/env_infos/initial/reward_dist Mean      0.0459417
expl/env_infos/initial/reward_dist Std       0.0526494
expl/env_infos/initial/reward_dist Max       0.282615
expl/env_infos/initial/reward_dist Min       0.00389698
expl/env_infos/reward_dist Mean              5.45932
expl/env_infos/reward_dist Std               4.58777
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000773002
eval/num steps total                      7600
eval/num paths total                       380
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.03283
eval/Rewards Std                             3.69325
eval/Rewards Max                            10
eval/Rewards Min                             0.00718455
eval/Returns Mean                          160.657
eval/Returns Std                            13.0614
eval/Returns Max                           173.156
eval/Returns Min                           135.589
eval/Actions Mean                           -0.0746983
eval/Actions Std                             0.585389
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       160.657
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0212716
eval/env_infos/initial/reward_dist Std       0.0122137
eval/env_infos/initial/reward_dist Max       0.0361802
eval/env_infos/initial/reward_dist Min       0.00718455
eval/env_infos/reward_dist Mean              8.03283
eval/env_infos/reward_dist Std               3.69325
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00718455
time/data storing (s)                        0.00159459
time/evaluation sampling (s)                 1.12981
time/exploration sampling (s)                5.76743
time/logging (s)                             0.00229192
time/saving (s)                              0.00100792
time/training (s)                            3.90311
time/epoch (s)                              10.8052
time/total (s)                            1272.95
Epoch                                       75
---------------------------------------  ---------------
2023-08-03 21:24:42.867552 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 76 finished
---------------------------------------  ---------------
epoch                                       76
replay_buffer/size                       48500
trainer/QF Loss                             82.2153
trainer/Policy Loss                       -269.793
trainer/Raw Policy Loss                   -269.793
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 258.197
trainer/Q Predictions Std                   35.5262
trainer/Q Predictions Max                  355.119
trainer/Q Predictions Min                  139.614
trainer/Q Targets Mean                     258.025
trainer/Q Targets Std                       36.9728
trainer/Q Targets Max                      365.161
trainer/Q Targets Min                      133.365
trainer/Bellman Errors Mean                 82.2153
trainer/Bellman Errors Std                 258.048
trainer/Bellman Errors Max                7419.01
trainer/Bellman Errors Min                   3.29711e-06
trainer/Policy Action Mean                   0.0836386
trainer/Policy Action Std                    0.81832
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     48500
expl/num paths total                      2425
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.51625
expl/Rewards Std                             4.67114
expl/Rewards Max                            10
expl/Rewards Min                             1.53651e-09
expl/Returns Mean                          110.325
expl/Returns Std                            74.5641
expl/Returns Max                           190.052
expl/Returns Min                             0.229062
expl/Actions Mean                           -0.016605
expl/Actions Std                             0.699315
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       110.325
expl/env_infos/final/reward_dist Mean        7.0518
expl/env_infos/final/reward_dist Std         4.33787
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         1.53651e-09
expl/env_infos/initial/reward_dist Mean      0.0343665
expl/env_infos/initial/reward_dist Std       0.0203993
expl/env_infos/initial/reward_dist Max       0.0823544
expl/env_infos/initial/reward_dist Min       0.00415783
expl/env_infos/reward_dist Mean              5.51625
expl/env_infos/reward_dist Std               4.67114
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.53651e-09
eval/num steps total                      7700
eval/num paths total                       385
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.16342
eval/Rewards Std                             3.62867
eval/Rewards Max                            10
eval/Rewards Min                             0.00822643
eval/Returns Mean                          163.268
eval/Returns Std                            12.1746
eval/Returns Max                           180.359
eval/Returns Min                           143.943
eval/Actions Mean                           -0.0996629
eval/Actions Std                             0.595474
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       163.268
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0284001
eval/env_infos/initial/reward_dist Std       0.0185258
eval/env_infos/initial/reward_dist Max       0.0612682
eval/env_infos/initial/reward_dist Min       0.00822643
eval/env_infos/reward_dist Mean              8.16342
eval/env_infos/reward_dist Std               3.62867
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00822643
time/data storing (s)                        0.00216042
time/evaluation sampling (s)                 1.00041
time/exploration sampling (s)                6.6082
time/logging (s)                             0.00226723
time/saving (s)                              0.00101751
time/training (s)                            4.12089
time/epoch (s)                              11.7349
time/total (s)                            1284.69
Epoch                                       76
---------------------------------------  ---------------
2023-08-03 21:24:54.004484 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 77 finished
---------------------------------------  ---------------
epoch                                       77
replay_buffer/size                       49000
trainer/QF Loss                             90.2464
trainer/Policy Loss                       -273.197
trainer/Raw Policy Loss                   -273.197
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 261.198
trainer/Q Predictions Std                   37.6651
trainer/Q Predictions Max                  364.458
trainer/Q Predictions Min                  116.476
trainer/Q Targets Mean                     261.15
trainer/Q Targets Std                       38.9337
trainer/Q Targets Max                      367.279
trainer/Q Targets Min                      120.407
trainer/Bellman Errors Mean                 90.2464
trainer/Bellman Errors Std                 277.568
trainer/Bellman Errors Max                6127.26
trainer/Bellman Errors Min                   5.59026e-07
trainer/Policy Action Mean                   0.0787199
trainer/Policy Action Std                    0.816296
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     49000
expl/num paths total                      2450
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.51222
expl/Rewards Std                             4.49893
expl/Rewards Max                            10
expl/Rewards Min                             0.00136869
expl/Returns Mean                          110.244
expl/Returns Std                            63.7685
expl/Returns Max                           184.385
expl/Returns Min                             0.529647
expl/Actions Mean                           -0.0795673
expl/Actions Std                             0.696272
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       110.244
expl/env_infos/final/reward_dist Mean        7.51253
expl/env_infos/final/reward_dist Std         4.06271
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0300501
expl/env_infos/initial/reward_dist Mean      0.0654112
expl/env_infos/initial/reward_dist Std       0.147597
expl/env_infos/initial/reward_dist Max       0.78448
expl/env_infos/initial/reward_dist Min       0.00851964
expl/env_infos/reward_dist Mean              5.51222
expl/env_infos/reward_dist Std               4.49893
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00136869
eval/num steps total                      7800
eval/num paths total                       390
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            5.49959
eval/Rewards Std                             4.20202
eval/Rewards Max                            10
eval/Rewards Min                             0.0142561
eval/Returns Mean                          109.992
eval/Returns Std                            59.4138
eval/Returns Max                           169.745
eval/Returns Min                            37.5207
eval/Actions Mean                           -0.125711
eval/Actions Std                             0.661022
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                               5
eval/Average Returns                       109.992
eval/env_infos/final/reward_dist Mean        7.02714
eval/env_infos/final/reward_dist Std         3.64235
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         2.41076
eval/env_infos/initial/reward_dist Mean      0.0441653
eval/env_infos/initial/reward_dist Std       0.015467
eval/env_infos/initial/reward_dist Max       0.0729499
eval/env_infos/initial/reward_dist Min       0.029978
eval/env_infos/reward_dist Mean              5.49959
eval/env_infos/reward_dist Std               4.20202
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0142561
time/data storing (s)                        0.00215969
time/evaluation sampling (s)                 1.13691
time/exploration sampling (s)                5.8043
time/logging (s)                             0.00246242
time/saving (s)                              0.0101045
time/training (s)                            4.17846
time/epoch (s)                              11.1344
time/total (s)                            1295.82
Epoch                                       77
---------------------------------------  ---------------
2023-08-03 21:25:05.977263 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 78 finished
---------------------------------------  ---------------
epoch                                       78
replay_buffer/size                       49500
trainer/QF Loss                            101.137
trainer/Policy Loss                       -274.177
trainer/Raw Policy Loss                   -274.177
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 262.202
trainer/Q Predictions Std                   38.3751
trainer/Q Predictions Max                  355.39
trainer/Q Predictions Min                   93.3185
trainer/Q Targets Mean                     262.55
trainer/Q Targets Std                       39.8888
trainer/Q Targets Max                      368.677
trainer/Q Targets Min                       88.4861
trainer/Bellman Errors Mean                101.137
trainer/Bellman Errors Std                 316.278
trainer/Bellman Errors Max                5661.14
trainer/Bellman Errors Min                   3.36207e-07
trainer/Policy Action Mean                   0.087107
trainer/Policy Action Std                    0.817317
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     49500
expl/num paths total                      2475
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.71456
expl/Rewards Std                             4.39043
expl/Rewards Max                            10
expl/Rewards Min                             4.17726e-05
expl/Returns Mean                           94.2913
expl/Returns Std                            67.3865
expl/Returns Max                           181.608
expl/Returns Min                             0.687741
expl/Actions Mean                           -0.0391975
expl/Actions Std                             0.694854
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        94.2913
expl/env_infos/final/reward_dist Mean        5.6975
expl/env_infos/final/reward_dist Std         4.54629
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00433179
expl/env_infos/initial/reward_dist Mean      0.037263
expl/env_infos/initial/reward_dist Std       0.0435748
expl/env_infos/initial/reward_dist Max       0.2345
expl/env_infos/initial/reward_dist Min       0.00471502
expl/env_infos/reward_dist Mean              4.71456
expl/env_infos/reward_dist Std               4.39043
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               4.17726e-05
eval/num steps total                      7900
eval/num paths total                       395
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.68935
eval/Rewards Std                             3.96899
eval/Rewards Max                            10
eval/Rewards Min                             0.0172001
eval/Returns Mean                          153.787
eval/Returns Std                            22.2496
eval/Returns Max                           182.349
eval/Returns Min                           121.277
eval/Actions Mean                           -0.0256864
eval/Actions Std                             0.678486
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       153.787
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.101653
eval/env_infos/initial/reward_dist Std       0.129254
eval/env_infos/initial/reward_dist Max       0.359512
eval/env_infos/initial/reward_dist Min       0.0226148
eval/env_infos/reward_dist Mean              7.68935
eval/env_infos/reward_dist Std               3.96899
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0172001
time/data storing (s)                        0.00154472
time/evaluation sampling (s)                 1.27424
time/exploration sampling (s)                6.14724
time/logging (s)                             0.00231282
time/saving (s)                              0.00101056
time/training (s)                            4.54165
time/epoch (s)                              11.968
time/total (s)                            1307.79
Epoch                                       78
---------------------------------------  ---------------
2023-08-03 21:25:18.336520 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 79 finished
---------------------------------------  ---------------
epoch                                       79
replay_buffer/size                       50000
trainer/QF Loss                             95.8108
trainer/Policy Loss                       -276.982
trainer/Raw Policy Loss                   -276.982
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 264.974
trainer/Q Predictions Std                   40.2332
trainer/Q Predictions Max                  358.282
trainer/Q Predictions Min                   85.9462
trainer/Q Targets Mean                     264.746
trainer/Q Targets Std                       41.6645
trainer/Q Targets Max                      380.313
trainer/Q Targets Min                       91.5559
trainer/Bellman Errors Mean                 95.8108
trainer/Bellman Errors Std                 322.231
trainer/Bellman Errors Max                6873.63
trainer/Bellman Errors Min                   1.42048e-05
trainer/Policy Action Mean                   0.0727607
trainer/Policy Action Std                    0.812271
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     50000
expl/num paths total                      2500
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.63943
expl/Rewards Std                             4.42993
expl/Rewards Max                            10
expl/Rewards Min                             0.000380489
expl/Returns Mean                           92.7886
expl/Returns Std                            62.5804
expl/Returns Max                           190.827
expl/Returns Min                             0.388671
expl/Actions Mean                           -0.0788567
expl/Actions Std                             0.695979
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        92.7886
expl/env_infos/final/reward_dist Mean        6.55716
expl/env_infos/final/reward_dist Std         4.29856
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000463217
expl/env_infos/initial/reward_dist Mean      0.0649941
expl/env_infos/initial/reward_dist Std       0.156948
expl/env_infos/initial/reward_dist Max       0.82712
expl/env_infos/initial/reward_dist Min       0.00467754
expl/env_infos/reward_dist Mean              4.63943
expl/env_infos/reward_dist Std               4.42993
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000380489
eval/num steps total                      8000
eval/num paths total                       400
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.29073
eval/Rewards Std                             3.93784
eval/Rewards Max                            10
eval/Rewards Min                             0.0146769
eval/Returns Mean                          145.815
eval/Returns Std                            51.3493
eval/Returns Max                           173.978
eval/Returns Min                            43.1819
eval/Actions Mean                           -0.0404189
eval/Actions Std                             0.648771
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       145.815
eval/env_infos/final/reward_dist Mean        8.31854
eval/env_infos/final/reward_dist Std         3.36292
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.5927
eval/env_infos/initial/reward_dist Mean      0.0316585
eval/env_infos/initial/reward_dist Std       0.0172458
eval/env_infos/initial/reward_dist Max       0.0591585
eval/env_infos/initial/reward_dist Min       0.0146769
eval/env_infos/reward_dist Mean              7.29073
eval/env_infos/reward_dist Std               3.93784
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0146769
time/data storing (s)                        0.00155738
time/evaluation sampling (s)                 1.31439
time/exploration sampling (s)                6.88837
time/logging (s)                             0.00287703
time/saving (s)                              0.00112479
time/training (s)                            4.14847
time/epoch (s)                              12.3568
time/total (s)                            1320.15
Epoch                                       79
---------------------------------------  ---------------
2023-08-03 21:25:30.203424 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 80 finished
---------------------------------------  ---------------
epoch                                       80
replay_buffer/size                       50500
trainer/QF Loss                            113.205
trainer/Policy Loss                       -277.466
trainer/Raw Policy Loss                   -277.466
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 265.182
trainer/Q Predictions Std                   40.7507
trainer/Q Predictions Max                  371.319
trainer/Q Predictions Min                   98.2322
trainer/Q Targets Mean                     265.6
trainer/Q Targets Std                       42.3556
trainer/Q Targets Max                      381.679
trainer/Q Targets Min                       95.4979
trainer/Bellman Errors Mean                113.205
trainer/Bellman Errors Std                 502.525
trainer/Bellman Errors Max               13007.5
trainer/Bellman Errors Min                   9.31323e-06
trainer/Policy Action Mean                   0.0652614
trainer/Policy Action Std                    0.819112
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     50500
expl/num paths total                      2525
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.05659
expl/Rewards Std                             4.4528
expl/Rewards Max                            10
expl/Rewards Min                             6.68065e-08
expl/Returns Mean                           81.1319
expl/Returns Std                            68.6693
expl/Returns Max                           181.703
expl/Returns Min                             0.564501
expl/Actions Mean                           -0.0134616
expl/Actions Std                             0.695629
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        81.1319
expl/env_infos/final/reward_dist Mean        6.28045
expl/env_infos/final/reward_dist Std         4.60404
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.04642e-07
expl/env_infos/initial/reward_dist Mean      0.0594663
expl/env_infos/initial/reward_dist Std       0.117777
expl/env_infos/initial/reward_dist Max       0.599422
expl/env_infos/initial/reward_dist Min       0.00731638
expl/env_infos/reward_dist Mean              4.05659
expl/env_infos/reward_dist Std               4.4528
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.68065e-08
eval/num steps total                      8100
eval/num paths total                       405
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.34343
eval/Rewards Std                             3.48714
eval/Rewards Max                            10
eval/Rewards Min                             0.0126713
eval/Returns Mean                          166.869
eval/Returns Std                            16.9504
eval/Returns Max                           190.364
eval/Returns Min                           137.994
eval/Actions Mean                           -0.180466
eval/Actions Std                             0.671438
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       166.869
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.118611
eval/env_infos/initial/reward_dist Std       0.123242
eval/env_infos/initial/reward_dist Max       0.364034
eval/env_infos/initial/reward_dist Min       0.0352904
eval/env_infos/reward_dist Mean              8.34343
eval/env_infos/reward_dist Std               3.48714
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0126713
time/data storing (s)                        0.0021897
time/evaluation sampling (s)                 1.01859
time/exploration sampling (s)                6.72802
time/logging (s)                             0.00172462
time/saving (s)                              0.000771062
time/training (s)                            4.11084
time/epoch (s)                              11.8621
time/total (s)                            1332.02
Epoch                                       80
---------------------------------------  ---------------
2023-08-03 21:25:40.850748 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 81 finished
---------------------------------------  ---------------
epoch                                       81
replay_buffer/size                       51000
trainer/QF Loss                            108.417
trainer/Policy Loss                       -278.816
trainer/Raw Policy Loss                   -278.816
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 266.567
trainer/Q Predictions Std                   42.6431
trainer/Q Predictions Max                  371.574
trainer/Q Predictions Min                   50.0075
trainer/Q Targets Mean                     266.502
trainer/Q Targets Std                       43.932
trainer/Q Targets Max                      382.488
trainer/Q Targets Min                       57.7781
trainer/Bellman Errors Mean                108.417
trainer/Bellman Errors Std                 424.247
trainer/Bellman Errors Max               10047
trainer/Bellman Errors Min                   1.20699e-06
trainer/Policy Action Mean                   0.0395952
trainer/Policy Action Std                    0.816478
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     51000
expl/num paths total                      2550
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.91109
expl/Rewards Std                             4.61053
expl/Rewards Max                            10
expl/Rewards Min                             0.000416225
expl/Returns Mean                           98.2218
expl/Returns Std                            74.4924
expl/Returns Max                           183.456
expl/Returns Min                             0.349376
expl/Actions Mean                           -0.0393822
expl/Actions Std                             0.698921
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        98.2218
expl/env_infos/final/reward_dist Mean        6.3937
expl/env_infos/final/reward_dist Std         4.47898
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000416225
expl/env_infos/initial/reward_dist Mean      0.0469072
expl/env_infos/initial/reward_dist Std       0.0959259
expl/env_infos/initial/reward_dist Max       0.50738
expl/env_infos/initial/reward_dist Min       0.00545475
expl/env_infos/reward_dist Mean              4.91109
expl/env_infos/reward_dist Std               4.61053
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000416225
eval/num steps total                      8200
eval/num paths total                       410
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.28712
eval/Rewards Std                             4.69042
eval/Rewards Max                            10
eval/Rewards Min                             0.00438743
eval/Returns Mean                          125.742
eval/Returns Std                            68.9953
eval/Returns Max                           181.217
eval/Returns Min                             0.82694
eval/Actions Mean                           -0.127387
eval/Actions Std                             0.687085
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       125.742
eval/env_infos/final/reward_dist Mean        8.00729
eval/env_infos/final/reward_dist Std         3.98542
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0364416
eval/env_infos/initial/reward_dist Mean      0.0562063
eval/env_infos/initial/reward_dist Std       0.0639394
eval/env_infos/initial/reward_dist Max       0.179988
eval/env_infos/initial/reward_dist Min       0.00438743
eval/env_infos/reward_dist Mean              6.28712
eval/env_infos/reward_dist Std               4.69042
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00438743
time/data storing (s)                        0.00159463
time/evaluation sampling (s)                 0.978102
time/exploration sampling (s)                5.53953
time/logging (s)                             0.00236908
time/saving (s)                              0.00102988
time/training (s)                            4.12326
time/epoch (s)                              10.6459
time/total (s)                            1342.67
Epoch                                       81
---------------------------------------  ---------------
2023-08-03 21:25:53.209549 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 82 finished
---------------------------------------  ---------------
epoch                                       82
replay_buffer/size                       51500
trainer/QF Loss                             94.2369
trainer/Policy Loss                       -281.591
trainer/Raw Policy Loss                   -281.591
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 269.066
trainer/Q Predictions Std                   41.8921
trainer/Q Predictions Max                  377.217
trainer/Q Predictions Min                   98.1832
trainer/Q Targets Mean                     269.264
trainer/Q Targets Std                       42.7755
trainer/Q Targets Max                      379.308
trainer/Q Targets Min                       97.058
trainer/Bellman Errors Mean                 94.2369
trainer/Bellman Errors Std                 332.592
trainer/Bellman Errors Max                9586.43
trainer/Bellman Errors Min                   1.01421e-06
trainer/Policy Action Mean                   0.0414314
trainer/Policy Action Std                    0.815119
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     51500
expl/num paths total                      2575
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.63665
expl/Rewards Std                             4.57236
expl/Rewards Max                            10
expl/Rewards Min                             2.3346e-05
expl/Returns Mean                          112.733
expl/Returns Std                            62.8002
expl/Returns Max                           178.309
expl/Returns Min                             0.339921
expl/Actions Mean                           -0.103812
expl/Actions Std                             0.701344
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       112.733
expl/env_infos/final/reward_dist Mean        7.83149
expl/env_infos/final/reward_dist Std         3.91407
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.3346e-05
expl/env_infos/initial/reward_dist Mean      0.0438617
expl/env_infos/initial/reward_dist Std       0.0514402
expl/env_infos/initial/reward_dist Max       0.285861
expl/env_infos/initial/reward_dist Min       0.00263987
expl/env_infos/reward_dist Mean              5.63665
expl/env_infos/reward_dist Std               4.57236
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.3346e-05
eval/num steps total                      8300
eval/num paths total                       415
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.65525
eval/Rewards Std                             3.77837
eval/Rewards Max                            10
eval/Rewards Min                             0.0301613
eval/Returns Mean                          153.105
eval/Returns Std                            27.8323
eval/Returns Max                           172.39
eval/Returns Min                            97.9476
eval/Actions Mean                           -0.0848033
eval/Actions Std                             0.658109
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       153.105
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0607983
eval/env_infos/initial/reward_dist Std       0.0183644
eval/env_infos/initial/reward_dist Max       0.0834101
eval/env_infos/initial/reward_dist Min       0.0301613
eval/env_infos/reward_dist Mean              7.65525
eval/env_infos/reward_dist Std               3.77837
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0301613
time/data storing (s)                        0.00157522
time/evaluation sampling (s)                 1.52073
time/exploration sampling (s)                6.81027
time/logging (s)                             0.00225853
time/saving (s)                              0.000986804
time/training (s)                            4.01968
time/epoch (s)                              12.3555
time/total (s)                            1355.02
Epoch                                       82
---------------------------------------  ---------------
2023-08-03 21:26:06.447738 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 83 finished
---------------------------------------  ---------------
epoch                                       83
replay_buffer/size                       52000
trainer/QF Loss                             97.9876
trainer/Policy Loss                       -283.985
trainer/Raw Policy Loss                   -283.985
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 271.527
trainer/Q Predictions Std                   40.6574
trainer/Q Predictions Max                  368.227
trainer/Q Predictions Min                   77.8465
trainer/Q Targets Mean                     271.606
trainer/Q Targets Std                       42.0129
trainer/Q Targets Max                      374.881
trainer/Q Targets Min                       76.6488
trainer/Bellman Errors Mean                 97.9876
trainer/Bellman Errors Std                 384.273
trainer/Bellman Errors Max               13360.7
trainer/Bellman Errors Min                   1.432e-05
trainer/Policy Action Mean                   0.0333743
trainer/Policy Action Std                    0.810519
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     52000
expl/num paths total                      2600
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.05105
expl/Rewards Std                             4.69232
expl/Rewards Max                            10
expl/Rewards Min                             2.44678e-08
expl/Returns Mean                          101.021
expl/Returns Std                            69.1252
expl/Returns Max                           184.114
expl/Returns Min                             0.438682
expl/Actions Mean                           -0.0426323
expl/Actions Std                             0.704537
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       101.021
expl/env_infos/final/reward_dist Mean        7.32113
expl/env_infos/final/reward_dist Std         4.32471
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.44678e-08
expl/env_infos/initial/reward_dist Mean      0.0470367
expl/env_infos/initial/reward_dist Std       0.0585161
expl/env_infos/initial/reward_dist Max       0.305126
expl/env_infos/initial/reward_dist Min       0.00654432
expl/env_infos/reward_dist Mean              5.05105
expl/env_infos/reward_dist Std               4.69232
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.44678e-08
eval/num steps total                      8400
eval/num paths total                       420
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.12717
eval/Rewards Std                             3.60476
eval/Rewards Max                            10
eval/Rewards Min                             0.0170367
eval/Returns Mean                          162.543
eval/Returns Std                            24.34
eval/Returns Max                           180.547
eval/Returns Min                           114.426
eval/Actions Mean                           -0.163952
eval/Actions Std                             0.67932
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       162.543
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0417125
eval/env_infos/initial/reward_dist Std       0.0174609
eval/env_infos/initial/reward_dist Max       0.0714846
eval/env_infos/initial/reward_dist Min       0.0183785
eval/env_infos/reward_dist Mean              8.12717
eval/env_infos/reward_dist Std               3.60476
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0170367
time/data storing (s)                        0.00153879
time/evaluation sampling (s)                 1.46297
time/exploration sampling (s)                7.67678
time/logging (s)                             0.00223821
time/saving (s)                              0.00100915
time/training (s)                            4.09088
time/epoch (s)                              13.2354
time/total (s)                            1368.26
Epoch                                       83
---------------------------------------  ---------------
2023-08-03 21:26:19.134771 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 84 finished
---------------------------------------  ---------------
epoch                                       84
replay_buffer/size                       52500
trainer/QF Loss                             96.3451
trainer/Policy Loss                       -285.118
trainer/Raw Policy Loss                   -285.118
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 272.644
trainer/Q Predictions Std                   39.8288
trainer/Q Predictions Max                  376.553
trainer/Q Predictions Min                  136.507
trainer/Q Targets Mean                     272.305
trainer/Q Targets Std                       41.1888
trainer/Q Targets Max                      380.298
trainer/Q Targets Min                      129.351
trainer/Bellman Errors Mean                 96.3451
trainer/Bellman Errors Std                 333.257
trainer/Bellman Errors Max                8317.47
trainer/Bellman Errors Min                   2.32831e-10
trainer/Policy Action Mean                   0.0553934
trainer/Policy Action Std                    0.81139
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     52500
expl/num paths total                      2625
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.19753
expl/Rewards Std                             4.5927
expl/Rewards Max                            10
expl/Rewards Min                             4.05959e-08
expl/Returns Mean                          103.951
expl/Returns Std                            70.0776
expl/Returns Max                           190.717
expl/Returns Min                             0.331944
expl/Actions Mean                           -0.0734811
expl/Actions Std                             0.68924
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       103.951
expl/env_infos/final/reward_dist Mean        7.35524
expl/env_infos/final/reward_dist Std         4.26481
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.1367e-07
expl/env_infos/initial/reward_dist Mean      0.0903648
expl/env_infos/initial/reward_dist Std       0.178078
expl/env_infos/initial/reward_dist Max       0.717311
expl/env_infos/initial/reward_dist Min       0.00290554
expl/env_infos/reward_dist Mean              5.19753
expl/env_infos/reward_dist Std               4.5927
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               4.05959e-08
eval/num steps total                      8500
eval/num paths total                       425
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.88349
eval/Rewards Std                             3.73983
eval/Rewards Max                            10
eval/Rewards Min                             0.0144453
eval/Returns Mean                          157.67
eval/Returns Std                            28.0211
eval/Returns Max                           190.051
eval/Returns Min                           119.564
eval/Actions Mean                           -0.135916
eval/Actions Std                             0.622326
eval/Actions Max                             0.999999
eval/Actions Min                            -0.999995
eval/Num Paths                               5
eval/Average Returns                       157.67
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0375397
eval/env_infos/initial/reward_dist Std       0.0156515
eval/env_infos/initial/reward_dist Max       0.0582214
eval/env_infos/initial/reward_dist Min       0.0144453
eval/env_infos/reward_dist Mean              7.88349
eval/env_infos/reward_dist Std               3.73983
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0144453
time/data storing (s)                        0.00266591
time/evaluation sampling (s)                 0.998266
time/exploration sampling (s)                7.59081
time/logging (s)                             0.0022593
time/saving (s)                              0.00100541
time/training (s)                            4.0893
time/epoch (s)                              12.6843
time/total (s)                            1380.95
Epoch                                       84
---------------------------------------  ---------------
2023-08-03 21:26:29.913609 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 85 finished
---------------------------------------  ---------------
epoch                                       85
replay_buffer/size                       53000
trainer/QF Loss                             89.9464
trainer/Policy Loss                       -284.544
trainer/Raw Policy Loss                   -284.544
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 272.376
trainer/Q Predictions Std                   38.1567
trainer/Q Predictions Max                  371.504
trainer/Q Predictions Min                  144.126
trainer/Q Targets Mean                     272.262
trainer/Q Targets Std                       39.618
trainer/Q Targets Max                      380.472
trainer/Q Targets Min                      139.513
trainer/Bellman Errors Mean                 89.9464
trainer/Bellman Errors Std                 282.609
trainer/Bellman Errors Max                5581.06
trainer/Bellman Errors Min                   2.69152e-07
trainer/Policy Action Mean                   0.027837
trainer/Policy Action Std                    0.812426
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     53000
expl/num paths total                      2650
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.00638
expl/Rewards Std                             4.68083
expl/Rewards Max                            10
expl/Rewards Min                             6.02334e-10
expl/Returns Mean                          100.128
expl/Returns Std                            67.0583
expl/Returns Max                           190.123
expl/Returns Min                             0.513554
expl/Actions Mean                           -0.0374804
expl/Actions Std                             0.690335
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       100.128
expl/env_infos/final/reward_dist Mean        7.17729
expl/env_infos/final/reward_dist Std         4.1932
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         6.02334e-10
expl/env_infos/initial/reward_dist Mean      0.0334
expl/env_infos/initial/reward_dist Std       0.0280421
expl/env_infos/initial/reward_dist Max       0.122758
expl/env_infos/initial/reward_dist Min       0.000629106
expl/env_infos/reward_dist Mean              5.00638
expl/env_infos/reward_dist Std               4.68083
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.02334e-10
eval/num steps total                      8600
eval/num paths total                       430
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.68562
eval/Rewards Std                             3.16385
eval/Rewards Max                            10
eval/Rewards Min                             0.0116727
eval/Returns Mean                          173.712
eval/Returns Std                             8.77454
eval/Returns Max                           190.053
eval/Returns Min                           165.655
eval/Actions Mean                           -0.107585
eval/Actions Std                             0.618786
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       173.712
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0276217
eval/env_infos/initial/reward_dist Std       0.0140827
eval/env_infos/initial/reward_dist Max       0.0529798
eval/env_infos/initial/reward_dist Min       0.0116727
eval/env_infos/reward_dist Mean              8.68562
eval/env_infos/reward_dist Std               3.16385
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0116727
time/data storing (s)                        0.00154702
time/evaluation sampling (s)                 1.04231
time/exploration sampling (s)                5.55333
time/logging (s)                             0.00230903
time/saving (s)                              0.00102145
time/training (s)                            4.17563
time/epoch (s)                              10.7762
time/total (s)                            1391.73
Epoch                                       85
---------------------------------------  ---------------
2023-08-03 21:26:42.524594 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 86 finished
---------------------------------------  ---------------
epoch                                       86
replay_buffer/size                       53500
trainer/QF Loss                             85.1106
trainer/Policy Loss                       -283.443
trainer/Raw Policy Loss                   -283.443
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 271.495
trainer/Q Predictions Std                   38.275
trainer/Q Predictions Max                  367.07
trainer/Q Predictions Min                  115.421
trainer/Q Targets Mean                     271.776
trainer/Q Targets Std                       39.1694
trainer/Q Targets Max                      381.333
trainer/Q Targets Min                      118.375
trainer/Bellman Errors Mean                 85.1106
trainer/Bellman Errors Std                 278.699
trainer/Bellman Errors Max                6373.72
trainer/Bellman Errors Min                   6.29574e-07
trainer/Policy Action Mean                   0.0195997
trainer/Policy Action Std                    0.808973
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     53500
expl/num paths total                      2675
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.84663
expl/Rewards Std                             4.49279
expl/Rewards Max                            10
expl/Rewards Min                             0.000150788
expl/Returns Mean                          116.933
expl/Returns Std                            65.2421
expl/Returns Max                           190.029
expl/Returns Min                             0.405421
expl/Actions Mean                           -0.0819332
expl/Actions Std                             0.683252
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       116.933
expl/env_infos/final/reward_dist Mean        7.30828
expl/env_infos/final/reward_dist Std         4.32523
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00333045
expl/env_infos/initial/reward_dist Mean      0.0478422
expl/env_infos/initial/reward_dist Std       0.0548234
expl/env_infos/initial/reward_dist Max       0.301968
expl/env_infos/initial/reward_dist Min       0.00880807
expl/env_infos/reward_dist Mean              5.84663
expl/env_infos/reward_dist Std               4.49279
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000150788
eval/num steps total                      8700
eval/num paths total                       435
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.96278
eval/Rewards Std                             3.65197
eval/Rewards Max                            10
eval/Rewards Min                             0.0132597
eval/Returns Mean                          159.256
eval/Returns Std                            17.4476
eval/Returns Max                           183.694
eval/Returns Min                           130.593
eval/Actions Mean                           -0.263594
eval/Actions Std                             0.635128
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       159.256
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0445196
eval/env_infos/initial/reward_dist Std       0.0179251
eval/env_infos/initial/reward_dist Max       0.0701478
eval/env_infos/initial/reward_dist Min       0.0235709
eval/env_infos/reward_dist Mean              7.96278
eval/env_infos/reward_dist Std               3.65197
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0132597
time/data storing (s)                        0.0015517
time/evaluation sampling (s)                 1.50438
time/exploration sampling (s)                6.74786
time/logging (s)                             0.00229772
time/saving (s)                              0.00101562
time/training (s)                            4.35105
time/epoch (s)                              12.6082
time/total (s)                            1404.34
Epoch                                       86
---------------------------------------  ---------------
2023-08-03 21:26:54.814765 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 87 finished
---------------------------------------  ---------------
epoch                                       87
replay_buffer/size                       54000
trainer/QF Loss                             86.806
trainer/Policy Loss                       -281.327
trainer/Raw Policy Loss                   -281.327
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 269.702
trainer/Q Predictions Std                   37.3046
trainer/Q Predictions Max                  357.663
trainer/Q Predictions Min                  138.88
trainer/Q Targets Mean                     269.71
trainer/Q Targets Std                       38.7164
trainer/Q Targets Max                      362.779
trainer/Q Targets Min                      146.392
trainer/Bellman Errors Mean                 86.806
trainer/Bellman Errors Std                 321.272
trainer/Bellman Errors Max                8525.43
trainer/Bellman Errors Min                   1.56185e-05
trainer/Policy Action Mean                   0.0368763
trainer/Policy Action Std                    0.807925
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     54000
expl/num paths total                      2700
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.32403
expl/Rewards Std                             4.52594
expl/Rewards Max                            10
expl/Rewards Min                             0.000126821
expl/Returns Mean                          106.481
expl/Returns Std                            70.027
expl/Returns Max                           190.056
expl/Returns Min                             0.692035
expl/Actions Mean                           -0.0743437
expl/Actions Std                             0.683187
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       106.481
expl/env_infos/final/reward_dist Mean        7.41454
expl/env_infos/final/reward_dist Std         3.85426
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00648561
expl/env_infos/initial/reward_dist Mean      0.0404379
expl/env_infos/initial/reward_dist Std       0.0165387
expl/env_infos/initial/reward_dist Max       0.0651848
expl/env_infos/initial/reward_dist Min       0.010464
expl/env_infos/reward_dist Mean              5.32403
expl/env_infos/reward_dist Std               4.52594
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000126821
eval/num steps total                      8800
eval/num paths total                       440
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.57734
eval/Rewards Std                             3.80614
eval/Rewards Max                            10
eval/Rewards Min                             0.0134018
eval/Returns Mean                          151.547
eval/Returns Std                            55.4127
eval/Returns Max                           190.113
eval/Returns Min                            41.324
eval/Actions Mean                           -0.0252113
eval/Actions Std                             0.631817
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       151.547
eval/env_infos/final/reward_dist Mean        8.79056
eval/env_infos/final/reward_dist Std         2.41888
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.9528
eval/env_infos/initial/reward_dist Mean      0.0373223
eval/env_infos/initial/reward_dist Std       0.037836
eval/env_infos/initial/reward_dist Max       0.112553
eval/env_infos/initial/reward_dist Min       0.0134018
eval/env_infos/reward_dist Mean              7.57734
eval/env_infos/reward_dist Std               3.80614
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0134018
time/data storing (s)                        0.00159111
time/evaluation sampling (s)                 1.45882
time/exploration sampling (s)                6.44086
time/logging (s)                             0.00226739
time/saving (s)                              0.00101754
time/training (s)                            4.38241
time/epoch (s)                              12.287
time/total (s)                            1416.63
Epoch                                       87
---------------------------------------  ---------------
2023-08-03 21:27:06.389228 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 88 finished
---------------------------------------  ---------------
epoch                                       88
replay_buffer/size                       54500
trainer/QF Loss                             82.4263
trainer/Policy Loss                       -279.287
trainer/Raw Policy Loss                   -279.287
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 267.562
trainer/Q Predictions Std                   37.1506
trainer/Q Predictions Max                  361.774
trainer/Q Predictions Min                  102.699
trainer/Q Targets Mean                     267.127
trainer/Q Targets Std                       38.2942
trainer/Q Targets Max                      361.36
trainer/Q Targets Min                      104.583
trainer/Bellman Errors Mean                 82.4263
trainer/Bellman Errors Std                 284.4
trainer/Bellman Errors Max                5817.33
trainer/Bellman Errors Min                   5.82077e-09
trainer/Policy Action Mean                   0.0171386
trainer/Policy Action Std                    0.811736
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     54500
expl/num paths total                      2725
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.754
expl/Rewards Std                             4.54732
expl/Rewards Max                            10
expl/Rewards Min                             0.00183157
expl/Returns Mean                          115.08
expl/Returns Std                            68.5438
expl/Returns Max                           190.327
expl/Returns Min                             0.487381
expl/Actions Mean                           -0.0800414
expl/Actions Std                             0.700746
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       115.08
expl/env_infos/final/reward_dist Mean        7.97082
expl/env_infos/final/reward_dist Std         3.67592
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0376193
expl/env_infos/initial/reward_dist Mean      0.0644574
expl/env_infos/initial/reward_dist Std       0.0894137
expl/env_infos/initial/reward_dist Max       0.326773
expl/env_infos/initial/reward_dist Min       0.0055369
expl/env_infos/reward_dist Mean              5.754
expl/env_infos/reward_dist Std               4.54732
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00183157
eval/num steps total                      8900
eval/num paths total                       445
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.87099
eval/Rewards Std                             4.07538
eval/Rewards Max                            10
eval/Rewards Min                             0.0167642
eval/Returns Mean                          137.42
eval/Returns Std                            56.0453
eval/Returns Max                           184.978
eval/Returns Min                            40.8321
eval/Actions Mean                           -0.216293
eval/Actions Std                             0.695093
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       137.42
eval/env_infos/final/reward_dist Mean        8.23486
eval/env_infos/final/reward_dist Std         3.53028
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.1743
eval/env_infos/initial/reward_dist Mean      0.0418354
eval/env_infos/initial/reward_dist Std       0.0187686
eval/env_infos/initial/reward_dist Max       0.0704403
eval/env_infos/initial/reward_dist Min       0.0180681
eval/env_infos/reward_dist Mean              6.87099
eval/env_infos/reward_dist Std               4.07538
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0167642
time/data storing (s)                        0.0021599
time/evaluation sampling (s)                 1.08178
time/exploration sampling (s)                6.29278
time/logging (s)                             0.00237674
time/saving (s)                              0.00106616
time/training (s)                            4.19164
time/epoch (s)                              11.5718
time/total (s)                            1428.2
Epoch                                       88
---------------------------------------  ---------------
2023-08-03 21:27:17.515292 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 89 finished
---------------------------------------  ---------------
epoch                                       89
replay_buffer/size                       55000
trainer/QF Loss                             90.4148
trainer/Policy Loss                       -277.508
trainer/Raw Policy Loss                   -277.508
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 265.838
trainer/Q Predictions Std                   37.4001
trainer/Q Predictions Max                  374.563
trainer/Q Predictions Min                  125.564
trainer/Q Targets Mean                     265.493
trainer/Q Targets Std                       38.4316
trainer/Q Targets Max                      374.718
trainer/Q Targets Min                      116.333
trainer/Bellman Errors Mean                 90.4148
trainer/Bellman Errors Std                 354.113
trainer/Bellman Errors Max                8455.68
trainer/Bellman Errors Min                   5.36442e-07
trainer/Policy Action Mean                   0.0392062
trainer/Policy Action Std                    0.80953
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     55000
expl/num paths total                      2750
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.03397
expl/Rewards Std                             4.52597
expl/Rewards Max                            10
expl/Rewards Min                             0.000655408
expl/Returns Mean                           80.6795
expl/Returns Std                            73.2599
expl/Returns Max                           190.255
expl/Returns Min                             0.565257
expl/Actions Mean                           -0.0484276
expl/Actions Std                             0.69924
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        80.6795
expl/env_infos/final/reward_dist Mean        6.42052
expl/env_infos/final/reward_dist Std         4.49207
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0087087
expl/env_infos/initial/reward_dist Mean      0.0434946
expl/env_infos/initial/reward_dist Std       0.0577003
expl/env_infos/initial/reward_dist Max       0.25492
expl/env_infos/initial/reward_dist Min       0.00768054
expl/env_infos/reward_dist Mean              4.03397
expl/env_infos/reward_dist Std               4.52597
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000655408
eval/num steps total                      9000
eval/num paths total                       450
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.61174
eval/Rewards Std                             3.34736
eval/Rewards Max                            10
eval/Rewards Min                             0.0106196
eval/Returns Mean                          172.235
eval/Returns Std                            13.0221
eval/Returns Max                           190.082
eval/Returns Min                           154.211
eval/Actions Mean                           -0.136854
eval/Actions Std                             0.606604
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       172.235
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.045018
eval/env_infos/initial/reward_dist Std       0.0261032
eval/env_infos/initial/reward_dist Max       0.082444
eval/env_infos/initial/reward_dist Min       0.0106196
eval/env_infos/reward_dist Mean              8.61174
eval/env_infos/reward_dist Std               3.34736
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0106196
time/data storing (s)                        0.00160742
time/evaluation sampling (s)                 1.00005
time/exploration sampling (s)                5.96604
time/logging (s)                             0.00232609
time/saving (s)                              0.00103918
time/training (s)                            4.15029
time/epoch (s)                              11.1213
time/total (s)                            1439.32
Epoch                                       89
---------------------------------------  ---------------
2023-08-03 21:27:29.532993 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 90 finished
---------------------------------------  ---------------
epoch                                       90
replay_buffer/size                       55500
trainer/QF Loss                             84.1968
trainer/Policy Loss                       -277.437
trainer/Raw Policy Loss                   -277.437
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 265.835
trainer/Q Predictions Std                   37.1563
trainer/Q Predictions Max                  357
trainer/Q Predictions Min                  128.389
trainer/Q Targets Mean                     265.561
trainer/Q Targets Std                       38.3736
trainer/Q Targets Max                      357.116
trainer/Q Targets Min                      130.6
trainer/Bellman Errors Mean                 84.1968
trainer/Bellman Errors Std                 317.69
trainer/Bellman Errors Max                8603.59
trainer/Bellman Errors Min                   4.9267e-07
trainer/Policy Action Mean                   0.0200647
trainer/Policy Action Std                    0.81113
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     55500
expl/num paths total                      2775
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.25212
expl/Rewards Std                             4.63518
expl/Rewards Max                            10
expl/Rewards Min                             7.05932e-05
expl/Returns Mean                          105.042
expl/Returns Std                            75.4399
expl/Returns Max                           190.169
expl/Returns Min                             0.567463
expl/Actions Mean                           -0.0507248
expl/Actions Std                             0.690245
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       105.042
expl/env_infos/final/reward_dist Mean        6.79254
expl/env_infos/final/reward_dist Std         4.34324
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0137666
expl/env_infos/initial/reward_dist Mean      0.0537295
expl/env_infos/initial/reward_dist Std       0.0533993
expl/env_infos/initial/reward_dist Max       0.245649
expl/env_infos/initial/reward_dist Min       0.00804659
expl/env_infos/reward_dist Mean              5.25212
expl/env_infos/reward_dist Std               4.63518
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               7.05932e-05
eval/num steps total                      9100
eval/num paths total                       455
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            5.44936
eval/Rewards Std                             4.12127
eval/Rewards Max                            10
eval/Rewards Min                             0.0146876
eval/Returns Mean                          108.987
eval/Returns Std                            61.5264
eval/Returns Max                           177.642
eval/Returns Min                            33.7808
eval/Actions Mean                           -0.0932012
eval/Actions Std                             0.654343
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       108.987
eval/env_infos/final/reward_dist Mean        7.29646
eval/env_infos/final/reward_dist Std         3.31255
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.08897
eval/env_infos/initial/reward_dist Mean      0.0320297
eval/env_infos/initial/reward_dist Std       0.0169677
eval/env_infos/initial/reward_dist Max       0.0619261
eval/env_infos/initial/reward_dist Min       0.0146876
eval/env_infos/reward_dist Mean              5.44936
eval/env_infos/reward_dist Std               4.12127
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0146876
time/data storing (s)                        0.00161145
time/evaluation sampling (s)                 1.45745
time/exploration sampling (s)                6.12123
time/logging (s)                             0.00225949
time/saving (s)                              0.00103677
time/training (s)                            4.43118
time/epoch (s)                              12.0148
time/total (s)                            1451.34
Epoch                                       90
---------------------------------------  ---------------
2023-08-03 21:27:41.773864 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 91 finished
---------------------------------------  ---------------
epoch                                       91
replay_buffer/size                       56000
trainer/QF Loss                             92.1067
trainer/Policy Loss                       -276.847
trainer/Raw Policy Loss                   -276.847
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 265.301
trainer/Q Predictions Std                   37.5915
trainer/Q Predictions Max                  374.248
trainer/Q Predictions Min                  123.425
trainer/Q Targets Mean                     264.872
trainer/Q Targets Std                       38.7756
trainer/Q Targets Max                      376.82
trainer/Q Targets Min                      122.304
trainer/Bellman Errors Mean                 92.1067
trainer/Bellman Errors Std                 419.295
trainer/Bellman Errors Max               16261.3
trainer/Bellman Errors Min                   7.71228e-06
trainer/Policy Action Mean                   0.0289663
trainer/Policy Action Std                    0.813907
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     56000
expl/num paths total                      2800
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.87481
expl/Rewards Std                             4.60471
expl/Rewards Max                            10
expl/Rewards Min                             0.000295511
expl/Returns Mean                           97.4963
expl/Returns Std                            68.151
expl/Returns Max                           180.64
expl/Returns Min                             0.684333
expl/Actions Mean                           -0.0387395
expl/Actions Std                             0.699371
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        97.4963
expl/env_infos/final/reward_dist Mean        6.70684
expl/env_infos/final/reward_dist Std         4.44039
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00965709
expl/env_infos/initial/reward_dist Mean      0.0344782
expl/env_infos/initial/reward_dist Std       0.0241584
expl/env_infos/initial/reward_dist Max       0.080985
expl/env_infos/initial/reward_dist Min       0.00208087
expl/env_infos/reward_dist Mean              4.87481
expl/env_infos/reward_dist Std               4.60471
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000295511
eval/num steps total                      9200
eval/num paths total                       460
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.65472
eval/Rewards Std                             3.2436
eval/Rewards Max                            10
eval/Rewards Min                             0.0138852
eval/Returns Mean                          173.094
eval/Returns Std                            12.0608
eval/Returns Max                           190.246
eval/Returns Min                           155.714
eval/Actions Mean                           -0.119156
eval/Actions Std                             0.646997
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       173.094
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0855733
eval/env_infos/initial/reward_dist Std       0.0820459
eval/env_infos/initial/reward_dist Max       0.245942
eval/env_infos/initial/reward_dist Min       0.0138852
eval/env_infos/reward_dist Mean              8.65472
eval/env_infos/reward_dist Std               3.2436
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0138852
time/data storing (s)                        0.0021671
time/evaluation sampling (s)                 1.00293
time/exploration sampling (s)                6.88626
time/logging (s)                             0.00216294
time/saving (s)                              0.0098894
time/training (s)                            4.33453
time/epoch (s)                              12.2379
time/total (s)                            1463.58
Epoch                                       91
---------------------------------------  ---------------
2023-08-03 21:27:54.539915 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 92 finished
---------------------------------------  ---------------
epoch                                       92
replay_buffer/size                       56500
trainer/QF Loss                             91.9169
trainer/Policy Loss                       -278.278
trainer/Raw Policy Loss                   -278.278
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 266.666
trainer/Q Predictions Std                   38.3438
trainer/Q Predictions Max                  369.803
trainer/Q Predictions Min                  108.609
trainer/Q Targets Mean                     266.379
trainer/Q Targets Std                       39.3683
trainer/Q Targets Max                      366.564
trainer/Q Targets Min                      110.404
trainer/Bellman Errors Mean                 91.9169
trainer/Bellman Errors Std                 367.162
trainer/Bellman Errors Max                9501.58
trainer/Bellman Errors Min                   7.54371e-08
trainer/Policy Action Mean                   0.020511
trainer/Policy Action Std                    0.811784
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     56500
expl/num paths total                      2825
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.30649
expl/Rewards Std                             4.51185
expl/Rewards Max                            10
expl/Rewards Min                             0.000381184
expl/Returns Mean                          106.13
expl/Returns Std                            69.9743
expl/Returns Max                           184.339
expl/Returns Min                             0.612735
expl/Actions Mean                           -0.0455896
expl/Actions Std                             0.6958
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       106.13
expl/env_infos/final/reward_dist Mean        6.98163
expl/env_infos/final/reward_dist Std         4.17233
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000732003
expl/env_infos/initial/reward_dist Mean      0.0376251
expl/env_infos/initial/reward_dist Std       0.0196554
expl/env_infos/initial/reward_dist Max       0.08163
expl/env_infos/initial/reward_dist Min       0.00266477
expl/env_infos/reward_dist Mean              5.30649
expl/env_infos/reward_dist Std               4.51185
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000381184
eval/num steps total                      9300
eval/num paths total                       465
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.34599
eval/Rewards Std                             3.94469
eval/Rewards Max                            10
eval/Rewards Min                             0.0242843
eval/Returns Mean                          146.92
eval/Returns Std                            54.3981
eval/Returns Max                           183.324
eval/Returns Min                            39.1354
eval/Actions Mean                           -0.183917
eval/Actions Std                             0.660618
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       146.92
eval/env_infos/final/reward_dist Mean        8.6944
eval/env_infos/final/reward_dist Std         2.6112
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.472
eval/env_infos/initial/reward_dist Mean      0.040339
eval/env_infos/initial/reward_dist Std       0.0131273
eval/env_infos/initial/reward_dist Max       0.0520759
eval/env_infos/initial/reward_dist Min       0.0242843
eval/env_infos/reward_dist Mean              7.34599
eval/env_infos/reward_dist Std               3.94469
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0242843
time/data storing (s)                        0.00189651
time/evaluation sampling (s)                 1.11067
time/exploration sampling (s)                6.32531
time/logging (s)                             0.00334029
time/saving (s)                              0.00132322
time/training (s)                            5.32259
time/epoch (s)                              12.7651
time/total (s)                            1476.35
Epoch                                       92
---------------------------------------  ---------------
2023-08-03 21:28:05.191098 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 93 finished
---------------------------------------  ---------------
epoch                                       93
replay_buffer/size                       57000
trainer/QF Loss                             90.1062
trainer/Policy Loss                       -279.17
trainer/Raw Policy Loss                   -279.17
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 267.717
trainer/Q Predictions Std                   38.4028
trainer/Q Predictions Max                  364.91
trainer/Q Predictions Min                  112.748
trainer/Q Targets Mean                     267.588
trainer/Q Targets Std                       39.4926
trainer/Q Targets Max                      368.309
trainer/Q Targets Min                      103.074
trainer/Bellman Errors Mean                 90.1062
trainer/Bellman Errors Std                 404.083
trainer/Bellman Errors Max               17149.9
trainer/Bellman Errors Min                   4.10713e-07
trainer/Policy Action Mean                   0.0016523
trainer/Policy Action Std                    0.811188
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     57000
expl/num paths total                      2850
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            6.12069
expl/Rewards Std                             4.55385
expl/Rewards Max                            10
expl/Rewards Min                             2.23008e-05
expl/Returns Mean                          122.414
expl/Returns Std                            65.0092
expl/Returns Max                           190.075
expl/Returns Min                             0.571219
expl/Actions Mean                           -0.0751502
expl/Actions Std                             0.705106
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       122.414
expl/env_infos/final/reward_dist Mean        7.72381
expl/env_infos/final/reward_dist Std         4.07053
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.23008e-05
expl/env_infos/initial/reward_dist Mean      0.0376813
expl/env_infos/initial/reward_dist Std       0.0265055
expl/env_infos/initial/reward_dist Max       0.124536
expl/env_infos/initial/reward_dist Min       0.00556975
expl/env_infos/reward_dist Mean              6.12069
expl/env_infos/reward_dist Std               4.55385
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.23008e-05
eval/num steps total                      9400
eval/num paths total                       470
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.64819
eval/Rewards Std                             3.25888
eval/Rewards Max                            10
eval/Rewards Min                             0.0191808
eval/Returns Mean                          172.964
eval/Returns Std                             7.44395
eval/Returns Max                           182.79
eval/Returns Min                           164.727
eval/Actions Mean                           -0.225455
eval/Actions Std                             0.607303
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       172.964
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0325672
eval/env_infos/initial/reward_dist Std       0.0145082
eval/env_infos/initial/reward_dist Max       0.053629
eval/env_infos/initial/reward_dist Min       0.0191808
eval/env_infos/reward_dist Mean              8.64819
eval/env_infos/reward_dist Std               3.25888
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0191808
time/data storing (s)                        0.00156288
time/evaluation sampling (s)                 1.14928
time/exploration sampling (s)                5.27769
time/logging (s)                             0.00239626
time/saving (s)                              0.00105074
time/training (s)                            4.21253
time/epoch (s)                              10.6445
time/total (s)                            1487
Epoch                                       93
---------------------------------------  ---------------
2023-08-03 21:28:17.205944 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 94 finished
---------------------------------------  ---------------
epoch                                       94
replay_buffer/size                       57500
trainer/QF Loss                             96.3688
trainer/Policy Loss                       -278.372
trainer/Raw Policy Loss                   -278.372
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 267.06
trainer/Q Predictions Std                   38.6146
trainer/Q Predictions Max                  387.003
trainer/Q Predictions Min                   96.1576
trainer/Q Targets Mean                     266.937
trainer/Q Targets Std                       39.7571
trainer/Q Targets Max                      384.971
trainer/Q Targets Min                       85.6168
trainer/Bellman Errors Mean                 96.3688
trainer/Bellman Errors Std                 387.602
trainer/Bellman Errors Max               10716.6
trainer/Bellman Errors Min                   9.31323e-08
trainer/Policy Action Mean                   0.024499
trainer/Policy Action Std                    0.813201
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     57500
expl/num paths total                      2875
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.78259
expl/Rewards Std                             4.55872
expl/Rewards Max                            10
expl/Rewards Min                             1.21248e-05
expl/Returns Mean                           95.6518
expl/Returns Std                            71.5284
expl/Returns Max                           182.181
expl/Returns Min                             0.417549
expl/Actions Mean                           -0.00834484
expl/Actions Std                             0.715382
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        95.6518
expl/env_infos/final/reward_dist Mean        6.73298
expl/env_infos/final/reward_dist Std         4.4165
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00389005
expl/env_infos/initial/reward_dist Mean      0.0360665
expl/env_infos/initial/reward_dist Std       0.0167997
expl/env_infos/initial/reward_dist Max       0.0754052
expl/env_infos/initial/reward_dist Min       0.00685722
expl/env_infos/reward_dist Mean              4.78259
expl/env_infos/reward_dist Std               4.55872
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.21248e-05
eval/num steps total                      9500
eval/num paths total                       475
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.57071
eval/Rewards Std                             3.24274
eval/Rewards Max                            10
eval/Rewards Min                             0.0143162
eval/Returns Mean                          171.414
eval/Returns Std                             7.66347
eval/Returns Max                           180.989
eval/Returns Min                           159.576
eval/Actions Mean                           -0.0715902
eval/Actions Std                             0.640412
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       171.414
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.036925
eval/env_infos/initial/reward_dist Std       0.0189979
eval/env_infos/initial/reward_dist Max       0.0589957
eval/env_infos/initial/reward_dist Min       0.0143162
eval/env_infos/reward_dist Mean              8.57071
eval/env_infos/reward_dist Std               3.24274
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0143162
time/data storing (s)                        0.0015478
time/evaluation sampling (s)                 1.21941
time/exploration sampling (s)                6.42078
time/logging (s)                             0.00226788
time/saving (s)                              0.00100662
time/training (s)                            4.36501
time/epoch (s)                              12.01
time/total (s)                            1499.01
Epoch                                       94
---------------------------------------  ---------------
2023-08-03 21:28:29.788870 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 95 finished
---------------------------------------  ---------------
epoch                                       95
replay_buffer/size                       58000
trainer/QF Loss                             94.9239
trainer/Policy Loss                       -277.811
trainer/Raw Policy Loss                   -277.811
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 266.333
trainer/Q Predictions Std                   38.9277
trainer/Q Predictions Max                  369.434
trainer/Q Predictions Min                  111.504
trainer/Q Targets Mean                     266.554
trainer/Q Targets Std                       40.129
trainer/Q Targets Max                      373.251
trainer/Q Targets Min                      122.503
trainer/Bellman Errors Mean                 94.9239
trainer/Bellman Errors Std                 340.608
trainer/Bellman Errors Max                9578.16
trainer/Bellman Errors Min                   3.54135e-07
trainer/Policy Action Mean                  -0.00644884
trainer/Policy Action Std                    0.813205
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     58000
expl/num paths total                      2900
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.58081
expl/Rewards Std                             4.39889
expl/Rewards Max                            10
expl/Rewards Min                             6.38856e-06
expl/Returns Mean                           71.6162
expl/Returns Std                            68.3826
expl/Returns Max                           174.886
expl/Returns Min                             0.435199
expl/Actions Mean                           -0.0915712
expl/Actions Std                             0.698339
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        71.6162
expl/env_infos/final/reward_dist Mean        5.44967
expl/env_infos/final/reward_dist Std         4.80725
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00100564
expl/env_infos/initial/reward_dist Mean      0.0337499
expl/env_infos/initial/reward_dist Std       0.0363426
expl/env_infos/initial/reward_dist Max       0.192378
expl/env_infos/initial/reward_dist Min       0.00057747
expl/env_infos/reward_dist Mean              3.58081
expl/env_infos/reward_dist Std               4.39889
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.38856e-06
eval/num steps total                      9600
eval/num paths total                       480
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.31207
eval/Rewards Std                             3.38852
eval/Rewards Max                            10
eval/Rewards Min                             0.0186605
eval/Returns Mean                          166.241
eval/Returns Std                             6.74064
eval/Returns Max                           177.366
eval/Returns Min                           158.951
eval/Actions Mean                           -0.124886
eval/Actions Std                             0.644523
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       166.241
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0849402
eval/env_infos/initial/reward_dist Std       0.102726
eval/env_infos/initial/reward_dist Max       0.289163
eval/env_infos/initial/reward_dist Min       0.0186605
eval/env_infos/reward_dist Mean              8.31207
eval/env_infos/reward_dist Std               3.38852
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0186605
time/data storing (s)                        0.00216921
time/evaluation sampling (s)                 1.12994
time/exploration sampling (s)                7.07759
time/logging (s)                             0.00225272
time/saving (s)                              0.00103474
time/training (s)                            4.36708
time/epoch (s)                              12.5801
time/total (s)                            1511.59
Epoch                                       95
---------------------------------------  ---------------
2023-08-03 21:28:41.254052 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 96 finished
---------------------------------------  ---------------
epoch                                       96
replay_buffer/size                       58500
trainer/QF Loss                             98.1105
trainer/Policy Loss                       -277.194
trainer/Raw Policy Loss                   -277.194
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 265.905
trainer/Q Predictions Std                   39.9295
trainer/Q Predictions Max                  367.971
trainer/Q Predictions Min                   89.2953
trainer/Q Targets Mean                     266.187
trainer/Q Targets Std                       41.4141
trainer/Q Targets Max                      366.894
trainer/Q Targets Min                       76.1888
trainer/Bellman Errors Mean                 98.1105
trainer/Bellman Errors Std                 364.441
trainer/Bellman Errors Max                8079.35
trainer/Bellman Errors Min                   1.59824e-05
trainer/Policy Action Mean                  -0.0013398
trainer/Policy Action Std                    0.81263
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     58500
expl/num paths total                      2925
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.83785
expl/Rewards Std                             4.61515
expl/Rewards Max                            10
expl/Rewards Min                             0.000227407
expl/Returns Mean                           96.757
expl/Returns Std                            74.1779
expl/Returns Max                           190.069
expl/Returns Min                             0.46497
expl/Actions Mean                           -0.0596543
expl/Actions Std                             0.709936
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        96.757
expl/env_infos/final/reward_dist Mean        6.21578
expl/env_infos/final/reward_dist Std         4.67693
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00245441
expl/env_infos/initial/reward_dist Mean      0.0806523
expl/env_infos/initial/reward_dist Std       0.157144
expl/env_infos/initial/reward_dist Max       0.820932
expl/env_infos/initial/reward_dist Min       0.00831806
expl/env_infos/reward_dist Mean              4.83785
expl/env_infos/reward_dist Std               4.61515
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000227407
eval/num steps total                      9700
eval/num paths total                       485
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.49188
eval/Rewards Std                             3.37708
eval/Rewards Max                            10
eval/Rewards Min                             0.0219947
eval/Returns Mean                          169.838
eval/Returns Std                            12.3503
eval/Returns Max                           181.357
eval/Returns Min                           146.182
eval/Actions Mean                           -0.168343
eval/Actions Std                             0.577615
eval/Actions Max                             1
eval/Actions Min                            -0.999999
eval/Num Paths                               5
eval/Average Returns                       169.838
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0518828
eval/env_infos/initial/reward_dist Std       0.0201967
eval/env_infos/initial/reward_dist Max       0.0729747
eval/env_infos/initial/reward_dist Min       0.0219947
eval/env_infos/reward_dist Mean              8.49188
eval/env_infos/reward_dist Std               3.37708
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0219947
time/data storing (s)                        0.00218151
time/evaluation sampling (s)                 0.971594
time/exploration sampling (s)                6.33723
time/logging (s)                             0.00227973
time/saving (s)                              0.000989186
time/training (s)                            4.14815
time/epoch (s)                              11.4624
time/total (s)                            1523.06
Epoch                                       96
---------------------------------------  ---------------
2023-08-03 21:28:51.866221 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 97 finished
---------------------------------------  ---------------
epoch                                       97
replay_buffer/size                       59000
trainer/QF Loss                             92.3463
trainer/Policy Loss                       -277.244
trainer/Raw Policy Loss                   -277.244
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 265.887
trainer/Q Predictions Std                   39.9787
trainer/Q Predictions Max                  383.157
trainer/Q Predictions Min                   88.0828
trainer/Q Targets Mean                     265.689
trainer/Q Targets Std                       41.3254
trainer/Q Targets Max                      385.853
trainer/Q Targets Min                       75.5687
trainer/Bellman Errors Mean                 92.3463
trainer/Bellman Errors Std                 292.223
trainer/Bellman Errors Max                5756.55
trainer/Bellman Errors Min                   0.000122719
trainer/Policy Action Mean                  -0.013776
trainer/Policy Action Std                    0.815043
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     59000
expl/num paths total                      2950
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.23939
expl/Rewards Std                             4.71146
expl/Rewards Max                            10
expl/Rewards Min                             3.16637e-05
expl/Returns Mean                          104.788
expl/Returns Std                            69.7601
expl/Returns Max                           181.498
expl/Returns Min                             0.305315
expl/Actions Mean                           -0.0673978
expl/Actions Std                             0.696251
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       104.788
expl/env_infos/final/reward_dist Mean        6.94341
expl/env_infos/final/reward_dist Std         4.4884
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00121082
expl/env_infos/initial/reward_dist Mean      0.0387419
expl/env_infos/initial/reward_dist Std       0.0231452
expl/env_infos/initial/reward_dist Max       0.0894581
expl/env_infos/initial/reward_dist Min       0.00770885
expl/env_infos/reward_dist Mean              5.23939
expl/env_infos/reward_dist Std               4.71146
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               3.16637e-05
eval/num steps total                      9800
eval/num paths total                       490
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.86601
eval/Rewards Std                             4.46411
eval/Rewards Max                            10
eval/Rewards Min                             0.00731179
eval/Returns Mean                          137.32
eval/Returns Std                            46.053
eval/Returns Max                           165.768
eval/Returns Min                            45.6597
eval/Actions Mean                           -0.133254
eval/Actions Std                             0.636668
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       137.32
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0489131
eval/env_infos/initial/reward_dist Std       0.0068436
eval/env_infos/initial/reward_dist Max       0.0572355
eval/env_infos/initial/reward_dist Min       0.0390207
eval/env_infos/reward_dist Mean              6.86601
eval/env_infos/reward_dist Std               4.46411
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00731179
time/data storing (s)                        0.00154986
time/evaluation sampling (s)                 1.04746
time/exploration sampling (s)                5.37437
time/logging (s)                             0.00229304
time/saving (s)                              0.00100033
time/training (s)                            4.18227
time/epoch (s)                              10.609
time/total (s)                            1533.67
Epoch                                       97
---------------------------------------  ---------------
2023-08-03 21:29:03.532851 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 98 finished
---------------------------------------  ---------------
epoch                                       98
replay_buffer/size                       59500
trainer/QF Loss                            107.29
trainer/Policy Loss                       -280.433
trainer/Raw Policy Loss                   -280.433
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 268.251
trainer/Q Predictions Std                   41.0837
trainer/Q Predictions Max                  382.747
trainer/Q Predictions Min                   74.4124
trainer/Q Targets Mean                     268.168
trainer/Q Targets Std                       42.4413
trainer/Q Targets Max                      390.35
trainer/Q Targets Min                       66.5216
trainer/Bellman Errors Mean                107.29
trainer/Bellman Errors Std                 475.35
trainer/Bellman Errors Max               17289
trainer/Bellman Errors Min                   1.14087e-06
trainer/Policy Action Mean                   0.00284248
trainer/Policy Action Std                    0.834189
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     59500
expl/num paths total                      2975
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.10832
expl/Rewards Std                             4.69746
expl/Rewards Max                            10
expl/Rewards Min                             1.74237e-05
expl/Returns Mean                          102.166
expl/Returns Std                            63.2579
expl/Returns Max                           180.679
expl/Returns Min                             0.262952
expl/Actions Mean                           -0.0711464
expl/Actions Std                             0.705793
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       102.166
expl/env_infos/final/reward_dist Mean        7.30475
expl/env_infos/final/reward_dist Std         4.34174
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00150141
expl/env_infos/initial/reward_dist Mean      0.0362378
expl/env_infos/initial/reward_dist Std       0.0191545
expl/env_infos/initial/reward_dist Max       0.0690855
expl/env_infos/initial/reward_dist Min       0.00606429
expl/env_infos/reward_dist Mean              5.10832
expl/env_infos/reward_dist Std               4.69746
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.74237e-05
eval/num steps total                      9900
eval/num paths total                       495
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.74743
eval/Rewards Std                             3.05102
eval/Rewards Max                            10
eval/Rewards Min                             0.0234695
eval/Returns Mean                          174.949
eval/Returns Std                            13.4744
eval/Returns Max                           190.161
eval/Returns Min                           151.114
eval/Actions Mean                           -0.135596
eval/Actions Std                             0.758738
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       174.949
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0622775
eval/env_infos/initial/reward_dist Std       0.050334
eval/env_infos/initial/reward_dist Max       0.161445
eval/env_infos/initial/reward_dist Min       0.0234695
eval/env_infos/reward_dist Mean              8.74743
eval/env_infos/reward_dist Std               3.05102
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0234695
time/data storing (s)                        0.0017107
time/evaluation sampling (s)                 1.24378
time/exploration sampling (s)                6.39271
time/logging (s)                             0.00229093
time/saving (s)                              0.00101447
time/training (s)                            4.02216
time/epoch (s)                              11.6637
time/total (s)                            1545.33
Epoch                                       98
---------------------------------------  ---------------
2023-08-03 21:29:15.362702 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 99 finished
---------------------------------------  ---------------
epoch                                       99
replay_buffer/size                       60000
trainer/QF Loss                            113.933
trainer/Policy Loss                       -285.958
trainer/Raw Policy Loss                   -285.958
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 273.537
trainer/Q Predictions Std                   42.8293
trainer/Q Predictions Max                  391.831
trainer/Q Predictions Min                  105.764
trainer/Q Targets Mean                     273.237
trainer/Q Targets Std                       44.388
trainer/Q Targets Max                      392.017
trainer/Q Targets Min                      101.48
trainer/Bellman Errors Mean                113.933
trainer/Bellman Errors Std                 426.587
trainer/Bellman Errors Max               11439.7
trainer/Bellman Errors Min                   1.57394e-05
trainer/Policy Action Mean                  -0.0012315
trainer/Policy Action Std                    0.842779
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     60000
expl/num paths total                      3000
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.53591
expl/Rewards Std                             4.69734
expl/Rewards Max                            10
expl/Rewards Min                             0.000299536
expl/Returns Mean                           90.7182
expl/Returns Std                            75.7235
expl/Returns Max                           190.167
expl/Returns Min                             0.543812
expl/Actions Mean                           -0.0414711
expl/Actions Std                             0.736836
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        90.7182
expl/env_infos/final/reward_dist Mean        6.01491
expl/env_infos/final/reward_dist Std         4.88079
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00179129
expl/env_infos/initial/reward_dist Mean      0.0474339
expl/env_infos/initial/reward_dist Std       0.0372106
expl/env_infos/initial/reward_dist Max       0.167485
expl/env_infos/initial/reward_dist Min       0.00875478
expl/env_infos/reward_dist Mean              4.53591
expl/env_infos/reward_dist Std               4.69734
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000299536
eval/num steps total                     10000
eval/num paths total                       500
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.57705
eval/Rewards Std                             4.48035
eval/Rewards Max                            10
eval/Rewards Min                             0.00517834
eval/Returns Mean                          131.541
eval/Returns Std                            68.0633
eval/Returns Max                           190.069
eval/Returns Min                             0.964708
eval/Actions Mean                           -0.038422
eval/Actions Std                             0.722729
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       131.541
eval/env_infos/final/reward_dist Mean        8.0054
eval/env_infos/final/reward_dist Std         3.9892
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0269952
eval/env_infos/initial/reward_dist Mean      0.0410052
eval/env_infos/initial/reward_dist Std       0.0230093
eval/env_infos/initial/reward_dist Max       0.0685277
eval/env_infos/initial/reward_dist Min       0.00517834
eval/env_infos/reward_dist Mean              6.57705
eval/env_infos/reward_dist Std               4.48035
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00517834
time/data storing (s)                        0.00159494
time/evaluation sampling (s)                 1.10532
time/exploration sampling (s)                5.97534
time/logging (s)                             0.00327213
time/saving (s)                              0.00129005
time/training (s)                            4.74114
time/epoch (s)                              11.828
time/total (s)                            1557.16
Epoch                                       99
---------------------------------------  ---------------
2023-08-03 21:29:26.365200 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 100 finished
---------------------------------------  ---------------
epoch                                      100
replay_buffer/size                       60500
trainer/QF Loss                             96.1337
trainer/Policy Loss                       -288.817
trainer/Raw Policy Loss                   -288.817
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 276.604
trainer/Q Predictions Std                   39.9057
trainer/Q Predictions Max                  388.094
trainer/Q Predictions Min                  117.302
trainer/Q Targets Mean                     276.52
trainer/Q Targets Std                       41.1778
trainer/Q Targets Max                      388.551
trainer/Q Targets Min                      111.723
trainer/Bellman Errors Mean                 96.1337
trainer/Bellman Errors Std                 372.091
trainer/Bellman Errors Max               15363.5
trainer/Bellman Errors Min                   6.72881e-08
trainer/Policy Action Mean                  -0.0208233
trainer/Policy Action Std                    0.841892
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     60500
expl/num paths total                      3025
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.74989
expl/Rewards Std                             4.69479
expl/Rewards Max                            10
expl/Rewards Min                             0.000137148
expl/Returns Mean                           94.9978
expl/Returns Std                            68.939
expl/Returns Max                           184.125
expl/Returns Min                             0.459326
expl/Actions Mean                           -0.0508458
expl/Actions Std                             0.72228
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        94.9978
expl/env_infos/final/reward_dist Mean        6.68526
expl/env_infos/final/reward_dist Std         4.47904
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000267049
expl/env_infos/initial/reward_dist Mean      0.0308671
expl/env_infos/initial/reward_dist Std       0.0168744
expl/env_infos/initial/reward_dist Max       0.0585734
expl/env_infos/initial/reward_dist Min       0.00408785
expl/env_infos/reward_dist Mean              4.74989
expl/env_infos/reward_dist Std               4.69479
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000137148
eval/num steps total                     10100
eval/num paths total                       505
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            5.80593
eval/Rewards Std                             4.23232
eval/Rewards Max                            10
eval/Rewards Min                             0.0167013
eval/Returns Mean                          116.119
eval/Returns Std                            45.9879
eval/Returns Max                           159.17
eval/Returns Min                            37.4855
eval/Actions Mean                           -0.116292
eval/Actions Std                             0.774317
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       116.119
eval/env_infos/final/reward_dist Mean        8.33076
eval/env_infos/final/reward_dist Std         3.33847
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.65382
eval/env_infos/initial/reward_dist Mean      0.0608006
eval/env_infos/initial/reward_dist Std       0.0133583
eval/env_infos/initial/reward_dist Max       0.0772627
eval/env_infos/initial/reward_dist Min       0.0401321
eval/env_infos/reward_dist Mean              5.80593
eval/env_infos/reward_dist Std               4.23232
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0167013
time/data storing (s)                        0.0015906
time/evaluation sampling (s)                 1.31697
time/exploration sampling (s)                5.56625
time/logging (s)                             0.00229311
time/saving (s)                              0.00103823
time/training (s)                            4.10964
time/epoch (s)                              10.9978
time/total (s)                            1568.16
Epoch                                      100
---------------------------------------  ---------------
2023-08-03 21:29:38.061233 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 101 finished
---------------------------------------  ---------------
epoch                                      101
replay_buffer/size                       61000
trainer/QF Loss                             99.6806
trainer/Policy Loss                       -290.849
trainer/Raw Policy Loss                   -290.849
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 278.986
trainer/Q Predictions Std                   39.5294
trainer/Q Predictions Max                  398.592
trainer/Q Predictions Min                  141.302
trainer/Q Targets Mean                     279.469
trainer/Q Targets Std                       40.7182
trainer/Q Targets Max                      394.024
trainer/Q Targets Min                      143.977
trainer/Bellman Errors Mean                 99.6806
trainer/Bellman Errors Std                 367.716
trainer/Bellman Errors Max               14858.3
trainer/Bellman Errors Min                   1.52588e-05
trainer/Policy Action Mean                   0.00766169
trainer/Policy Action Std                    0.843112
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     61000
expl/num paths total                      3050
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.81109
expl/Rewards Std                             4.47497
expl/Rewards Max                            10
expl/Rewards Min                             0.00017862
expl/Returns Mean                           96.2218
expl/Returns Std                            63.6535
expl/Returns Max                           182.948
expl/Returns Min                             0.864751
expl/Actions Mean                           -0.0392414
expl/Actions Std                             0.734031
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        96.2218
expl/env_infos/final/reward_dist Mean        7.13821
expl/env_infos/final/reward_dist Std         4.22619
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00406194
expl/env_infos/initial/reward_dist Mean      0.0315278
expl/env_infos/initial/reward_dist Std       0.0289393
expl/env_infos/initial/reward_dist Max       0.151164
expl/env_infos/initial/reward_dist Min       0.00353696
expl/env_infos/reward_dist Mean              4.81109
expl/env_infos/reward_dist Std               4.47497
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00017862
eval/num steps total                     10200
eval/num paths total                       510
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.3932
eval/Rewards Std                             3.82079
eval/Rewards Max                            10
eval/Rewards Min                             0.00560053
eval/Returns Mean                          147.864
eval/Returns Std                            50.6579
eval/Returns Max                           176.913
eval/Returns Min                            46.9052
eval/Actions Mean                           -0.118965
eval/Actions Std                             0.668793
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       147.864
eval/env_infos/final/reward_dist Mean        8.66034
eval/env_infos/final/reward_dist Std         2.67931
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.30172
eval/env_infos/initial/reward_dist Mean      0.0277794
eval/env_infos/initial/reward_dist Std       0.0191076
eval/env_infos/initial/reward_dist Max       0.05854
eval/env_infos/initial/reward_dist Min       0.00560053
eval/env_infos/reward_dist Mean              7.3932
eval/env_infos/reward_dist Std               3.82079
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00560053
time/data storing (s)                        0.00158012
time/evaluation sampling (s)                 1.29098
time/exploration sampling (s)                6.09646
time/logging (s)                             0.00231587
time/saving (s)                              0.00112948
time/training (s)                            4.29934
time/epoch (s)                              11.6918
time/total (s)                            1579.86
Epoch                                      101
---------------------------------------  ---------------
2023-08-03 21:29:50.003168 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 102 finished
---------------------------------------  ---------------
epoch                                      102
replay_buffer/size                       61500
trainer/QF Loss                            107.71
trainer/Policy Loss                       -291.423
trainer/Raw Policy Loss                   -291.423
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 279.555
trainer/Q Predictions Std                   41.1041
trainer/Q Predictions Max                  387.951
trainer/Q Predictions Min                  122.196
trainer/Q Targets Mean                     280.373
trainer/Q Targets Std                       42.2719
trainer/Q Targets Max                      396.418
trainer/Q Targets Min                      110.228
trainer/Bellman Errors Mean                107.71
trainer/Bellman Errors Std                 353.572
trainer/Bellman Errors Max                5848.67
trainer/Bellman Errors Min                   8.49403e-05
trainer/Policy Action Mean                   0.0322403
trainer/Policy Action Std                    0.854387
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     61500
expl/num paths total                      3075
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.12423
expl/Rewards Std                             4.39336
expl/Rewards Max                            10
expl/Rewards Min                             0.00013288
expl/Returns Mean                           82.4847
expl/Returns Std                            68.2425
expl/Returns Max                           190.087
expl/Returns Min                             0.426204
expl/Actions Mean                           -0.0362637
expl/Actions Std                             0.728315
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        82.4847
expl/env_infos/final/reward_dist Mean        6.08987
expl/env_infos/final/reward_dist Std         4.51397
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000644412
expl/env_infos/initial/reward_dist Mean      0.0346914
expl/env_infos/initial/reward_dist Std       0.0186533
expl/env_infos/initial/reward_dist Max       0.0873156
expl/env_infos/initial/reward_dist Min       0.013575
expl/env_infos/reward_dist Mean              4.12423
expl/env_infos/reward_dist Std               4.39336
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00013288
eval/num steps total                     10300
eval/num paths total                       515
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.04035
eval/Rewards Std                             3.93552
eval/Rewards Max                            10
eval/Rewards Min                             0.0153824
eval/Returns Mean                          140.807
eval/Returns Std                            38.6925
eval/Returns Max                           182.56
eval/Returns Min                            71.3671
eval/Actions Mean                           -0.0683335
eval/Actions Std                             0.720101
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       140.807
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0445991
eval/env_infos/initial/reward_dist Std       0.0207772
eval/env_infos/initial/reward_dist Max       0.0769159
eval/env_infos/initial/reward_dist Min       0.0204691
eval/env_infos/reward_dist Mean              7.04035
eval/env_infos/reward_dist Std               3.93552
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0153824
time/data storing (s)                        0.00154793
time/evaluation sampling (s)                 1.13526
time/exploration sampling (s)                6.01373
time/logging (s)                             0.0033374
time/saving (s)                              0.00128292
time/training (s)                            4.78388
time/epoch (s)                              11.939
time/total (s)                            1591.8
Epoch                                      102
---------------------------------------  ---------------
2023-08-03 21:30:00.706356 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 103 finished
---------------------------------------  ---------------
epoch                                      103
replay_buffer/size                       62000
trainer/QF Loss                            121.614
trainer/Policy Loss                       -296.969
trainer/Raw Policy Loss                   -296.969
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 284.563
trainer/Q Predictions Std                   42.9155
trainer/Q Predictions Max                  398.479
trainer/Q Predictions Min                  132.555
trainer/Q Targets Mean                     285.123
trainer/Q Targets Std                       44.0203
trainer/Q Targets Max                      395.868
trainer/Q Targets Min                      134.811
trainer/Bellman Errors Mean                121.614
trainer/Bellman Errors Std                 528.901
trainer/Bellman Errors Max               16961.1
trainer/Bellman Errors Min                   1.31885e-05
trainer/Policy Action Mean                   0.0644486
trainer/Policy Action Std                    0.871596
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     62000
expl/num paths total                      3100
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.18618
expl/Rewards Std                             4.48399
expl/Rewards Max                            10
expl/Rewards Min                             0.000179489
expl/Returns Mean                          103.724
expl/Returns Std                            61.3271
expl/Returns Max                           190.053
expl/Returns Min                             0.507212
expl/Actions Mean                            0.0208496
expl/Actions Std                             0.761279
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       103.724
expl/env_infos/final/reward_dist Mean        7.59998
expl/env_infos/final/reward_dist Std         3.921
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0102662
expl/env_infos/initial/reward_dist Mean      0.04649
expl/env_infos/initial/reward_dist Std       0.0460537
expl/env_infos/initial/reward_dist Max       0.2405
expl/env_infos/initial/reward_dist Min       0.00369442
expl/env_infos/reward_dist Mean              5.18618
expl/env_infos/reward_dist Std               4.48399
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000179489
eval/num steps total                     10400
eval/num paths total                       520
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.75161
eval/Rewards Std                             4.48035
eval/Rewards Max                            10
eval/Rewards Min                             0.0029925
eval/Returns Mean                          135.032
eval/Returns Std                            69.1498
eval/Returns Max                           190.126
eval/Returns Min                             5.55535
eval/Actions Mean                            0.0749295
eval/Actions Std                             0.832077
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       135.032
eval/env_infos/final/reward_dist Mean        8.06072
eval/env_infos/final/reward_dist Std         3.87856
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.3036
eval/env_infos/initial/reward_dist Mean      0.0634571
eval/env_infos/initial/reward_dist Std       0.0320195
eval/env_infos/initial/reward_dist Max       0.126022
eval/env_infos/initial/reward_dist Min       0.0372116
eval/env_infos/reward_dist Mean              6.75161
eval/env_infos/reward_dist Std               4.48035
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0029925
time/data storing (s)                        0.00159626
time/evaluation sampling (s)                 1.05289
time/exploration sampling (s)                5.52458
time/logging (s)                             0.00237576
time/saving (s)                              0.0010063
time/training (s)                            4.116
time/epoch (s)                              10.6985
time/total (s)                            1602.5
Epoch                                      103
---------------------------------------  ---------------
2023-08-03 21:30:11.348335 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 104 finished
---------------------------------------  ---------------
epoch                                      104
replay_buffer/size                       62500
trainer/QF Loss                            107.149
trainer/Policy Loss                       -298.631
trainer/Raw Policy Loss                   -298.631
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 286.58
trainer/Q Predictions Std                   41.5369
trainer/Q Predictions Max                  383.295
trainer/Q Predictions Min                  130.689
trainer/Q Targets Mean                     286.662
trainer/Q Targets Std                       42.4949
trainer/Q Targets Max                      378.671
trainer/Q Targets Min                      135.501
trainer/Bellman Errors Mean                107.149
trainer/Bellman Errors Std                 295.592
trainer/Bellman Errors Max                4775
trainer/Bellman Errors Min                   1.07626e-05
trainer/Policy Action Mean                   0.0398048
trainer/Policy Action Std                    0.877738
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     62500
expl/num paths total                      3125
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.08503
expl/Rewards Std                             4.48808
expl/Rewards Max                            10
expl/Rewards Min                             2.15797e-08
expl/Returns Mean                           81.7006
expl/Returns Std                            72.6133
expl/Returns Max                           190.343
expl/Returns Min                             0.0738459
expl/Actions Mean                            0.0240959
expl/Actions Std                             0.772564
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        81.7006
expl/env_infos/final/reward_dist Mean        5.88049
expl/env_infos/final/reward_dist Std         4.68266
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         3.43101e-08
expl/env_infos/initial/reward_dist Mean      0.0486099
expl/env_infos/initial/reward_dist Std       0.0633916
expl/env_infos/initial/reward_dist Max       0.342853
expl/env_infos/initial/reward_dist Min       0.00783105
expl/env_infos/reward_dist Mean              4.08503
expl/env_infos/reward_dist Std               4.48808
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.15797e-08
eval/num steps total                     10500
eval/num paths total                       525
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.22034
eval/Rewards Std                             4.02483
eval/Rewards Max                            10
eval/Rewards Min                             0.0102835
eval/Returns Mean                          144.407
eval/Returns Std                            58.2118
eval/Returns Max                           190.05
eval/Returns Min                            29.891
eval/Actions Mean                           -0.09822
eval/Actions Std                             0.857554
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       144.407
eval/env_infos/final/reward_dist Mean        8.32786
eval/env_infos/final/reward_dist Std         3.34428
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.63929
eval/env_infos/initial/reward_dist Mean      0.0405636
eval/env_infos/initial/reward_dist Std       0.0155238
eval/env_infos/initial/reward_dist Max       0.052438
eval/env_infos/initial/reward_dist Min       0.0102835
eval/env_infos/reward_dist Mean              7.22034
eval/env_infos/reward_dist Std               4.02483
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0102835
time/data storing (s)                        0.00156384
time/evaluation sampling (s)                 1.04638
time/exploration sampling (s)                5.68128
time/logging (s)                             0.00227478
time/saving (s)                              0.00104736
time/training (s)                            3.90466
time/epoch (s)                              10.6372
time/total (s)                            1613.14
Epoch                                      104
---------------------------------------  ---------------
2023-08-03 21:30:24.182993 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 105 finished
---------------------------------------  ---------------
epoch                                      105
replay_buffer/size                       63000
trainer/QF Loss                            104.493
trainer/Policy Loss                       -300.417
trainer/Raw Policy Loss                   -300.417
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 288.68
trainer/Q Predictions Std                   39.9333
trainer/Q Predictions Max                  379.304
trainer/Q Predictions Min                  118.744
trainer/Q Targets Mean                     288.108
trainer/Q Targets Std                       41.4711
trainer/Q Targets Max                      384.524
trainer/Q Targets Min                      107.009
trainer/Bellman Errors Mean                104.493
trainer/Bellman Errors Std                 368.219
trainer/Bellman Errors Max               11733.8
trainer/Bellman Errors Min                   3.35276e-06
trainer/Policy Action Mean                   0.0249198
trainer/Policy Action Std                    0.871141
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     63000
expl/num paths total                      3150
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.3984
expl/Rewards Std                             4.01339
expl/Rewards Max                            10
expl/Rewards Min                             8.9711e-05
expl/Returns Mean                           67.968
expl/Returns Std                            63.1983
expl/Returns Max                           173.265
expl/Returns Min                             0.575679
expl/Actions Mean                           -0.0127679
expl/Actions Std                             0.762343
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        67.968
expl/env_infos/final/reward_dist Mean        5.26458
expl/env_infos/final/reward_dist Std         4.12147
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0113234
expl/env_infos/initial/reward_dist Mean      0.0347652
expl/env_infos/initial/reward_dist Std       0.0166679
expl/env_infos/initial/reward_dist Max       0.0716661
expl/env_infos/initial/reward_dist Min       0.00466834
expl/env_infos/reward_dist Mean              3.3984
expl/env_infos/reward_dist Std               4.01339
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               8.9711e-05
eval/num steps total                     10600
eval/num paths total                       530
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            5.29235
eval/Rewards Std                             4.35621
eval/Rewards Max                            10
eval/Rewards Min                             0.0132486
eval/Returns Mean                          105.847
eval/Returns Std                            65.7816
eval/Returns Max                           180.146
eval/Returns Min                            25.3614
eval/Actions Mean                            0.00798942
eval/Actions Std                             0.828524
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       105.847
eval/env_infos/final/reward_dist Mean        6.95797
eval/env_infos/final/reward_dist Std         3.75929
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.6022
eval/env_infos/initial/reward_dist Mean      0.0258694
eval/env_infos/initial/reward_dist Std       0.0124778
eval/env_infos/initial/reward_dist Max       0.0498477
eval/env_infos/initial/reward_dist Min       0.0132486
eval/env_infos/reward_dist Mean              5.29235
eval/env_infos/reward_dist Std               4.35621
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0132486
time/data storing (s)                        0.00155843
time/evaluation sampling (s)                 1.46415
time/exploration sampling (s)                7.26663
time/logging (s)                             0.00229339
time/saving (s)                              0.000989593
time/training (s)                            4.0961
time/epoch (s)                              12.8317
time/total (s)                            1625.98
Epoch                                      105
---------------------------------------  ---------------
2023-08-03 21:30:36.476912 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 106 finished
---------------------------------------  ---------------
epoch                                      106
replay_buffer/size                       63500
trainer/QF Loss                             96.4408
trainer/Policy Loss                       -294.486
trainer/Raw Policy Loss                   -294.486
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 283.106
trainer/Q Predictions Std                   38.5152
trainer/Q Predictions Max                  370.743
trainer/Q Predictions Min                  148.426
trainer/Q Targets Mean                     282.873
trainer/Q Targets Std                       39.9345
trainer/Q Targets Max                      375.696
trainer/Q Targets Min                      144.066
trainer/Bellman Errors Mean                 96.4408
trainer/Bellman Errors Std                 313.314
trainer/Bellman Errors Max                6445.73
trainer/Bellman Errors Min                   4.56348e-08
trainer/Policy Action Mean                   0.0104058
trainer/Policy Action Std                    0.866108
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     63500
expl/num paths total                      3175
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.45729
expl/Rewards Std                             4.46622
expl/Rewards Max                            10
expl/Rewards Min                             0.00013525
expl/Returns Mean                          109.146
expl/Returns Std                            62.7555
expl/Returns Max                           190.038
expl/Returns Min                             0.453912
expl/Actions Mean                           -0.0252474
expl/Actions Std                             0.748633
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       109.146
expl/env_infos/final/reward_dist Mean        7.71656
expl/env_infos/final/reward_dist Std         3.72908
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000520615
expl/env_infos/initial/reward_dist Mean      0.0366435
expl/env_infos/initial/reward_dist Std       0.013829
expl/env_infos/initial/reward_dist Max       0.0670912
expl/env_infos/initial/reward_dist Min       0.0126105
expl/env_infos/reward_dist Mean              5.45729
expl/env_infos/reward_dist Std               4.46622
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00013525
eval/num steps total                     10700
eval/num paths total                       535
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.70489
eval/Rewards Std                             4.31562
eval/Rewards Max                            10
eval/Rewards Min                             0.011239
eval/Returns Mean                          134.098
eval/Returns Std                            57.51
eval/Returns Max                           184.091
eval/Returns Min                            24.7576
eval/Actions Mean                           -0.00246015
eval/Actions Std                             0.846662
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       134.098
eval/env_infos/final/reward_dist Mean        8.51219
eval/env_infos/final/reward_dist Std         2.97561
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         2.56097
eval/env_infos/initial/reward_dist Mean      0.0420025
eval/env_infos/initial/reward_dist Std       0.0127346
eval/env_infos/initial/reward_dist Max       0.0622774
eval/env_infos/initial/reward_dist Min       0.0221855
eval/env_infos/reward_dist Mean              6.70489
eval/env_infos/reward_dist Std               4.31562
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.011239
time/data storing (s)                        0.00158796
time/evaluation sampling (s)                 1.22405
time/exploration sampling (s)                6.92438
time/logging (s)                             0.0022709
time/saving (s)                              0.000996539
time/training (s)                            4.13774
time/epoch (s)                              12.291
time/total (s)                            1638.27
Epoch                                      106
---------------------------------------  ---------------
2023-08-03 21:30:48.156698 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 107 finished
---------------------------------------  ---------------
epoch                                      107
replay_buffer/size                       64000
trainer/QF Loss                             86.8232
trainer/Policy Loss                       -288.905
trainer/Raw Policy Loss                   -288.905
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 277.877
trainer/Q Predictions Std                   37.2543
trainer/Q Predictions Max                  366.549
trainer/Q Predictions Min                  167.067
trainer/Q Targets Mean                     278.366
trainer/Q Targets Std                       38.2433
trainer/Q Targets Max                      370.579
trainer/Q Targets Min                      158.028
trainer/Bellman Errors Mean                 86.8232
trainer/Bellman Errors Std                 253.965
trainer/Bellman Errors Max                5422.19
trainer/Bellman Errors Min                   3.58e-06
trainer/Policy Action Mean                   0.0212956
trainer/Policy Action Std                    0.863506
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     64000
expl/num paths total                      3200
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            6.11827
expl/Rewards Std                             4.27144
expl/Rewards Max                            10
expl/Rewards Min                             0.00203091
expl/Returns Mean                          122.365
expl/Returns Std                            52.0047
expl/Returns Max                           181.679
expl/Returns Min                             0.852941
expl/Actions Mean                           -0.0588507
expl/Actions Std                             0.740596
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       122.365
expl/env_infos/final/reward_dist Mean        9.31809
expl/env_infos/final/reward_dist Std         2.34904
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0161602
expl/env_infos/initial/reward_dist Mean      0.0377143
expl/env_infos/initial/reward_dist Std       0.0166967
expl/env_infos/initial/reward_dist Max       0.0653161
expl/env_infos/initial/reward_dist Min       0.00470861
expl/env_infos/reward_dist Mean              6.11827
expl/env_infos/reward_dist Std               4.27144
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00203091
eval/num steps total                     10800
eval/num paths total                       540
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.82662
eval/Rewards Std                             3.98727
eval/Rewards Max                            10
eval/Rewards Min                             0.035125
eval/Returns Mean                          136.532
eval/Returns Std                            48.5072
eval/Returns Max                           175.826
eval/Returns Min                            43.7761
eval/Actions Mean                           -0.151791
eval/Actions Std                             0.792851
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       136.532
eval/env_infos/final/reward_dist Mean        8.6558
eval/env_infos/final/reward_dist Std         2.68841
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.27898
eval/env_infos/initial/reward_dist Mean      0.0524148
eval/env_infos/initial/reward_dist Std       0.0153037
eval/env_infos/initial/reward_dist Max       0.0713487
eval/env_infos/initial/reward_dist Min       0.035125
eval/env_infos/reward_dist Mean              6.82662
eval/env_infos/reward_dist Std               3.98727
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.035125
time/data storing (s)                        0.00219541
time/evaluation sampling (s)                 1.07235
time/exploration sampling (s)                6.42504
time/logging (s)                             0.00230759
time/saving (s)                              0.000994206
time/training (s)                            4.17406
time/epoch (s)                              11.677
time/total (s)                            1649.95
Epoch                                      107
---------------------------------------  ---------------
2023-08-03 21:30:59.186355 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 108 finished
---------------------------------------  ---------------
epoch                                      108
replay_buffer/size                       64500
trainer/QF Loss                             80.2464
trainer/Policy Loss                       -283.064
trainer/Raw Policy Loss                   -283.064
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 272.396
trainer/Q Predictions Std                   36.564
trainer/Q Predictions Max                  359.971
trainer/Q Predictions Min                  121.741
trainer/Q Targets Mean                     272.46
trainer/Q Targets Std                       37.6268
trainer/Q Targets Max                      361.988
trainer/Q Targets Min                      107.594
trainer/Bellman Errors Mean                 80.2464
trainer/Bellman Errors Std                 231.144
trainer/Bellman Errors Max                5259.72
trainer/Bellman Errors Min                   2.32831e-10
trainer/Policy Action Mean                   0.0299828
trainer/Policy Action Std                    0.865973
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     64500
expl/num paths total                      3225
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.15238
expl/Rewards Std                             4.33838
expl/Rewards Max                            10
expl/Rewards Min                             2.74943e-05
expl/Returns Mean                           83.0477
expl/Returns Std                            62.2266
expl/Returns Max                           180.219
expl/Returns Min                             0.522322
expl/Actions Mean                           -0.00852091
expl/Actions Std                             0.748129
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        83.0477
expl/env_infos/final/reward_dist Mean        6.40257
expl/env_infos/final/reward_dist Std         4.44775
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00386799
expl/env_infos/initial/reward_dist Mean      0.0475912
expl/env_infos/initial/reward_dist Std       0.0260317
expl/env_infos/initial/reward_dist Max       0.0907557
expl/env_infos/initial/reward_dist Min       0.00712317
expl/env_infos/reward_dist Mean              4.15238
expl/env_infos/reward_dist Std               4.33838
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.74943e-05
eval/num steps total                     10900
eval/num paths total                       545
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.08932
eval/Rewards Std                             3.96054
eval/Rewards Max                            10
eval/Rewards Min                             0.0154173
eval/Returns Mean                          141.786
eval/Returns Std                            57.6262
eval/Returns Max                           190.326
eval/Returns Min                            34.3522
eval/Actions Mean                           -0.0811968
eval/Actions Std                             0.781448
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       141.786
eval/env_infos/final/reward_dist Mean        8.37113
eval/env_infos/final/reward_dist Std         3.25775
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.85563
eval/env_infos/initial/reward_dist Mean      0.0984479
eval/env_infos/initial/reward_dist Std       0.116506
eval/env_infos/initial/reward_dist Max       0.326368
eval/env_infos/initial/reward_dist Min       0.0154173
eval/env_infos/reward_dist Mean              7.08932
eval/env_infos/reward_dist Std               3.96054
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0154173
time/data storing (s)                        0.00216653
time/evaluation sampling (s)                 1.12805
time/exploration sampling (s)                5.7266
time/logging (s)                             0.0023476
time/saving (s)                              0.000992618
time/training (s)                            4.16629
time/epoch (s)                              11.0265
time/total (s)                            1660.98
Epoch                                      108
---------------------------------------  ---------------
2023-08-03 21:31:11.356217 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 109 finished
---------------------------------------  ---------------
epoch                                      109
replay_buffer/size                       65000
trainer/QF Loss                             86.1745
trainer/Policy Loss                       -279.735
trainer/Raw Policy Loss                   -279.735
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 268.706
trainer/Q Predictions Std                   36.4638
trainer/Q Predictions Max                  362.043
trainer/Q Predictions Min                  100.327
trainer/Q Targets Mean                     268.66
trainer/Q Targets Std                       37.6328
trainer/Q Targets Max                      362.357
trainer/Q Targets Min                       92.5661
trainer/Bellman Errors Mean                 86.1745
trainer/Bellman Errors Std                 241.795
trainer/Bellman Errors Max                4960.48
trainer/Bellman Errors Min                   2.05729e-06
trainer/Policy Action Mean                   0.0171731
trainer/Policy Action Std                    0.860504
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     65000
expl/num paths total                      3250
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.90087
expl/Rewards Std                             4.42784
expl/Rewards Max                            10
expl/Rewards Min                             0.000172633
expl/Returns Mean                           98.0174
expl/Returns Std                            65.2174
expl/Returns Max                           185.059
expl/Returns Min                             0.428461
expl/Actions Mean                           -0.0444485
expl/Actions Std                             0.728974
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        98.0174
expl/env_infos/final/reward_dist Mean        7.02524
expl/env_infos/final/reward_dist Std         4.06671
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0349165
expl/env_infos/initial/reward_dist Mean      0.0350005
expl/env_infos/initial/reward_dist Std       0.017316
expl/env_infos/initial/reward_dist Max       0.0786089
expl/env_infos/initial/reward_dist Min       0.0137025
expl/env_infos/reward_dist Mean              4.90087
expl/env_infos/reward_dist Std               4.42784
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000172633
eval/num steps total                     11000
eval/num paths total                       550
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.34096
eval/Rewards Std                             3.98577
eval/Rewards Max                            10
eval/Rewards Min                             0.0129056
eval/Returns Mean                          146.819
eval/Returns Std                            24.4307
eval/Returns Max                           181.422
eval/Returns Min                           114.402
eval/Actions Mean                           -0.0261725
eval/Actions Std                             0.802617
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       146.819
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0288165
eval/env_infos/initial/reward_dist Std       0.0108052
eval/env_infos/initial/reward_dist Max       0.043235
eval/env_infos/initial/reward_dist Min       0.0156617
eval/env_infos/reward_dist Mean              7.34096
eval/env_infos/reward_dist Std               3.98577
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0129056
time/data storing (s)                        0.00155946
time/evaluation sampling (s)                 1.28137
time/exploration sampling (s)                6.41162
time/logging (s)                             0.00309963
time/saving (s)                              0.0013013
time/training (s)                            4.46685
time/epoch (s)                              12.1658
time/total (s)                            1673.15
Epoch                                      109
---------------------------------------  ---------------
2023-08-03 21:31:23.109817 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 110 finished
---------------------------------------  ---------------
epoch                                      110
replay_buffer/size                       65500
trainer/QF Loss                             89.0198
trainer/Policy Loss                       -277.536
trainer/Raw Policy Loss                   -277.536
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 266.922
trainer/Q Predictions Std                   36.6944
trainer/Q Predictions Max                  355.818
trainer/Q Predictions Min                   91.0722
trainer/Q Targets Mean                     266.924
trainer/Q Targets Std                       37.9912
trainer/Q Targets Max                      356.555
trainer/Q Targets Min                       93.6561
trainer/Bellman Errors Mean                 89.0198
trainer/Bellman Errors Std                 286.041
trainer/Bellman Errors Max                5300.03
trainer/Bellman Errors Min                   3.93484e-06
trainer/Policy Action Mean                   0.0309174
trainer/Policy Action Std                    0.85642
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     65500
expl/num paths total                      3275
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.61724
expl/Rewards Std                             4.75484
expl/Rewards Max                            10
expl/Rewards Min                             2.46252e-07
expl/Returns Mean                           92.3449
expl/Returns Std                            75.7249
expl/Returns Max                           190.042
expl/Returns Min                             0.618289
expl/Actions Mean                           -0.0073176
expl/Actions Std                             0.746289
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        92.3449
expl/env_infos/final/reward_dist Mean        6.81401
expl/env_infos/final/reward_dist Std         4.64444
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.46252e-07
expl/env_infos/initial/reward_dist Mean      0.0305986
expl/env_infos/initial/reward_dist Std       0.0202827
expl/env_infos/initial/reward_dist Max       0.0753704
expl/env_infos/initial/reward_dist Min       0.00320769
expl/env_infos/reward_dist Mean              4.61724
expl/env_infos/reward_dist Std               4.75484
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.46252e-07
eval/num steps total                     11100
eval/num paths total                       555
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.5654
eval/Rewards Std                             3.24086
eval/Rewards Max                            10
eval/Rewards Min                             0.0104318
eval/Returns Mean                          171.308
eval/Returns Std                             8.16996
eval/Returns Max                           180.735
eval/Returns Min                           157.347
eval/Actions Mean                           -0.00987567
eval/Actions Std                             0.742518
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       171.308
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0487863
eval/env_infos/initial/reward_dist Std       0.0192435
eval/env_infos/initial/reward_dist Max       0.0608072
eval/env_infos/initial/reward_dist Min       0.0104318
eval/env_infos/reward_dist Mean              8.5654
eval/env_infos/reward_dist Std               3.24086
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0104318
time/data storing (s)                        0.00190489
time/evaluation sampling (s)                 1.24677
time/exploration sampling (s)                6.1261
time/logging (s)                             0.00230637
time/saving (s)                              0.00104368
time/training (s)                            4.3708
time/epoch (s)                              11.7489
time/total (s)                            1684.9
Epoch                                      110
---------------------------------------  ---------------
2023-08-03 21:31:34.370730 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 111 finished
---------------------------------------  ---------------
epoch                                      111
replay_buffer/size                       66000
trainer/QF Loss                             81.3063
trainer/Policy Loss                       -274.597
trainer/Raw Policy Loss                   -274.597
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 263.982
trainer/Q Predictions Std                   35.6889
trainer/Q Predictions Max                  351.586
trainer/Q Predictions Min                   88.6162
trainer/Q Targets Mean                     264.018
trainer/Q Targets Std                       36.7471
trainer/Q Targets Max                      359.827
trainer/Q Targets Min                       89.9383
trainer/Bellman Errors Mean                 81.3063
trainer/Bellman Errors Std                 253.618
trainer/Bellman Errors Max                4978.12
trainer/Bellman Errors Min                   4.30644e-06
trainer/Policy Action Mean                   0.0208678
trainer/Policy Action Std                    0.855339
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     66000
expl/num paths total                      3300
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.80887
expl/Rewards Std                             4.60616
expl/Rewards Max                            10
expl/Rewards Min                             0.00021903
expl/Returns Mean                          116.177
expl/Returns Std                            62.7718
expl/Returns Max                           190.393
expl/Returns Min                             0.425617
expl/Actions Mean                           -0.00375649
expl/Actions Std                             0.736446
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       116.177
expl/env_infos/final/reward_dist Mean        8.11262
expl/env_infos/final/reward_dist Std         3.80565
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00754016
expl/env_infos/initial/reward_dist Mean      0.0487379
expl/env_infos/initial/reward_dist Std       0.0737884
expl/env_infos/initial/reward_dist Max       0.392504
expl/env_infos/initial/reward_dist Min       0.00691571
expl/env_infos/reward_dist Mean              5.80887
expl/env_infos/reward_dist Std               4.60616
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00021903
eval/num steps total                     11200
eval/num paths total                       560
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.20063
eval/Rewards Std                             3.89116
eval/Rewards Max                            10
eval/Rewards Min                             0.0130104
eval/Returns Mean                          144.013
eval/Returns Std                            52.6486
eval/Returns Max                           190.062
eval/Returns Min                            41.4934
eval/Actions Mean                            0.013867
eval/Actions Std                             0.735052
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       144.013
eval/env_infos/final/reward_dist Mean        8.39058
eval/env_infos/final/reward_dist Std         3.21883
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.95291
eval/env_infos/initial/reward_dist Mean      0.0378677
eval/env_infos/initial/reward_dist Std       0.0205657
eval/env_infos/initial/reward_dist Max       0.0623736
eval/env_infos/initial/reward_dist Min       0.0130104
eval/env_infos/reward_dist Mean              7.20063
eval/env_infos/reward_dist Std               3.89116
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0130104
time/data storing (s)                        0.0016074
time/evaluation sampling (s)                 1.0957
time/exploration sampling (s)                5.89403
time/logging (s)                             0.00243948
time/saving (s)                              0.00103272
time/training (s)                            4.26331
time/epoch (s)                              11.2581
time/total (s)                            1696.16
Epoch                                      111
---------------------------------------  ---------------
2023-08-03 21:31:45.416453 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 112 finished
---------------------------------------  ---------------
epoch                                      112
replay_buffer/size                       66500
trainer/QF Loss                             83.5754
trainer/Policy Loss                       -275.582
trainer/Raw Policy Loss                   -275.582
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 264.943
trainer/Q Predictions Std                   36.1376
trainer/Q Predictions Max                  356.893
trainer/Q Predictions Min                  132.836
trainer/Q Targets Mean                     264.76
trainer/Q Targets Std                       37.4454
trainer/Q Targets Max                      356.136
trainer/Q Targets Min                      125.41
trainer/Bellman Errors Mean                 83.5754
trainer/Bellman Errors Std                 246.764
trainer/Bellman Errors Max                4950.53
trainer/Bellman Errors Min                   4.56348e-08
trainer/Policy Action Mean                   0.031544
trainer/Policy Action Std                    0.852054
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     66500
expl/num paths total                      3325
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.1198
expl/Rewards Std                             4.57422
expl/Rewards Max                            10
expl/Rewards Min                             2.28195e-05
expl/Returns Mean                          102.396
expl/Returns Std                            69.7974
expl/Returns Max                           185.054
expl/Returns Min                             0.51607
expl/Actions Mean                           -0.0151673
expl/Actions Std                             0.74539
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       102.396
expl/env_infos/final/reward_dist Mean        7.13466
expl/env_infos/final/reward_dist Std         4.26071
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000498867
expl/env_infos/initial/reward_dist Mean      0.0395042
expl/env_infos/initial/reward_dist Std       0.0298256
expl/env_infos/initial/reward_dist Max       0.135443
expl/env_infos/initial/reward_dist Min       0.00250335
expl/env_infos/reward_dist Mean              5.1198
expl/env_infos/reward_dist Std               4.57422
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.28195e-05
eval/num steps total                     11300
eval/num paths total                       565
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.40452
eval/Rewards Std                             3.36912
eval/Rewards Max                            10
eval/Rewards Min                             0.0180189
eval/Returns Mean                          168.09
eval/Returns Std                             7.96581
eval/Returns Max                           177.022
eval/Returns Min                           154.602
eval/Actions Mean                           -0.0548351
eval/Actions Std                             0.763063
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       168.09
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.043587
eval/env_infos/initial/reward_dist Std       0.0191592
eval/env_infos/initial/reward_dist Max       0.0682583
eval/env_infos/initial/reward_dist Min       0.0180189
eval/env_infos/reward_dist Mean              8.40452
eval/env_infos/reward_dist Std               3.36912
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0180189
time/data storing (s)                        0.00155614
time/evaluation sampling (s)                 1.06115
time/exploration sampling (s)                5.72696
time/logging (s)                             0.00234648
time/saving (s)                              0.00108116
time/training (s)                            4.24791
time/epoch (s)                              11.041
time/total (s)                            1707.2
Epoch                                      112
---------------------------------------  ---------------
2023-08-03 21:31:57.118768 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 113 finished
---------------------------------------  ---------------
epoch                                      113
replay_buffer/size                       67000
trainer/QF Loss                             83.963
trainer/Policy Loss                       -273.46
trainer/Raw Policy Loss                   -273.46
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 262.923
trainer/Q Predictions Std                   36.5327
trainer/Q Predictions Max                  353.176
trainer/Q Predictions Min                  134.926
trainer/Q Targets Mean                     263.279
trainer/Q Targets Std                       37.4714
trainer/Q Targets Max                      355.159
trainer/Q Targets Min                      140.621
trainer/Bellman Errors Mean                 83.963
trainer/Bellman Errors Std                 264.319
trainer/Bellman Errors Max                6669.65
trainer/Bellman Errors Min                   5.96046e-06
trainer/Policy Action Mean                   0.0425355
trainer/Policy Action Std                    0.84998
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     67000
expl/num paths total                      3350
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.08204
expl/Rewards Std                             4.42505
expl/Rewards Max                            10
expl/Rewards Min                             5.0914e-05
expl/Returns Mean                           81.6408
expl/Returns Std                            69.9609
expl/Returns Max                           183.277
expl/Returns Min                             0.332055
expl/Actions Mean                           -0.000125928
expl/Actions Std                             0.745019
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        81.6408
expl/env_infos/final/reward_dist Mean        5.81321
expl/env_infos/final/reward_dist Std         4.75627
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000285332
expl/env_infos/initial/reward_dist Mean      0.0589487
expl/env_infos/initial/reward_dist Std       0.106688
expl/env_infos/initial/reward_dist Max       0.569469
expl/env_infos/initial/reward_dist Min       0.00202205
expl/env_infos/reward_dist Mean              4.08204
expl/env_infos/reward_dist Std               4.42505
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               5.0914e-05
eval/num steps total                     11400
eval/num paths total                       570
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.29896
eval/Rewards Std                             3.37763
eval/Rewards Max                            10
eval/Rewards Min                             0.0334065
eval/Returns Mean                          165.979
eval/Returns Std                            20.6853
eval/Returns Max                           190.539
eval/Returns Min                           136.522
eval/Actions Mean                           -0.138606
eval/Actions Std                             0.773287
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       165.979
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.149166
eval/env_infos/initial/reward_dist Std       0.19527
eval/env_infos/initial/reward_dist Max       0.538733
eval/env_infos/initial/reward_dist Min       0.0334065
eval/env_infos/reward_dist Mean              8.29896
eval/env_infos/reward_dist Std               3.37763
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0334065
time/data storing (s)                        0.00155993
time/evaluation sampling (s)                 1.50314
time/exploration sampling (s)                5.86436
time/logging (s)                             0.00292839
time/saving (s)                              0.00111091
time/training (s)                            4.32668
time/epoch (s)                              11.6998
time/total (s)                            1718.91
Epoch                                      113
---------------------------------------  ---------------
2023-08-03 21:32:09.124502 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 114 finished
---------------------------------------  ---------------
epoch                                      114
replay_buffer/size                       67500
trainer/QF Loss                             78.5849
trainer/Policy Loss                       -273.989
trainer/Raw Policy Loss                   -273.989
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 263.559
trainer/Q Predictions Std                   35.497
trainer/Q Predictions Max                  358.607
trainer/Q Predictions Min                  103.108
trainer/Q Targets Mean                     263.001
trainer/Q Targets Std                       36.5502
trainer/Q Targets Max                      354.784
trainer/Q Targets Min                      103.012
trainer/Bellman Errors Mean                 78.5849
trainer/Bellman Errors Std                 237.701
trainer/Bellman Errors Max                5737.81
trainer/Bellman Errors Min                   5.82077e-09
trainer/Policy Action Mean                   0.00780268
trainer/Policy Action Std                    0.841077
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     67500
expl/num paths total                      3375
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.13133
expl/Rewards Std                             4.55104
expl/Rewards Max                            10
expl/Rewards Min                             2.21986e-05
expl/Returns Mean                          102.627
expl/Returns Std                            68.1915
expl/Returns Max                           184.566
expl/Returns Min                             0.218554
expl/Actions Mean                           -0.0296492
expl/Actions Std                             0.725374
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       102.627
expl/env_infos/final/reward_dist Mean        7.07536
expl/env_infos/final/reward_dist Std         4.31394
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00076469
expl/env_infos/initial/reward_dist Mean      0.0334803
expl/env_infos/initial/reward_dist Std       0.0216481
expl/env_infos/initial/reward_dist Max       0.105131
expl/env_infos/initial/reward_dist Min       0.00710691
expl/env_infos/reward_dist Mean              5.13133
expl/env_infos/reward_dist Std               4.55104
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.21986e-05
eval/num steps total                     11500
eval/num paths total                       575
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.5913
eval/Rewards Std                             3.18421
eval/Rewards Max                            10
eval/Rewards Min                             0.0548682
eval/Returns Mean                          171.826
eval/Returns Std                            12.9179
eval/Returns Max                           190.064
eval/Returns Min                           152.946
eval/Actions Mean                           -0.0501924
eval/Actions Std                             0.782017
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       171.826
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0636732
eval/env_infos/initial/reward_dist Std       0.00582472
eval/env_infos/initial/reward_dist Max       0.0719187
eval/env_infos/initial/reward_dist Min       0.0548682
eval/env_infos/reward_dist Mean              8.5913
eval/env_infos/reward_dist Std               3.18421
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0548682
time/data storing (s)                        0.00160293
time/evaluation sampling (s)                 1.0885
time/exploration sampling (s)                6.62328
time/logging (s)                             0.00228835
time/saving (s)                              0.0010004
time/training (s)                            4.28453
time/epoch (s)                              12.0012
time/total (s)                            1730.91
Epoch                                      114
---------------------------------------  ---------------
2023-08-03 21:32:20.866050 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 115 finished
---------------------------------------  ---------------
epoch                                      115
replay_buffer/size                       68000
trainer/QF Loss                             79.3852
trainer/Policy Loss                       -272.054
trainer/Raw Policy Loss                   -272.054
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 261.772
trainer/Q Predictions Std                   35.5036
trainer/Q Predictions Max                  355.991
trainer/Q Predictions Min                  126.526
trainer/Q Targets Mean                     261.571
trainer/Q Targets Std                       36.7814
trainer/Q Targets Max                      359.322
trainer/Q Targets Min                      115.29
trainer/Bellman Errors Mean                 79.3852
trainer/Bellman Errors Std                 245.553
trainer/Bellman Errors Max                6156.99
trainer/Bellman Errors Min                   7.56467e-07
trainer/Policy Action Mean                   0.0145444
trainer/Policy Action Std                    0.839634
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     68000
expl/num paths total                      3400
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.09495
expl/Rewards Std                             4.40874
expl/Rewards Max                            10
expl/Rewards Min                             0.000495873
expl/Returns Mean                           81.8989
expl/Returns Std                            62.9219
expl/Returns Max                           173.726
expl/Returns Min                             0.494623
expl/Actions Mean                           -0.0204068
expl/Actions Std                             0.716031
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        81.8989
expl/env_infos/final/reward_dist Mean        6.69075
expl/env_infos/final/reward_dist Std         4.4923
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00308131
expl/env_infos/initial/reward_dist Mean      0.0325044
expl/env_infos/initial/reward_dist Std       0.0182324
expl/env_infos/initial/reward_dist Max       0.0708996
expl/env_infos/initial/reward_dist Min       0.00515376
expl/env_infos/reward_dist Mean              4.09495
expl/env_infos/reward_dist Std               4.40874
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000495873
eval/num steps total                     11600
eval/num paths total                       580
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.93965
eval/Rewards Std                             3.59151
eval/Rewards Max                            10
eval/Rewards Min                             0.0183344
eval/Returns Mean                          158.793
eval/Returns Std                            16.9741
eval/Returns Max                           178.044
eval/Returns Min                           129.19
eval/Actions Mean                           -0.170672
eval/Actions Std                             0.698562
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       158.793
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0377074
eval/env_infos/initial/reward_dist Std       0.0144223
eval/env_infos/initial/reward_dist Max       0.053355
eval/env_infos/initial/reward_dist Min       0.0183344
eval/env_infos/reward_dist Mean              7.93965
eval/env_infos/reward_dist Std               3.59151
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0183344
time/data storing (s)                        0.00216784
time/evaluation sampling (s)                 1.03665
time/exploration sampling (s)                6.52638
time/logging (s)                             0.00233923
time/saving (s)                              0.00103363
time/training (s)                            4.17013
time/epoch (s)                              11.7387
time/total (s)                            1742.65
Epoch                                      115
---------------------------------------  ---------------
2023-08-03 21:32:32.509514 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 116 finished
---------------------------------------  ---------------
epoch                                      116
replay_buffer/size                       68500
trainer/QF Loss                             81.7794
trainer/Policy Loss                       -271.552
trainer/Raw Policy Loss                   -271.552
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 261.225
trainer/Q Predictions Std                   36.369
trainer/Q Predictions Max                  359.39
trainer/Q Predictions Min                  133.935
trainer/Q Targets Mean                     260.775
trainer/Q Targets Std                       37.4846
trainer/Q Targets Max                      361.91
trainer/Q Targets Min                      136.262
trainer/Bellman Errors Mean                 81.7794
trainer/Bellman Errors Std                 260.475
trainer/Bellman Errors Max                6489.89
trainer/Bellman Errors Min                   1.88593e-06
trainer/Policy Action Mean                  -0.0104591
trainer/Policy Action Std                    0.837228
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     68500
expl/num paths total                      3425
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.52445
expl/Rewards Std                             4.39346
expl/Rewards Max                            10
expl/Rewards Min                             0.000191947
expl/Returns Mean                          110.489
expl/Returns Std                            63.2954
expl/Returns Max                           181.675
expl/Returns Min                             0.814276
expl/Actions Mean                           -0.076263
expl/Actions Std                             0.735498
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       110.489
expl/env_infos/final/reward_dist Mean        8.10076
expl/env_infos/final/reward_dist Std         3.44568
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.14499
expl/env_infos/initial/reward_dist Mean      0.036515
expl/env_infos/initial/reward_dist Std       0.018463
expl/env_infos/initial/reward_dist Max       0.066992
expl/env_infos/initial/reward_dist Min       0.00783468
expl/env_infos/reward_dist Mean              5.52445
expl/env_infos/reward_dist Std               4.39346
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000191947
eval/num steps total                     11700
eval/num paths total                       585
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.40966
eval/Rewards Std                             4.21785
eval/Rewards Max                            10
eval/Rewards Min                             0.00461729
eval/Returns Mean                          148.193
eval/Returns Std                            70.1983
eval/Returns Max                           190.098
eval/Returns Min                             8.35666
eval/Actions Mean                           -0.0133919
eval/Actions Std                             0.751365
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       148.193
eval/env_infos/final/reward_dist Mean        8.80643
eval/env_infos/final/reward_dist Std         2.38713
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         4.03217
eval/env_infos/initial/reward_dist Mean      0.165787
eval/env_infos/initial/reward_dist Std       0.193357
eval/env_infos/initial/reward_dist Max       0.549796
eval/env_infos/initial/reward_dist Min       0.0282422
eval/env_infos/reward_dist Mean              7.40966
eval/env_infos/reward_dist Std               4.21785
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00461729
time/data storing (s)                        0.0015576
time/evaluation sampling (s)                 1.28585
time/exploration sampling (s)                6.03147
time/logging (s)                             0.00233398
time/saving (s)                              0.00112811
time/training (s)                            4.31815
time/epoch (s)                              11.6405
time/total (s)                            1754.29
Epoch                                      116
---------------------------------------  ---------------
2023-08-03 21:32:44.748380 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 117 finished
---------------------------------------  ---------------
epoch                                      117
replay_buffer/size                       69000
trainer/QF Loss                             82.8863
trainer/Policy Loss                       -271.597
trainer/Raw Policy Loss                   -271.597
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 261.491
trainer/Q Predictions Std                   35.2465
trainer/Q Predictions Max                  355.279
trainer/Q Predictions Min                  137.846
trainer/Q Targets Mean                     261.202
trainer/Q Targets Std                       36.4283
trainer/Q Targets Max                      355.786
trainer/Q Targets Min                      127.322
trainer/Bellman Errors Mean                 82.8863
trainer/Bellman Errors Std                 252.666
trainer/Bellman Errors Max                5839.41
trainer/Bellman Errors Min                   5.96046e-06
trainer/Policy Action Mean                  -0.0125803
trainer/Policy Action Std                    0.834511
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     69000
expl/num paths total                      3450
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.42482
expl/Rewards Std                             4.59233
expl/Rewards Max                            10
expl/Rewards Min                             0.0011336
expl/Returns Mean                          108.496
expl/Returns Std                            74.7674
expl/Returns Max                           190.243
expl/Returns Min                             0.543375
expl/Actions Mean                           -0.0228286
expl/Actions Std                             0.713914
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       108.496
expl/env_infos/final/reward_dist Mean        6.53956
expl/env_infos/final/reward_dist Std         4.35263
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00556637
expl/env_infos/initial/reward_dist Mean      0.0489004
expl/env_infos/initial/reward_dist Std       0.0593053
expl/env_infos/initial/reward_dist Max       0.242534
expl/env_infos/initial/reward_dist Min       0.00504605
expl/env_infos/reward_dist Mean              5.42482
expl/env_infos/reward_dist Std               4.59233
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.0011336
eval/num steps total                     11800
eval/num paths total                       590
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.49721
eval/Rewards Std                             3.37429
eval/Rewards Max                            10
eval/Rewards Min                             0.0175545
eval/Returns Mean                          169.944
eval/Returns Std                            13.3893
eval/Returns Max                           183.392
eval/Returns Min                           145.57
eval/Actions Mean                           -0.110289
eval/Actions Std                             0.748916
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       169.944
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0405748
eval/env_infos/initial/reward_dist Std       0.0239853
eval/env_infos/initial/reward_dist Max       0.0848896
eval/env_infos/initial/reward_dist Min       0.0175545
eval/env_infos/reward_dist Mean              8.49721
eval/env_infos/reward_dist Std               3.37429
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0175545
time/data storing (s)                        0.00155449
time/evaluation sampling (s)                 1.23452
time/exploration sampling (s)                6.6398
time/logging (s)                             0.00227615
time/saving (s)                              0.0010209
time/training (s)                            4.35622
time/epoch (s)                              12.2354
time/total (s)                            1766.53
Epoch                                      117
---------------------------------------  ---------------
2023-08-03 21:32:56.398298 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 118 finished
---------------------------------------  ---------------
epoch                                      118
replay_buffer/size                       69500
trainer/QF Loss                             80.3612
trainer/Policy Loss                       -269.805
trainer/Raw Policy Loss                   -269.805
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 259.734
trainer/Q Predictions Std                   35.056
trainer/Q Predictions Max                  354.316
trainer/Q Predictions Min                  146.665
trainer/Q Targets Mean                     260.434
trainer/Q Targets Std                       36.3649
trainer/Q Targets Max                      359.373
trainer/Q Targets Min                      140.038
trainer/Bellman Errors Mean                 80.3612
trainer/Bellman Errors Std                 269.417
trainer/Bellman Errors Max                6156.07
trainer/Bellman Errors Min                   2.75522e-05
trainer/Policy Action Mean                  -0.015135
trainer/Policy Action Std                    0.834137
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     69500
expl/num paths total                      3475
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.71502
expl/Rewards Std                             4.62774
expl/Rewards Max                            10
expl/Rewards Min                             1.66313e-05
expl/Returns Mean                           94.3004
expl/Returns Std                            68.7714
expl/Returns Max                           190.021
expl/Returns Min                             0.428844
expl/Actions Mean                           -0.036621
expl/Actions Std                             0.723126
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        94.3004
expl/env_infos/final/reward_dist Mean        6.55419
expl/env_infos/final/reward_dist Std         4.60945
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0122855
expl/env_infos/initial/reward_dist Mean      0.0329063
expl/env_infos/initial/reward_dist Std       0.0149143
expl/env_infos/initial/reward_dist Max       0.0624477
expl/env_infos/initial/reward_dist Min       0.00604773
expl/env_infos/reward_dist Mean              4.71502
expl/env_infos/reward_dist Std               4.62774
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.66313e-05
eval/num steps total                     11900
eval/num paths total                       595
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.61253
eval/Rewards Std                             3.23004
eval/Rewards Max                            10
eval/Rewards Min                             0.0117774
eval/Returns Mean                          172.251
eval/Returns Std                             6.48027
eval/Returns Max                           180.99
eval/Returns Min                           164.048
eval/Actions Mean                           -0.0459382
eval/Actions Std                             0.766523
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       172.251
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0421887
eval/env_infos/initial/reward_dist Std       0.019945
eval/env_infos/initial/reward_dist Max       0.0649427
eval/env_infos/initial/reward_dist Min       0.0117774
eval/env_infos/reward_dist Mean              8.61253
eval/env_infos/reward_dist Std               3.23004
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0117774
time/data storing (s)                        0.00216839
time/evaluation sampling (s)                 0.982216
time/exploration sampling (s)                6.9239
time/logging (s)                             0.00172261
time/saving (s)                              0.00078509
time/training (s)                            3.73566
time/epoch (s)                              11.6464
time/total (s)                            1778.18
Epoch                                      118
---------------------------------------  ---------------
2023-08-03 21:33:07.563153 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 119 finished
---------------------------------------  ---------------
epoch                                      119
replay_buffer/size                       70000
trainer/QF Loss                             85.7238
trainer/Policy Loss                       -270.825
trainer/Raw Policy Loss                   -270.825
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 260.807
trainer/Q Predictions Std                   35.8006
trainer/Q Predictions Max                  353.146
trainer/Q Predictions Min                  140.315
trainer/Q Targets Mean                     260.668
trainer/Q Targets Std                       36.8525
trainer/Q Targets Max                      362.88
trainer/Q Targets Min                      135.737
trainer/Bellman Errors Mean                 85.7238
trainer/Bellman Errors Std                 296.866
trainer/Bellman Errors Max                8722.82
trainer/Bellman Errors Min                   2.2375e-07
trainer/Policy Action Mean                  -0.0206028
trainer/Policy Action Std                    0.835506
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     70000
expl/num paths total                      3500
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.82054
expl/Rewards Std                             4.56417
expl/Rewards Max                            10
expl/Rewards Min                             0.000805424
expl/Returns Mean                          116.411
expl/Returns Std                            74.8558
expl/Returns Max                           184.66
expl/Returns Min                             0.454005
expl/Actions Mean                           -0.0574197
expl/Actions Std                             0.717847
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       116.411
expl/env_infos/final/reward_dist Mean        6.84763
expl/env_infos/final/reward_dist Std         4.31059
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00890006
expl/env_infos/initial/reward_dist Mean      0.0507403
expl/env_infos/initial/reward_dist Std       0.0550946
expl/env_infos/initial/reward_dist Max       0.304868
expl/env_infos/initial/reward_dist Min       0.0115914
expl/env_infos/reward_dist Mean              5.82054
expl/env_infos/reward_dist Std               4.56417
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000805424
eval/num steps total                     12000
eval/num paths total                       600
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.37137
eval/Rewards Std                             3.77129
eval/Rewards Max                            10
eval/Rewards Min                             0.0360955
eval/Returns Mean                          147.427
eval/Returns Std                            51.1189
eval/Returns Max                           190.038
eval/Returns Min                            51.7776
eval/Actions Mean                           -0.0460408
eval/Actions Std                             0.734273
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       147.427
eval/env_infos/final/reward_dist Mean        8.00885
eval/env_infos/final/reward_dist Std         3.9823
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0442508
eval/env_infos/initial/reward_dist Mean      0.0470682
eval/env_infos/initial/reward_dist Std       0.0149604
eval/env_infos/initial/reward_dist Max       0.0757943
eval/env_infos/initial/reward_dist Min       0.0360955
eval/env_infos/reward_dist Mean              7.37137
eval/env_infos/reward_dist Std               3.77129
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0360955
time/data storing (s)                        0.00159626
time/evaluation sampling (s)                 1.08669
time/exploration sampling (s)                5.88183
time/logging (s)                             0.00239567
time/saving (s)                              0.00108564
time/training (s)                            4.18971
time/epoch (s)                              11.1633
time/total (s)                            1789.34
Epoch                                      119
---------------------------------------  ---------------
2023-08-03 21:33:18.659513 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 120 finished
---------------------------------------  ---------------
epoch                                      120
replay_buffer/size                       70500
trainer/QF Loss                             88.0165
trainer/Policy Loss                       -270.66
trainer/Raw Policy Loss                   -270.66
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 260.73
trainer/Q Predictions Std                   35.1091
trainer/Q Predictions Max                  359.974
trainer/Q Predictions Min                  148.186
trainer/Q Targets Mean                     260.76
trainer/Q Targets Std                       36.7307
trainer/Q Targets Max                      363.161
trainer/Q Targets Min                      147.081
trainer/Bellman Errors Mean                 88.0165
trainer/Bellman Errors Std                 281.859
trainer/Bellman Errors Max                7551.68
trainer/Bellman Errors Min                   3.29167e-05
trainer/Policy Action Mean                  -0.0182598
trainer/Policy Action Std                    0.832799
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     70500
expl/num paths total                      3525
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.9989
expl/Rewards Std                             4.44015
expl/Rewards Max                            10
expl/Rewards Min                             0.000262025
expl/Returns Mean                           99.9779
expl/Returns Std                            65.8751
expl/Returns Max                           180.155
expl/Returns Min                             0.470189
expl/Actions Mean                           -0.0698633
expl/Actions Std                             0.717904
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        99.9779
expl/env_infos/final/reward_dist Mean        7.096
expl/env_infos/final/reward_dist Std         3.99573
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0173797
expl/env_infos/initial/reward_dist Mean      0.035629
expl/env_infos/initial/reward_dist Std       0.0179693
expl/env_infos/initial/reward_dist Max       0.0754982
expl/env_infos/initial/reward_dist Min       0.00154318
expl/env_infos/reward_dist Mean              4.9989
expl/env_infos/reward_dist Std               4.44015
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000262025
eval/num steps total                     12100
eval/num paths total                       605
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.72153
eval/Rewards Std                             3.10271
eval/Rewards Max                            10
eval/Rewards Min                             0.0306169
eval/Returns Mean                          174.431
eval/Returns Std                            10.4275
eval/Returns Max                           190.065
eval/Returns Min                           157.179
eval/Actions Mean                           -0.0936836
eval/Actions Std                             0.722817
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       174.431
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0499467
eval/env_infos/initial/reward_dist Std       0.0172737
eval/env_infos/initial/reward_dist Max       0.0755494
eval/env_infos/initial/reward_dist Min       0.0306169
eval/env_infos/reward_dist Mean              8.72153
eval/env_infos/reward_dist Std               3.10271
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0306169
time/data storing (s)                        0.00155908
time/evaluation sampling (s)                 1.08384
time/exploration sampling (s)                5.89895
time/logging (s)                             0.00230911
time/saving (s)                              0.00103665
time/training (s)                            4.10382
time/epoch (s)                              11.0915
time/total (s)                            1800.44
Epoch                                      120
---------------------------------------  ---------------
2023-08-03 21:33:30.471344 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 121 finished
---------------------------------------  ---------------
epoch                                      121
replay_buffer/size                       71000
trainer/QF Loss                             79.2551
trainer/Policy Loss                       -270.767
trainer/Raw Policy Loss                   -270.767
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 260.6
trainer/Q Predictions Std                   35.2952
trainer/Q Predictions Max                  365.085
trainer/Q Predictions Min                  144.585
trainer/Q Targets Mean                     260.746
trainer/Q Targets Std                       36.4962
trainer/Q Targets Max                      369.926
trainer/Q Targets Min                      148.148
trainer/Bellman Errors Mean                 79.2551
trainer/Bellman Errors Std                 272.802
trainer/Bellman Errors Max                7705.44
trainer/Bellman Errors Min                   8.66363e-07
trainer/Policy Action Mean                  -0.0256631
trainer/Policy Action Std                    0.830251
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     71000
expl/num paths total                      3550
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.80247
expl/Rewards Std                             4.4938
expl/Rewards Max                            10
expl/Rewards Min                             0.000128044
expl/Returns Mean                           96.0495
expl/Returns Std                            66.6008
expl/Returns Max                           183.849
expl/Returns Min                             0.516211
expl/Actions Mean                           -0.0461679
expl/Actions Std                             0.718991
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        96.0495
expl/env_infos/final/reward_dist Mean        6.80156
expl/env_infos/final/reward_dist Std         4.31746
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0253323
expl/env_infos/initial/reward_dist Mean      0.0432682
expl/env_infos/initial/reward_dist Std       0.0217804
expl/env_infos/initial/reward_dist Max       0.0895812
expl/env_infos/initial/reward_dist Min       0.00834095
expl/env_infos/reward_dist Mean              4.80247
expl/env_infos/reward_dist Std               4.4938
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000128044
eval/num steps total                     12200
eval/num paths total                       610
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.71096
eval/Rewards Std                             3.11999
eval/Rewards Max                            10
eval/Rewards Min                             0.0102697
eval/Returns Mean                          174.219
eval/Returns Std                            22.4101
eval/Returns Max                           190.074
eval/Returns Min                           130.251
eval/Actions Mean                           -0.139383
eval/Actions Std                             0.677429
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       174.219
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0411042
eval/env_infos/initial/reward_dist Std       0.0266095
eval/env_infos/initial/reward_dist Max       0.0741741
eval/env_infos/initial/reward_dist Min       0.0102697
eval/env_infos/reward_dist Mean              8.71096
eval/env_infos/reward_dist Std               3.11999
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0102697
time/data storing (s)                        0.00154697
time/evaluation sampling (s)                 1.03044
time/exploration sampling (s)                6.03858
time/logging (s)                             0.00233613
time/saving (s)                              0.00100124
time/training (s)                            4.73448
time/epoch (s)                              11.8084
time/total (s)                            1812.25
Epoch                                      121
---------------------------------------  ---------------
2023-08-03 21:33:41.807833 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 122 finished
---------------------------------------  ---------------
epoch                                      122
replay_buffer/size                       71500
trainer/QF Loss                             85.7701
trainer/Policy Loss                       -271.083
trainer/Raw Policy Loss                   -271.083
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 261.373
trainer/Q Predictions Std                   35.5545
trainer/Q Predictions Max                  367.584
trainer/Q Predictions Min                  153.138
trainer/Q Targets Mean                     261.471
trainer/Q Targets Std                       36.7611
trainer/Q Targets Max                      382.393
trainer/Q Targets Min                      152.135
trainer/Bellman Errors Mean                 85.7701
trainer/Bellman Errors Std                 271.221
trainer/Bellman Errors Max                6299.1
trainer/Bellman Errors Min                   4.30504e-07
trainer/Policy Action Mean                  -0.0287736
trainer/Policy Action Std                    0.831041
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     71500
expl/num paths total                      3575
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.60269
expl/Rewards Std                             4.69589
expl/Rewards Max                            10
expl/Rewards Min                             0.000240992
expl/Returns Mean                          112.054
expl/Returns Std                            71.3319
expl/Returns Max                           182.828
expl/Returns Min                             0.438278
expl/Actions Mean                           -0.0201966
expl/Actions Std                             0.720242
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       112.054
expl/env_infos/final/reward_dist Mean        7.29113
expl/env_infos/final/reward_dist Std         4.35619
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.001052
expl/env_infos/initial/reward_dist Mean      0.0376638
expl/env_infos/initial/reward_dist Std       0.0284425
expl/env_infos/initial/reward_dist Max       0.150298
expl/env_infos/initial/reward_dist Min       0.00121973
expl/env_infos/reward_dist Mean              5.60269
expl/env_infos/reward_dist Std               4.69589
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000240992
eval/num steps total                     12300
eval/num paths total                       615
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.87967
eval/Rewards Std                             2.9489
eval/Rewards Max                            10
eval/Rewards Min                             0.00971346
eval/Returns Mean                          177.593
eval/Returns Std                             9.34376
eval/Returns Max                           190.899
eval/Returns Min                           162.158
eval/Actions Mean                           -0.205787
eval/Actions Std                             0.709017
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       177.593
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.229374
eval/env_infos/initial/reward_dist Std       0.337432
eval/env_infos/initial/reward_dist Max       0.89864
eval/env_infos/initial/reward_dist Min       0.00971346
eval/env_infos/reward_dist Mean              8.87967
eval/env_infos/reward_dist Std               2.9489
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00971346
time/data storing (s)                        0.00161286
time/evaluation sampling (s)                 1.12722
time/exploration sampling (s)                5.73829
time/logging (s)                             0.00227187
time/saving (s)                              0.00103711
time/training (s)                            4.46294
time/epoch (s)                              11.3334
time/total (s)                            1823.59
Epoch                                      122
---------------------------------------  ---------------
2023-08-03 21:33:53.122432 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 123 finished
---------------------------------------  ---------------
epoch                                      123
replay_buffer/size                       72000
trainer/QF Loss                             93.4462
trainer/Policy Loss                       -269.709
trainer/Raw Policy Loss                   -269.709
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 259.955
trainer/Q Predictions Std                   35.2116
trainer/Q Predictions Max                  380.772
trainer/Q Predictions Min                  141.24
trainer/Q Targets Mean                     260.132
trainer/Q Targets Std                       36.3102
trainer/Q Targets Max                      387.798
trainer/Q Targets Min                      135.439
trainer/Bellman Errors Mean                 93.4462
trainer/Bellman Errors Std                 309.049
trainer/Bellman Errors Max                5173.94
trainer/Bellman Errors Min                   3.18745e-07
trainer/Policy Action Mean                  -0.0304436
trainer/Policy Action Std                    0.828808
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     72000
expl/num paths total                      3600
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.52943
expl/Rewards Std                             4.60132
expl/Rewards Max                            10
expl/Rewards Min                             2.72472e-09
expl/Returns Mean                          110.589
expl/Returns Std                            61.5691
expl/Returns Max                           182.996
expl/Returns Min                             0.348438
expl/Actions Mean                           -0.0553857
expl/Actions Std                             0.718529
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       110.589
expl/env_infos/final/reward_dist Mean        7.78886
expl/env_infos/final/reward_dist Std         3.96085
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.72472e-09
expl/env_infos/initial/reward_dist Mean      0.0377814
expl/env_infos/initial/reward_dist Std       0.0198213
expl/env_infos/initial/reward_dist Max       0.0680138
expl/env_infos/initial/reward_dist Min       0.00432571
expl/env_infos/reward_dist Mean              5.52943
expl/env_infos/reward_dist Std               4.60132
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.72472e-09
eval/num steps total                     12400
eval/num paths total                       620
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.26092
eval/Rewards Std                             4.05857
eval/Rewards Max                            10
eval/Rewards Min                             0.0135285
eval/Returns Mean                          125.218
eval/Returns Std                            65.5492
eval/Returns Max                           180.556
eval/Returns Min                            41.9598
eval/Actions Mean                           -0.138381
eval/Actions Std                             0.773247
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       125.218
eval/env_infos/final/reward_dist Mean        7.27691
eval/env_infos/final/reward_dist Std         3.34506
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         2.7843
eval/env_infos/initial/reward_dist Mean      0.0321591
eval/env_infos/initial/reward_dist Std       0.0154543
eval/env_infos/initial/reward_dist Max       0.0583156
eval/env_infos/initial/reward_dist Min       0.0135285
eval/env_infos/reward_dist Mean              6.26092
eval/env_infos/reward_dist Std               4.05857
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0135285
time/data storing (s)                        0.00160462
time/evaluation sampling (s)                 1.13247
time/exploration sampling (s)                6.13335
time/logging (s)                             0.0017046
time/saving (s)                              0.000776963
time/training (s)                            4.0412
time/epoch (s)                              11.3111
time/total (s)                            1834.9
Epoch                                      123
---------------------------------------  ---------------
2023-08-03 21:34:04.914690 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 124 finished
---------------------------------------  ---------------
epoch                                      124
replay_buffer/size                       72500
trainer/QF Loss                             86.4153
trainer/Policy Loss                       -270.474
trainer/Raw Policy Loss                   -270.474
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 260.707
trainer/Q Predictions Std                   35.3755
trainer/Q Predictions Max                  376.345
trainer/Q Predictions Min                  161.662
trainer/Q Targets Mean                     260.927
trainer/Q Targets Std                       36.611
trainer/Q Targets Max                      374.638
trainer/Q Targets Min                      158.624
trainer/Bellman Errors Mean                 86.4153
trainer/Bellman Errors Std                 279.61
trainer/Bellman Errors Max                5688.87
trainer/Bellman Errors Min                   2.32831e-08
trainer/Policy Action Mean                  -0.0491384
trainer/Policy Action Std                    0.826634
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     72500
expl/num paths total                      3625
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.83912
expl/Rewards Std                             4.44195
expl/Rewards Max                            10
expl/Rewards Min                             6.66214e-05
expl/Returns Mean                           76.7824
expl/Returns Std                            66.7716
expl/Returns Max                           183.615
expl/Returns Min                             0.226908
expl/Actions Mean                           -0.0390549
expl/Actions Std                             0.725323
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        76.7824
expl/env_infos/final/reward_dist Mean        6.03403
expl/env_infos/final/reward_dist Std         4.57622
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000454887
expl/env_infos/initial/reward_dist Mean      0.0364165
expl/env_infos/initial/reward_dist Std       0.0180733
expl/env_infos/initial/reward_dist Max       0.0798575
expl/env_infos/initial/reward_dist Min       0.00483378
expl/env_infos/reward_dist Mean              3.83912
expl/env_infos/reward_dist Std               4.44195
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.66214e-05
eval/num steps total                     12500
eval/num paths total                       625
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.72594
eval/Rewards Std                             3.11504
eval/Rewards Max                            10
eval/Rewards Min                             0.0263408
eval/Returns Mean                          174.519
eval/Returns Std                            11.8193
eval/Returns Max                           190.037
eval/Returns Min                           157.8
eval/Actions Mean                           -0.0972693
eval/Actions Std                             0.73265
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       174.519
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0405871
eval/env_infos/initial/reward_dist Std       0.0128042
eval/env_infos/initial/reward_dist Max       0.0608582
eval/env_infos/initial/reward_dist Min       0.0263408
eval/env_infos/reward_dist Mean              8.72594
eval/env_infos/reward_dist Std               3.11504
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0263408
time/data storing (s)                        0.00158073
time/evaluation sampling (s)                 1.01206
time/exploration sampling (s)                6.62011
time/logging (s)                             0.00241345
time/saving (s)                              0.00111736
time/training (s)                            4.15345
time/epoch (s)                              11.7907
time/total (s)                            1846.69
Epoch                                      124
---------------------------------------  ---------------
2023-08-03 21:34:15.974353 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 125 finished
---------------------------------------  ---------------
epoch                                      125
replay_buffer/size                       73000
trainer/QF Loss                             87.4963
trainer/Policy Loss                       -269.631
trainer/Raw Policy Loss                   -269.631
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 259.643
trainer/Q Predictions Std                   35.0615
trainer/Q Predictions Max                  372.342
trainer/Q Predictions Min                  160.477
trainer/Q Targets Mean                     260.221
trainer/Q Targets Std                       36.4137
trainer/Q Targets Max                      369.398
trainer/Q Targets Min                      159.326
trainer/Bellman Errors Mean                 87.4963
trainer/Bellman Errors Std                 251.17
trainer/Bellman Errors Max                4503.92
trainer/Bellman Errors Min                   2.26647e-05
trainer/Policy Action Mean                  -0.045242
trainer/Policy Action Std                    0.830056
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     73000
expl/num paths total                      3650
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.95791
expl/Rewards Std                             4.69784
expl/Rewards Max                            10
expl/Rewards Min                             2.69725e-05
expl/Returns Mean                           99.1583
expl/Returns Std                            75.8204
expl/Returns Max                           190.134
expl/Returns Min                             0.480298
expl/Actions Mean                           -0.0434302
expl/Actions Std                             0.718344
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        99.1583
expl/env_infos/final/reward_dist Mean        6.67632
expl/env_infos/final/reward_dist Std         4.47782
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000652282
expl/env_infos/initial/reward_dist Mean      0.0538324
expl/env_infos/initial/reward_dist Std       0.0800467
expl/env_infos/initial/reward_dist Max       0.427176
expl/env_infos/initial/reward_dist Min       0.011956
expl/env_infos/reward_dist Mean              4.95791
expl/env_infos/reward_dist Std               4.69784
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.69725e-05
eval/num steps total                     12600
eval/num paths total                       630
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.76695
eval/Rewards Std                             3.66939
eval/Rewards Max                            10
eval/Rewards Min                             0.0223122
eval/Returns Mean                          155.339
eval/Returns Std                            28.6167
eval/Returns Max                           176.784
eval/Returns Min                            99.1378
eval/Actions Mean                           -0.216217
eval/Actions Std                             0.737103
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       155.339
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.041241
eval/env_infos/initial/reward_dist Std       0.0171585
eval/env_infos/initial/reward_dist Max       0.0689382
eval/env_infos/initial/reward_dist Min       0.0223122
eval/env_infos/reward_dist Mean              7.76695
eval/env_infos/reward_dist Std               3.66939
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0223122
time/data storing (s)                        0.00216649
time/evaluation sampling (s)                 1.08362
time/exploration sampling (s)                5.77918
time/logging (s)                             0.0022639
time/saving (s)                              0.000980409
time/training (s)                            4.18666
time/epoch (s)                              11.0549
time/total (s)                            1857.75
Epoch                                      125
---------------------------------------  ---------------
2023-08-03 21:34:26.491460 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 126 finished
---------------------------------------  ---------------
epoch                                      126
replay_buffer/size                       73500
trainer/QF Loss                             89.7967
trainer/Policy Loss                       -270.436
trainer/Raw Policy Loss                   -270.436
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 260.655
trainer/Q Predictions Std                   34.9915
trainer/Q Predictions Max                  386.19
trainer/Q Predictions Min                  161.033
trainer/Q Targets Mean                     260.964
trainer/Q Targets Std                       36.2731
trainer/Q Targets Max                      392.392
trainer/Q Targets Min                      166.097
trainer/Bellman Errors Mean                 89.7967
trainer/Bellman Errors Std                 277.772
trainer/Bellman Errors Max                6081.57
trainer/Bellman Errors Min                   1.1065e-05
trainer/Policy Action Mean                  -0.0255703
trainer/Policy Action Std                    0.826538
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     73500
expl/num paths total                      3675
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            6.20336
expl/Rewards Std                             4.54226
expl/Rewards Max                            10
expl/Rewards Min                             3.18112e-05
expl/Returns Mean                          124.067
expl/Returns Std                            66.4808
expl/Returns Max                           190.524
expl/Returns Min                             0.492676
expl/Actions Mean                           -0.0870001
expl/Actions Std                             0.722926
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       124.067
expl/env_infos/final/reward_dist Mean        7.65565
expl/env_infos/final/reward_dist Std         4.17772
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         5.47732e-05
expl/env_infos/initial/reward_dist Mean      0.0847082
expl/env_infos/initial/reward_dist Std       0.112402
expl/env_infos/initial/reward_dist Max       0.523963
expl/env_infos/initial/reward_dist Min       0.00664608
expl/env_infos/reward_dist Mean              6.20336
expl/env_infos/reward_dist Std               4.54226
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               3.18112e-05
eval/num steps total                     12700
eval/num paths total                       635
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.58311
eval/Rewards Std                             3.97559
eval/Rewards Max                            10
eval/Rewards Min                             0.0070909
eval/Returns Mean                          151.662
eval/Returns Std                            32.631
eval/Returns Max                           190.081
eval/Returns Min                            96.5828
eval/Actions Mean                           -0.102343
eval/Actions Std                             0.748693
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       151.662
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0372704
eval/env_infos/initial/reward_dist Std       0.0266704
eval/env_infos/initial/reward_dist Max       0.0810301
eval/env_infos/initial/reward_dist Min       0.0135685
eval/env_infos/reward_dist Mean              7.58311
eval/env_infos/reward_dist Std               3.97559
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0070909
time/data storing (s)                        0.00154648
time/evaluation sampling (s)                 1.2309
time/exploration sampling (s)                5.53793
time/logging (s)                             0.0023052
time/saving (s)                              0.0010052
time/training (s)                            3.74034
time/epoch (s)                              10.514
time/total (s)                            1868.27
Epoch                                      126
---------------------------------------  ---------------
2023-08-03 21:34:39.910063 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 127 finished
---------------------------------------  ---------------
epoch                                      127
replay_buffer/size                       74000
trainer/QF Loss                             81.9676
trainer/Policy Loss                       -270.482
trainer/Raw Policy Loss                   -270.482
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 260.617
trainer/Q Predictions Std                   35.1812
trainer/Q Predictions Max                  381.225
trainer/Q Predictions Min                  144.608
trainer/Q Targets Mean                     260.617
trainer/Q Targets Std                       36.2923
trainer/Q Targets Max                      385.877
trainer/Q Targets Min                      149.593
trainer/Bellman Errors Mean                 81.9676
trainer/Bellman Errors Std                 261.775
trainer/Bellman Errors Max                6795.47
trainer/Bellman Errors Min                   9.31323e-08
trainer/Policy Action Mean                  -0.0598914
trainer/Policy Action Std                    0.825654
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     74000
expl/num paths total                      3700
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.29208
expl/Rewards Std                             4.37901
expl/Rewards Max                            10
expl/Rewards Min                             6.95487e-05
expl/Returns Mean                           85.8416
expl/Returns Std                            64.3943
expl/Returns Max                           181.845
expl/Returns Min                             0.120444
expl/Actions Mean                           -0.109849
expl/Actions Std                             0.716467
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        85.8416
expl/env_infos/final/reward_dist Mean        6.44292
expl/env_infos/final/reward_dist Std         4.42981
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00625251
expl/env_infos/initial/reward_dist Mean      0.0553448
expl/env_infos/initial/reward_dist Std       0.070879
expl/env_infos/initial/reward_dist Max       0.310133
expl/env_infos/initial/reward_dist Min       0.00538839
expl/env_infos/reward_dist Mean              4.29208
expl/env_infos/reward_dist Std               4.37901
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.95487e-05
eval/num steps total                     12800
eval/num paths total                       640
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.78869
eval/Rewards Std                             3.07196
eval/Rewards Max                            10
eval/Rewards Min                             0.0300494
eval/Returns Mean                          175.774
eval/Returns Std                             9.6232
eval/Returns Max                           190.148
eval/Returns Min                           164.435
eval/Actions Mean                           -0.297915
eval/Actions Std                             0.718706
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       175.774
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0723256
eval/env_infos/initial/reward_dist Std       0.0402042
eval/env_infos/initial/reward_dist Max       0.148402
eval/env_infos/initial/reward_dist Min       0.0300494
eval/env_infos/reward_dist Mean              8.78869
eval/env_infos/reward_dist Std               3.07196
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0300494
time/data storing (s)                        0.00154097
time/evaluation sampling (s)                 1.44304
time/exploration sampling (s)                7.64512
time/logging (s)                             0.0023255
time/saving (s)                              0.00100757
time/training (s)                            4.32214
time/epoch (s)                              13.4152
time/total (s)                            1881.68
Epoch                                      127
---------------------------------------  ---------------
2023-08-03 21:34:53.475032 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 128 finished
---------------------------------------  ---------------
epoch                                      128
replay_buffer/size                       74500
trainer/QF Loss                             88.9791
trainer/Policy Loss                       -270.801
trainer/Raw Policy Loss                   -270.801
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 261.023
trainer/Q Predictions Std                   34.2661
trainer/Q Predictions Max                  361.813
trainer/Q Predictions Min                  173.556
trainer/Q Targets Mean                     260.723
trainer/Q Targets Std                       35.3636
trainer/Q Targets Max                      367.573
trainer/Q Targets Min                      168.642
trainer/Bellman Errors Mean                 88.9791
trainer/Bellman Errors Std                 273.541
trainer/Bellman Errors Max                5992.64
trainer/Bellman Errors Min                   4.9267e-07
trainer/Policy Action Mean                  -0.065966
trainer/Policy Action Std                    0.825473
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     74500
expl/num paths total                      3725
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.86786
expl/Rewards Std                             4.60387
expl/Rewards Max                            10
expl/Rewards Min                             9.9106e-06
expl/Returns Mean                           97.3573
expl/Returns Std                            70.4572
expl/Returns Max                           190.041
expl/Returns Min                             0.2322
expl/Actions Mean                           -0.0623348
expl/Actions Std                             0.712484
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        97.3573
expl/env_infos/final/reward_dist Mean        6.9597
expl/env_infos/final/reward_dist Std         4.45659
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000992302
expl/env_infos/initial/reward_dist Mean      0.0502712
expl/env_infos/initial/reward_dist Std       0.0593046
expl/env_infos/initial/reward_dist Max       0.329739
expl/env_infos/initial/reward_dist Min       0.00557831
expl/env_infos/reward_dist Mean              4.86786
expl/env_infos/reward_dist Std               4.60387
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               9.9106e-06
eval/num steps total                     12900
eval/num paths total                       645
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.38441
eval/Rewards Std                             3.29956
eval/Rewards Max                            10
eval/Rewards Min                             0.0377749
eval/Returns Mean                          167.688
eval/Returns Std                            15.1123
eval/Returns Max                           190.074
eval/Returns Min                           144.792
eval/Actions Mean                           -0.18786
eval/Actions Std                             0.637802
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       167.688
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0546482
eval/env_infos/initial/reward_dist Std       0.0114303
eval/env_infos/initial/reward_dist Max       0.0736593
eval/env_infos/initial/reward_dist Min       0.0377749
eval/env_infos/reward_dist Mean              8.38441
eval/env_infos/reward_dist Std               3.29956
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0377749
time/data storing (s)                        0.00156084
time/evaluation sampling (s)                 1.47554
time/exploration sampling (s)                7.67096
time/logging (s)                             0.00233126
time/saving (s)                              0.00100406
time/training (s)                            4.41051
time/epoch (s)                              13.5619
time/total (s)                            1895.25
Epoch                                      128
---------------------------------------  ---------------
2023-08-03 21:35:07.316544 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 129 finished
---------------------------------------  ---------------
epoch                                      129
replay_buffer/size                       75000
trainer/QF Loss                             78.2468
trainer/Policy Loss                       -268.794
trainer/Raw Policy Loss                   -268.794
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 259.201
trainer/Q Predictions Std                   34.0576
trainer/Q Predictions Max                  359.348
trainer/Q Predictions Min                  154.104
trainer/Q Targets Mean                     259.148
trainer/Q Targets Std                       35.1882
trainer/Q Targets Max                      358.838
trainer/Q Targets Min                      149.211
trainer/Bellman Errors Mean                 78.2468
trainer/Bellman Errors Std                 227.284
trainer/Bellman Errors Max                3827.25
trainer/Bellman Errors Min                   5.96046e-06
trainer/Policy Action Mean                  -0.0594678
trainer/Policy Action Std                    0.828692
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     75000
expl/num paths total                      3750
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.05165
expl/Rewards Std                             4.70147
expl/Rewards Max                            10
expl/Rewards Min                             3.46991e-05
expl/Returns Mean                           81.033
expl/Returns Std                            69.5907
expl/Returns Max                           184.416
expl/Returns Min                             0.545086
expl/Actions Mean                           -0.0806408
expl/Actions Std                             0.71931
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        81.033
expl/env_infos/final/reward_dist Mean        6.14642
expl/env_infos/final/reward_dist Std         4.73215
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00234148
expl/env_infos/initial/reward_dist Mean      0.0367005
expl/env_infos/initial/reward_dist Std       0.0212371
expl/env_infos/initial/reward_dist Max       0.0843116
expl/env_infos/initial/reward_dist Min       0.00236392
expl/env_infos/reward_dist Mean              4.05165
expl/env_infos/reward_dist Std               4.70147
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               3.46991e-05
eval/num steps total                     13000
eval/num paths total                       650
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.80206
eval/Rewards Std                             3.13983
eval/Rewards Max                            10
eval/Rewards Min                             0.0268179
eval/Returns Mean                          176.041
eval/Returns Std                            10.5291
eval/Returns Max                           190.212
eval/Returns Min                           160.318
eval/Actions Mean                           -0.175681
eval/Actions Std                             0.599538
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       176.041
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0747976
eval/env_infos/initial/reward_dist Std       0.0692403
eval/env_infos/initial/reward_dist Max       0.211535
eval/env_infos/initial/reward_dist Min       0.0268179
eval/env_infos/reward_dist Mean              8.80206
eval/env_infos/reward_dist Std               3.13983
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0268179
time/data storing (s)                        0.0015409
time/evaluation sampling (s)                 1.02945
time/exploration sampling (s)                8.49317
time/logging (s)                             0.00224372
time/saving (s)                              0.001031
time/training (s)                            4.31046
time/epoch (s)                              13.8379
time/total (s)                            1909.09
Epoch                                      129
---------------------------------------  ---------------
2023-08-03 21:35:20.074693 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 130 finished
---------------------------------------  ---------------
epoch                                      130
replay_buffer/size                       75500
trainer/QF Loss                             81.1967
trainer/Policy Loss                       -266.981
trainer/Raw Policy Loss                   -266.981
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 257.225
trainer/Q Predictions Std                   33.3059
trainer/Q Predictions Max                  358.566
trainer/Q Predictions Min                  146.609
trainer/Q Targets Mean                     257.276
trainer/Q Targets Std                       34.4014
trainer/Q Targets Max                      356.957
trainer/Q Targets Min                      155.436
trainer/Bellman Errors Mean                 81.1967
trainer/Bellman Errors Std                 275.151
trainer/Bellman Errors Max                7673.32
trainer/Bellman Errors Min                   3.36207e-07
trainer/Policy Action Mean                  -0.0740743
trainer/Policy Action Std                    0.823577
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     75500
expl/num paths total                      3775
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.22887
expl/Rewards Std                             4.63675
expl/Rewards Max                            10
expl/Rewards Min                             2.01931e-05
expl/Returns Mean                          104.577
expl/Returns Std                            72.8414
expl/Returns Max                           184.032
expl/Returns Min                             0.587191
expl/Actions Mean                           -0.0851074
expl/Actions Std                             0.726076
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       104.577
expl/env_infos/final/reward_dist Mean        6.80038
expl/env_infos/final/reward_dist Std         4.37718
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00100417
expl/env_infos/initial/reward_dist Mean      0.0503807
expl/env_infos/initial/reward_dist Std       0.0333103
expl/env_infos/initial/reward_dist Max       0.175714
expl/env_infos/initial/reward_dist Min       0.00692246
expl/env_infos/reward_dist Mean              5.22887
expl/env_infos/reward_dist Std               4.63675
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.01931e-05
eval/num steps total                     13100
eval/num paths total                       655
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.75385
eval/Rewards Std                             4.42264
eval/Rewards Max                            10
eval/Rewards Min                             0.0161191
eval/Returns Mean                          135.077
eval/Returns Std                            65.5303
eval/Returns Max                           180.45
eval/Returns Min                             5.52746
eval/Actions Mean                           -0.109585
eval/Actions Std                             0.721683
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       135.077
eval/env_infos/final/reward_dist Mean        8.00897
eval/env_infos/final/reward_dist Std         3.98206
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0448605
eval/env_infos/initial/reward_dist Mean      0.0419501
eval/env_infos/initial/reward_dist Std       0.0137477
eval/env_infos/initial/reward_dist Max       0.0587977
eval/env_infos/initial/reward_dist Min       0.0240118
eval/env_infos/reward_dist Mean              6.75385
eval/env_infos/reward_dist Std               4.42264
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0161191
time/data storing (s)                        0.00156035
time/evaluation sampling (s)                 1.32793
time/exploration sampling (s)                7.01722
time/logging (s)                             0.00228295
time/saving (s)                              0.000995938
time/training (s)                            4.40521
time/epoch (s)                              12.7552
time/total (s)                            1921.84
Epoch                                      130
---------------------------------------  ---------------
2023-08-03 21:35:32.539512 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 131 finished
---------------------------------------  ---------------
epoch                                      131
replay_buffer/size                       76000
trainer/QF Loss                             78.9534
trainer/Policy Loss                       -264.54
trainer/Raw Policy Loss                   -264.54
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 255.2
trainer/Q Predictions Std                   32.493
trainer/Q Predictions Max                  355.374
trainer/Q Predictions Min                  168.642
trainer/Q Targets Mean                     255.545
trainer/Q Targets Std                       33.6416
trainer/Q Targets Max                      359.007
trainer/Q Targets Min                      168.642
trainer/Bellman Errors Mean                 78.9534
trainer/Bellman Errors Std                 273.794
trainer/Bellman Errors Max                9764.38
trainer/Bellman Errors Min                   2.97301e-06
trainer/Policy Action Mean                  -0.063639
trainer/Policy Action Std                    0.825117
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     76000
expl/num paths total                      3800
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.96775
expl/Rewards Std                             4.58787
expl/Rewards Max                            10
expl/Rewards Min                             1.41744e-05
expl/Returns Mean                           99.355
expl/Returns Std                            72.9177
expl/Returns Max                           190.637
expl/Returns Min                             0.792399
expl/Actions Mean                           -0.102764
expl/Actions Std                             0.711647
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        99.355
expl/env_infos/final/reward_dist Mean        7.06173
expl/env_infos/final/reward_dist Std         4.33421
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.32957e-05
expl/env_infos/initial/reward_dist Mean      0.06448
expl/env_infos/initial/reward_dist Std       0.121514
expl/env_infos/initial/reward_dist Max       0.637254
expl/env_infos/initial/reward_dist Min       0.00398145
expl/env_infos/reward_dist Mean              4.96775
expl/env_infos/reward_dist Std               4.58787
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.41744e-05
eval/num steps total                     13200
eval/num paths total                       660
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.63701
eval/Rewards Std                             3.61981
eval/Rewards Max                            10
eval/Rewards Min                             0.0288524
eval/Returns Mean                          152.74
eval/Returns Std                            53.106
eval/Returns Max                           190.119
eval/Returns Min                            47.2166
eval/Actions Mean                           -0.273921
eval/Actions Std                             0.706824
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       152.74
eval/env_infos/final/reward_dist Mean        8.29921
eval/env_infos/final/reward_dist Std         3.40158
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.49605
eval/env_infos/initial/reward_dist Mean      0.05923
eval/env_infos/initial/reward_dist Std       0.031986
eval/env_infos/initial/reward_dist Max       0.11911
eval/env_infos/initial/reward_dist Min       0.0288524
eval/env_infos/reward_dist Mean              7.63701
eval/env_infos/reward_dist Std               3.61981
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0288524
time/data storing (s)                        0.00215998
time/evaluation sampling (s)                 1.12657
time/exploration sampling (s)                6.98327
time/logging (s)                             0.00228604
time/saving (s)                              0.000999716
time/training (s)                            4.34652
time/epoch (s)                              12.4618
time/total (s)                            1934.31
Epoch                                      131
---------------------------------------  ---------------
2023-08-03 21:35:44.445305 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 132 finished
---------------------------------------  ---------------
epoch                                      132
replay_buffer/size                       76500
trainer/QF Loss                             75.4684
trainer/Policy Loss                       -263.673
trainer/Raw Policy Loss                   -263.673
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 254.444
trainer/Q Predictions Std                   32.6565
trainer/Q Predictions Max                  343.629
trainer/Q Predictions Min                  148.014
trainer/Q Targets Mean                     254.384
trainer/Q Targets Std                       33.8006
trainer/Q Targets Max                      348.737
trainer/Q Targets Min                      139.575
trainer/Bellman Errors Mean                 75.4684
trainer/Bellman Errors Std                 234.709
trainer/Bellman Errors Max                3563.04
trainer/Bellman Errors Min                   1.88593e-08
trainer/Policy Action Mean                  -0.0649987
trainer/Policy Action Std                    0.820724
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     76500
expl/num paths total                      3825
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.76354
expl/Rewards Std                             4.55771
expl/Rewards Max                            10
expl/Rewards Min                             3.1262e-05
expl/Returns Mean                          115.271
expl/Returns Std                            60.1962
expl/Returns Max                           183.77
expl/Returns Min                             0.518338
expl/Actions Mean                           -0.116628
expl/Actions Std                             0.70307
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       115.271
expl/env_infos/final/reward_dist Mean        8.22302
expl/env_infos/final/reward_dist Std         3.61574
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000308231
expl/env_infos/initial/reward_dist Mean      0.0413025
expl/env_infos/initial/reward_dist Std       0.0242633
expl/env_infos/initial/reward_dist Max       0.109623
expl/env_infos/initial/reward_dist Min       0.0075089
expl/env_infos/reward_dist Mean              5.76354
expl/env_infos/reward_dist Std               4.55771
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               3.1262e-05
eval/num steps total                     13300
eval/num paths total                       665
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.57488
eval/Rewards Std                             3.86076
eval/Rewards Max                            10
eval/Rewards Min                             0.0236683
eval/Returns Mean                          151.498
eval/Returns Std                            57.7546
eval/Returns Max                           190.489
eval/Returns Min                            36.9711
eval/Actions Mean                           -0.170434
eval/Actions Std                             0.719501
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       151.498
eval/env_infos/final/reward_dist Mean        8.63392
eval/env_infos/final/reward_dist Std         2.73217
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.16958
eval/env_infos/initial/reward_dist Mean      0.136204
eval/env_infos/initial/reward_dist Std       0.176966
eval/env_infos/initial/reward_dist Max       0.488876
eval/env_infos/initial/reward_dist Min       0.0294379
eval/env_infos/reward_dist Mean              7.57488
eval/env_infos/reward_dist Std               3.86076
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0236683
time/data storing (s)                        0.0021682
time/evaluation sampling (s)                 1.08989
time/exploration sampling (s)                6.59263
time/logging (s)                             0.00228948
time/saving (s)                              0.000988843
time/training (s)                            4.21477
time/epoch (s)                              11.9027
time/total (s)                            1946.21
Epoch                                      132
---------------------------------------  ---------------
2023-08-03 21:35:56.061099 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 133 finished
---------------------------------------  ---------------
epoch                                      133
replay_buffer/size                       77000
trainer/QF Loss                             75.098
trainer/Policy Loss                       -261.989
trainer/Raw Policy Loss                   -261.989
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 252.77
trainer/Q Predictions Std                   32.0137
trainer/Q Predictions Max                  335.826
trainer/Q Predictions Min                  134.769
trainer/Q Targets Mean                     252.821
trainer/Q Targets Std                       32.9228
trainer/Q Targets Max                      337.61
trainer/Q Targets Min                      128.026
trainer/Bellman Errors Mean                 75.098
trainer/Bellman Errors Std                 224.626
trainer/Bellman Errors Max                4828.49
trainer/Bellman Errors Min                   1.38045e-06
trainer/Policy Action Mean                  -0.06493
trainer/Policy Action Std                    0.819073
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     77000
expl/num paths total                      3850
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.31618
expl/Rewards Std                             4.46836
expl/Rewards Max                            10
expl/Rewards Min                             6.20565e-05
expl/Returns Mean                          106.324
expl/Returns Std                            64.0104
expl/Returns Max                           190.155
expl/Returns Min                             0.494326
expl/Actions Mean                           -0.12255
expl/Actions Std                             0.702841
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       106.324
expl/env_infos/final/reward_dist Mean        6.99759
expl/env_infos/final/reward_dist Std         4.40403
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.01479
expl/env_infos/initial/reward_dist Mean      0.0724778
expl/env_infos/initial/reward_dist Std       0.100875
expl/env_infos/initial/reward_dist Max       0.520305
expl/env_infos/initial/reward_dist Min       0.00577334
expl/env_infos/reward_dist Mean              5.31618
expl/env_infos/reward_dist Std               4.46836
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.20565e-05
eval/num steps total                     13400
eval/num paths total                       670
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.29979
eval/Rewards Std                             3.99971
eval/Rewards Max                            10
eval/Rewards Min                             0.0227102
eval/Returns Mean                          145.996
eval/Returns Std                            57.3656
eval/Returns Max                           190.055
eval/Returns Min                            34.2602
eval/Actions Mean                           -0.104179
eval/Actions Std                             0.702989
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       145.996
eval/env_infos/final/reward_dist Mean        8.27064
eval/env_infos/final/reward_dist Std         3.45872
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         1.35321
eval/env_infos/initial/reward_dist Mean      0.0442246
eval/env_infos/initial/reward_dist Std       0.018846
eval/env_infos/initial/reward_dist Max       0.0710461
eval/env_infos/initial/reward_dist Min       0.0227102
eval/env_infos/reward_dist Mean              7.29979
eval/env_infos/reward_dist Std               3.99971
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0227102
time/data storing (s)                        0.00217186
time/evaluation sampling (s)                 1.04635
time/exploration sampling (s)                6.33629
time/logging (s)                             0.00226461
time/saving (s)                              0.00099493
time/training (s)                            4.2247
time/epoch (s)                              11.6128
time/total (s)                            1957.83
Epoch                                      133
---------------------------------------  ---------------
2023-08-03 21:36:08.096781 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 134 finished
---------------------------------------  ---------------
epoch                                      134
replay_buffer/size                       77500
trainer/QF Loss                             76.3902
trainer/Policy Loss                       -258.247
trainer/Raw Policy Loss                   -258.247
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 249.103
trainer/Q Predictions Std                   31.1798
trainer/Q Predictions Max                  338.75
trainer/Q Predictions Min                  134.801
trainer/Q Targets Mean                     249.123
trainer/Q Targets Std                       32.3898
trainer/Q Targets Max                      339.944
trainer/Q Targets Min                      131.251
trainer/Bellman Errors Mean                 76.3902
trainer/Bellman Errors Std                 249.719
trainer/Bellman Errors Max                5491.75
trainer/Bellman Errors Min                   3.24193e-06
trainer/Policy Action Mean                  -0.0794316
trainer/Policy Action Std                    0.819899
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     77500
expl/num paths total                      3875
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.12192
expl/Rewards Std                             4.21794
expl/Rewards Max                            10
expl/Rewards Min                             7.37516e-05
expl/Returns Mean                           62.4383
expl/Returns Std                            68.1789
expl/Returns Max                           190.035
expl/Returns Min                             0.207071
expl/Actions Mean                           -0.0644594
expl/Actions Std                             0.734189
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        62.4383
expl/env_infos/final/reward_dist Mean        4.77449
expl/env_infos/final/reward_dist Std         4.73687
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000605852
expl/env_infos/initial/reward_dist Mean      0.0331394
expl/env_infos/initial/reward_dist Std       0.0178954
expl/env_infos/initial/reward_dist Max       0.0642604
expl/env_infos/initial/reward_dist Min       0.00405206
expl/env_infos/reward_dist Mean              3.12192
expl/env_infos/reward_dist Std               4.21794
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               7.37516e-05
eval/num steps total                     13500
eval/num paths total                       675
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.04833
eval/Rewards Std                             3.95603
eval/Rewards Max                            10
eval/Rewards Min                             0.0140209
eval/Returns Mean                          140.967
eval/Returns Std                            47.7468
eval/Returns Max                           190.051
eval/Returns Min                            50.5175
eval/Actions Mean                           -0.0690615
eval/Actions Std                             0.709136
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       140.967
eval/env_infos/final/reward_dist Mean        8.87032
eval/env_infos/final/reward_dist Std         2.25937
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         4.35158
eval/env_infos/initial/reward_dist Mean      0.0439143
eval/env_infos/initial/reward_dist Std       0.0218286
eval/env_infos/initial/reward_dist Max       0.0695799
eval/env_infos/initial/reward_dist Min       0.0140209
eval/env_infos/reward_dist Mean              7.04833
eval/env_infos/reward_dist Std               3.95603
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0140209
time/data storing (s)                        0.00173268
time/evaluation sampling (s)                 1.58324
time/exploration sampling (s)                6.25052
time/logging (s)                             0.00235851
time/saving (s)                              0.00101356
time/training (s)                            4.19371
time/epoch (s)                              12.0326
time/total (s)                            1969.86
Epoch                                      134
---------------------------------------  ---------------
2023-08-03 21:36:19.795085 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 135 finished
---------------------------------------  ---------------
epoch                                      135
replay_buffer/size                       78000
trainer/QF Loss                             71.1871
trainer/Policy Loss                       -256.608
trainer/Raw Policy Loss                   -256.608
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 247.557
trainer/Q Predictions Std                   31.8465
trainer/Q Predictions Max                  331.927
trainer/Q Predictions Min                  137.971
trainer/Q Targets Mean                     247.441
trainer/Q Targets Std                       33.1051
trainer/Q Targets Max                      331.904
trainer/Q Targets Min                      141.803
trainer/Bellman Errors Mean                 71.1871
trainer/Bellman Errors Std                 246.341
trainer/Bellman Errors Max                6129.5
trainer/Bellman Errors Min                   6.64988e-06
trainer/Policy Action Mean                  -0.0595292
trainer/Policy Action Std                    0.819697
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     78000
expl/num paths total                      3900
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.59828
expl/Rewards Std                             4.63167
expl/Rewards Max                            10
expl/Rewards Min                             6.94223e-05
expl/Returns Mean                          111.966
expl/Returns Std                            72.218
expl/Returns Max                           190.343
expl/Returns Min                             0.324484
expl/Actions Mean                           -0.127969
expl/Actions Std                             0.714389
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       111.966
expl/env_infos/final/reward_dist Mean        7.06865
expl/env_infos/final/reward_dist Std         4.31232
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000100153
expl/env_infos/initial/reward_dist Mean      0.047784
expl/env_infos/initial/reward_dist Std       0.0639974
expl/env_infos/initial/reward_dist Max       0.343149
expl/env_infos/initial/reward_dist Min       0.00435306
expl/env_infos/reward_dist Mean              5.59828
expl/env_infos/reward_dist Std               4.63167
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.94223e-05
eval/num steps total                     13600
eval/num paths total                       680
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.17878
eval/Rewards Std                             3.40791
eval/Rewards Max                            10
eval/Rewards Min                             0.0240304
eval/Returns Mean                          163.576
eval/Returns Std                            37.2846
eval/Returns Max                           190.257
eval/Returns Min                            90.6923
eval/Actions Mean                           -0.132809
eval/Actions Std                             0.706568
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       163.576
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.134779
eval/env_infos/initial/reward_dist Std       0.0938544
eval/env_infos/initial/reward_dist Max       0.256593
eval/env_infos/initial/reward_dist Min       0.0240304
eval/env_infos/reward_dist Mean              8.17878
eval/env_infos/reward_dist Std               3.40791
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0240304
time/data storing (s)                        0.00158069
time/evaluation sampling (s)                 1.19879
time/exploration sampling (s)                6.21858
time/logging (s)                             0.00232916
time/saving (s)                              0.00102485
time/training (s)                            4.27246
time/epoch (s)                              11.6948
time/total (s)                            1981.56
Epoch                                      135
---------------------------------------  ---------------
2023-08-03 21:36:32.293685 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 136 finished
---------------------------------------  ---------------
epoch                                      136
replay_buffer/size                       78500
trainer/QF Loss                             67.9155
trainer/Policy Loss                       -255.804
trainer/Raw Policy Loss                   -255.804
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 246.747
trainer/Q Predictions Std                   31.9742
trainer/Q Predictions Max                  338.13
trainer/Q Predictions Min                  134.018
trainer/Q Targets Mean                     246.768
trainer/Q Targets Std                       33.1592
trainer/Q Targets Max                      337.571
trainer/Q Targets Min                      130.396
trainer/Bellman Errors Mean                 67.9155
trainer/Bellman Errors Std                 223.082
trainer/Bellman Errors Max                4255.92
trainer/Bellman Errors Min                   0
trainer/Policy Action Mean                  -0.101856
trainer/Policy Action Std                    0.815075
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     78500
expl/num paths total                      3925
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.4254
expl/Rewards Std                             4.68882
expl/Rewards Max                            10
expl/Rewards Min                             8.85305e-05
expl/Returns Mean                          108.508
expl/Returns Std                            69.5811
expl/Returns Max                           183.989
expl/Returns Min                             0.299462
expl/Actions Mean                           -0.101756
expl/Actions Std                             0.70217
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       108.508
expl/env_infos/final/reward_dist Mean        7.39786
expl/env_infos/final/reward_dist Std         4.19301
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00184157
expl/env_infos/initial/reward_dist Mean      0.0357139
expl/env_infos/initial/reward_dist Std       0.0190498
expl/env_infos/initial/reward_dist Max       0.0787197
expl/env_infos/initial/reward_dist Min       0.0097735
expl/env_infos/reward_dist Mean              5.4254
expl/env_infos/reward_dist Std               4.68882
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               8.85305e-05
eval/num steps total                     13700
eval/num paths total                       685
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.35302
eval/Rewards Std                             3.93449
eval/Rewards Max                            10
eval/Rewards Min                             0.0161528
eval/Returns Mean                          147.06
eval/Returns Std                            51.433
eval/Returns Max                           180.108
eval/Returns Min                            44.704
eval/Actions Mean                           -0.218519
eval/Actions Std                             0.693174
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       147.06
eval/env_infos/final/reward_dist Mean        8.4104
eval/env_infos/final/reward_dist Std         3.17921
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         2.05198
eval/env_infos/initial/reward_dist Mean      0.0495247
eval/env_infos/initial/reward_dist Std       0.0130178
eval/env_infos/initial/reward_dist Max       0.0730284
eval/env_infos/initial/reward_dist Min       0.0335093
eval/env_infos/reward_dist Mean              7.35302
eval/env_infos/reward_dist Std               3.93449
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0161528
time/data storing (s)                        0.00217384
time/evaluation sampling (s)                 1.09171
time/exploration sampling (s)                6.9487
time/logging (s)                             0.0022782
time/saving (s)                              0.00100347
time/training (s)                            4.44959
time/epoch (s)                              12.4955
time/total (s)                            1994.06
Epoch                                      136
---------------------------------------  ---------------
2023-08-03 21:36:44.003488 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 137 finished
---------------------------------------  ---------------
epoch                                      137
replay_buffer/size                       79000
trainer/QF Loss                             68.0414
trainer/Policy Loss                       -255.933
trainer/Raw Policy Loss                   -255.933
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 246.726
trainer/Q Predictions Std                   32.6516
trainer/Q Predictions Max                  339.179
trainer/Q Predictions Min                  111.94
trainer/Q Targets Mean                     246.94
trainer/Q Targets Std                       33.7996
trainer/Q Targets Max                      333.514
trainer/Q Targets Min                      118.888
trainer/Bellman Errors Mean                 68.0414
trainer/Bellman Errors Std                 203.629
trainer/Bellman Errors Max                3596.68
trainer/Bellman Errors Min                   6.41588e-06
trainer/Policy Action Mean                  -0.0826085
trainer/Policy Action Std                    0.818388
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     79000
expl/num paths total                      3950
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.771
expl/Rewards Std                             4.56096
expl/Rewards Max                            10
expl/Rewards Min                             8.55371e-06
expl/Returns Mean                           95.4199
expl/Returns Std                            70.3375
expl/Returns Max                           184.751
expl/Returns Min                             0.351923
expl/Actions Mean                           -0.121502
expl/Actions Std                             0.707385
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        95.4199
expl/env_infos/final/reward_dist Mean        6.4789
expl/env_infos/final/reward_dist Std         4.38483
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00138441
expl/env_infos/initial/reward_dist Mean      0.0419555
expl/env_infos/initial/reward_dist Std       0.0231835
expl/env_infos/initial/reward_dist Max       0.0846802
expl/env_infos/initial/reward_dist Min       0.00420162
expl/env_infos/reward_dist Mean              4.771
expl/env_infos/reward_dist Std               4.56096
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               8.55371e-06
eval/num steps total                     13800
eval/num paths total                       690
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.70814
eval/Rewards Std                             3.21862
eval/Rewards Max                            10
eval/Rewards Min                             0.0361785
eval/Returns Mean                          174.163
eval/Returns Std                            13.7426
eval/Returns Max                           190.068
eval/Returns Min                           157.15
eval/Actions Mean                           -0.126276
eval/Actions Std                             0.656735
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       174.163
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0617866
eval/env_infos/initial/reward_dist Std       0.0128486
eval/env_infos/initial/reward_dist Max       0.0700917
eval/env_infos/initial/reward_dist Min       0.0361785
eval/env_infos/reward_dist Mean              8.70814
eval/env_infos/reward_dist Std               3.21862
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0361785
time/data storing (s)                        0.00159045
time/evaluation sampling (s)                 1.04878
time/exploration sampling (s)                6.39296
time/logging (s)                             0.00230319
time/saving (s)                              0.000973165
time/training (s)                            4.26019
time/epoch (s)                              11.7068
time/total (s)                            2005.77
Epoch                                      137
---------------------------------------  ---------------
2023-08-03 21:36:54.965003 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 138 finished
---------------------------------------  ---------------
epoch                                      138
replay_buffer/size                       79500
trainer/QF Loss                             71.9378
trainer/Policy Loss                       -256.942
trainer/Raw Policy Loss                   -256.942
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 247.724
trainer/Q Predictions Std                   32.432
trainer/Q Predictions Max                  328.907
trainer/Q Predictions Min                  124.681
trainer/Q Targets Mean                     247.827
trainer/Q Targets Std                       33.6107
trainer/Q Targets Max                      328.807
trainer/Q Targets Min                      122.657
trainer/Bellman Errors Mean                 71.9378
trainer/Bellman Errors Std                 228.344
trainer/Bellman Errors Max                4976.72
trainer/Bellman Errors Min                   3.99062e-05
trainer/Policy Action Mean                  -0.0887256
trainer/Policy Action Std                    0.816919
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     79500
expl/num paths total                      3975
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.51546
expl/Rewards Std                             4.63885
expl/Rewards Max                            10
expl/Rewards Min                             0.00120085
expl/Returns Mean                          110.309
expl/Returns Std                            70.6377
expl/Returns Max                           190.338
expl/Returns Min                             0.453117
expl/Actions Mean                           -0.126719
expl/Actions Std                             0.712098
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       110.309
expl/env_infos/final/reward_dist Mean        7.72003
expl/env_infos/final/reward_dist Std         4.08682
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00851163
expl/env_infos/initial/reward_dist Mean      0.0486644
expl/env_infos/initial/reward_dist Std       0.0610371
expl/env_infos/initial/reward_dist Max       0.337773
expl/env_infos/initial/reward_dist Min       0.0106053
expl/env_infos/reward_dist Mean              5.51546
expl/env_infos/reward_dist Std               4.63885
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00120085
eval/num steps total                     13900
eval/num paths total                       695
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.39046
eval/Rewards Std                             3.41544
eval/Rewards Max                            10
eval/Rewards Min                             0.00970048
eval/Returns Mean                          167.809
eval/Returns Std                             8.78141
eval/Returns Max                           175.29
eval/Returns Min                           151.22
eval/Actions Mean                           -0.214516
eval/Actions Std                             0.679467
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       167.809
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0593214
eval/env_infos/initial/reward_dist Std       0.0456383
eval/env_infos/initial/reward_dist Max       0.137426
eval/env_infos/initial/reward_dist Min       0.00970048
eval/env_infos/reward_dist Mean              8.39046
eval/env_infos/reward_dist Std               3.41544
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00970048
time/data storing (s)                        0.00154043
time/evaluation sampling (s)                 1.16006
time/exploration sampling (s)                5.70909
time/logging (s)                             0.00232004
time/saving (s)                              0.00100284
time/training (s)                            4.08392
time/epoch (s)                              10.9579
time/total (s)                            2016.73
Epoch                                      138
---------------------------------------  ---------------
2023-08-03 21:37:06.029919 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 139 finished
---------------------------------------  ---------------
epoch                                      139
replay_buffer/size                       80000
trainer/QF Loss                             70.362
trainer/Policy Loss                       -258.856
trainer/Raw Policy Loss                   -258.856
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 249.47
trainer/Q Predictions Std                   33.0549
trainer/Q Predictions Max                  329.152
trainer/Q Predictions Min                  106.064
trainer/Q Targets Mean                     248.925
trainer/Q Targets Std                       34.0506
trainer/Q Targets Max                      327.41
trainer/Q Targets Min                      106.697
trainer/Bellman Errors Mean                 70.362
trainer/Bellman Errors Std                 230.716
trainer/Bellman Errors Max                4355.94
trainer/Bellman Errors Min                   5.96046e-08
trainer/Policy Action Mean                  -0.101267
trainer/Policy Action Std                    0.815029
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     80000
expl/num paths total                      4000
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.72395
expl/Rewards Std                             4.75094
expl/Rewards Max                            10
expl/Rewards Min                             0.000236043
expl/Returns Mean                           94.4789
expl/Returns Std                            69.5191
expl/Returns Max                           190.219
expl/Returns Min                             0.439651
expl/Actions Mean                           -0.106691
expl/Actions Std                             0.688764
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        94.4789
expl/env_infos/final/reward_dist Mean        6.89442
expl/env_infos/final/reward_dist Std         4.54537
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00362685
expl/env_infos/initial/reward_dist Mean      0.0382368
expl/env_infos/initial/reward_dist Std       0.041328
expl/env_infos/initial/reward_dist Max       0.219064
expl/env_infos/initial/reward_dist Min       0.00294774
expl/env_infos/reward_dist Mean              4.72395
expl/env_infos/reward_dist Std               4.75094
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000236043
eval/num steps total                     14000
eval/num paths total                       700
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.75711
eval/Rewards Std                             3.2292
eval/Rewards Max                            10
eval/Rewards Min                             0.00875562
eval/Returns Mean                          175.142
eval/Returns Std                            16.6243
eval/Returns Max                           190.075
eval/Returns Min                           142.702
eval/Actions Mean                           -0.244609
eval/Actions Std                             0.647732
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       175.142
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0281401
eval/env_infos/initial/reward_dist Std       0.0239302
eval/env_infos/initial/reward_dist Max       0.0748569
eval/env_infos/initial/reward_dist Min       0.00875562
eval/env_infos/reward_dist Mean              8.75711
eval/env_infos/reward_dist Std               3.2292
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00875562
time/data storing (s)                        0.00156493
time/evaluation sampling (s)                 1.0711
time/exploration sampling (s)                5.77841
time/logging (s)                             0.00223572
time/saving (s)                              0.00993266
time/training (s)                            4.19841
time/epoch (s)                              11.0616
time/total (s)                            2027.79
Epoch                                      139
---------------------------------------  ---------------
2023-08-03 21:37:17.127003 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 140 finished
---------------------------------------  ---------------
epoch                                      140
replay_buffer/size                       80500
trainer/QF Loss                             76.138
trainer/Policy Loss                       -260.953
trainer/Raw Policy Loss                   -260.953
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 251.354
trainer/Q Predictions Std                   33.285
trainer/Q Predictions Max                  330.457
trainer/Q Predictions Min                  100.614
trainer/Q Targets Mean                     251.323
trainer/Q Targets Std                       34.2814
trainer/Q Targets Max                      326.427
trainer/Q Targets Min                       94.1936
trainer/Bellman Errors Mean                 76.138
trainer/Bellman Errors Std                 262.426
trainer/Bellman Errors Max                4413.08
trainer/Bellman Errors Min                   5.59026e-07
trainer/Policy Action Mean                  -0.0709883
trainer/Policy Action Std                    0.814204
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     80500
expl/num paths total                      4025
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.56064
expl/Rewards Std                             4.48938
expl/Rewards Max                            10
expl/Rewards Min                             1.13856e-05
expl/Returns Mean                          111.213
expl/Returns Std                            66.9501
expl/Returns Max                           190.634
expl/Returns Min                             0.406385
expl/Actions Mean                           -0.098281
expl/Actions Std                             0.700144
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       111.213
expl/env_infos/final/reward_dist Mean        6.99087
expl/env_infos/final/reward_dist Std         4.40895
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00261598
expl/env_infos/initial/reward_dist Mean      0.0603537
expl/env_infos/initial/reward_dist Std       0.118603
expl/env_infos/initial/reward_dist Max       0.633536
expl/env_infos/initial/reward_dist Min       0.00198868
expl/env_infos/reward_dist Mean              5.56064
expl/env_infos/reward_dist Std               4.48938
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.13856e-05
eval/num steps total                     14100
eval/num paths total                       705
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.89454
eval/Rewards Std                             2.91807
eval/Rewards Max                            10
eval/Rewards Min                             0.0212247
eval/Returns Mean                          177.891
eval/Returns Std                             7.48237
eval/Returns Max                           190.069
eval/Returns Min                           168.494
eval/Actions Mean                           -0.152394
eval/Actions Std                             0.625007
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       177.891
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0468765
eval/env_infos/initial/reward_dist Std       0.0201443
eval/env_infos/initial/reward_dist Max       0.06902
eval/env_infos/initial/reward_dist Min       0.0212247
eval/env_infos/reward_dist Mean              8.89454
eval/env_infos/reward_dist Std               2.91807
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0212247
time/data storing (s)                        0.00158
time/evaluation sampling (s)                 1.00426
time/exploration sampling (s)                5.77392
time/logging (s)                             0.00233285
time/saving (s)                              0.00102276
time/training (s)                            4.31175
time/epoch (s)                              11.0949
time/total (s)                            2038.89
Epoch                                      140
---------------------------------------  ---------------
2023-08-03 21:37:28.235935 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 141 finished
---------------------------------------  ---------------
epoch                                      141
replay_buffer/size                       81000
trainer/QF Loss                             67.6536
trainer/Policy Loss                       -261.431
trainer/Raw Policy Loss                   -261.431
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 251.68
trainer/Q Predictions Std                   32.8589
trainer/Q Predictions Max                  327.802
trainer/Q Predictions Min                  110.788
trainer/Q Targets Mean                     251.798
trainer/Q Targets Std                       34.1259
trainer/Q Targets Max                      328.598
trainer/Q Targets Min                      112.918
trainer/Bellman Errors Mean                 67.6536
trainer/Bellman Errors Std                 193.139
trainer/Bellman Errors Max                2831.59
trainer/Bellman Errors Min                   9.83709e-07
trainer/Policy Action Mean                  -0.0625788
trainer/Policy Action Std                    0.817321
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     81000
expl/num paths total                      4050
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.24089
expl/Rewards Std                             4.58735
expl/Rewards Max                            10
expl/Rewards Min                             0.00202934
expl/Returns Mean                          104.818
expl/Returns Std                            68.7724
expl/Returns Max                           184.865
expl/Returns Min                             0.688734
expl/Actions Mean                           -0.116929
expl/Actions Std                             0.689375
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       104.818
expl/env_infos/final/reward_dist Mean        7.15416
expl/env_infos/final/reward_dist Std         4.21362
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.014674
expl/env_infos/initial/reward_dist Mean      0.0345824
expl/env_infos/initial/reward_dist Std       0.0165786
expl/env_infos/initial/reward_dist Max       0.0645983
expl/env_infos/initial/reward_dist Min       0.00509016
expl/env_infos/reward_dist Mean              5.24089
expl/env_infos/reward_dist Std               4.58735
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00202934
eval/num steps total                     14200
eval/num paths total                       710
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.9261
eval/Rewards Std                             4.10194
eval/Rewards Max                            10
eval/Rewards Min                             0.0183448
eval/Returns Mean                          138.522
eval/Returns Std                            48.417
eval/Returns Max                           180.433
eval/Returns Min                            47.5075
eval/Actions Mean                           -0.262132
eval/Actions Std                             0.683655
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       138.522
eval/env_infos/final/reward_dist Mean        8.70837
eval/env_infos/final/reward_dist Std         2.58326
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.54186
eval/env_infos/initial/reward_dist Mean      0.031216
eval/env_infos/initial/reward_dist Std       0.0153603
eval/env_infos/initial/reward_dist Max       0.0607051
eval/env_infos/initial/reward_dist Min       0.0189638
eval/env_infos/reward_dist Mean              6.9261
eval/env_infos/reward_dist Std               4.10194
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0183448
time/data storing (s)                        0.00166483
time/evaluation sampling (s)                 1.09073
time/exploration sampling (s)                5.79952
time/logging (s)                             0.00239059
time/saving (s)                              0.000994189
time/training (s)                            4.21065
time/epoch (s)                              11.1059
time/total (s)                            2049.99
Epoch                                      141
---------------------------------------  ---------------
2023-08-03 21:37:39.794234 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 142 finished
---------------------------------------  ---------------
epoch                                      142
replay_buffer/size                       81500
trainer/QF Loss                             78.5857
trainer/Policy Loss                       -262.791
trainer/Raw Policy Loss                   -262.791
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 252.937
trainer/Q Predictions Std                   33.4967
trainer/Q Predictions Max                  328.81
trainer/Q Predictions Min                   88.8384
trainer/Q Targets Mean                     253.099
trainer/Q Targets Std                       34.52
trainer/Q Targets Max                      329.697
trainer/Q Targets Min                       81.0303
trainer/Bellman Errors Mean                 78.5857
trainer/Bellman Errors Std                 263.506
trainer/Bellman Errors Max                3913.89
trainer/Bellman Errors Min                   1.1269e-05
trainer/Policy Action Mean                  -0.0671264
trainer/Policy Action Std                    0.813703
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     81500
expl/num paths total                      4075
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.58109
expl/Rewards Std                             4.61126
expl/Rewards Max                            10
expl/Rewards Min                             0.000283122
expl/Returns Mean                          111.622
expl/Returns Std                            64.7376
expl/Returns Max                           190.474
expl/Returns Min                             0.709992
expl/Actions Mean                           -0.109103
expl/Actions Std                             0.717155
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       111.622
expl/env_infos/final/reward_dist Mean        7.94905
expl/env_infos/final/reward_dist Std         3.73087
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00247871
expl/env_infos/initial/reward_dist Mean      0.0548748
expl/env_infos/initial/reward_dist Std       0.0881114
expl/env_infos/initial/reward_dist Max       0.474109
expl/env_infos/initial/reward_dist Min       0.00495706
expl/env_infos/reward_dist Mean              5.58109
expl/env_infos/reward_dist Std               4.61126
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000283122
eval/num steps total                     14300
eval/num paths total                       715
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.05955
eval/Rewards Std                             3.81446
eval/Rewards Max                            10
eval/Rewards Min                             0.00261493
eval/Returns Mean                          161.191
eval/Returns Std                            20.5935
eval/Returns Max                           190.233
eval/Returns Min                           136.113
eval/Actions Mean                           -0.161507
eval/Actions Std                             0.633876
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       161.191
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0816299
eval/env_infos/initial/reward_dist Std       0.0772999
eval/env_infos/initial/reward_dist Max       0.233375
eval/env_infos/initial/reward_dist Min       0.0151066
eval/env_infos/reward_dist Mean              8.05955
eval/env_infos/reward_dist Std               3.81446
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00261493
time/data storing (s)                        0.00156168
time/evaluation sampling (s)                 1.21753
time/exploration sampling (s)                6.01265
time/logging (s)                             0.00233882
time/saving (s)                              0.000998841
time/training (s)                            4.31824
time/epoch (s)                              11.5533
time/total (s)                            2061.55
Epoch                                      142
---------------------------------------  ---------------
2023-08-03 21:37:51.040423 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 143 finished
---------------------------------------  ---------------
epoch                                      143
replay_buffer/size                       82000
trainer/QF Loss                             74.9455
trainer/Policy Loss                       -263.168
trainer/Raw Policy Loss                   -263.168
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 253.486
trainer/Q Predictions Std                   33.1733
trainer/Q Predictions Max                  328.463
trainer/Q Predictions Min                  114.428
trainer/Q Targets Mean                     253.681
trainer/Q Targets Std                       34.2179
trainer/Q Targets Max                      328.046
trainer/Q Targets Min                      105.738
trainer/Bellman Errors Mean                 74.9455
trainer/Bellman Errors Std                 250.735
trainer/Bellman Errors Max                6538.01
trainer/Bellman Errors Min                   2.42237e-06
trainer/Policy Action Mean                  -0.0880329
trainer/Policy Action Std                    0.815426
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     82000
expl/num paths total                      4100
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.24075
expl/Rewards Std                             4.52473
expl/Rewards Max                            10
expl/Rewards Min                             6.00603e-06
expl/Returns Mean                           84.815
expl/Returns Std                            75.6083
expl/Returns Max                           190.042
expl/Returns Min                             0.268619
expl/Actions Mean                           -0.144809
expl/Actions Std                             0.688927
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        84.815
expl/env_infos/final/reward_dist Mean        5.57354
expl/env_infos/final/reward_dist Std         4.66587
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00108472
expl/env_infos/initial/reward_dist Mean      0.039736
expl/env_infos/initial/reward_dist Std       0.0312407
expl/env_infos/initial/reward_dist Max       0.159487
expl/env_infos/initial/reward_dist Min       0.00782172
expl/env_infos/reward_dist Mean              4.24075
expl/env_infos/reward_dist Std               4.52473
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.00603e-06
eval/num steps total                     14400
eval/num paths total                       720
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.82784
eval/Rewards Std                             2.98211
eval/Rewards Max                            10
eval/Rewards Min                             0.0499773
eval/Returns Mean                          176.557
eval/Returns Std                             5.35792
eval/Returns Max                           181.644
eval/Returns Min                           169.121
eval/Actions Mean                           -0.197333
eval/Actions Std                             0.665761
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       176.557
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.06046
eval/env_infos/initial/reward_dist Std       0.00998698
eval/env_infos/initial/reward_dist Max       0.0778643
eval/env_infos/initial/reward_dist Min       0.0499773
eval/env_infos/reward_dist Mean              8.82784
eval/env_infos/reward_dist Std               2.98211
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0499773
time/data storing (s)                        0.0017097
time/evaluation sampling (s)                 1.01824
time/exploration sampling (s)                5.87318
time/logging (s)                             0.00227251
time/saving (s)                              0.00100463
time/training (s)                            4.34649
time/epoch (s)                              11.2429
time/total (s)                            2072.8
Epoch                                      143
---------------------------------------  ---------------
2023-08-03 21:38:02.545011 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 144 finished
---------------------------------------  ---------------
epoch                                      144
replay_buffer/size                       82500
trainer/QF Loss                             65.6549
trainer/Policy Loss                       -263.655
trainer/Raw Policy Loss                   -263.655
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 254.128
trainer/Q Predictions Std                   33.0315
trainer/Q Predictions Max                  328.317
trainer/Q Predictions Min                   82.7581
trainer/Q Targets Mean                     253.805
trainer/Q Targets Std                       34.0423
trainer/Q Targets Max                      325.986
trainer/Q Targets Min                       70.1989
trainer/Bellman Errors Mean                 65.6549
trainer/Bellman Errors Std                 201.8
trainer/Bellman Errors Max                3730.74
trainer/Bellman Errors Min                   1.97068e-06
trainer/Policy Action Mean                  -0.0839289
trainer/Policy Action Std                    0.81407
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     82500
expl/num paths total                      4125
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.24227
expl/Rewards Std                             4.53975
expl/Rewards Max                            10
expl/Rewards Min                             2.07959e-05
expl/Returns Mean                          104.845
expl/Returns Std                            71.4235
expl/Returns Max                           177.018
expl/Returns Min                             0.415987
expl/Actions Mean                           -0.149397
expl/Actions Std                             0.683645
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       104.845
expl/env_infos/final/reward_dist Mean        6.72618
expl/env_infos/final/reward_dist Std         4.38718
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         2.07959e-05
expl/env_infos/initial/reward_dist Mean      0.0293934
expl/env_infos/initial/reward_dist Std       0.0207445
expl/env_infos/initial/reward_dist Max       0.0742489
expl/env_infos/initial/reward_dist Min       0.00321001
expl/env_infos/reward_dist Mean              5.24227
expl/env_infos/reward_dist Std               4.53975
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.07959e-05
eval/num steps total                     14500
eval/num paths total                       725
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.75739
eval/Rewards Std                             3.02353
eval/Rewards Max                            10
eval/Rewards Min                             0.0250686
eval/Returns Mean                          175.148
eval/Returns Std                             8.26152
eval/Returns Max                           183.332
eval/Returns Min                           160.651
eval/Actions Mean                           -0.260865
eval/Actions Std                             0.610047
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       175.148
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0545272
eval/env_infos/initial/reward_dist Std       0.0155931
eval/env_infos/initial/reward_dist Max       0.0689865
eval/env_infos/initial/reward_dist Min       0.0250686
eval/env_infos/reward_dist Mean              8.75739
eval/env_infos/reward_dist Std               3.02353
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0250686
time/data storing (s)                        0.00217489
time/evaluation sampling (s)                 0.978752
time/exploration sampling (s)                6.2872
time/logging (s)                             0.00231219
time/saving (s)                              0.00101924
time/training (s)                            4.23013
time/epoch (s)                              11.5016
time/total (s)                            2084.3
Epoch                                      144
---------------------------------------  ---------------
2023-08-03 21:38:13.813807 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 145 finished
---------------------------------------  ---------------
epoch                                      145
replay_buffer/size                       83000
trainer/QF Loss                             74.8275
trainer/Policy Loss                       -263.782
trainer/Raw Policy Loss                   -263.782
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 254.099
trainer/Q Predictions Std                   33.5493
trainer/Q Predictions Max                  325.218
trainer/Q Predictions Min                   78.1947
trainer/Q Targets Mean                     253.744
trainer/Q Targets Std                       34.6395
trainer/Q Targets Max                      324.349
trainer/Q Targets Min                       63.887
trainer/Bellman Errors Mean                 74.8275
trainer/Bellman Errors Std                 240.893
trainer/Bellman Errors Max                6430.48
trainer/Bellman Errors Min                   4.10713e-07
trainer/Policy Action Mean                  -0.0696423
trainer/Policy Action Std                    0.813446
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     83000
expl/num paths total                      4150
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.79388
expl/Rewards Std                             4.55387
expl/Rewards Max                            10
expl/Rewards Min                             0.000145731
expl/Returns Mean                          115.878
expl/Returns Std                            67.3586
expl/Returns Max                           190.394
expl/Returns Min                             0.367161
expl/Actions Mean                           -0.107782
expl/Actions Std                             0.686179
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       115.878
expl/env_infos/final/reward_dist Mean        7.78958
expl/env_infos/final/reward_dist Std         3.9718
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0060786
expl/env_infos/initial/reward_dist Mean      0.0565486
expl/env_infos/initial/reward_dist Std       0.0769985
expl/env_infos/initial/reward_dist Max       0.393826
expl/env_infos/initial/reward_dist Min       0.00880679
expl/env_infos/reward_dist Mean              5.79388
expl/env_infos/reward_dist Std               4.55387
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000145731
eval/num steps total                     14600
eval/num paths total                       730
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            9.07504
eval/Rewards Std                             2.59562
eval/Rewards Max                            10
eval/Rewards Min                             0.0312451
eval/Returns Mean                          181.501
eval/Returns Std                             6.48909
eval/Returns Max                           190.064
eval/Returns Min                           170.502
eval/Actions Mean                           -0.153241
eval/Actions Std                             0.555639
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       181.501
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.048726
eval/env_infos/initial/reward_dist Std       0.0128109
eval/env_infos/initial/reward_dist Max       0.0640917
eval/env_infos/initial/reward_dist Min       0.0312451
eval/env_infos/reward_dist Mean              9.07504
eval/env_infos/reward_dist Std               2.59562
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0312451
time/data storing (s)                        0.00156594
time/evaluation sampling (s)                 1.41117
time/exploration sampling (s)                5.76145
time/logging (s)                             0.00242609
time/saving (s)                              0.00100636
time/training (s)                            4.0879
time/epoch (s)                              11.2655
time/total (s)                            2095.57
Epoch                                      145
---------------------------------------  ---------------
2023-08-03 21:38:26.720656 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 146 finished
---------------------------------------  ---------------
epoch                                      146
replay_buffer/size                       83500
trainer/QF Loss                             69.3456
trainer/Policy Loss                       -263.426
trainer/Raw Policy Loss                   -263.426
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 253.897
trainer/Q Predictions Std                   32.9791
trainer/Q Predictions Max                  325.893
trainer/Q Predictions Min                   81.4204
trainer/Q Targets Mean                     253.675
trainer/Q Targets Std                       33.8792
trainer/Q Targets Max                      328.632
trainer/Q Targets Min                       81.1337
trainer/Bellman Errors Mean                 69.3456
trainer/Bellman Errors Std                 211.509
trainer/Bellman Errors Max                4349.51
trainer/Bellman Errors Min                   9.00785e-05
trainer/Policy Action Mean                  -0.0969125
trainer/Policy Action Std                    0.811188
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     83500
expl/num paths total                      4175
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.48782
expl/Rewards Std                             4.71861
expl/Rewards Max                            10
expl/Rewards Min                             4.62973e-05
expl/Returns Mean                          109.756
expl/Returns Std                            71.4567
expl/Returns Max                           190.043
expl/Returns Min                             0.497497
expl/Actions Mean                           -0.114587
expl/Actions Std                             0.68973
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       109.756
expl/env_infos/final/reward_dist Mean        7.66235
expl/env_infos/final/reward_dist Std         4.16816
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00342998
expl/env_infos/initial/reward_dist Mean      0.0356509
expl/env_infos/initial/reward_dist Std       0.0179391
expl/env_infos/initial/reward_dist Max       0.06753
expl/env_infos/initial/reward_dist Min       0.00723306
expl/env_infos/reward_dist Mean              5.48782
expl/env_infos/reward_dist Std               4.71861
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               4.62973e-05
eval/num steps total                     14700
eval/num paths total                       735
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.00098
eval/Rewards Std                             3.62719
eval/Rewards Max                            10
eval/Rewards Min                             0.00959005
eval/Returns Mean                          160.02
eval/Returns Std                            44.1841
eval/Returns Max                           190.721
eval/Returns Min                            72.2897
eval/Actions Mean                           -0.152528
eval/Actions Std                             0.694869
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       160.02
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.24176
eval/env_infos/initial/reward_dist Std       0.274177
eval/env_infos/initial/reward_dist Max       0.720922
eval/env_infos/initial/reward_dist Min       0.00959005
eval/env_infos/reward_dist Mean              8.00098
eval/env_infos/reward_dist Std               3.62719
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00959005
time/data storing (s)                        0.00158254
time/evaluation sampling (s)                 1.48358
time/exploration sampling (s)                7.05084
time/logging (s)                             0.00224897
time/saving (s)                              0.00100289
time/training (s)                            4.36267
time/epoch (s)                              12.9019
time/total (s)                            2108.47
Epoch                                      146
---------------------------------------  ---------------
2023-08-03 21:38:39.548389 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 147 finished
---------------------------------------  ---------------
epoch                                      147
replay_buffer/size                       84000
trainer/QF Loss                             62.2075
trainer/Policy Loss                       -263.516
trainer/Raw Policy Loss                   -263.516
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 254.039
trainer/Q Predictions Std                   33.0032
trainer/Q Predictions Max                  326.911
trainer/Q Predictions Min                   81.5369
trainer/Q Targets Mean                     253.817
trainer/Q Targets Std                       34.2155
trainer/Q Targets Max                      325.758
trainer/Q Targets Min                       82.3891
trainer/Bellman Errors Mean                 62.2075
trainer/Bellman Errors Std                 175.813
trainer/Bellman Errors Max                2946.01
trainer/Bellman Errors Min                   7.54371e-08
trainer/Policy Action Mean                  -0.106816
trainer/Policy Action Std                    0.811208
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     84000
expl/num paths total                      4200
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.63428
expl/Rewards Std                             4.50209
expl/Rewards Max                            10
expl/Rewards Min                             0.00131127
expl/Returns Mean                           92.6856
expl/Returns Std                            64.3213
expl/Returns Max                           181.445
expl/Returns Min                             0.530707
expl/Actions Mean                           -0.10475
expl/Actions Std                             0.688567
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        92.6856
expl/env_infos/final/reward_dist Mean        6.94672
expl/env_infos/final/reward_dist Std         4.17143
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0111161
expl/env_infos/initial/reward_dist Mean      0.0322988
expl/env_infos/initial/reward_dist Std       0.0218645
expl/env_infos/initial/reward_dist Max       0.0739415
expl/env_infos/initial/reward_dist Min       0.00335077
expl/env_infos/reward_dist Mean              4.63428
expl/env_infos/reward_dist Std               4.50209
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00131127
eval/num steps total                     14800
eval/num paths total                       740
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.84408
eval/Rewards Std                             4.53477
eval/Rewards Max                            10
eval/Rewards Min                             0.00481615
eval/Returns Mean                          136.882
eval/Returns Std                            68.1514
eval/Returns Max                           174.052
eval/Returns Min                             0.834618
eval/Actions Mean                           -0.147952
eval/Actions Std                             0.634937
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       136.882
eval/env_infos/final/reward_dist Mean        8.00482
eval/env_infos/final/reward_dist Std         3.99036
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.024104
eval/env_infos/initial/reward_dist Mean      0.0296552
eval/env_infos/initial/reward_dist Std       0.00982512
eval/env_infos/initial/reward_dist Max       0.0431499
eval/env_infos/initial/reward_dist Min       0.0140262
eval/env_infos/reward_dist Mean              6.84408
eval/env_infos/reward_dist Std               4.53477
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00481615
time/data storing (s)                        0.00299097
time/evaluation sampling (s)                 1.00813
time/exploration sampling (s)                7.52079
time/logging (s)                             0.00227805
time/saving (s)                              0.00100224
time/training (s)                            4.28947
time/epoch (s)                              12.8247
time/total (s)                            2121.3
Epoch                                      147
---------------------------------------  ---------------
2023-08-03 21:38:50.135148 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 148 finished
---------------------------------------  ---------------
epoch                                      148
replay_buffer/size                       84500
trainer/QF Loss                             68.5102
trainer/Policy Loss                       -262.262
trainer/Raw Policy Loss                   -262.262
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 252.869
trainer/Q Predictions Std                   32.3728
trainer/Q Predictions Max                  320.755
trainer/Q Predictions Min                  105.54
trainer/Q Targets Mean                     253.25
trainer/Q Targets Std                       33.5785
trainer/Q Targets Max                      325.656
trainer/Q Targets Min                      101.556
trainer/Bellman Errors Mean                 68.5102
trainer/Bellman Errors Std                 208.148
trainer/Bellman Errors Max                4594.64
trainer/Bellman Errors Min                   1.38045e-06
trainer/Policy Action Mean                  -0.108982
trainer/Policy Action Std                    0.81263
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     84500
expl/num paths total                      4225
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            6.1148
expl/Rewards Std                             4.34249
expl/Rewards Max                            10
expl/Rewards Min                             0.000200263
expl/Returns Mean                          122.296
expl/Returns Std                            57.817
expl/Returns Max                           184.939
expl/Returns Min                             0.307704
expl/Actions Mean                           -0.19414
expl/Actions Std                             0.692053
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       122.296
expl/env_infos/final/reward_dist Mean        8.51151
expl/env_infos/final/reward_dist Std         3.44261
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000200263
expl/env_infos/initial/reward_dist Mean      0.0651703
expl/env_infos/initial/reward_dist Std       0.10558
expl/env_infos/initial/reward_dist Max       0.572661
expl/env_infos/initial/reward_dist Min       0.00571771
expl/env_infos/reward_dist Mean              6.1148
expl/env_infos/reward_dist Std               4.34249
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000200263
eval/num steps total                     14900
eval/num paths total                       745
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            9.00976
eval/Rewards Std                             2.85424
eval/Rewards Max                            10
eval/Rewards Min                             0.0122041
eval/Returns Mean                          180.195
eval/Returns Std                             7.00037
eval/Returns Max                           190.407
eval/Returns Min                           168.374
eval/Actions Mean                           -0.170006
eval/Actions Std                             0.666641
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       180.195
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.113502
eval/env_infos/initial/reward_dist Std       0.147792
eval/env_infos/initial/reward_dist Max       0.407341
eval/env_infos/initial/reward_dist Min       0.0122041
eval/env_infos/reward_dist Mean              9.00976
eval/env_infos/reward_dist Std               2.85424
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0122041
time/data storing (s)                        0.00163687
time/evaluation sampling (s)                 0.965179
time/exploration sampling (s)                5.47631
time/logging (s)                             0.00239567
time/saving (s)                              0.00098662
time/training (s)                            4.1373
time/epoch (s)                              10.5838
time/total (s)                            2131.89
Epoch                                      148
---------------------------------------  ---------------
2023-08-03 21:39:02.338226 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 149 finished
---------------------------------------  ---------------
epoch                                      149
replay_buffer/size                       85000
trainer/QF Loss                             68.9454
trainer/Policy Loss                       -262.959
trainer/Raw Policy Loss                   -262.959
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 253.753
trainer/Q Predictions Std                   32.5475
trainer/Q Predictions Max                  321.702
trainer/Q Predictions Min                   69.0372
trainer/Q Targets Mean                     254.157
trainer/Q Targets Std                       33.4869
trainer/Q Targets Max                      323.226
trainer/Q Targets Min                       70.3423
trainer/Bellman Errors Mean                 68.9454
trainer/Bellman Errors Std                 218.502
trainer/Bellman Errors Max                3961.04
trainer/Bellman Errors Min                   5.66617e-06
trainer/Policy Action Mean                  -0.0949172
trainer/Policy Action Std                    0.811709
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     85000
expl/num paths total                      4250
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.9518
expl/Rewards Std                             4.51063
expl/Rewards Max                            10
expl/Rewards Min                             3.72316e-05
expl/Returns Mean                          119.036
expl/Returns Std                            65.5644
expl/Returns Max                           190.062
expl/Returns Min                             0.428911
expl/Actions Mean                           -0.135474
expl/Actions Std                             0.695994
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       119.036
expl/env_infos/final/reward_dist Mean        7.6381
expl/env_infos/final/reward_dist Std         3.89277
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         3.72316e-05
expl/env_infos/initial/reward_dist Mean      0.0389703
expl/env_infos/initial/reward_dist Std       0.0179845
expl/env_infos/initial/reward_dist Max       0.0789054
expl/env_infos/initial/reward_dist Min       0.0115859
expl/env_infos/reward_dist Mean              5.9518
expl/env_infos/reward_dist Std               4.51063
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               3.72316e-05
eval/num steps total                     15000
eval/num paths total                       750
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.85251
eval/Rewards Std                             3.01297
eval/Rewards Max                            10
eval/Rewards Min                             0.012541
eval/Returns Mean                          177.05
eval/Returns Std                             9.06594
eval/Returns Max                           190.659
eval/Returns Min                           163.151
eval/Actions Mean                           -0.231574
eval/Actions Std                             0.638735
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       177.05
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.175003
eval/env_infos/initial/reward_dist Std       0.242899
eval/env_infos/initial/reward_dist Max       0.658843
eval/env_infos/initial/reward_dist Min       0.012541
eval/env_infos/reward_dist Mean              8.85251
eval/env_infos/reward_dist Std               3.01297
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.012541
time/data storing (s)                        0.00153418
time/evaluation sampling (s)                 1.51496
time/exploration sampling (s)                6.30759
time/logging (s)                             0.00229232
time/saving (s)                              0.000986697
time/training (s)                            4.37067
time/epoch (s)                              12.198
time/total (s)                            2144.09
Epoch                                      149
---------------------------------------  ---------------
2023-08-03 21:39:13.714636 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 150 finished
---------------------------------------  ---------------
epoch                                      150
replay_buffer/size                       85500
trainer/QF Loss                             61.8829
trainer/Policy Loss                       -262.066
trainer/Raw Policy Loss                   -262.066
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 252.769
trainer/Q Predictions Std                   32.0479
trainer/Q Predictions Max                  320.225
trainer/Q Predictions Min                   90.0267
trainer/Q Targets Mean                     252.399
trainer/Q Targets Std                       33.0495
trainer/Q Targets Max                      321.669
trainer/Q Targets Min                       85.207
trainer/Bellman Errors Mean                 61.8829
trainer/Bellman Errors Std                 193.703
trainer/Bellman Errors Max                3587.22
trainer/Bellman Errors Min                   3.24193e-06
trainer/Policy Action Mean                  -0.103163
trainer/Policy Action Std                    0.812592
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     85500
expl/num paths total                      4275
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.22929
expl/Rewards Std                             4.53439
expl/Rewards Max                            10
expl/Rewards Min                             0.000164041
expl/Returns Mean                          104.586
expl/Returns Std                            67.1935
expl/Returns Max                           190.202
expl/Returns Min                             0.785335
expl/Actions Mean                           -0.133231
expl/Actions Std                             0.702769
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       104.586
expl/env_infos/final/reward_dist Mean        6.97642
expl/env_infos/final/reward_dist Std         4.16294
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0410427
expl/env_infos/initial/reward_dist Mean      0.0395066
expl/env_infos/initial/reward_dist Std       0.0376171
expl/env_infos/initial/reward_dist Max       0.201927
expl/env_infos/initial/reward_dist Min       0.003975
expl/env_infos/reward_dist Mean              5.22929
expl/env_infos/reward_dist Std               4.53439
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000164041
eval/num steps total                     15100
eval/num paths total                       755
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.74344
eval/Rewards Std                             3.62889
eval/Rewards Max                            10
eval/Rewards Min                             0.0153342
eval/Returns Mean                          154.869
eval/Returns Std                            51.0151
eval/Returns Max                           190.595
eval/Returns Min                            53.829
eval/Actions Mean                           -0.208003
eval/Actions Std                             0.643947
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       154.869
eval/env_infos/final/reward_dist Mean        8.77818
eval/env_infos/final/reward_dist Std         2.44365
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         3.89088
eval/env_infos/initial/reward_dist Mean      0.147359
eval/env_infos/initial/reward_dist Std       0.224758
eval/env_infos/initial/reward_dist Max       0.595154
eval/env_infos/initial/reward_dist Min       0.0153342
eval/env_infos/reward_dist Mean              7.74344
eval/env_infos/reward_dist Std               3.62889
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0153342
time/data storing (s)                        0.00155894
time/evaluation sampling (s)                 1.11269
time/exploration sampling (s)                5.88982
time/logging (s)                             0.00228955
time/saving (s)                              0.000989874
time/training (s)                            4.36582
time/epoch (s)                              11.3732
time/total (s)                            2155.46
Epoch                                      150
---------------------------------------  ---------------
2023-08-03 21:39:24.960598 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 151 finished
---------------------------------------  ---------------
epoch                                      151
replay_buffer/size                       86000
trainer/QF Loss                             61.208
trainer/Policy Loss                       -261.248
trainer/Raw Policy Loss                   -261.248
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 251.891
trainer/Q Predictions Std                   31.2548
trainer/Q Predictions Max                  319.282
trainer/Q Predictions Min                   88.2539
trainer/Q Targets Mean                     251.458
trainer/Q Targets Std                       32.4952
trainer/Q Targets Max                      326.528
trainer/Q Targets Min                       70.6004
trainer/Bellman Errors Mean                 61.208
trainer/Bellman Errors Std                 178.2
trainer/Bellman Errors Max                3145
trainer/Bellman Errors Min                   4.37e-06
trainer/Policy Action Mean                  -0.100903
trainer/Policy Action Std                    0.811521
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     86000
expl/num paths total                      4300
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.93036
expl/Rewards Std                             4.43731
expl/Rewards Max                            10
expl/Rewards Min                             0.000255354
expl/Returns Mean                          118.607
expl/Returns Std                            60.6257
expl/Returns Max                           183.378
expl/Returns Min                             0.376869
expl/Actions Mean                           -0.148909
expl/Actions Std                             0.690555
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       118.607
expl/env_infos/final/reward_dist Mean        8.22361
expl/env_infos/final/reward_dist Std         3.58375
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000871868
expl/env_infos/initial/reward_dist Mean      0.0427675
expl/env_infos/initial/reward_dist Std       0.0229398
expl/env_infos/initial/reward_dist Max       0.0830801
expl/env_infos/initial/reward_dist Min       0.0028347
expl/env_infos/reward_dist Mean              5.93036
expl/env_infos/reward_dist Std               4.43731
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000255354
eval/num steps total                     15200
eval/num paths total                       760
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            9.05863
eval/Rewards Std                             2.84575
eval/Rewards Max                            10
eval/Rewards Min                             0.0333084
eval/Returns Mean                          181.173
eval/Returns Std                             6.44032
eval/Returns Max                           190.064
eval/Returns Min                           170.168
eval/Actions Mean                           -0.240746
eval/Actions Std                             0.631636
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       181.173
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0549487
eval/env_infos/initial/reward_dist Std       0.0162649
eval/env_infos/initial/reward_dist Max       0.0729166
eval/env_infos/initial/reward_dist Min       0.0333084
eval/env_infos/reward_dist Mean              9.05863
eval/env_infos/reward_dist Std               2.84575
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0333084
time/data storing (s)                        0.00160109
time/evaluation sampling (s)                 0.993681
time/exploration sampling (s)                5.87362
time/logging (s)                             0.00236442
time/saving (s)                              0.00111736
time/training (s)                            4.37053
time/epoch (s)                              11.2429
time/total (s)                            2166.71
Epoch                                      151
---------------------------------------  ---------------
2023-08-03 21:39:36.789727 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 152 finished
---------------------------------------  ---------------
epoch                                      152
replay_buffer/size                       86500
trainer/QF Loss                             65.3625
trainer/Policy Loss                       -259.396
trainer/Raw Policy Loss                   -259.396
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 250.31
trainer/Q Predictions Std                   31.551
trainer/Q Predictions Max                  319.498
trainer/Q Predictions Min                   63.4156
trainer/Q Targets Mean                     250.431
trainer/Q Targets Std                       32.4945
trainer/Q Targets Max                      326.638
trainer/Q Targets Min                       51.3631
trainer/Bellman Errors Mean                 65.3625
trainer/Bellman Errors Std                 213.575
trainer/Bellman Errors Max                4253.14
trainer/Bellman Errors Min                   2.23611e-06
trainer/Policy Action Mean                  -0.0916915
trainer/Policy Action Std                    0.80914
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     86500
expl/num paths total                      4325
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.92206
expl/Rewards Std                             4.66708
expl/Rewards Max                            10
expl/Rewards Min                             0.000263431
expl/Returns Mean                          118.441
expl/Returns Std                            72.7513
expl/Returns Max                           190.084
expl/Returns Min                             0.515729
expl/Actions Mean                           -0.141565
expl/Actions Std                             0.679056
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       118.441
expl/env_infos/final/reward_dist Mean        7.72309
expl/env_infos/final/reward_dist Std         4.08886
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00676864
expl/env_infos/initial/reward_dist Mean      0.0609974
expl/env_infos/initial/reward_dist Std       0.0477607
expl/env_infos/initial/reward_dist Max       0.200927
expl/env_infos/initial/reward_dist Min       0.0125175
expl/env_infos/reward_dist Mean              5.92206
expl/env_infos/reward_dist Std               4.66708
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000263431
eval/num steps total                     15300
eval/num paths total                       765
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.61704
eval/Rewards Std                             3.2253
eval/Rewards Max                            10
eval/Rewards Min                             0.0208652
eval/Returns Mean                          172.341
eval/Returns Std                            13.1961
eval/Returns Max                           190.129
eval/Returns Min                           150.958
eval/Actions Mean                           -0.189845
eval/Actions Std                             0.660458
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       172.341
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.066161
eval/env_infos/initial/reward_dist Std       0.0353641
eval/env_infos/initial/reward_dist Max       0.12882
eval/env_infos/initial/reward_dist Min       0.0208652
eval/env_infos/reward_dist Mean              8.61704
eval/env_infos/reward_dist Std               3.2253
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0208652
time/data storing (s)                        0.0015748
time/evaluation sampling (s)                 1.26388
time/exploration sampling (s)                5.52031
time/logging (s)                             0.00235436
time/saving (s)                              0.00108924
time/training (s)                            5.03523
time/epoch (s)                              11.8244
time/total (s)                            2178.54
Epoch                                      152
---------------------------------------  ---------------
2023-08-03 21:39:49.593078 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 153 finished
---------------------------------------  ---------------
epoch                                      153
replay_buffer/size                       87000
trainer/QF Loss                             59.6757
trainer/Policy Loss                       -257.604
trainer/Raw Policy Loss                   -257.604
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 248.6
trainer/Q Predictions Std                   31.209
trainer/Q Predictions Max                  313.537
trainer/Q Predictions Min                   83.0167
trainer/Q Targets Mean                     248.722
trainer/Q Targets Std                       32.1963
trainer/Q Targets Max                      325.926
trainer/Q Targets Min                       77.7585
trainer/Bellman Errors Mean                 59.6757
trainer/Bellman Errors Std                 169.489
trainer/Bellman Errors Max                3121.6
trainer/Bellman Errors Min                   9.31323e-10
trainer/Policy Action Mean                  -0.116084
trainer/Policy Action Std                    0.809528
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     87000
expl/num paths total                      4350
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.50591
expl/Rewards Std                             4.75819
expl/Rewards Max                            10
expl/Rewards Min                             1.06571e-05
expl/Returns Mean                          110.118
expl/Returns Std                            74.2566
expl/Returns Max                           184.982
expl/Returns Min                             0.334225
expl/Actions Mean                           -0.0879076
expl/Actions Std                             0.704125
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       110.118
expl/env_infos/final/reward_dist Mean        7.24247
expl/env_infos/final/reward_dist Std         4.42451
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000500289
expl/env_infos/initial/reward_dist Mean      0.0379417
expl/env_infos/initial/reward_dist Std       0.0202107
expl/env_infos/initial/reward_dist Max       0.0776435
expl/env_infos/initial/reward_dist Min       0.00284929
expl/env_infos/reward_dist Mean              5.50591
expl/env_infos/reward_dist Std               4.75819
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               1.06571e-05
eval/num steps total                     15400
eval/num paths total                       770
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.65508
eval/Rewards Std                             4.5227
eval/Rewards Max                            10
eval/Rewards Min                             0.000247646
eval/Returns Mean                          133.102
eval/Returns Std                            67.1472
eval/Returns Max                           180.372
eval/Returns Min                             0.757516
eval/Actions Mean                           -0.200327
eval/Actions Std                             0.674997
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       133.102
eval/env_infos/final/reward_dist Mean        8.00718
eval/env_infos/final/reward_dist Std         3.98565
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.0358754
eval/env_infos/initial/reward_dist Mean      0.0488474
eval/env_infos/initial/reward_dist Std       0.018304
eval/env_infos/initial/reward_dist Max       0.0721907
eval/env_infos/initial/reward_dist Min       0.0234715
eval/env_infos/reward_dist Mean              6.65508
eval/env_infos/reward_dist Std               4.5227
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.000247646
time/data storing (s)                        0.00153877
time/evaluation sampling (s)                 1.57318
time/exploration sampling (s)                6.77764
time/logging (s)                             0.00232397
time/saving (s)                              0.00107311
time/training (s)                            4.44413
time/epoch (s)                              12.7999
time/total (s)                            2191.34
Epoch                                      153
---------------------------------------  ---------------
2023-08-03 21:40:00.931195 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 154 finished
---------------------------------------  ---------------
epoch                                      154
replay_buffer/size                       87500
trainer/QF Loss                             62.805
trainer/Policy Loss                       -257.386
trainer/Raw Policy Loss                   -257.386
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 248.297
trainer/Q Predictions Std                   31.8051
trainer/Q Predictions Max                  324.154
trainer/Q Predictions Min                   63.2129
trainer/Q Targets Mean                     248.068
trainer/Q Targets Std                       32.7924
trainer/Q Targets Max                      330.105
trainer/Q Targets Min                       64.9311
trainer/Bellman Errors Mean                 62.805
trainer/Bellman Errors Std                 206.502
trainer/Bellman Errors Max                4484.79
trainer/Bellman Errors Min                   0
trainer/Policy Action Mean                  -0.123222
trainer/Policy Action Std                    0.80909
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     87500
expl/num paths total                      4375
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            6.17651
expl/Rewards Std                             4.53159
expl/Rewards Max                            10
expl/Rewards Min                             5.10703e-06
expl/Returns Mean                          123.53
expl/Returns Std                            65.2439
expl/Returns Max                           190.059
expl/Returns Min                             0.332823
expl/Actions Mean                           -0.11701
expl/Actions Std                             0.688602
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       123.53
expl/env_infos/final/reward_dist Mean        7.8965
expl/env_infos/final/reward_dist Std         3.79304
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00212301
expl/env_infos/initial/reward_dist Mean      0.0662743
expl/env_infos/initial/reward_dist Std       0.121201
expl/env_infos/initial/reward_dist Max       0.631107
expl/env_infos/initial/reward_dist Min       0.00397144
expl/env_infos/reward_dist Mean              6.17651
expl/env_infos/reward_dist Std               4.53159
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               5.10703e-06
eval/num steps total                     15500
eval/num paths total                       775
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            6.98817
eval/Rewards Std                             4.51289
eval/Rewards Max                            10
eval/Rewards Min                             0.00861997
eval/Returns Mean                          139.763
eval/Returns Std                            70.4866
eval/Returns Max                           190.147
eval/Returns Min                             0.950633
eval/Actions Mean                           -0.231147
eval/Actions Std                             0.651001
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       139.763
eval/env_infos/final/reward_dist Mean        8.01478
eval/env_infos/final/reward_dist Std         3.97043
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         0.073922
eval/env_infos/initial/reward_dist Mean      0.0546151
eval/env_infos/initial/reward_dist Std       0.0494905
eval/env_infos/initial/reward_dist Max       0.146961
eval/env_infos/initial/reward_dist Min       0.00944009
eval/env_infos/reward_dist Mean              6.98817
eval/env_infos/reward_dist Std               4.51289
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00861997
time/data storing (s)                        0.00162765
time/evaluation sampling (s)                 1.05762
time/exploration sampling (s)                5.42922
time/logging (s)                             0.00290879
time/saving (s)                              0.00112115
time/training (s)                            4.84261
time/epoch (s)                              11.3351
time/total (s)                            2202.68
Epoch                                      154
---------------------------------------  ---------------
2023-08-03 21:40:13.087859 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 155 finished
---------------------------------------  --------------
epoch                                      155
replay_buffer/size                       88000
trainer/QF Loss                             62.8273
trainer/Policy Loss                       -256.438
trainer/Raw Policy Loss                   -256.438
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 247.514
trainer/Q Predictions Std                   31.77
trainer/Q Predictions Max                  322.155
trainer/Q Predictions Min                   64.3248
trainer/Q Targets Mean                     247.601
trainer/Q Targets Std                       32.787
trainer/Q Targets Max                      326.974
trainer/Q Targets Min                       64.3838
trainer/Bellman Errors Mean                 62.8273
trainer/Bellman Errors Std                 186.274
trainer/Bellman Errors Max                3882.76
trainer/Bellman Errors Min                   2.8359e-05
trainer/Policy Action Mean                  -0.10608
trainer/Policy Action Std                    0.81093
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     88000
expl/num paths total                      4400
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.65358
expl/Rewards Std                             4.53125
expl/Rewards Max                            10
expl/Rewards Min                             0.0001169
expl/Returns Mean                          113.072
expl/Returns Std                            68.5298
expl/Returns Max                           190.08
expl/Returns Min                             0.334774
expl/Actions Mean                           -0.117795
expl/Actions Std                             0.696085
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       113.072
expl/env_infos/final/reward_dist Mean        7.43511
expl/env_infos/final/reward_dist Std         4.15658
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00236221
expl/env_infos/initial/reward_dist Mean      0.0514313
expl/env_infos/initial/reward_dist Std       0.0535172
expl/env_infos/initial/reward_dist Max       0.278866
expl/env_infos/initial/reward_dist Min       0.00554446
expl/env_infos/reward_dist Mean              5.65358
expl/env_infos/reward_dist Std               4.53125
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.0001169
eval/num steps total                     15600
eval/num paths total                       780
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.09882
eval/Rewards Std                             3.94965
eval/Rewards Max                            10
eval/Rewards Min                             0.0242093
eval/Returns Mean                          141.976
eval/Returns Std                            53.2301
eval/Returns Max                           178.348
eval/Returns Min                            37.4785
eval/Actions Mean                           -0.183508
eval/Actions Std                             0.682954
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       141.976
eval/env_infos/final/reward_dist Mean        8.58679
eval/env_infos/final/reward_dist Std         2.82641
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         2.93397
eval/env_infos/initial/reward_dist Mean      0.0592758
eval/env_infos/initial/reward_dist Std       0.0212568
eval/env_infos/initial/reward_dist Max       0.0880773
eval/env_infos/initial/reward_dist Min       0.0242093
eval/env_infos/reward_dist Mean              7.09882
eval/env_infos/reward_dist Std               3.94965
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0242093
time/data storing (s)                        0.0021631
time/evaluation sampling (s)                 1.17195
time/exploration sampling (s)                6.70947
time/logging (s)                             0.00236072
time/saving (s)                              0.00101762
time/training (s)                            4.26494
time/epoch (s)                              12.1519
time/total (s)                            2214.83
Epoch                                      155
---------------------------------------  --------------
2023-08-03 21:40:24.410311 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 156 finished
---------------------------------------  ---------------
epoch                                      156
replay_buffer/size                       88500
trainer/QF Loss                             61.1564
trainer/Policy Loss                       -256.482
trainer/Raw Policy Loss                   -256.482
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 247.322
trainer/Q Predictions Std                   31.5439
trainer/Q Predictions Max                  322.134
trainer/Q Predictions Min                   55.8798
trainer/Q Targets Mean                     247.112
trainer/Q Targets Std                       32.469
trainer/Q Targets Max                      327.703
trainer/Q Targets Min                       48.428
trainer/Bellman Errors Mean                 61.1564
trainer/Bellman Errors Std                 205.079
trainer/Bellman Errors Max                6960.82
trainer/Bellman Errors Min                   9.31323e-10
trainer/Policy Action Mean                  -0.119199
trainer/Policy Action Std                    0.812888
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     88500
expl/num paths total                      4425
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.96888
expl/Rewards Std                             4.6625
expl/Rewards Max                            10
expl/Rewards Min                             0.000139997
expl/Returns Mean                           99.3776
expl/Returns Std                            75.883
expl/Returns Max                           190.08
expl/Returns Min                             0.408397
expl/Actions Mean                           -0.11752
expl/Actions Std                             0.692617
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        99.3776
expl/env_infos/final/reward_dist Mean        6.95244
expl/env_infos/final/reward_dist Std         4.46096
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00431897
expl/env_infos/initial/reward_dist Mean      0.0691199
expl/env_infos/initial/reward_dist Std       0.14814
expl/env_infos/initial/reward_dist Max       0.788323
expl/env_infos/initial/reward_dist Min       0.00424869
expl/env_infos/reward_dist Mean              4.96888
expl/env_infos/reward_dist Std               4.6625
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000139997
eval/num steps total                     15700
eval/num paths total                       785
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.16734
eval/Rewards Std                             4.02567
eval/Rewards Max                            10
eval/Rewards Min                             0.0124241
eval/Returns Mean                          143.347
eval/Returns Std                            52.4883
eval/Returns Max                           190.132
eval/Returns Min                            43.5928
eval/Actions Mean                           -0.243906
eval/Actions Std                             0.651149
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       143.347
eval/env_infos/final/reward_dist Mean        8.41581
eval/env_infos/final/reward_dist Std         3.16838
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         2.07906
eval/env_infos/initial/reward_dist Mean      0.0477684
eval/env_infos/initial/reward_dist Std       0.0432681
eval/env_infos/initial/reward_dist Max       0.131517
eval/env_infos/initial/reward_dist Min       0.0124241
eval/env_infos/reward_dist Mean              7.16734
eval/env_infos/reward_dist Std               4.02567
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0124241
time/data storing (s)                        0.00155771
time/evaluation sampling (s)                 1.32677
time/exploration sampling (s)                5.73842
time/logging (s)                             0.00236523
time/saving (s)                              0.000989405
time/training (s)                            4.24736
time/epoch (s)                              11.3175
time/total (s)                            2226.15
Epoch                                      156
---------------------------------------  ---------------
2023-08-03 21:40:37.626721 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 157 finished
---------------------------------------  ---------------
epoch                                      157
replay_buffer/size                       89000
trainer/QF Loss                             58.0706
trainer/Policy Loss                       -257.239
trainer/Raw Policy Loss                   -257.239
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 248.003
trainer/Q Predictions Std                   32.2007
trainer/Q Predictions Max                  320.067
trainer/Q Predictions Min                   62.374
trainer/Q Targets Mean                     247.779
trainer/Q Targets Std                       33.13
trainer/Q Targets Max                      322.883
trainer/Q Targets Min                       62.9317
trainer/Bellman Errors Mean                 58.0706
trainer/Bellman Errors Std                 192.113
trainer/Bellman Errors Max                5018.11
trainer/Bellman Errors Min                   4.49852e-06
trainer/Policy Action Mean                  -0.129985
trainer/Policy Action Std                    0.809757
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     89000
expl/num paths total                      4450
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.78719
expl/Rewards Std                             4.48866
expl/Rewards Max                            10
expl/Rewards Min                             2.23342e-05
expl/Returns Mean                          115.744
expl/Returns Std                            59.1916
expl/Returns Max                           184.468
expl/Returns Min                             0.671743
expl/Actions Mean                           -0.175624
expl/Actions Std                             0.686379
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       115.744
expl/env_infos/final/reward_dist Mean        8.48597
expl/env_infos/final/reward_dist Std         3.14485
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0507403
expl/env_infos/initial/reward_dist Mean      0.0493865
expl/env_infos/initial/reward_dist Std       0.0195702
expl/env_infos/initial/reward_dist Max       0.0879117
expl/env_infos/initial/reward_dist Min       0.0150512
expl/env_infos/reward_dist Mean              5.78719
expl/env_infos/reward_dist Std               4.48866
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.23342e-05
eval/num steps total                     15800
eval/num paths total                       790
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.90065
eval/Rewards Std                             3.00972
eval/Rewards Max                            10
eval/Rewards Min                             0.0142276
eval/Returns Mean                          178.013
eval/Returns Std                             5.01588
eval/Returns Max                           183.447
eval/Returns Min                           170.237
eval/Actions Mean                           -0.241983
eval/Actions Std                             0.604661
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       178.013
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0529249
eval/env_infos/initial/reward_dist Std       0.0204007
eval/env_infos/initial/reward_dist Max       0.0742669
eval/env_infos/initial/reward_dist Min       0.0213586
eval/env_infos/reward_dist Mean              8.90065
eval/env_infos/reward_dist Std               3.00972
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0142276
time/data storing (s)                        0.00153903
time/evaluation sampling (s)                 1.44187
time/exploration sampling (s)                7.27748
time/logging (s)                             0.00229515
time/saving (s)                              0.00101396
time/training (s)                            4.48751
time/epoch (s)                              13.2117
time/total (s)                            2239.37
Epoch                                      157
---------------------------------------  ---------------
2023-08-03 21:40:51.576332 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 158 finished
---------------------------------------  ---------------
epoch                                      158
replay_buffer/size                       89500
trainer/QF Loss                             61.3746
trainer/Policy Loss                       -258.202
trainer/Raw Policy Loss                   -258.202
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 249.025
trainer/Q Predictions Std                   31.859
trainer/Q Predictions Max                  318.891
trainer/Q Predictions Min                   76.6096
trainer/Q Targets Mean                     249.035
trainer/Q Targets Std                       32.9178
trainer/Q Targets Max                      323.368
trainer/Q Targets Min                       82.3577
trainer/Bellman Errors Mean                 61.3746
trainer/Bellman Errors Std                 174.722
trainer/Bellman Errors Max                3450.88
trainer/Bellman Errors Min                   7.54371e-08
trainer/Policy Action Mean                  -0.113081
trainer/Policy Action Std                    0.81118
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     89500
expl/num paths total                      4475
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.77176
expl/Rewards Std                             4.63822
expl/Rewards Max                            10
expl/Rewards Min                             0.000102057
expl/Returns Mean                          115.435
expl/Returns Std                            67.4368
expl/Returns Max                           181.014
expl/Returns Min                             0.276122
expl/Actions Mean                           -0.110633
expl/Actions Std                             0.712766
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       115.435
expl/env_infos/final/reward_dist Mean        7.68179
expl/env_infos/final/reward_dist Std         4.13146
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00737511
expl/env_infos/initial/reward_dist Mean      0.042711
expl/env_infos/initial/reward_dist Std       0.0201527
expl/env_infos/initial/reward_dist Max       0.0945881
expl/env_infos/initial/reward_dist Min       0.0118029
expl/env_infos/reward_dist Mean              5.77176
expl/env_infos/reward_dist Std               4.63822
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000102057
eval/num steps total                     15900
eval/num paths total                       795
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.46321
eval/Rewards Std                             3.35129
eval/Rewards Max                            10
eval/Rewards Min                             0.0125933
eval/Returns Mean                          169.264
eval/Returns Std                            10.6837
eval/Returns Max                           180.738
eval/Returns Min                           154.988
eval/Actions Mean                           -0.217157
eval/Actions Std                             0.617169
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       169.264
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0700687
eval/env_infos/initial/reward_dist Std       0.00377036
eval/env_infos/initial/reward_dist Max       0.0749118
eval/env_infos/initial/reward_dist Min       0.0640275
eval/env_infos/reward_dist Mean              8.46321
eval/env_infos/reward_dist Std               3.35129
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0125933
time/data storing (s)                        0.00289089
time/evaluation sampling (s)                 1.40099
time/exploration sampling (s)                8.08821
time/logging (s)                             0.00289042
time/saving (s)                              0.00112076
time/training (s)                            4.45094
time/epoch (s)                              13.947
time/total (s)                            2253.32
Epoch                                      158
---------------------------------------  ---------------
2023-08-03 21:41:02.384282 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 159 finished
---------------------------------------  ---------------
epoch                                      159
replay_buffer/size                       90000
trainer/QF Loss                             57.9515
trainer/Policy Loss                       -259.266
trainer/Raw Policy Loss                   -259.266
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 249.971
trainer/Q Predictions Std                   32.0973
trainer/Q Predictions Max                  324.204
trainer/Q Predictions Min                   59.6351
trainer/Q Targets Mean                     249.93
trainer/Q Targets Std                       32.9595
trainer/Q Targets Max                      320.769
trainer/Q Targets Min                       64.731
trainer/Bellman Errors Mean                 57.9515
trainer/Bellman Errors Std                 166.413
trainer/Bellman Errors Max                2401.85
trainer/Bellman Errors Min                   5.82077e-09
trainer/Policy Action Mean                  -0.132178
trainer/Policy Action Std                    0.806931
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     90000
expl/num paths total                      4500
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            6.2483
expl/Rewards Std                             4.48841
expl/Rewards Max                            10
expl/Rewards Min                             0.000245477
expl/Returns Mean                          124.966
expl/Returns Std                            60.7158
expl/Returns Max                           190.078
expl/Returns Min                             0.519196
expl/Actions Mean                           -0.177114
expl/Actions Std                             0.662102
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       124.966
expl/env_infos/final/reward_dist Mean        8.28915
expl/env_infos/final/reward_dist Std         3.496
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000412045
expl/env_infos/initial/reward_dist Mean      0.0447201
expl/env_infos/initial/reward_dist Std       0.035714
expl/env_infos/initial/reward_dist Max       0.187179
expl/env_infos/initial/reward_dist Min       0.00618681
expl/env_infos/reward_dist Mean              6.2483
expl/env_infos/reward_dist Std               4.48841
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000245477
eval/num steps total                     16000
eval/num paths total                       800
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.99868
eval/Rewards Std                             2.68523
eval/Rewards Max                            10
eval/Rewards Min                             0.056462
eval/Returns Mean                          179.974
eval/Returns Std                             9.73272
eval/Returns Max                           190.073
eval/Returns Min                           161.659
eval/Actions Mean                           -0.33398
eval/Actions Std                             0.611533
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       179.974
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.341574
eval/env_infos/initial/reward_dist Std       0.521068
eval/env_infos/initial/reward_dist Max       1.38311
eval/env_infos/initial/reward_dist Min       0.056462
eval/env_infos/reward_dist Mean              8.99868
eval/env_infos/reward_dist Std               2.68523
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.056462
time/data storing (s)                        0.00162731
time/evaluation sampling (s)                 0.988144
time/exploration sampling (s)                5.6171
time/logging (s)                             0.00226504
time/saving (s)                              0.000992282
time/training (s)                            4.19298
time/epoch (s)                              10.8031
time/total (s)                            2264.12
Epoch                                      159
---------------------------------------  ---------------
2023-08-03 21:41:13.361234 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 160 finished
---------------------------------------  ---------------
epoch                                      160
replay_buffer/size                       90500
trainer/QF Loss                             65.9588
trainer/Policy Loss                       -260.486
trainer/Raw Policy Loss                   -260.486
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 251.356
trainer/Q Predictions Std                   31.7018
trainer/Q Predictions Max                  332.209
trainer/Q Predictions Min                   66.564
trainer/Q Targets Mean                     251.428
trainer/Q Targets Std                       32.8316
trainer/Q Targets Max                      336.396
trainer/Q Targets Min                       77.6291
trainer/Bellman Errors Mean                 65.9588
trainer/Bellman Errors Std                 200.635
trainer/Bellman Errors Max                4145.26
trainer/Bellman Errors Min                   6.26221e-06
trainer/Policy Action Mean                  -0.153984
trainer/Policy Action Std                    0.802973
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     90500
expl/num paths total                      4525
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.60523
expl/Rewards Std                             4.40146
expl/Rewards Max                            10
expl/Rewards Min                             0.000292985
expl/Returns Mean                          112.105
expl/Returns Std                            60.9889
expl/Returns Max                           191.113
expl/Returns Min                             0.993879
expl/Actions Mean                           -0.203555
expl/Actions Std                             0.683072
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       112.105
expl/env_infos/final/reward_dist Mean        8.43379
expl/env_infos/final/reward_dist Std         3.232
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.093688
expl/env_infos/initial/reward_dist Mean      0.083428
expl/env_infos/initial/reward_dist Std       0.212632
expl/env_infos/initial/reward_dist Max       1.11332
expl/env_infos/initial/reward_dist Min       0.00186109
expl/env_infos/reward_dist Mean              5.60523
expl/env_infos/reward_dist Std               4.40146
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000292985
eval/num steps total                     16100
eval/num paths total                       805
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.81714
eval/Rewards Std                             3.54386
eval/Rewards Max                            10
eval/Rewards Min                             0.0166886
eval/Returns Mean                          156.343
eval/Returns Std                            34.4606
eval/Returns Max                           180.319
eval/Returns Min                            88.3029
eval/Actions Mean                           -0.295108
eval/Actions Std                             0.646381
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       156.343
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0440122
eval/env_infos/initial/reward_dist Std       0.0178592
eval/env_infos/initial/reward_dist Max       0.0673557
eval/env_infos/initial/reward_dist Min       0.0166886
eval/env_infos/reward_dist Mean              7.81714
eval/env_infos/reward_dist Std               3.54386
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0166886
time/data storing (s)                        0.0015974
time/evaluation sampling (s)                 1.1356
time/exploration sampling (s)                5.63741
time/logging (s)                             0.00226555
time/saving (s)                              0.000975994
time/training (s)                            4.19553
time/epoch (s)                              10.9734
time/total (s)                            2275.1
Epoch                                      160
---------------------------------------  ---------------
2023-08-03 21:41:25.742395 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 161 finished
---------------------------------------  ---------------
epoch                                      161
replay_buffer/size                       91000
trainer/QF Loss                             63.1181
trainer/Policy Loss                       -259.99
trainer/Raw Policy Loss                   -259.99
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 250.772
trainer/Q Predictions Std                   31.7311
trainer/Q Predictions Max                  321.682
trainer/Q Predictions Min                   60.6966
trainer/Q Targets Mean                     250.638
trainer/Q Targets Std                       32.6686
trainer/Q Targets Max                      324.936
trainer/Q Targets Min                       60.4329
trainer/Bellman Errors Mean                 63.1181
trainer/Bellman Errors Std                 209.836
trainer/Bellman Errors Max                4560.13
trainer/Bellman Errors Min                   1.1269e-05
trainer/Policy Action Mean                  -0.126838
trainer/Policy Action Std                    0.809273
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     91000
expl/num paths total                      4550
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.05131
expl/Rewards Std                             4.87571
expl/Rewards Max                            10
expl/Rewards Min                             0.000149732
expl/Returns Mean                          101.026
expl/Returns Std                            76.803
expl/Returns Max                           184.164
expl/Returns Min                             0.486963
expl/Actions Mean                           -0.0722275
expl/Actions Std                             0.70501
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       101.026
expl/env_infos/final/reward_dist Mean        7.07912
expl/env_infos/final/reward_dist Std         4.34053
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00259035
expl/env_infos/initial/reward_dist Mean      0.0389684
expl/env_infos/initial/reward_dist Std       0.0458605
expl/env_infos/initial/reward_dist Max       0.241611
expl/env_infos/initial/reward_dist Min       0.00298516
expl/env_infos/reward_dist Mean              5.05131
expl/env_infos/reward_dist Std               4.87571
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000149732
eval/num steps total                     16200
eval/num paths total                       810
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.15298
eval/Rewards Std                             3.58706
eval/Rewards Max                            10
eval/Rewards Min                             0.00371838
eval/Returns Mean                          163.06
eval/Returns Std                            19.8269
eval/Returns Max                           180.408
eval/Returns Min                           125.875
eval/Actions Mean                           -0.203207
eval/Actions Std                             0.688108
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       163.06
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.050432
eval/env_infos/initial/reward_dist Std       0.0161824
eval/env_infos/initial/reward_dist Max       0.061954
eval/env_infos/initial/reward_dist Min       0.0187181
eval/env_infos/reward_dist Mean              8.15298
eval/env_infos/reward_dist Std               3.58706
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00371838
time/data storing (s)                        0.0015487
time/evaluation sampling (s)                 1.5335
time/exploration sampling (s)                6.53143
time/logging (s)                             0.00229414
time/saving (s)                              0.000987726
time/training (s)                            4.30785
time/epoch (s)                              12.3776
time/total (s)                            2287.48
Epoch                                      161
---------------------------------------  ---------------
2023-08-03 21:41:38.919620 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 162 finished
---------------------------------------  ---------------
epoch                                      162
replay_buffer/size                       91500
trainer/QF Loss                             62.7456
trainer/Policy Loss                       -258.778
trainer/Raw Policy Loss                   -258.778
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 249.649
trainer/Q Predictions Std                   31.7165
trainer/Q Predictions Max                  322.459
trainer/Q Predictions Min                   76.0635
trainer/Q Targets Mean                     250.011
trainer/Q Targets Std                       32.8854
trainer/Q Targets Max                      325.328
trainer/Q Targets Min                       71.3783
trainer/Bellman Errors Mean                 62.7456
trainer/Bellman Errors Std                 190.737
trainer/Bellman Errors Max                4190.12
trainer/Bellman Errors Min                   6.78934e-07
trainer/Policy Action Mean                  -0.139014
trainer/Policy Action Std                    0.805081
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     91500
expl/num paths total                      4575
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.06522
expl/Rewards Std                             4.54177
expl/Rewards Max                            10
expl/Rewards Min                             0.000585227
expl/Returns Mean                          101.304
expl/Returns Std                            68.8544
expl/Returns Max                           190.276
expl/Returns Min                             0.726685
expl/Actions Mean                           -0.164116
expl/Actions Std                             0.698409
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       101.304
expl/env_infos/final/reward_dist Mean        7.35645
expl/env_infos/final/reward_dist Std         3.94994
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0168506
expl/env_infos/initial/reward_dist Mean      0.0598843
expl/env_infos/initial/reward_dist Std       0.0676597
expl/env_infos/initial/reward_dist Max       0.281943
expl/env_infos/initial/reward_dist Min       0.00208301
expl/env_infos/reward_dist Mean              5.06522
expl/env_infos/reward_dist Std               4.54177
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000585227
eval/num steps total                     16300
eval/num paths total                       815
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.08794
eval/Rewards Std                             3.4785
eval/Rewards Max                            10
eval/Rewards Min                             0.00667369
eval/Returns Mean                          161.759
eval/Returns Std                            19.7563
eval/Returns Max                           183.054
eval/Returns Min                           127.56
eval/Actions Mean                           -0.182684
eval/Actions Std                             0.638161
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       161.759
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.049401
eval/env_infos/initial/reward_dist Std       0.024664
eval/env_infos/initial/reward_dist Max       0.0807229
eval/env_infos/initial/reward_dist Min       0.00667369
eval/env_infos/reward_dist Mean              8.08794
eval/env_infos/reward_dist Std               3.4785
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00667369
time/data storing (s)                        0.00153847
time/evaluation sampling (s)                 1.29649
time/exploration sampling (s)                7.09332
time/logging (s)                             0.002317
time/saving (s)                              0.000997928
time/training (s)                            4.77952
time/epoch (s)                              13.1742
time/total (s)                            2300.65
Epoch                                      162
---------------------------------------  ---------------
2023-08-03 21:41:51.094083 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 163 finished
---------------------------------------  ---------------
epoch                                      163
replay_buffer/size                       92000
trainer/QF Loss                             62.9477
trainer/Policy Loss                       -260.172
trainer/Raw Policy Loss                   -260.172
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 250.999
trainer/Q Predictions Std                   31.8916
trainer/Q Predictions Max                  332.144
trainer/Q Predictions Min                   75.0696
trainer/Q Targets Mean                     250.59
trainer/Q Targets Std                       32.8542
trainer/Q Targets Max                      335.257
trainer/Q Targets Min                       65.4014
trainer/Bellman Errors Mean                 62.9477
trainer/Bellman Errors Std                 195.333
trainer/Bellman Errors Max                4518.94
trainer/Bellman Errors Min                   6.11041e-06
trainer/Policy Action Mean                  -0.121355
trainer/Policy Action Std                    0.80091
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     92000
expl/num paths total                      4600
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.37127
expl/Rewards Std                             4.61991
expl/Rewards Max                            10
expl/Rewards Min                             0.000170993
expl/Returns Mean                          107.425
expl/Returns Std                            71.7527
expl/Returns Max                           190.616
expl/Returns Min                             0.333748
expl/Actions Mean                           -0.175483
expl/Actions Std                             0.679122
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       107.425
expl/env_infos/final/reward_dist Mean        7.26398
expl/env_infos/final/reward_dist Std         4.3915
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.000782643
expl/env_infos/initial/reward_dist Mean      0.0912634
expl/env_infos/initial/reward_dist Std       0.174394
expl/env_infos/initial/reward_dist Max       0.734966
expl/env_infos/initial/reward_dist Min       0.00394194
expl/env_infos/reward_dist Mean              5.37127
expl/env_infos/reward_dist Std               4.61991
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000170993
eval/num steps total                     16400
eval/num paths total                       820
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.80638
eval/Rewards Std                             3.60069
eval/Rewards Max                            10
eval/Rewards Min                             0.02318
eval/Returns Mean                          156.128
eval/Returns Std                            54.0873
eval/Returns Max                           190.042
eval/Returns Min                            48.319
eval/Actions Mean                           -0.113057
eval/Actions Std                             0.65235
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       156.128
eval/env_infos/final/reward_dist Mean        8.41978
eval/env_infos/final/reward_dist Std         3.16045
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min         2.09888
eval/env_infos/initial/reward_dist Mean      0.0299624
eval/env_infos/initial/reward_dist Std       0.00658143
eval/env_infos/initial/reward_dist Max       0.0420481
eval/env_infos/initial/reward_dist Min       0.02318
eval/env_infos/reward_dist Mean              7.80638
eval/env_infos/reward_dist Std               3.60069
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.02318
time/data storing (s)                        0.00263166
time/evaluation sampling (s)                 1.04097
time/exploration sampling (s)                6.73718
time/logging (s)                             0.00228926
time/saving (s)                              0.0010306
time/training (s)                            4.38713
time/epoch (s)                              12.1712
time/total (s)                            2312.83
Epoch                                      163
---------------------------------------  ---------------
2023-08-03 21:42:02.835531 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 164 finished
---------------------------------------  --------------
epoch                                      164
replay_buffer/size                       92500
trainer/QF Loss                             62.6062
trainer/Policy Loss                       -260.112
trainer/Raw Policy Loss                   -260.112
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 251.183
trainer/Q Predictions Std                   32.2107
trainer/Q Predictions Max                  335.139
trainer/Q Predictions Min                   46.3092
trainer/Q Targets Mean                     251.163
trainer/Q Targets Std                       33.1328
trainer/Q Targets Max                      340.383
trainer/Q Targets Min                       49.2892
trainer/Bellman Errors Mean                 62.6062
trainer/Bellman Errors Std                 197.75
trainer/Bellman Errors Max                5160.06
trainer/Bellman Errors Min                   8.3819e-09
trainer/Policy Action Mean                  -0.132684
trainer/Policy Action Std                    0.798825
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     92500
expl/num paths total                      4625
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            3.7512
expl/Rewards Std                             4.36526
expl/Rewards Max                            10
expl/Rewards Min                             2.8217e-05
expl/Returns Mean                           75.0239
expl/Returns Std                            66.4656
expl/Returns Max                           180.079
expl/Returns Min                             0.541504
expl/Actions Mean                           -0.127307
expl/Actions Std                             0.686637
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        75.0239
expl/env_infos/final/reward_dist Mean        6.04875
expl/env_infos/final/reward_dist Std         4.49575
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00419949
expl/env_infos/initial/reward_dist Mean      0.0341381
expl/env_infos/initial/reward_dist Std       0.0202025
expl/env_infos/initial/reward_dist Max       0.0837622
expl/env_infos/initial/reward_dist Min       0.00373819
expl/env_infos/reward_dist Mean              3.7512
expl/env_infos/reward_dist Std               4.36526
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               2.8217e-05
eval/num steps total                     16500
eval/num paths total                       825
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            7.61887
eval/Rewards Std                             3.69286
eval/Rewards Max                            10
eval/Rewards Min                             0.0251104
eval/Returns Mean                          152.377
eval/Returns Std                            31.1775
eval/Returns Max                           183.697
eval/Returns Min                            99.8676
eval/Actions Mean                           -0.27826
eval/Actions Std                             0.553891
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       152.377
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.064983
eval/env_infos/initial/reward_dist Std       0.0483084
eval/env_infos/initial/reward_dist Max       0.158877
eval/env_infos/initial/reward_dist Min       0.0251104
eval/env_infos/reward_dist Mean              7.61887
eval/env_infos/reward_dist Std               3.69286
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0251104
time/data storing (s)                        0.00158098
time/evaluation sampling (s)                 1.087
time/exploration sampling (s)                6.14721
time/logging (s)                             0.00231754
time/saving (s)                              0.00103911
time/training (s)                            4.49914
time/epoch (s)                              11.7383
time/total (s)                            2324.57
Epoch                                      164
---------------------------------------  --------------
2023-08-03 21:42:13.978089 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 165 finished
---------------------------------------  ---------------
epoch                                      165
replay_buffer/size                       93000
trainer/QF Loss                             64.1073
trainer/Policy Loss                       -259.222
trainer/Raw Policy Loss                   -259.222
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 250.198
trainer/Q Predictions Std                   31.8314
trainer/Q Predictions Max                  323.445
trainer/Q Predictions Min                   46.3341
trainer/Q Targets Mean                     250.238
trainer/Q Targets Std                       32.6949
trainer/Q Targets Max                      335.982
trainer/Q Targets Min                       49.3748
trainer/Bellman Errors Mean                 64.1073
trainer/Bellman Errors Std                 207.385
trainer/Bellman Errors Max                3889.91
trainer/Bellman Errors Min                   6.49341e-06
trainer/Policy Action Mean                  -0.127117
trainer/Policy Action Std                    0.800361
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     93000
expl/num paths total                      4650
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.26913
expl/Rewards Std                             4.48806
expl/Rewards Max                            10
expl/Rewards Min                             6.79808e-05
expl/Returns Mean                          105.383
expl/Returns Std                            66.6984
expl/Returns Max                           183.016
expl/Returns Min                             0.53371
expl/Actions Mean                           -0.126764
expl/Actions Std                             0.685898
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       105.383
expl/env_infos/final/reward_dist Mean        7.1556
expl/env_infos/final/reward_dist Std         4.2119
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00221098
expl/env_infos/initial/reward_dist Mean      0.0322089
expl/env_infos/initial/reward_dist Std       0.0165421
expl/env_infos/initial/reward_dist Max       0.0696447
expl/env_infos/initial/reward_dist Min       0.00922708
expl/env_infos/reward_dist Mean              5.26913
expl/env_infos/reward_dist Std               4.48806
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               6.79808e-05
eval/num steps total                     16600
eval/num paths total                       830
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.90572
eval/Rewards Std                             2.88181
eval/Rewards Max                            10
eval/Rewards Min                             0.0296723
eval/Returns Mean                          178.114
eval/Returns Std                             2.96367
eval/Returns Max                           182.623
eval/Returns Min                           175.038
eval/Actions Mean                           -0.286287
eval/Actions Std                             0.539227
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       178.114
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0505116
eval/env_infos/initial/reward_dist Std       0.0327276
eval/env_infos/initial/reward_dist Max       0.115526
eval/env_infos/initial/reward_dist Min       0.0296723
eval/env_infos/reward_dist Mean              8.90572
eval/env_infos/reward_dist Std               2.88181
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0296723
time/data storing (s)                        0.00155492
time/evaluation sampling (s)                 1.04669
time/exploration sampling (s)                5.90097
time/logging (s)                             0.00234178
time/saving (s)                              0.000999285
time/training (s)                            4.18648
time/epoch (s)                              11.139
time/total (s)                            2335.71
Epoch                                      165
---------------------------------------  ---------------
2023-08-03 21:42:25.830381 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 166 finished
---------------------------------------  ---------------
epoch                                      166
replay_buffer/size                       93500
trainer/QF Loss                             68.1205
trainer/Policy Loss                       -258.583
trainer/Raw Policy Loss                   -258.583
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 249.57
trainer/Q Predictions Std                   31.7032
trainer/Q Predictions Max                  330.995
trainer/Q Predictions Min                   86.6686
trainer/Q Targets Mean                     250.237
trainer/Q Targets Std                       32.7502
trainer/Q Targets Max                      336.217
trainer/Q Targets Min                       80.6665
trainer/Bellman Errors Mean                 68.1205
trainer/Bellman Errors Std                 202.633
trainer/Bellman Errors Max                3110.31
trainer/Bellman Errors Min                   8.10483e-07
trainer/Policy Action Mean                  -0.138315
trainer/Policy Action Std                    0.795656
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     93500
expl/num paths total                      4675
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            4.75232
expl/Rewards Std                             4.78772
expl/Rewards Max                            10
expl/Rewards Min                             0.000154242
expl/Returns Mean                           95.0463
expl/Returns Std                            72.6258
expl/Returns Max                           183.817
expl/Returns Min                             0.30025
expl/Actions Mean                           -0.163529
expl/Actions Std                             0.689817
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                        95.0463
expl/env_infos/final/reward_dist Mean        7.09325
expl/env_infos/final/reward_dist Std         4.32042
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0186624
expl/env_infos/initial/reward_dist Mean      0.0420413
expl/env_infos/initial/reward_dist Std       0.027444
expl/env_infos/initial/reward_dist Max       0.116039
expl/env_infos/initial/reward_dist Min       0.00126316
expl/env_infos/reward_dist Mean              4.75232
expl/env_infos/reward_dist Std               4.78772
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000154242
eval/num steps total                     16700
eval/num paths total                       835
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.74303
eval/Rewards Std                             3.06749
eval/Rewards Max                            10
eval/Rewards Min                             0.0107308
eval/Returns Mean                          174.861
eval/Returns Std                            16.4499
eval/Returns Max                           190.234
eval/Returns Min                           143.278
eval/Actions Mean                           -0.375673
eval/Actions Std                             0.565547
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       174.861
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0713828
eval/env_infos/initial/reward_dist Std       0.0829545
eval/env_infos/initial/reward_dist Max       0.234247
eval/env_infos/initial/reward_dist Min       0.0107308
eval/env_infos/reward_dist Mean              8.74303
eval/env_infos/reward_dist Std               3.06749
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0107308
time/data storing (s)                        0.00233725
time/evaluation sampling (s)                 1.15917
time/exploration sampling (s)                6.5554
time/logging (s)                             0.00229025
time/saving (s)                              0.00100105
time/training (s)                            4.12845
time/epoch (s)                              11.8486
time/total (s)                            2347.56
Epoch                                      166
---------------------------------------  ---------------
2023-08-03 21:42:37.485226 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 167 finished
---------------------------------------  ---------------
epoch                                      167
replay_buffer/size                       94000
trainer/QF Loss                             71.9426
trainer/Policy Loss                       -259.428
trainer/Raw Policy Loss                   -259.428
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 250.134
trainer/Q Predictions Std                   31.5836
trainer/Q Predictions Max                  316.183
trainer/Q Predictions Min                   78.1588
trainer/Q Targets Mean                     250.181
trainer/Q Targets Std                       32.9072
trainer/Q Targets Max                      338.048
trainer/Q Targets Min                       78.715
trainer/Bellman Errors Mean                 71.9426
trainer/Bellman Errors Std                 232.184
trainer/Bellman Errors Max                3546.46
trainer/Bellman Errors Min                   1.92807e-06
trainer/Policy Action Mean                  -0.136413
trainer/Policy Action Std                    0.798275
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     94000
expl/num paths total                      4700
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.03542
expl/Rewards Std                             4.46774
expl/Rewards Max                            10
expl/Rewards Min                             0.00311334
expl/Returns Mean                          100.708
expl/Returns Std                            68.9358
expl/Returns Max                           190.073
expl/Returns Min                             0.668587
expl/Actions Mean                           -0.21124
expl/Actions Std                             0.67981
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       100.708
expl/env_infos/final/reward_dist Mean        6.9051
expl/env_infos/final/reward_dist Std         4.16099
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.022821
expl/env_infos/initial/reward_dist Mean      0.0743699
expl/env_infos/initial/reward_dist Std       0.178318
expl/env_infos/initial/reward_dist Max       0.943665
expl/env_infos/initial/reward_dist Min       0.00692785
expl/env_infos/reward_dist Mean              5.03542
expl/env_infos/reward_dist Std               4.46774
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00311334
eval/num steps total                     16800
eval/num paths total                       840
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.71567
eval/Rewards Std                             3.23229
eval/Rewards Max                            10
eval/Rewards Min                             0.00694201
eval/Returns Mean                          174.313
eval/Returns Std                             8.20876
eval/Returns Max                           184.952
eval/Returns Min                           160.679
eval/Actions Mean                           -0.237209
eval/Actions Std                             0.61254
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       174.313
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.017115
eval/env_infos/initial/reward_dist Std       0.00675191
eval/env_infos/initial/reward_dist Max       0.0278605
eval/env_infos/initial/reward_dist Min       0.00694201
eval/env_infos/reward_dist Mean              8.71567
eval/env_infos/reward_dist Std               3.23229
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.00694201
time/data storing (s)                        0.00216868
time/evaluation sampling (s)                 0.970305
time/exploration sampling (s)                6.42335
time/logging (s)                             0.00237934
time/saving (s)                              0.000973572
time/training (s)                            4.25259
time/epoch (s)                              11.6518
time/total (s)                            2359.21
Epoch                                      167
---------------------------------------  ---------------
2023-08-03 21:42:48.787850 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 168 finished
---------------------------------------  ---------------
epoch                                      168
replay_buffer/size                       94500
trainer/QF Loss                             68.535
trainer/Policy Loss                       -259.403
trainer/Raw Policy Loss                   -259.403
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 250.23
trainer/Q Predictions Std                   32.8278
trainer/Q Predictions Max                  330.099
trainer/Q Predictions Min                   61.5191
trainer/Q Targets Mean                     250.05
trainer/Q Targets Std                       33.9484
trainer/Q Targets Max                      324.429
trainer/Q Targets Min                       72.4323
trainer/Bellman Errors Mean                 68.535
trainer/Bellman Errors Std                 208.47
trainer/Bellman Errors Max                4739.95
trainer/Bellman Errors Min                   1.54981e-05
trainer/Policy Action Mean                  -0.146777
trainer/Policy Action Std                    0.799322
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     94500
expl/num paths total                      4725
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.21411
expl/Rewards Std                             4.5777
expl/Rewards Max                            10
expl/Rewards Min                             7.90977e-05
expl/Returns Mean                          104.282
expl/Returns Std                            66.3711
expl/Returns Max                           190.027
expl/Returns Min                             0.550537
expl/Actions Mean                           -0.154596
expl/Actions Std                             0.676407
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       104.282
expl/env_infos/final/reward_dist Mean        7.45281
expl/env_infos/final/reward_dist Std         4.13056
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0343858
expl/env_infos/initial/reward_dist Mean      0.0407519
expl/env_infos/initial/reward_dist Std       0.0173743
expl/env_infos/initial/reward_dist Max       0.0708052
expl/env_infos/initial/reward_dist Min       0.0107337
expl/env_infos/reward_dist Mean              5.21411
expl/env_infos/reward_dist Std               4.5777
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               7.90977e-05
eval/num steps total                     16900
eval/num paths total                       845
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.65325
eval/Rewards Std                             3.05315
eval/Rewards Max                            10
eval/Rewards Min                             0.0133533
eval/Returns Mean                          173.065
eval/Returns Std                             7.44019
eval/Returns Max                           182.785
eval/Returns Min                           162.326
eval/Actions Mean                           -0.24788
eval/Actions Std                             0.552701
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       173.065
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0444169
eval/env_infos/initial/reward_dist Std       0.0187392
eval/env_infos/initial/reward_dist Max       0.0684966
eval/env_infos/initial/reward_dist Min       0.0133533
eval/env_infos/reward_dist Mean              8.65325
eval/env_infos/reward_dist Std               3.05315
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0133533
time/data storing (s)                        0.00157961
time/evaluation sampling (s)                 1.25124
time/exploration sampling (s)                5.73107
time/logging (s)                             0.00236094
time/saving (s)                              0.00110193
time/training (s)                            4.31017
time/epoch (s)                              11.2975
time/total (s)                            2370.51
Epoch                                      168
---------------------------------------  ---------------
2023-08-03 21:43:01.616092 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 169 finished
---------------------------------------  ---------------
epoch                                      169
replay_buffer/size                       95000
trainer/QF Loss                             62.5183
trainer/Policy Loss                       -259.627
trainer/Raw Policy Loss                   -259.627
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 250.522
trainer/Q Predictions Std                   32.1989
trainer/Q Predictions Max                  330.909
trainer/Q Predictions Min                   78.032
trainer/Q Targets Mean                     250.398
trainer/Q Targets Std                       33.2872
trainer/Q Targets Max                      335.089
trainer/Q Targets Min                       73.3591
trainer/Bellman Errors Mean                 62.5183
trainer/Bellman Errors Std                 185.543
trainer/Bellman Errors Max                3281.31
trainer/Bellman Errors Min                   8.66363e-07
trainer/Policy Action Mean                  -0.152263
trainer/Policy Action Std                    0.794719
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     95000
expl/num paths total                      4750
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            5.92908
expl/Rewards Std                             4.36374
expl/Rewards Max                            10
expl/Rewards Min                             0.00132631
expl/Returns Mean                          118.582
expl/Returns Std                            60.2071
expl/Returns Max                           190.193
expl/Returns Min                             0.408875
expl/Actions Mean                           -0.204095
expl/Actions Std                             0.677831
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       118.582
expl/env_infos/final/reward_dist Mean        8.62821
expl/env_infos/final/reward_dist Std         3.19403
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.00527087
expl/env_infos/initial/reward_dist Mean      0.045007
expl/env_infos/initial/reward_dist Std       0.0355048
expl/env_infos/initial/reward_dist Max       0.192967
expl/env_infos/initial/reward_dist Min       0.00903192
expl/env_infos/reward_dist Mean              5.92908
expl/env_infos/reward_dist Std               4.36374
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.00132631
eval/num steps total                     17000
eval/num paths total                       850
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            9.04039
eval/Rewards Std                             2.79349
eval/Rewards Max                            10
eval/Rewards Min                             0.0363238
eval/Returns Mean                          180.808
eval/Returns Std                             7.56616
eval/Returns Max                           190.096
eval/Returns Min                           167.263
eval/Actions Mean                           -0.255593
eval/Actions Std                             0.615501
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       180.808
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.0635664
eval/env_infos/initial/reward_dist Std       0.0196855
eval/env_infos/initial/reward_dist Max       0.0963456
eval/env_infos/initial/reward_dist Min       0.0363238
eval/env_infos/reward_dist Mean              9.04039
eval/env_infos/reward_dist Std               2.79349
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0363238
time/data storing (s)                        0.00154058
time/evaluation sampling (s)                 1.42828
time/exploration sampling (s)                7.18137
time/logging (s)                             0.00230971
time/saving (s)                              0.00103768
time/training (s)                            4.21039
time/epoch (s)                              12.8249
time/total (s)                            2383.34
Epoch                                      169
---------------------------------------  ---------------
2023-08-03 21:43:12.778854 PDT | [Fanuc_peg_in_hole_ddpg_2023_08_03_21_03_18_0000--s-0] Epoch 170 finished
---------------------------------------  ---------------
epoch                                      170
replay_buffer/size                       95500
trainer/QF Loss                             64.0147
trainer/Policy Loss                       -259.41
trainer/Raw Policy Loss                   -259.41
trainer/Preactivation Policy Loss            0
trainer/Q Predictions Mean                 250.436
trainer/Q Predictions Std                   31.7742
trainer/Q Predictions Max                  326.531
trainer/Q Predictions Min                   95.5094
trainer/Q Targets Mean                     250.181
trainer/Q Targets Std                       32.8695
trainer/Q Targets Max                      331.355
trainer/Q Targets Min                       86.1471
trainer/Bellman Errors Mean                 64.0147
trainer/Bellman Errors Std                 188.456
trainer/Bellman Errors Max                3092.26
trainer/Bellman Errors Min                   5.96046e-08
trainer/Policy Action Mean                  -0.134552
trainer/Policy Action Std                    0.792907
trainer/Policy Action Max                    1
trainer/Policy Action Min                   -1
expl/num steps total                     95500
expl/num paths total                      4775
expl/path length Mean                       20
expl/path length Std                         0
expl/path length Max                        20
expl/path length Min                        20
expl/Rewards Mean                            6.11738
expl/Rewards Std                             4.44985
expl/Rewards Max                            10
expl/Rewards Min                             0.000311373
expl/Returns Mean                          122.348
expl/Returns Std                            62.4351
expl/Returns Max                           190.13
expl/Returns Min                             0.576382
expl/Actions Mean                           -0.152442
expl/Actions Std                             0.664153
expl/Actions Max                             1
expl/Actions Min                            -1
expl/Num Paths                              25
expl/Average Returns                       122.348
expl/env_infos/final/reward_dist Mean        7.98587
expl/env_infos/final/reward_dist Std         3.67716
expl/env_infos/final/reward_dist Max        10
expl/env_infos/final/reward_dist Min         0.0311932
expl/env_infos/initial/reward_dist Mean      0.0410726
expl/env_infos/initial/reward_dist Std       0.0241167
expl/env_infos/initial/reward_dist Max       0.129577
expl/env_infos/initial/reward_dist Min       0.00296209
expl/env_infos/reward_dist Mean              6.11738
expl/env_infos/reward_dist Std               4.44985
expl/env_infos/reward_dist Max              10
expl/env_infos/reward_dist Min               0.000311373
eval/num steps total                     17100
eval/num paths total                       855
eval/path length Mean                       20
eval/path length Std                         0
eval/path length Max                        20
eval/path length Min                        20
eval/Rewards Mean                            8.99538
eval/Rewards Std                             2.79333
eval/Rewards Max                            10
eval/Rewards Min                             0.0352052
eval/Returns Mean                          179.908
eval/Returns Std                             5.23505
eval/Returns Max                           184.935
eval/Returns Min                           172.588
eval/Actions Mean                           -0.24084
eval/Actions Std                             0.566692
eval/Actions Max                             1
eval/Actions Min                            -1
eval/Num Paths                               5
eval/Average Returns                       179.908
eval/env_infos/final/reward_dist Mean       10
eval/env_infos/final/reward_dist Std         0
eval/env_infos/final/reward_dist Max        10
eval/env_infos/final/reward_dist Min        10
eval/env_infos/initial/reward_dist Mean      0.156232
eval/env_infos/initial/reward_dist Std       0.21828
eval/env_infos/initial/reward_dist Max       0.592352
eval/env_infos/initial/reward_dist Min       0.0352052
eval/env_infos/reward_dist Mean              8.99538
eval/env_infos/reward_dist Std               2.79333
eval/env_infos/reward_dist Max              10
eval/env_infos/reward_dist Min               0.0352052
time/data storing (s)                        0.0018268
time/evaluation sampling (s)                 1.00144
time/exploration sampling (s)                5.8555
time/logging (s)                             0.00291067
time/saving (s)                              0.00111513
time/training (s)                            4.29734
time/epoch (s)                              11.1601
time/total (s)                            2394.5
Epoch                                      170
---------------------------------------  ---------------
